import os
import time
import subprocess
import textwrap
from concurrent.futures import ThreadPoolExecutor
from faster_whisper import WhisperModel
from openai import OpenAI
from tqdm import tqdm

# ================= CONFIGURA√á√ïES DE ALTA PERFORMANCE =================

# PASTA DOS V√çDEOS
INPUT_FOLDER = "Aulas_PGM_RJ"

# CONFIGURA√á√ÉO DE TRANSCRI√á√ÉO (LOCAL)
# 'medium' = Melhor custo-benef√≠cio de velocidade/precis√£o
# 'large-v3' = M√°xima precis√£o (mais lento)
WHISPER_SIZE = "medium" 
# 'int8' voa na GPU. Se der erro, mude para 'float32'
COMPUTE_TYPE = "int8" 
DEVICE = "cuda" if os.system("nvidia-smi") == 0 else "cpu"

# CONFIGURA√á√ÉO DE FORMATA√á√ÉO (API OPENAI)
API_KEY = "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"
MODELO_GPT = "gpt-4o"  # Use gpt-4o (o mais inteligente e r√°pido atualmente)

# Prompt Otimizado para N√£o-Resumo
SYSTEM_PROMPT = """
VOC√ä √â UM REVISOR DE TEXTO JUR√çDICO DE ELITE.
SUA MISS√ÉO: Formatar a transcri√ß√£o bruta abaixo em um texto de estudo (formato apostila).

REGRAS INEGOCI√ÅVEIS:
1. INTEGRIDADE TOTAL: N√£o resuma. N√£o remova explica√ß√µes. Mantenha 100% do conte√∫do t√©cnico.
2. ESTILO: Transforme a fala coloquial em norma culta. Ajuste concord√¢ncias.
3. VISUAL: Use par√°grafos claros. Use **Negrito** para termos jur√≠dicos, leis e princ√≠pios.
4. CITA√á√ïES: Formate refer√™ncias a leis corretamente (Ex: "Art. 5¬∫, inciso LV da CF/88").
5. FLUIDEZ: Remova v√≠cios de linguagem (n√©, tipo, √£hn) que sujem o texto, mas mantenha o racioc√≠nio.

Entrada: Transcri√ß√£o bruta de fala.
Sa√≠da: Texto did√°tico, denso e completo.
"""

# ================= MOTOR DO SCRIPT =================

def extract_audio_fast(video_path):
    """Extrai √°udio usando FFmpeg direto (sem reencodar, muito r√°pido)"""
    audio_path = os.path.splitext(video_path)[0] + ".mp3"
    if os.path.exists(audio_path): return audio_path
    
    print(f"‚ö° Extraindo √°udio de {os.path.basename(video_path)}...")
    try:
        # Extrai em mono, 16k rate (ideal para whisper), low bitrate (r√°pido)
        subprocess.run(
            f'ffmpeg -i "{video_path}" -vn -ac 1 -ar 16000 -b:a 64k "{audio_path}" -y -hide_banner -loglevel error', 
            shell=True, check=True
        )
        return audio_path
    except Exception as e:
        print(f"Erro no FFmpeg: {e}")
        return None

def transcribe_batched(audio_path):
    """Transcreve usando Faster-Whisper com Batch Size (Velocidade M√°xima na GPU)"""
    print(f"üöÄ Transcrevendo {os.path.basename(audio_path)} usando {DEVICE.upper()}...")
    
    start = time.time()
    
    # Carrega o modelo
    model = WhisperModel(WHISPER_SIZE, device=DEVICE, compute_type=COMPUTE_TYPE)
    
    # BATCH SIZE = O segredo da velocidade. Processa v√°rios peda√ßos de √°udio de uma vez na VRAM.
    segments, info = model.transcribe(
        audio_path, 
        beam_size=5, 
        language="pt",
        vad_filter=True, # Remove sil√™ncios (acelera muito)
        vad_parameters=dict(min_silence_duration_ms=500)
    )
    
    # Coleta o texto com barra de progresso
    text_segments = []
    # Estimativa de segmentos baseada na dura√ß√£o (aprox 1 seg a cada 2s de fala)
    total_duration = info.duration
    
    with tqdm(total=total_duration, unit="s", desc="Progresso") as pbar:
        last_pos = 0
        for segment in segments:
            text_segments.append(segment.text)
            current_pos = segment.end
            pbar.update(current_pos - last_pos)
            last_pos = current_pos
            
    full_text = " ".join(text_segments)
    
    end = time.time()
    minutes = (end - start) / 60
    print(f"‚úÖ Transcri√ß√£o conclu√≠da em {minutes:.1f} minutos.")
    return full_text

def format_with_gpt_parallel(full_text, client):
    """Formata usando GPT-4o. Divide o texto e processa."""
    print(f"üß† Formatando com {MODELO_GPT}...")
    
    # Chunk size de 15.000 caracteres (aprox 3k-4k tokens) √© seguro para GPT-4o
    chunks = textwrap.wrap(full_text, 15000, break_long_words=False, replace_whitespace=False)
    print(f"   Dividido em {len(chunks)} partes para processamento.")
    
    formated_chunks = [None] * len(chunks)

    def process_chunk(index, text_chunk):
        try:
            response = client.chat.completions.create(
                model=MODELO_GPT,
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": text_chunk}
                ],
                temperature=0.2
            )
            return index, response.choices[0].message.content
        except Exception as e:
            print(f"Erro na parte {index}: {e}")
            return index, text_chunk # Retorna o bruto se falhar

    # Processamento sequencial √© mais seguro para garantir ordem e evitar Rate Limit da OpenAI
    # Mas usamos tqdm para visualizar
    for i, chunk in enumerate(tqdm(chunks, desc="Formatando blocos")):
        idx, res = process_chunk(i, chunk)
        formated_chunks[idx] = res

    return "\n\n".join(formated_chunks)

def main():
    if not os.path.exists(INPUT_FOLDER):
        print(f"Pasta {INPUT_FOLDER} n√£o encontrada.")
        return

    # Filtra arquivos de v√≠deo
    files = sorted([f for f in os.listdir(INPUT_FOLDER) if f.endswith(('.mp4', '.mkv', '.avi'))])
    
    client = OpenAI(api_key=API_KEY)

    print(f"üî• INICIANDO PROCESSAMENTO DE {len(files)} AULAS")
    print(f"   Modo: {'GPU ACELERADA' if DEVICE == 'cuda' else 'CPU (LENTO)'}")
    
    for filename in files:
        video_path = os.path.join(INPUT_FOLDER, filename)
        base_name = os.path.splitext(filename)[0]
        final_file = os.path.join(INPUT_FOLDER, f"{base_name}_APOSTILA.md")
        
        if os.path.exists(final_file):
            print(f"‚è© Pulando {filename} (j√° processado)")
            continue
            
        print(f"\n=========================================")
        print(f"üé¨ Processando: {filename}")
        
        # 1. Extra√ß√£o Ultra R√°pida
        audio_path = extract_audio_fast(video_path)
        if not audio_path: continue
        
        # 2. Transcri√ß√£o Bruta (Verifica cache)
        raw_txt_path = os.path.join(INPUT_FOLDER, f"{base_name}_RAW.txt")
        if os.path.exists(raw_txt_path):
            print("   üìÇ Transcri√ß√£o bruta encontrada em cache.")
            with open(raw_txt_path, 'r', encoding='utf-8') as f: full_text = f.read()
        else:
            full_text = transcribe_batched(audio_path)
            with open(raw_txt_path, 'w', encoding='utf-8') as f: f.write(full_text)
        
        # 3. Formata√ß√£o GPT-4o
        final_text = format_with_gpt_parallel(full_text, client)
        
        # Salva Resultado
        with open(final_file, 'w', encoding='utf-8') as f:
            f.write(f"# Transcri√ß√£o: {base_name}\n\n{final_text}")
            
        print(f"‚ú® AULA PRONTA: {final_file}")
        
        # Limpeza opcional (desabilitada para manter MP3s conforme pedido anteriormente)
        # if os.path.exists(audio_path): os.remove(audio_path)

if __name__ == "__main__":
    main()
