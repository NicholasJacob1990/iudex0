#!/usr/bin/env python3
"""
Script para processar transcri√ß√µes de aulas usando Gemini 3 Pro Preview
Formata conforme diretrizes espec√≠ficas para concursos de procuradorias
"""

import os
import sys
import time
from pathlib import Path
from docx import Document
from docx.shared import Pt, Inches
from docx.enum.text import WD_ALIGN_PARAGRAPH
import google.generativeai as genai
from typing import List
from colorama import Fore, init
from dotenv import load_dotenv
import re

init(autoreset=True)
load_dotenv(override=True)

# Configura√ß√£o
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
MODEL_NAME = 'gemini-2.0-flash-exp'  # Modelo dispon√≠vel atualmente
MAX_OUTPUT_TOKENS = 65_536
MAX_CHARS_PER_CHUNK = 50_000  # ~12.5k tokens, conservador para sa√≠da
OUTPUT_DIR = Path('/Users/nicholasjacob/Documents/Aplicativos/Iudex/Aulas_PGM_RJ')

PROMPT_FORMATACAO = """Voc√™ √© um especialista em revis√£o de transcri√ß√µes para concursos de procuradorias. Sua tarefa √© revisar a transcri√ß√£o fornecida de uma aula, corrigindo erros de portugu√™s, erros gramaticais e de pontua√ß√£o, melhorando a formata√ß√£o para facilitar a leitura, e mantendo o conte√∫do original. N√£o resuma, n√£o parafraseie e n√£o adicione informa√ß√µes que n√£o estejam na transcri√ß√£o original. Siga estas diretrizes:

- Mantenha o modo em primeira pessoa
- Corrija erros gramaticais, ortogr√°ficos e de pontua√ß√£o, tornando o texto gramaticalmente correto e claro
- Mantenha todo o conte√∫do original, incluindo ideias, exemplos, explica√ß√µes, pausas, hesita√ß√µes e ideias incompletas, fazendo o uso apropriado de aspas, par√™nteses. N√£o resuma, n√£o omita informa√ß√µes nem altere o significado
- Melhore a formata√ß√£o para facilitar a leitura
- Mantenha todo o conte√∫do original, mas corrija erros da linguagem coloquial para torn√°-la mais clara, did√°tica e leg√≠vel
- Ajuste a linguagem coloquial para um portugu√™s padr√£o, mantendo o significado original
- Elimine v√≠cios da oralidade e g√≠rias
- Preserve a sequ√™ncia exata das falas e ideias apresentadas
- Utilize formata√ß√£o e estrutura com par√°grafos bem definidos, facilitando a leitura e compreens√£o, para melhorar a legibilidade, seguindo o fluxo natural do discurso. Evite par√°grafos longos
- Reproduza fielmente as informa√ß√µes, apenas melhorando a clareza e a legibilidade
- Utilize conectivos necess√°rios para tornar o texto mais fluido. Aplique a pontua√ß√£o devida para deixar o texto coeso e coerente
- Corrija v√≠cios de linguagem, como repeti√ß√µes desnecess√°rias, uso excessivo de adv√©rbios, linguagem vaga ou imprecisa, g√≠rias, express√µes redundantes, e outros erros que afetem a clareza e a efic√°cia da comunica√ß√£o, sem alterar o significado do texto
- N√ÉO mencione os falantes (SPEAKER, Professor:, etc.) - converta para texto impessoal did√°tico
- Divida a aula em t√≥picos e subt√≥picos para melhor organiza√ß√£o e visualiza√ß√£o do conte√∫do
- Enumere os t√≥picos e subt√≥picos sequencialmente (1, 1.1, 1.2, 2, 2.1, etc.), use negrito quando mais apropriado
- Intercale par√°grafos curtos e longos conforme a ideia neles contida, tornando a leitura menos cansativa
- Seja did√°tico sem perder detalhes e conte√∫do
- USE TEXTO CORRIDO NA MEDIDA DO POSS√çVEL
- **Ao final de cada t√≥pico/cap√≠tulo, sintetize/resume o assunto de forma esquematizada, preferencialmente por tabelas

**Ao final de CADA t√≥pico principal, crie uma tabela de s√≠ntese:**

| Conceito/Instituto | Defini√ß√£o | Fundamento Legal | Observa√ß√µes |
|-------------------|-----------|-----------------|-------------|
| [Preencher] | [Resumo] | [Art. X, Lei Y] | [Dicas/Exce√ß√µes] |

IMPORTANTE: 
- Retorne APENAS o texto formatado em Markdown
- N√ÉO adicione coment√°rios como "Continua√ß√£o...", "Parte X...", "[Fim]", etc.
- Mantenha a numera√ß√£o sequencial dos t√≥picos
- N√ÉO mencione "Professor", "SPEAKER", "Aluno" - converta tudo para texto impessoal

{contexto_numeracao}

<transcri√ß√£o>
{texto}
</transcri√ß√£o>
"""


def extrair_texto_txt(caminho_arquivo: str) -> str:
    """Extrai texto de um arquivo .txt"""
    with open(caminho_arquivo, 'r', encoding='utf-8') as f:
        return f.read()


def dividir_texto_em_chunks(texto: str, max_chars: int = MAX_CHARS_PER_CHUNK) -> List[str]:
    """
    Divide o texto em chunks para n√£o exceder o limite de tokens do modelo.
    Tenta dividir em pontos naturais (par√°grafos).
    """
    paragrafos = texto.split('\n\n')
    chunks = []
    chunk_atual = []
    tamanho_atual = 0
    
    for paragrafo in paragrafos:
        tamanho_paragrafo = len(paragrafo)
        
        if tamanho_atual + tamanho_paragrafo > max_chars and chunk_atual:
            chunks.append('\n\n'.join(chunk_atual))
            chunk_atual = [paragrafo]
            tamanho_atual = tamanho_paragrafo
        else:
            chunk_atual.append(paragrafo)
            tamanho_atual += tamanho_paragrafo
    
    if chunk_atual:
        chunks.append('\n\n'.join(chunk_atual))
    
    return chunks


def processar_com_gemini(texto: str, parte_num: int = 1, total_partes: int = 1, ultimo_topico: int = 0) -> str:
    """Processa um chunk de texto com Gemini"""
    
    genai.configure(api_key=GEMINI_API_KEY)
    
    generation_config = {
        "temperature": 0.2,
        "top_p": 0.95,
        "top_k": 40,
        "max_output_tokens": MAX_OUTPUT_TOKENS,
    }
    
    safety_settings = [
        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
    ]
    
    model = genai.GenerativeModel(
        model_name=MODEL_NAME,
        generation_config=generation_config,
        safety_settings=safety_settings
    )
    
    # Contexto para manter numera√ß√£o cont√≠nua
    if parte_num == 1:
        contexto_numeracao = "Esta √© a PRIMEIRA parte. Inicie a numera√ß√£o dos t√≥picos em 1."
    else:
        contexto_numeracao = f"Esta √© a PARTE {parte_num} de {total_partes}. Continue a numera√ß√£o a partir do t√≥pico {ultimo_topico + 1}. N√ÉO reinicie a numera√ß√£o."
    
    prompt_completo = PROMPT_FORMATACAO.format(
        texto=texto,
        contexto_numeracao=contexto_numeracao
    )
    
    print(f"\n{Fore.CYAN}{'='*60}")
    print(f"{Fore.CYAN}üìù Processando parte {parte_num}/{total_partes}")
    print(f"{Fore.GREEN}   Tamanho do texto: {len(texto):,} caracteres")
    print(f"{Fore.CYAN}{'='*60}\n")
    
    try:
        response = model.generate_content(prompt_completo)
        return response.text
    except Exception as e:
        print(f"{Fore.RED}‚ö†Ô∏è  Erro ao processar com Gemini: {e}")
        raise


def extrair_ultimo_topico(texto: str) -> int:
    """Extrai o n√∫mero do √∫ltimo t√≥pico principal do texto formatado"""
    # Procura por padr√µes como "## 5." ou "# 12." ou "**5."
    matches = re.findall(r'(?:^|\n)(?:#+ |\*\*)?(\d+)\.', texto)
    if matches:
        return max(int(m) for m in matches)
    return 0


def salvar_resultado_markdown(texto: str, caminho: Path) -> Path:
    """Salva o resultado em um arquivo .md"""
    with open(caminho, 'w', encoding='utf-8') as f:
        f.write(texto)
    return caminho


def salvar_resultado_docx(texto_markdown: str, caminho: Path) -> Path:
    """Converte Markdown para DOCX e salva"""
    doc = Document()
    
    # Margens
    for section in doc.sections:
        section.top_margin = Inches(1)
        section.bottom_margin = Inches(1)
        section.left_margin = Inches(1.2)
        section.right_margin = Inches(1)
    
    lines = texto_markdown.split('\n')
    current_table_data = []
    in_table = False
    
    for line in lines:
        line_stripped = line.strip()
        
        if not line_stripped:
            if in_table and current_table_data:
                _add_table(doc, current_table_data)
                current_table_data = []
                in_table = False
            continue
        
        # Tabelas
        if line_stripped.startswith('|') and line_stripped.endswith('|'):
            in_table = True
            if not re.match(r'^[\|\-\:\s]+$', line_stripped):
                cells = [cell.strip() for cell in line_stripped.split('|')[1:-1]]
                if cells and any(c for c in cells):
                    current_table_data.append(cells)
            continue
        
        if in_table and current_table_data:
            _add_table(doc, current_table_data)
            current_table_data = []
            in_table = False
        
        # Headings
        if line_stripped.startswith('# '):
            doc.add_heading(line_stripped[2:], level=1)
        elif line_stripped.startswith('## '):
            doc.add_heading(line_stripped[3:], level=2)
        elif line_stripped.startswith('### '):
            doc.add_heading(line_stripped[4:], level=3)
        elif line_stripped.startswith('#### '):
            doc.add_heading(line_stripped[5:], level=4)
        elif line_stripped.startswith('- ') or line_stripped.startswith('* '):
            p = doc.add_paragraph(style='List Bullet')
            _add_formatted_text(p, line_stripped[2:])
        elif re.match(r'^\d+\.\s', line_stripped):
            p = doc.add_paragraph(style='List Number')
            text = re.sub(r'^\d+\.\s*', '', line_stripped)
            _add_formatted_text(p, text)
        elif line_stripped.startswith('---'):
            pass  # Ignora separadores
        else:
            p = doc.add_paragraph()
            _add_formatted_text(p, line_stripped)
    
    if in_table and current_table_data:
        _add_table(doc, current_table_data)
    
    doc.save(str(caminho))
    return caminho


def _add_table(doc, table_data):
    """Adiciona tabela ao documento"""
    if not table_data:
        return
    
    num_cols = max(len(row) for row in table_data)
    table = doc.add_table(rows=len(table_data), cols=num_cols)
    table.style = 'Table Grid'
    
    for i, row_data in enumerate(table_data):
        row = table.rows[i]
        for j, cell_text in enumerate(row_data):
            if j < len(row.cells):
                row.cells[j].text = cell_text
                if i == 0:
                    for para in row.cells[j].paragraphs:
                        for run in para.runs:
                            run.bold = True
    
    doc.add_paragraph()


def _add_formatted_text(paragraph, text):
    """Adiciona texto com formata√ß√£o"""
    parts = re.split(r'(\*\*[^*]+\*\*|\*[^*]+\*)', text)
    
    for part in parts:
        if not part:
            continue
        if part.startswith('**') and part.endswith('**') and len(part) > 4:
            run = paragraph.add_run(part[2:-2])
            run.bold = True
        elif part.startswith('*') and part.endswith('*') and len(part) > 2:
            run = paragraph.add_run(part[1:-1])
            run.italic = True
        else:
            paragraph.add_run(part)


def main():
    """Fun√ß√£o principal"""
    
    if not GEMINI_API_KEY:
        print(f"{Fore.RED}‚ùå ERRO: Configure a vari√°vel de ambiente GEMINI_API_KEY")
        print(f"{Fore.YELLOW}   Execute: export GEMINI_API_KEY='sua-chave-aqui'")
        return
    
    # Arquivo de entrada
    if len(sys.argv) > 1:
        arquivo_entrada = Path(sys.argv[1])
    else:
        arquivo_entrada = Path('/Users/nicholasjacob/Documents/Aplicativos/Iudex/Aulas_PGM_RJ/Administrativo.txt')
    
    if not arquivo_entrada.exists():
        print(f"{Fore.RED}‚ùå Arquivo n√£o encontrado: {arquivo_entrada}")
        return
    
    print(f"{Fore.CYAN}üìÑ Lendo arquivo: {arquivo_entrada}")
    texto_original = extrair_texto_txt(str(arquivo_entrada))
    
    print(f"{Fore.GREEN}‚úÖ Texto extra√≠do: {len(texto_original):,} caracteres")
    print(f"{Fore.GREEN}   Estimativa: ~{len(texto_original)//4:,} tokens")
    
    # Dividir em chunks
    chunks = dividir_texto_em_chunks(texto_original)
    print(f"\n{Fore.CYAN}üìä Documento dividido em {len(chunks)} parte(s)")
    
    # Processar cada chunk
    resultados = []
    ultimo_topico = 0
    
    for i, chunk in enumerate(chunks, 1):
        print(f"\n{Fore.YELLOW}üîÑ Processando parte {i}/{len(chunks)}...")
        
        try:
            resultado = processar_com_gemini(
                texto=chunk,
                parte_num=i,
                total_partes=len(chunks),
                ultimo_topico=ultimo_topico
            )
            resultados.append(resultado)
            
            # Atualiza o √∫ltimo t√≥pico para manter numera√ß√£o
            ultimo_topico = extrair_ultimo_topico(resultado)
            
            print(f"{Fore.GREEN}‚úÖ Parte {i} processada com sucesso (√∫ltimo t√≥pico: {ultimo_topico})")
            
            if i < len(chunks):
                print(f"{Fore.CYAN}‚è≥ Aguardando 2 segundos...")
                time.sleep(2)
                
        except Exception as e:
            print(f"{Fore.RED}‚ùå Erro ao processar parte {i}: {e}")
            continue
    
    # Combinar resultados
    texto_final = '\n\n'.join(resultados)
    
    print(f"\n{Fore.CYAN}üíæ Salvando resultados...")
    
    # Nome base para os arquivos
    nome_base = arquivo_entrada.stem
    
    # Salvar Markdown
    arquivo_md = OUTPUT_DIR / f'{nome_base}_GEMINI_APOSTILA.md'
    salvar_resultado_markdown(texto_final, arquivo_md)
    print(f"{Fore.GREEN}‚úÖ Markdown salvo: {arquivo_md}")
    
    # Salvar DOCX
    try:
        arquivo_docx = OUTPUT_DIR / f'{nome_base}_GEMINI_APOSTILA.docx'
        salvar_resultado_docx(texto_final, arquivo_docx)
        print(f"{Fore.GREEN}‚úÖ DOCX salvo: {arquivo_docx}")
    except Exception as e:
        print(f"{Fore.YELLOW}‚ö†Ô∏è  Erro ao salvar DOCX: {e}")
    
    print(f"\n{Fore.GREEN}{'='*60}")
    print(f"{Fore.GREEN}üéâ PROCESSAMENTO CONCLU√çDO!")
    print(f"{Fore.GREEN}   Total de partes processadas: {len(resultados)}/{len(chunks)}")
    print(f"{Fore.GREEN}   Tamanho final: {len(texto_final):,} caracteres")
    print(f"{Fore.GREEN}{'='*60}")


if __name__ == '__main__':
    main()
