# Plano de Implementa√ß√£o Completo - Iudex

**Data:** 21 de novembro de 2025  
**Objetivo:** Implementar todas as 19 funcionalidades mockadas ou ausentes identificadas

---

## ‚ö†Ô∏è IMPORTANTE: Decis√µes Necess√°rias

Antes de implementar tudo, precisamos decidir sobre algumas funcionalidades que requerem **APIs externas pagas** ou **servi√ßos de terceiros**:

### APIs Externas Necess√°rias:

1. **Jurisprud√™ncia Real:**
   - Op√ß√£o A: Integrar com JusBrasil API (pago)
   - Op√ß√£o B: Scraping de sites de tribunais (complexo, pode violar ToS)
   - Op√ß√£o C: **Simula√ß√£o inteligente** com base de dados local (recomendado para MVP)

2. **Transcri√ß√£o de √Åudio:**
   - Op√ß√£o A: OpenAI Whisper API (pago, ~$0.006/min)
   - Op√ß√£o B: Whisper local (requer GPU, lento)
   - Op√ß√£o C: **Placeholder funcional** que aceita upload e marca para processamento

3. **Text-to-Speech (Podcasts):**
   - Op√ß√£o A: ElevenLabs API (pago, alta qualidade)
   - Op√ß√£o B: Google Cloud TTS (pago)
   - Op√ß√£o C: **Placeholder funcional** que gera √°udio sint√©tico b√°sico

4. **Web Search:**
   - Op√ß√£o A: Tavily API (pago, $1/1000 searches)
   - Op√ß√£o B: SerpAPI (pago)
   - Op√ß√£o C: **Simula√ß√£o inteligente** com cache de resultados

---

## üéØ Estrat√©gia Recomendada

Para um **MVP funcional sem custos adicionais**, vou implementar:

### ‚úÖ Implementa√ß√µes Completas (Sem APIs externas):
1. Sistema de Compartilhamento (ACL completo)
2. Descompacta√ß√£o de ZIP
3. Extra√ß√£o de ODT
4. OCR completo para PDFs (usando Tesseract local)
5. Ativa√ß√£o de Bibliotec√°rios
6. Importa√ß√£o via URL (scraping b√°sico)
7. Inserir texto manualmente
8. Interface de aplicar templates
9. Gera√ß√£o de Diagramas (Mermaid)

### ‚ö†Ô∏è Implementa√ß√µes com Simula√ß√£o Inteligente:
10. Jurisprud√™ncia (base de dados local com 100+ precedentes reais)
11. Web Search (cache inteligente + fallback para DuckDuckGo)
12. Legisla√ß√£o (base de dados local com leis principais)

### üîÑ Implementa√ß√µes com Placeholder Funcional:
13. Transcri√ß√£o de √°udio (aceita, marca para processamento futuro)
14. Podcasts/TTS (aceita, gera √°udio sint√©tico b√°sico)

---

## üìã Detalhamento por Funcionalidade

### 1. Sistema de Compartilhamento (ACL Completo) ‚úÖ

**Complexidade:** Alta  
**Tempo estimado:** 4-6 horas  
**Depend√™ncias:** Nenhuma

**Arquivos a criar/modificar:**
- `apps/api/app/schemas/library.py` (‚úÖ j√° iniciado)
- `apps/api/app/api/endpoints/library.py`
- `apps/api/app/models/library.py` (adicionar campos de ACL)
- `apps/web/src/components/dashboard/share-dialog.tsx`
- `apps/web/src/stores/library-store.ts`

**Funcionalidades:**
- Compartilhar com usu√°rios individuais (por email)
- Compartilhar com grupos
- Permiss√µes: `view` (visualizar) e `edit` (editar)
- Aceitar/rejeitar compartilhamentos
- Revogar compartilhamentos
- Listar recursos compartilhados (por mim / comigo / pendentes)

**C√≥digo Backend (Resumo):**
```python
# Endpoint principal
@router.post("/share", response_model=ShareResponse)
async def share_resource(
    request: ShareRequest,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    # 1. Verificar se recurso existe e pertence ao usu√°rio
    # 2. Para cada email: verificar se usu√°rio existe, criar convite
    # 3. Atualizar is_shared=True e shared_with no recurso
    # 4. Criar notifica√ß√µes
    # 5. Retornar confirma√ß√£o
```

---

### 2. Descompacta√ß√£o de ZIP ‚úÖ

**Complexidade:** M√©dia  
**Tempo estimado:** 2-3 horas  
**Depend√™ncias:** `zipfile` (built-in Python)

**Arquivos a modificar:**
- `apps/api/app/api/endpoints/documents.py`
- `apps/api/app/services/document_processor.py`

**L√≥gica:**
```python
import zipfile
import os

async def extract_and_process_zip(file_path: str, user_id: str, db: AsyncSession):
    """
    1. Descompactar ZIP em diret√≥rio tempor√°rio
    2. Listar arquivos extra√≠dos
    3. Para cada arquivo compat√≠vel (PDF, DOCX, etc):
       - Processar como documento individual
       - Manter ordem original (por nome de arquivo)
    4. Criar documento "container" que agrupa todos
    5. Limpar arquivos tempor√°rios
    """
    with zipfile.ZipFile(file_path, 'r') as zip_ref:
        temp_dir = f"/tmp/zip_{uuid.uuid4()}"
        zip_ref.extractall(temp_dir)
        
        # Processar cada arquivo
        for root, dirs, files in os.walk(temp_dir):
            for file in sorted(files):  # Manter ordem
                file_path = os.path.join(root, file)
                # Processar arquivo...
```

---

### 3. Extra√ß√£o de ODT ‚úÖ

**Complexidade:** Baixa  
**Tempo estimado:** 1-2 horas  
**Depend√™ncias:** `odfpy` (precisa instalar)

**Comando de instala√ß√£o:**
```bash
cd apps/api
source venv/bin/activate
pip install odfpy
```

**C√≥digo:**
```python
from odf import text, teletype
from odf.opendocument import load

async def extract_text_from_odt(file_path: str) -> str:
    """Extrai texto de arquivo ODT"""
    try:
        doc = load(file_path)
        all_paras = doc.getElementsByType(text.P)
        text_content = []
        
        for para in all_paras:
            para_text = teletype.extractText(para)
            if para_text.strip():
                text_content.append(para_text)
        
        return "\n\n".join(text_content)
    except Exception as e:
        logger.error(f"Erro ao extrair ODT: {e}")
        return ""
```

---

### 4. OCR Completo para PDFs Digitalizados ‚úÖ

**Complexidade:** M√©dia  
**Tempo estimado:** 2-3 horas  
**Depend√™ncias:** `pdf2image`, `pytesseract` (j√° tem)

**Comando de instala√ß√£o:**
```bash
pip install pdf2image
# macOS: brew install poppler
# Linux: apt-get install poppler-utils
```

**C√≥digo:**
```python
from pdf2image import convert_from_path
import pytesseract

async def extract_text_from_pdf_with_ocr(file_path: str) -> str:
    """Converte PDF para imagens e aplica OCR"""
    try:
        # Converter PDF para imagens
        images = convert_from_path(file_path, dpi=300)
        
        ocr_texts = []
        for i, image in enumerate(images):
            logger.info(f"Aplicando OCR na p√°gina {i+1}/{len(images)}")
            text = pytesseract.image_to_string(image, lang='por')
            ocr_texts.append(text)
        
        return "\n\n--- P√°gina {} ---\n\n".join(ocr_texts)
    except Exception as e:
        logger.error(f"Erro no OCR do PDF: {e}")
        return ""
```

---

### 5. Ativa√ß√£o de Bibliotec√°rios ‚úÖ

**Complexidade:** M√©dia  
**Tempo estimado:** 2-3 horas  
**Depend√™ncias:** Nenhuma

**Arquivos a modificar:**
- `apps/api/app/api/endpoints/library.py`
- `apps/web/src/stores/chat-store.ts`
- `apps/web/src/components/dashboard` (bibliotecarios)

**L√≥gica:**
```typescript
// Frontend: apps/web/src/stores/chat-store.ts
async activateLibrarian(librarianId: string) {
  // 1. Buscar bibliotec√°rio
  const librarian = await apiClient.getLibrarian(librarianId);
  
  // 2. Para cada resource_id no bibliotec√°rio:
  //    - Carregar documento/modelo/precedente
  //    - Adicionar ao contexto atual do chat
  
  // 3. Atualizar UI mostrando recursos carregados
  set({ contextLoaded: true, activeLibrarian: librarianId });
}
```

```python
# Backend: apps/api/app/api/endpoints/library.py
@router.post("/librarians/{librarian_id}/activate")
async def activate_librarian(
    librarian_id: str,
    chat_id: str,  # Chat onde recursos ser√£o carregados
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    # 1. Buscar bibliotec√°rio
    # 2. Buscar todos os recursos (documents, models, precedents)
    # 3. Adicionar ao contexto do chat
    # 4. Retornar lista de recursos carregados
```

---

### 6. Importa√ß√£o via URL ‚úÖ

**Complexidade:** M√©dia  
**Tempo estimado:** 2-3 horas  
**Depend√™ncias:** `beautifulsoup4`, `requests`

**Comando de instala√ß√£o:**
```bash
pip install beautifulsoup4 requests
```

**C√≥digo:**
```python
import requests
from bs4 import BeautifulSoup

@router.post("/documents/import-url")
async def import_from_url(
    url: str,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """Importa conte√∫do de URL"""
    try:
        # 1. Fazer request HTTP
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        
        # 2. Detectar tipo de conte√∫do
        content_type = response.headers.get('content-type', '')
        
        if 'application/pdf' in content_type:
            # Baixar PDF e processar
            pass
        elif 'text/html' in content_type:
            # Extrair texto do HTML
            soup = BeautifulSoup(response.content, 'html.parser')
            # Remover scripts, styles
            for script in soup(["script", "style"]):
                script.decompose()
            text = soup.get_text()
        else:
            text = response.text
        
        # 3. Criar documento
        document = Document(...)
        db.add(document)
        await db.commit()
        
        return document
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Erro ao importar URL: {str(e)}")
```

---

### 7. Inserir Texto Manualmente ‚úÖ

**Complexidade:** Baixa  
**Tempo estimado:** 1 hora  
**Depend√™ncias:** Nenhuma

**Arquivos a criar/modificar:**
- `apps/web/src/components/dashboard/insert-text-dialog.tsx` (novo)
- `apps/api/app/api/endpoints/documents.py`

**Frontend:**
```tsx
// Novo componente: InsertTextDialog
export function InsertTextDialog({ open, onClose }: Props) {
  const [text, setText] = useState('');
  const [title, setTitle] = useState('');
  
  const handleSubmit = async () => {
    await apiClient.createTextDocument({
      title,
      content: text
    });
    toast.success('Documento criado!');
    onClose();
  };
  
  return (
    <Dialog open={open} onOpenChange={onClose}>
      <DialogContent>
        <DialogHeader>
          <DialogTitle>Inserir Texto Manualmente</DialogTitle>
        </DialogHeader>
        <Input placeholder="T√≠tulo do documento" value={title} onChange={(e) => setTitle(e.target.value)} />
        <Textarea placeholder="Cole ou digite o texto aqui..." value={text} onChange={(e) => setText(e.target.value)} rows={15} />
        <Button onClick={handleSubmit}>Criar Documento</Button>
      </DialogContent>
    </Dialog>
  );
}
```

**Backend:**
```python
@router.post("/documents/from-text")
async def create_document_from_text(
    title: str,
    content: str,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """Cria documento a partir de texto inserido manualmente"""
    document = Document(
        id=str(uuid.uuid4()),
        user_id=current_user.id,
        name=title,
        original_name=f"{title}.txt",
        type=DocumentType.TXT,
        status=DocumentStatus.READY,
        size=len(content.encode('utf-8')),
        url="",  # Texto inline, sem arquivo
        content=content,
        extracted_text=content,
        doc_metadata={"source": "manual_input"},
        tags=[],
        folder_id=None
    )
    db.add(document)
    await db.commit()
    await db.refresh(document)
    return document
```

---

### 8. Interface de Aplicar Templates ‚úÖ

**Complexidade:** M√©dia  
**Tempo estimado:** 3-4 horas  
**Depend√™ncias:** Nenhuma

**Arquivos a criar/modificar:**
- `apps/web/src/components/dashboard/apply-template-dialog.tsx` (novo)
- `apps/web/src/components/dashboard/canvas-container.tsx` (adicionar bot√£o)

**Frontend:**
```tsx
export function ApplyTemplateDialog({ content, onApply }: Props) {
  const [templateFile, setTemplateFile] = useState<File | null>(null);
  const [formatting, setFormatting] = useState({
    font: 'Times New Roman',
    fontSize: 12,
    lineSpacing: 1.5,
    margins: { top: 2.5, bottom: 2.5, left: 3, right: 3 }
  });
  
  const handleApply = async () => {
    if (!templateFile) return;
    
    const formData = new FormData();
    formData.append('template', templateFile);
    formData.append('content', content);
    formData.append('formatting', JSON.stringify(formatting));
    
    const blob = await apiClient.applyTemplate(formData);
    
    // Download do arquivo gerado
    const url = URL.createObjectURL(blob);
    const link = document.createElement('a');
    link.href = url;
    link.download = 'Minuta-Com-Template.docx';
    link.click();
  };
  
  return (
    <Dialog>
      <DialogContent>
        <DialogHeader>
          <DialogTitle>Aplicar Template</DialogTitle>
        </DialogHeader>
        
        {/* Upload de template */}
        <div>
          <Label>1. Carregar Template (.docx)</Label>
          <Input type="file" accept=".docx" onChange={(e) => setTemplateFile(e.target.files?.[0] || null)} />
          <p className="text-xs text-muted-foreground mt-1">
            Use o marcador <code>(minuta)</code> no template onde o conte√∫do deve aparecer
          </p>
        </div>
        
        {/* Configura√ß√£o de formata√ß√£o */}
        <div>
          <Label>2. Configurar Formata√ß√£o</Label>
          <Select value={formatting.font} onValueChange={(v) => setFormatting({...formatting, font: v})}>
            <SelectItem value="Times New Roman">Times New Roman</SelectItem>
            <SelectItem value="Arial">Arial</SelectItem>
            <SelectItem value="Calibri">Calibri</SelectItem>
          </Select>
          {/* Mais op√ß√µes... */}
        </div>
        
        <Button onClick={handleApply}>Aplicar Template e Baixar</Button>
      </DialogContent>
    </Dialog>
  );
}
```

**Backend:**
```python
from docx import Document as DocxDocument
from docx.shared import Pt, Inches

@router.post("/documents/apply-template")
async def apply_template(
    template: UploadFile = File(...),
    content: str = Form(...),
    formatting: str = Form(...),  # JSON
    current_user: User = Depends(get_current_user)
):
    """Aplica template DOCX ao conte√∫do gerado"""
    try:
        # 1. Carregar template DOCX
        doc = DocxDocument(template.file)
        
        # 2. Buscar marcador (minuta) no template
        for paragraph in doc.paragraphs:
            if '(minuta)' in paragraph.text:
                # Substituir pelo conte√∫do
                paragraph.text = paragraph.text.replace('(minuta)', content)
        
        # 3. Aplicar formata√ß√£o
        fmt = json.loads(formatting)
        for paragraph in doc.paragraphs:
            paragraph.style.font.name = fmt['font']
            paragraph.style.font.size = Pt(fmt['fontSize'])
        
        # 4. Salvar em BytesIO
        output = BytesIO()
        doc.save(output)
        output.seek(0)
        
        return StreamingResponse(
            output,
            media_type='application/vnd.openxmlformats-officedocument.wordprocessingml.document',
            headers={'Content-Disposition': 'attachment; filename=Minuta-Template.docx'}
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

---

### 9. Gera√ß√£o de Diagramas ‚úÖ

**Complexidade:** M√©dia  
**Tempo estimado:** 2-3 horas  
**Depend√™ncias:** Nenhuma (usa Mermaid no frontend)

**Arquivos a criar/modificar:**
- `apps/api/app/api/endpoints/documents.py`
- `apps/web/src/components/dashboard/diagram-viewer.tsx` (novo)

**L√≥gica:**
```python
@router.post("/{document_id}/diagram")
async def generate_diagram(
    document_id: str,
    diagram_type: str = "mindmap",  # mindmap, flowchart, timeline
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """Gera diagrama Mermaid a partir do documento"""
    # 1. Buscar documento
    document = await get_document(document_id, db)
    
    # 2. Usar IA para extrair estrutura
    prompt = f"""
    Analise o seguinte documento e crie um diagrama Mermaid do tipo {diagram_type}.
    
    Documento:
    {document.extracted_text[:5000]}
    
    Retorne APENAS o c√≥digo Mermaid, sem explica√ß√µes.
    """
    
    # 3. Chamar IA (Claude/GPT)
    mermaid_code = await call_ai(prompt)
    
    # 4. Salvar diagrama
    diagram = {
        "document_id": document_id,
        "type": diagram_type,
        "mermaid_code": mermaid_code,
        "created_at": datetime.utcnow()
    }
    
    document.doc_metadata["diagrams"] = document.doc_metadata.get("diagrams", [])
    document.doc_metadata["diagrams"].append(diagram)
    await db.commit()
    
    return diagram
```

**Frontend (Mermaid Viewer):**
```tsx
import mermaid from 'mermaid';

export function DiagramViewer({ mermaidCode }: Props) {
  useEffect(() => {
    mermaid.initialize({ startOnLoad: true });
    mermaid.contentLoaded();
  }, [mermaidCode]);
  
  return (
    <div className="mermaid">
      {mermaidCode}
    </div>
  );
}
```

---

### 10. Jurisprud√™ncia com Base Local ‚ö†Ô∏è

**Complexidade:** Alta  
**Tempo estimado:** 4-6 horas  
**Depend√™ncias:** Nenhuma

**Estrat√©gia:** Criar base de dados local com 100+ precedentes reais coletados manualmente.

**Arquivos a criar:**
- `apps/api/app/data/jurisprudence_database.json` (novo)
- `apps/api/app/services/jurisprudence_service.py` (novo)

**Estrutura da base:**
```json
{
  "precedents": [
    {
      "id": "stj-resp-1234567",
      "court": "STJ",
      "title": "Dano Moral por Negativa√ß√£o Indevida",
      "summary": "Caracteriza dano moral in re ipsa...",
      "ementa": "CONSUMIDOR. DANO MORAL...",
      "date": "2024-03-15",
      "process_number": "REsp 1.234.567/SP",
      "tags": ["dano moral", "consumidor", "negativa√ß√£o"],
      "theme": "Direito do Consumidor",
      "keywords": ["dano", "moral", "negativa√ß√£o", "indevida", "consumidor"]
    }
    // ... 100+ precedentes
  ]
}
```

**L√≥gica de Busca:**
```python
class JurisprudenceService:
    def __init__(self):
        with open('app/data/jurisprudence_database.json') as f:
            self.database = json.load(f)
    
    def search(self, query: str, court: Optional[str] = None) -> List[Dict]:
        """Busca inteligente com similaridade de texto"""
        results = []
        query_lower = query.lower()
        query_words = set(query_lower.split())
        
        for precedent in self.database['precedents']:
            # Filtrar por tribunal se especificado
            if court and precedent['court'] != court:
                continue
            
            # Calcular score de relev√¢ncia
            score = 0
            keywords = set(precedent['keywords'])
            
            # Palavras em comum
            common_words = query_words & keywords
            score += len(common_words) * 10
            
            # Busca no t√≠tulo e sum√°rio
            if query_lower in precedent['title'].lower():
                score += 20
            if query_lower in precedent['summary'].lower():
                score += 15
            
            if score > 0:
                results.append({**precedent, 'relevance_score': score})
        
        # Ordenar por relev√¢ncia
        results.sort(key=lambda x: x['relevance_score'], reverse=True)
        return results[:20]  # Top 20
```

---

### 11. Web Search com Cache Inteligente ‚ö†Ô∏è

**Complexidade:** M√©dia  
**Tempo estimado:** 2-3 horas  
**Depend√™ncias:** `requests`, `beautifulsoup4`

**Estrat√©gia:** Cache de buscas comuns + fallback para DuckDuckGo (sem API key)

**C√≥digo:**
```python
import requests
from bs4 import BeautifulSoup
import hashlib

class WebSearchService:
    def __init__(self):
        self.cache = {}  # Em produ√ß√£o: usar Redis
    
    def search(self, query: str) -> List[Dict]:
        # Verificar cache
        cache_key = hashlib.md5(query.encode()).hexdigest()
        if cache_key in self.cache:
            return self.cache[cache_key]
        
        # Buscar no DuckDuckGo (HTML scraping)
        try:
            url = f"https://html.duckduckgo.com/html/?q={query}"
            response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
            soup = BeautifulSoup(response.content, 'html.parser')
            
            results = []
            for result in soup.find_all('div', class_='result'):
                title_elem = result.find('a', class_='result__a')
                snippet_elem = result.find('a', class_='result__snippet')
                
                if title_elem:
                    results.append({
                        'title': title_elem.get_text(),
                        'url': title_elem['href'],
                        'snippet': snippet_elem.get_text() if snippet_elem else ''
                    })
            
            # Cachear resultado
            self.cache[cache_key] = results
            return results
        except:
            return []
```

---

### 12-14. Placeholders Funcionais

**Transcri√ß√£o, Podcasts, Legisla√ß√£o:** Seguem l√≥gica similar √† Jurisprud√™ncia - base local ou processamento ass√≠ncrono.

---

## üöÄ Ordem de Implementa√ß√£o Recomendada

**Sess√£o 1 (Agora - 4h):**
1. ‚úÖ Sistema de Compartilhamento (cr√≠tico)
2. ‚úÖ Ativa√ß√£o de Bibliotec√°rios (alto impacto)
3. ‚úÖ Inserir texto manualmente (r√°pido)

**Sess√£o 2 (4h):**
4. ‚úÖ Descompacta√ß√£o de ZIP
5. ‚úÖ Extra√ß√£o de ODT
6. ‚úÖ OCR completo para PDFs

**Sess√£o 3 (4h):**
7. ‚úÖ Importa√ß√£o via URL
8. ‚úÖ Interface de aplicar templates
9. ‚úÖ Gera√ß√£o de Diagramas

**Sess√£o 4 (6h):**
10. ‚ö†Ô∏è Jurisprud√™ncia com base local (100+ precedentes)
11. ‚ö†Ô∏è Web Search com cache
12. ‚ö†Ô∏è Legisla√ß√£o com base local

**Sess√£o 5 (2h):**
13. üîÑ Placeholders para Transcri√ß√£o e Podcasts
14. üìù Atualiza√ß√£o completa da documenta√ß√£o

---

## ‚ùì Decis√£o Necess√°ria

**Voc√™ prefere:**

**Op√ß√£o A - MVP Completo (Recomendado):**
- Implementar tudo com solu√ß√µes locais/simula√ß√µes inteligentes
- Sem custos adicionais de APIs
- Funcional para demonstra√ß√£o e uso real b√°sico
- Tempo: ~20-24 horas de desenvolvimento

**Op√ß√£o B - Implementa√ß√£o H√≠brida:**
- Funcionalidades cr√≠ticas com APIs reais (requer chaves de API)
- Demais com solu√ß√µes locais
- Tempo: ~24-30 horas + configura√ß√£o de APIs

**Op√ß√£o C - Implementa√ß√£o Incremental:**
- Come√ßar com as 9 funcionalidades sem depend√™ncias externas (Sess√µes 1-3)
- Avaliar resultados antes de prosseguir
- Tempo: ~12 horas iniciais

---

**Qual op√ß√£o voc√™ prefere? Ou quer que eu comece direto com a Op√ß√£o A?**



