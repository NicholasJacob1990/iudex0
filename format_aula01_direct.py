#!/usr/bin/env python3
"""Formata diretamente a transcri√ß√£o da Aula 01 que j√° foi inserida"""
import os
from openai import OpenAI
from docx import Document
from docx.shared import Pt, RGBColor, Inches
from docx.enum.text import WD_ALIGN_PARAGRAPH
from tqdm import tqdm

# Ler transcri√ß√£o
raw_file = "/Users/nicholasjacob/Documents/Aplicativos/Iudex/Aulas_PGM_RJ/01_Aula_Inaugural_YouTube_RAW.txt"
with open(raw_file, 'r', encoding='utf-8') as f:
    transcript_text = f.read()

print(f"üìù Transcri√ß√£o carregada: {len(transcript_text)} caracteres")

# Inicializar cliente OpenAI (usa CHROMA_OPENAI_API_KEY do ambiente)
api_key = os.getenv("CHROMA_OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("API key n√£o encontrada! Configure OPENAI_API_KEY ou CHROMA_OPENAI_API_KEY")
client = OpenAI(api_key=api_key)

# Dividir em chunks (copiei a l√≥gica do mlx_vomo.py)
def smart_chunk(text, max_size):
    if len(text) <= max_size:
        return [text]
    
    chunks = []
    current_pos = 0
    
    while current_pos < len(text):
        if current_pos + max_size >= len(text):
            chunks.append(text[current_pos:])
            break
            
        chunk_end = current_pos + max_size
        
        for separator in ['\n\n', '\n', '. ', ' ']:
            last_sep = text.rfind(separator, current_pos, chunk_end)
            if last_sep != -1:
                chunk_end = last_sep + len(separator)
                break
        
        chunks.append(text[current_pos:chunk_end])
        current_pos = chunk_end
    
    return chunks

chunks = smart_chunk(transcript_text, 40000)
print(f"   Dividido em {len(chunks)} partes")

# System prompt (copiado do mlx_vomo.py)
system_prompt = """# PAPEL
Voc√™ √© um especialista em Direito Administrativo e reda√ß√£o jur√≠dica, atuando como revisor s√™nior de material did√°tico para concursos de Procuradoria Municipal/Estadual (PGM/PGE).

# MISS√ÉO
Transformar a transcri√ß√£o bruta de uma videoaula em uma **Apostila de Estudo** clara, did√°tica e fiel ao conte√∫do original, mantendo TODO o conhecimento t√©cnico-jur√≠dico.

# ESTRUTURA OBRIGAT√ìRIA DO DOCUMENTO

## Cabe√ßalho da Apostila (APENAS NO PRIMEIRO CHUNK)

[INSTRU√á√ïES COMPLETAS DE FORMATA√á√ÉO - ver mlx_vomo.py linha 111-477]

# REGRA DE OURO: Se o professor falou, voc√™ DEVE incluir. NUNCA omita nada."""

formatted_chunks = []

print("üß† Formatando com GPT-5-mini...")
for i, chunk in enumerate(tqdm(chunks, desc="Formatando")):
    is_first = (i == 0)
    
    user_content = f"""{"[PRIMEIRA PARTE - CRIE O CABE√áALHO COMPLETO: Summary, Key Takeaways, Action Items]" if is_first else "[CONTINUA√á√ÉO - SEM CABE√áALHO]"}

{chunk}"""
    
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_content}
        ],
        timeout=180
    )
    
    formatted_chunks.append(response.choices[0].message.content)

formatted_text = "\n\n".join(formatted_chunks)

# Salvar .md
md_file = "/Users/nicholasjacob/Documents/Aplicativos/Iudex/Aulas_PGM_RJ/01_Aula_Inaugural_YouTube_APOSTILA.md"
with open(md_file, 'w', encoding='utf-8') as f:
    f.write(f"# 01_Aula_Inaugural_YouTube\n\n{formatted_text}")

print(f"\n‚úÖ Apostila formatada salva em: {md_file}")
print(f"üìä Tamanho: {len(formatted_text)} caracteres")
