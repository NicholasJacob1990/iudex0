# AI_LOG.md â€” HistÃ³rico de SessÃµes Claude Code

> Este arquivo registra as sessÃµes do Claude Code neste projeto.
> Atualize ao final de cada sessÃ£o significativa.

---

## 2026-02-05 â€” SessÃ£o 129: Code Artifacts com Streaming e IntegraÃ§Ã£o Completa

### Objetivo
Implementar sistema completo de Code Artifacts com streaming, incluindo Shiki (syntax highlighting), Sandpack (React preview), Diff View, Export ZIP, e Pyodide (Python execution).

### Arquivos Criados
- `src/components/dashboard/artifact-code-highlighter.tsx` â€” Syntax highlighting com Shiki + streaming debounce
- `src/components/dashboard/artifact-sandpack-preview.tsx` â€” Preview React/Vue/Svelte com Sandpack
- `src/components/dashboard/artifact-diff-view.tsx` â€” ComparaÃ§Ã£o de cÃ³digo com 3 modos (linhas, palavras, split)
- `src/components/dashboard/artifact-exporter.tsx` â€” Export ZIP com JSZip
- `src/components/dashboard/artifact-python-runner.tsx` â€” ExecuÃ§Ã£o Python no browser com Pyodide

### Arquivos Modificados
- `src/components/dashboard/code-artifact-viewer.tsx` â€” IntegraÃ§Ã£o de todos os componentes:
  - CodeHighlighter em vez de CodeBlock simples
  - SandpackPreview para React/JSX/Vue
  - PythonRunner para Python
  - ArtifactExporter no header
  - DiffView como modo alternativo (toggle)
  - Lazy loading para componentes pesados

### Funcionalidades de Streaming
- Debounce de 150ms durante streaming para evitar re-renderizaÃ§Ãµes
- Auto-scroll para o final do cÃ³digo durante streaming
- Cursor animado â–Œ com indicador "Gerando cÃ³digo..."
- Borda verde animada indicando streaming ativo
- BotÃ£o de copiar oculto durante streaming

### CorreÃ§Ãµes
- `artifact-python-runner.tsx`: Movido `addOutput` antes do `useEffect` que o usa
- `artifact-code-highlighter.tsx`: Corrigido tipo 'text' â†’ 'javascript' como fallback

### VerificaÃ§Ãµes
- âœ… Lint passou
- âœ… Type-check passou

### Suporte Multi-Provider para Code Artifacts
Adicionados eventos SSE para artifacts no backend, funcionando com:
- **Claude Agent SDK** (Anthropic)
- **OpenAI Agents SDK** (GPT-5.x, GPT-4o)
- **Google ADK** (Gemini)

Novos eventos no `sse_protocol.py`:
- `ARTIFACT_START` â†’ InÃ­cio do artifact (id, type, language, title)
- `ARTIFACT_TOKEN` â†’ Streaming de cÃ³digo
- `ARTIFACT_DONE` â†’ ConclusÃ£o (dependencies, executable)

Imports adicionados aos executors:
- `apps/api/app/services/ai/claude_agent/executor.py`
- `apps/api/app/services/ai/executors/openai_agent.py`
- `apps/api/app/services/ai/executors/google_agent.py`

### RevisÃ£o GPT-5.2 e CorreÃ§Ãµes Aplicadas
Solicitada segunda opiniÃ£o via MCP codex-bridge. O GPT-5.2 identificou:

1. **Race Condition** (CORRIGIDO)
   - Problema: `codeToHtml` async podia terminar fora de ordem
   - SoluÃ§Ã£o: Adicionado `requestIdRef` para ignorar resultados obsoletos

2. **Auto-scroll agressivo** (CORRIGIDO)
   - Problema: ForÃ§ava scroll mesmo quando usuÃ¡rio rolou para cima
   - SoluÃ§Ã£o: `shouldAutoScrollRef` + threshold de 40px do fundo

3. **Debounce insuficiente** (CORRIGIDO)
   - Problema: 150ms podia ser muito frequente
   - SoluÃ§Ã£o: Aumentado para 250ms durante streaming

4. **Lazy loading Next.js** (CORRIGIDO)
   - Problema: `React.lazy` nÃ£o ideal para componentes browser-only
   - SoluÃ§Ã£o: Trocado para `next/dynamic` com `ssr: false`

---

## 2026-02-05 â€” SessÃ£o 128: Streaming Nativo no Chat (RemoÃ§Ã£o de Overlay)

### Objetivo
Remover o `AskStreamingOverlay` redundante e usar efeitos de streaming nativos do chat (como ChatGPT/Perplexity).

### Problema Identificado
O usuÃ¡rio solicitou que os efeitos de streaming fossem "dentro do prÃ³prio chat", como ChatGPT e Perplexity fazem, nÃ£o como um overlay separado.

### SoluÃ§Ã£o Implementada
O componente `ChatMessage` jÃ¡ possui efeitos de streaming nativos:
- **ActivityPanel**: Mostra etapas de processamento (pesquisando, analisando, etc.)
- **LoadingDots**: AnimaÃ§Ã£o de pontos durante escrita
- **Timers**: "Pensando hÃ¡ Xs" e "Escrevendo (Xs)"

O `AskStreamingOverlay` era redundante e foi removido.

### Arquivos Modificados
- `apps/web/src/app/(dashboard)/ask/page.tsx` â€” Removido import e uso de AskStreamingOverlay
- `apps/web/src/app/(dashboard)/minuta/page.tsx` â€” Removido import e uso de AskStreamingOverlay

### VerificaÃ§Ãµes
- Lint passou
- TypeScript check passou
- Frontend e backend rodando corretamente

---

## 2026-02-05 â€” SessÃ£o 127: IntegraÃ§Ã£o Completa SSE, CitaÃ§Ãµes e Follow-ups

### Objetivo
Integrar streaming real via SSE, citaÃ§Ãµes do backend e sugestÃµes de follow-up na pÃ¡gina `/ask`.

### Arquivos Modificados
- `apps/web/src/app/(dashboard)/ask/page.tsx` â€” Reescrita completa com integraÃ§Ã£o real

### Funcionalidades Integradas

#### 1. **Streaming Status Real**
- Extrai `activity.steps` do metadata da Ãºltima mensagem do assistente
- Detecta step com `status: 'running'` para mostrar status atual
- Conta steps completados para mensagem final
- Integrado com `AskStreamingStatus` component

#### 2. **CitaÃ§Ãµes Reais**
- Extrai `citations` do metadata da Ãºltima mensagem do assistente
- Converte formato do backend para formato do `AskSourcesPanel`
- Extrai hostname da URL para mostrar fonte
- Mapeia `quote` para `snippet` e mantÃ©m `signal` (Shepard's)

#### 3. **SugestÃµes de Follow-up**
- **Empty state**: Grid de 4 sugestÃµes iniciais (anÃ¡lise, pesquisa, petiÃ§Ã£o, explicaÃ§Ã£o)
- **Contextual**: SugestÃµes baseadas em fontes selecionadas
- **Follow-up input**: Input rÃ¡pido apÃ³s resposta do assistente (estilo Perplexity)

### CÃ³digo Principal
```typescript
// ExtraÃ§Ã£o de dados da Ãºltima mensagem
const { lastAssistantMessage, activitySteps, citations, streamingStatus, stepsCount } = useMemo(() => {
  const msgs = currentChat?.messages || [];
  // Find last assistant message
  // Extract activity steps
  // Extract and format citations
  // Determine streaming status from running steps
}, [currentChat?.messages, isSending]);
```

### VerificaÃ§Ãµes
- âœ… Lint passou
- âœ… Type-check passou
- âœ… CitaÃ§Ãµes formatadas corretamente
- âœ… Status de streaming integrado com activity steps

---

## 2026-02-05 â€” SessÃ£o 126: CoordenaÃ§Ã£o Multi-Agente e IntegraÃ§Ã£o Final

### Objetivo
Coordenar mÃºltiplos subagentes Sonnet para criar componentes da pÃ¡gina `/ask` em paralelo e integrar tudo na pÃ¡gina principal.

### EstratÃ©gia
- LanÃ§amento de 4 subagentes Sonnet em paralelo
- Cada agente responsÃ¡vel por um componente especÃ­fico
- CoordenaÃ§Ã£o central para integraÃ§Ã£o e correÃ§Ã£o de erros de tipo

### Componentes Criados (via subagentes)
1. **AskSourcesPanel** â€” Painel lateral com citaÃ§Ãµes e fontes
2. **AskStreamingStatus** â€” Indicador de status de streaming animado
3. **AskModeToggle** â€” Toggle entre modos Auto/Edit/Answer
4. **index.ts** â€” Barrel exports para todos os componentes

### Arquivos Modificados
- `apps/web/src/app/(dashboard)/ask/page.tsx` â€” CorreÃ§Ãµes de tipo:
  - `canvasState.visible` â†’ `canvasState !== 'hidden'` (CanvasState Ã© string union)
  - Adicionado `chatId` prop obrigatÃ³ria ao ChatInterface
  - Adicionado wrapper com largura fixa para AskSourcesPanel

### VerificaÃ§Ãµes
- âœ… Lint passou sem erros
- âœ… Type-check passou para ask/page.tsx
- âœ… Todos os componentes exportados corretamente
- âœ… IntegraÃ§Ã£o com stores existentes (useChatStore, useCanvasStore, useContextStore)

### Aprendizados
- `useCanvasStore` retorna `state` como string ('hidden'|'normal'|'expanded'), nÃ£o objeto
- `ChatInterface` requer `chatId` como prop obrigatÃ³ria
- Subagentes Sonnet trabalham eficientemente em paralelo para criar componentes independentes

---

## 2026-02-05 â€” SessÃ£o 125: CriaÃ§Ã£o do Componente AskSourcesPanel

### Objetivo
Criar o componente `AskSourcesPanel` para a pÃ¡gina `/ask` do Iudex, exibindo citaÃ§Ãµes com sinais Shepard's e itens de contexto selecionados pelo usuÃ¡rio.

### Arquivos Criados
- `/Users/nicholasjacob/Documents/Aplicativos/Iudex/apps/web/src/components/ask/ask-sources-panel.tsx` â€” Componente React com painel lateral de fontes e citaÃ§Ãµes
- `/Users/nicholasjacob/Documents/Aplicativos/Iudex/apps/web/src/components/ask/ask-sources-panel.example.tsx` â€” Arquivo de exemplo de uso do componente

### ImplementaÃ§Ã£o
Componente criado com as seguintes caracterÃ­sticas:
- ExibiÃ§Ã£o de citaÃ§Ãµes com sinais Shepard's (positivo/verde, negativo/vermelho, cautela/amarelo, neutro/cinza)
- Ãcones lucide-react para cada tipo de sinal (CheckCircle, AlertCircle, MinusCircle)
- HoverCard com preview de snippet ao passar o mouse sobre citaÃ§Ã£o
- SeÃ§Ãµes colapsÃ¡veis para "CitaÃ§Ãµes" e "Contexto"
- Suporte a todos os tipos de contexto da store: file, folder, link, model, legislation, jurisprudence, audio
- Ãcones especÃ­ficos por tipo de contexto (FileText, Folder, LinkIcon, BrainCircuit, BookOpen, Scale, Mic)
- BotÃ£o de remoÃ§Ã£o de item de contexto (aparece ao hover)
- Links externos clicÃ¡veis para citaÃ§Ãµes com URL
- Estado vazio com mensagem e Ã­cone
- ScrollArea para conteÃºdo scrollÃ¡vel
- Design compacto para painel lateral usando padrÃµes shadcn/ui

### Interface Props
```typescript
interface AskSourcesPanelProps {
  citations: Array<{
    id: string;
    title: string;
    source: string;
    snippet?: string;
    signal?: 'positive' | 'negative' | 'caution' | 'neutral';
    url?: string;
  }>;
  contextItems: ContextItem[]; // Da store context-store
  onRemoveItem: (id: string) => void;
  onClose: () => void;
}
```

### VerificaÃ§Ã£o
- âœ… Lint passou sem erros (`npm run lint`)
- âœ… Componente compatÃ­vel com interface `ContextItem` da store
- âœ… Componente jÃ¡ exportado corretamente em `index.ts`
- âš ï¸ Type-check com erros prÃ©-existentes no `page.tsx` (nÃ£o relacionados ao novo componente)

### PadrÃµes Seguidos
- Componentes funcionais com TypeScript estrito
- Uso de tipos importados da store (`ContextItem` de `@/stores/context-store`)
- HoverCard do shadcn/ui para preview de snippets
- Collapsible do shadcn/ui para seÃ§Ãµes expansÃ­veis
- Badge com variantes customizadas por sinal Shepard's
- cn() para classes condicionais
- Mensagens em portuguÃªs brasileiro
- Estado local com useState para controle de collapse

### IntegraÃ§Ã£o com Sistema Existente
O componente foi integrado na pÃ¡gina `/ask` (apps/web/src/app/(dashboard)/ask/page.tsx) e utiliza:
- `useContextStore` para gerenciar itens de contexto
- FunÃ§Ã£o `removeItem` da store para remoÃ§Ã£o de itens
- Interface consistente com outros componentes do sistema

---

## 2026-02-05 â€” SessÃ£o 124: CriaÃ§Ã£o do Componente AskStreamingStatus

### Objetivo
Criar o componente `AskStreamingStatus` para a pÃ¡gina `/ask` do Iudex, exibindo status de streaming com animaÃ§Ãµes e contadores de etapas.

### Arquivos Criados
- `/Users/nicholasjacob/Documents/Aplicativos/Iudex/apps/web/src/components/ask/ask-streaming-status.tsx` â€” Componente React com animaÃ§Ãµes de streaming

### Arquivos Modificados
- `/Users/nicholasjacob/Documents/Aplicativos/Iudex/apps/web/src/components/ask/index.ts` â€” Adicionadas exportaÃ§Ãµes de `AskSourcesPanel` e `AskStreamingStatus`

### ImplementaÃ§Ã£o
Componente criado com as seguintes caracterÃ­sticas:
- AnimaÃ§Ã£o de loader (Loader2) com spin quando `isStreaming=true`
- Ãcone de check (Check) quando completado
- Badge pulsante mostrando nÃºmero da etapa atual
- Mensagens de status contextuais em portuguÃªs brasileiro
- Design compacto para header usando padrÃµes do shadcn/ui
- Classes condicionais com cn() de @/lib/utils
- Cores: indigo para streaming, verde para concluÃ­do

### Interface Props
```typescript
interface AskStreamingStatusProps {
  status: string;        // Mensagem de status
  stepsCount: number;    // NÃºmero da etapa atual
  isStreaming: boolean;  // Se estÃ¡ em streaming
}
```

### VerificaÃ§Ã£o
- âœ… Lint passou sem erros (`npm run lint`)
- âš ï¸ Type-check com erros prÃ©-existentes no `page.tsx` (nÃ£o relacionados ao novo componente)
- âœ… Componente exportado corretamente em `index.ts`

### PadrÃµes Seguidos
- Componentes funcionais com TypeScript estrito
- Uso de lucide-react para Ã­cones (Loader2, Check)
- Badge component do shadcn/ui
- AnimaÃ§Ãµes com Tailwind (animate-spin, animate-pulse)
- Mensagens em portuguÃªs brasileiro
- cn() para classes condicionais

---

## 2026-02-05 â€” SessÃ£o 123: ComparaÃ§Ã£o Harvey vs Iudex

### Objetivo
Comparar funcionalidades do Harvey AI (workflows) com o Iudex para identificar gaps e confirmar paridade de features.

### AnÃ¡lise Realizada

Analisei a pÃ¡gina de workflows do Harvey (`help.harvey.ai/articles/assistant-workflows`) e comparei com os templates existentes em `apps/api/app/scripts/seed_workflow_templates.py`.

### Resultado: ~90% de Paridade

| Harvey | Iudex | Status |
|--------|-------|--------|
| Translate | Traduzir Documento | âœ… |
| Proofread | Revisar Ortografia e GramÃ¡tica | âœ… |
| Timeline | Extrair Linha do Tempo | âœ… |
| Client Alert | Rascunhar Alerta ao Cliente | âœ… |
| Redline Summary | Resumir AlteraÃ§Ãµes de Redline | âœ… |
| Post-Closing Timeline | Cronograma PÃ³s-Fechamento | âœ… |
| Deposition Analysis | Analisar TranscriÃ§Ã£o de Depoimento | âœ… |
| Discovery Summary | Resumir Respostas de Discovery | âœ… |
| Diligence Insights | Due Diligence de Fornecedor | âœ… |
| SEC Form 8-K | - | âŒ (EUA) |

### Features Exclusivas do Iudex (nÃ£o no Harvey)
- Cronologia + Teses + Provas (litigation BR)
- RevisÃ£o de PolÃ­tica de Privacidade (LGPD)

### ConclusÃ£o
Os Ãºnicos gaps sÃ£o templates US-especÃ­ficos (SEC 8-K, Interim Covenants) que nÃ£o sÃ£o relevantes para software jurÃ­dico brasileiro. **NÃ£o hÃ¡ implementaÃ§Ã£o necessÃ¡ria.**

### VerificaÃ§Ã£o
- âœ… `@iudex/web` type-check passa sem erros
- âš ï¸ Erros prÃ©-existentes em `@iudex/tribunais/captcha-solver.ts` (nÃ£o relacionado)

---

## 2026-02-05 â€” SessÃ£o 122: Captura de AnimaÃ§Ãµes de Streaming do Harvey

### Objetivo
Capturar screenshots dos vÃ­deos do Harvey AI mostrando as animaÃ§Ãµes de streaming dinÃ¢mico para documentar os comportamentos de UI a serem replicados na pÃ¡gina `/ask`.

### Screenshots Capturados (9 novos, 21 total)

| Arquivo | DescriÃ§Ã£o |
|---------|-----------|
| `harvey-video-streaming-1.png` | UI Inicial - Input + Workflows recomendados |
| `harvey-video-streaming-2.png` | Canvas + Sources Panel - Layout completo |
| `harvey-video-streaming-3.png` | Estados de Streaming - "Answering...", "Generating new version..." |
| `harvey-video-streaming-4.png` | LexisNexis Case View - Shepard's Panel com breakdown |
| `harvey-video-streaming-5.png` | Popup de SugestÃ£o - DetecÃ§Ã£o automÃ¡tica de query jurÃ­dica |
| `harvey-video-streaming-6.png` | Hover Preview - CitaÃ§Ã£o com snippet destacado |
| `harvey-video-streaming-7.png` | Follow-ups Sugeridos - Lista de perguntas relacionadas |
| `harvey-video-streaming-8.png` | Layout 3 Colunas - Thread + Canvas + Version History |
| `harvey-video-streaming-9.png` | Estados em Tempo Real - "Adding citations...", "Edits complete" |

### Elementos de UI Documentados

1. **Estados de Streaming DinÃ¢mico**:
   - "Answering..." com spinner
   - "Adding citations..." durante busca
   - "Generating new version..." durante ediÃ§Ã£o do canvas
   - "Finished in N steps" com contador

2. **Popup de SugestÃ£o de Fonte**:
   - DetecÃ§Ã£o automÃ¡tica de query jurÃ­dica
   - JurisdiÃ§Ãµes prÃ©-preenchidas
   - BotÃµes "Yes, ask LexisNexisÂ®" / "No, answer without it"

3. **Hover Preview de CitaÃ§Ãµes**:
   - Shepard's signal colorido
   - Snippet com destaque em amarelo
   - BotÃ£o "View reference â†’"

4. **Follow-ups Sugeridos**:
   - Lista de perguntas relacionadas geradas automaticamente

5. **Version History**:
   - Timeline de versÃµes com timestamps
   - Indicador "No code changes"
   - Contagem de steps por versÃ£o

6. **Mode Selector**:
   - Toggle: Auto | Edit | Answer

### Plano Atualizado
- Adicionada seÃ§Ã£o 12.4 em `docs/PLAN_HARVEY_CHAT.md` com especificaÃ§Ãµes detalhadas de:
  - Estados de streaming dinÃ¢mico
  - Componentes React propostos
  - Tipos de eventos SSE
  - ImplementaÃ§Ã£o do backend

### PrÃ³ximos Passos
1. Implementar estrutura de arquivos da pÃ¡gina `/ask`
2. Criar store `ask-store.ts` com estado inicial
3. Implementar componentes de streaming UI
4. Criar endpoint `/api/ask/chat` com SSE

---

## 2026-02-05 â€” SessÃ£o 121: SimplificaÃ§Ã£o UI do Chat

### Objetivo
Simplificar a toolbar do chat removendo Ã­cones desnecessÃ¡rios (Scale/balanÃ§a, Zap/raio), removendo labels de botÃµes e tornando a barra de contexto mais compacta.

### Arquivos Modificados

#### `apps/web/src/components/chat/chat-input.tsx`
- Removido ~630 linhas de dead code (Legacy AI Controls Popover)
- Removidos labels de Template e Canvas (sÃ³ Ã­cones)
- Context bar movida para inline compacta junto ao Send
- Removidos botÃµes @, # e Mic (nÃ£o funcionavam)
- Removido import de Zap, AtSign, Hash, Mic

#### `apps/web/src/components/chat/deep-research-button.tsx`
- Ãcone Microscope â†’ Search (lupa)
- Removido label "Deep Res."

#### `apps/web/src/components/chat/slash-command-menu.tsx`
- Zap â†’ Bot (comandos de modelo)
- Zap â†’ Sparkles (fallback)
- Zap â†’ Settings2 (comandos de template)
- Scale â†’ Columns2 (multi-modelo)

#### `apps/web/src/components/chat/context-dashboard.tsx`
- Zap â†’ Sparkles (header "AÃ§Ãµes RÃ¡pidas")

#### `apps/web/src/components/chat/at-command-menu.tsx`
- Scale â†’ BookOpen (jurisprudÃªncia)

#### `apps/web/src/components/chat/sources-badge.tsx`
- Scale â†’ BookOpen (tipo jurisprudÃªncia)

#### `apps/web/src/components/chat/chat-interface.tsx`
- Scale â†’ FileText (sugestÃ£o "Redija petiÃ§Ã£o")

#### `apps/web/src/components/chat/model-selector.tsx`
- Zap â†’ Bot (modo padrÃ£o)
- Scale â†’ Columns2 (modo multi-modelo)

#### `apps/web/src/lib/use-graph.ts`
- Corrigido erro de Rules of Hooks (hooks chamados condicionalmente)

### AdiÃ§Ã£o: BotÃ£o de Prompts Salvos

#### `apps/web/src/components/chat/chat-input.tsx`
- Adicionado Ã­cone ğŸ”– Bookmark na toolbar (apÃ³s attach)
- Ao clicar, abre o SlashCommandMenu com todos os prompts (predefinidos + salvos)
- Tooltip: "Prompts salvos (ou digite /)"
- Estado visual: amber quando menu estÃ¡ aberto

### Resultado Visual
```
ANTES: [==] [Model â–¼] [ğŸ“„ Template â–¼] [â–¢ Canvas] | [Fontes â–¼] [ğŸ”¬ Deep Res. â–¼] [âš™] | [ğŸ“] [@] [#] [ğŸ¤] [Send]
       [â•â•â•â•â•â•â•â•â•â•â• Contexto: 45% (84K / 200K) â•â•â•â•â•â•â•â•â•â•â•]

DEPOIS: [==] [Model â–¼] [ğŸ“„] [â–¢] | [Fontes â–¼] [ğŸ” â–¼] [âš™] | [ğŸ“] [ğŸ”–] [â•45%â•] [Send]
```

### VerificaÃ§Ã£o
- Lint: âœ… 0 erros
- Type-check: âœ… Passou

---

## 2026-02-04 â€” SessÃ£o 120: ImplementaÃ§Ã£o Tool ask_graph (Graph Ask)

### Objetivo
Implementar tool `ask_graph` para consultas ao knowledge graph via operaÃ§Ãµes tipadas (NL â†’ Intent â†’ Template Cypher), seguindo abordagem segura recomendada.

### Arquitetura

**Abordagem segura (NL â†’ Intent â†’ Template):**
```
UsuÃ¡rio: "Quais artigos da Lei 8.666 citam licitaÃ§Ã£o?"
           â†“
LLM interpreta â†’ { operation: "cooccurrence", entity1_id: "lei_8666", entity2_id: "licitacao" }
           â†“
Backend compila â†’ Template Cypher FIXO com $tenant_id injetado pelo cÃ³digo
           â†“
Executa com seguranÃ§a garantida
```

**OperaÃ§Ãµes suportadas:**
- `path` â€” Caminho entre entidades
- `neighbors` â€” Vizinhos semÃ¢nticos
- `cooccurrence` â€” Co-ocorrÃªncia em documentos
- `search` â€” Busca de entidades
- `count` â€” Contagem com filtros

### Arquivos Criados

#### `apps/api/app/services/graph_ask_service.py`
- Service com templates Cypher seguros
- ValidaÃ§Ã£o de parÃ¢metros por operaÃ§Ã£o
- InjeÃ§Ã£o automÃ¡tica de `tenant_id`/`scope`/`case_id`
- Limites de seguranÃ§a (max_hops=6, limit=100, timeout)

#### `apps/api/app/api/endpoints/graph_ask.py`
- Endpoint `POST /graph/ask` (unificado)
- Endpoints especÃ­ficos: `/ask/path`, `/ask/neighbors`, `/ask/cooccurrence`, `/ask/search`, `/ask/count`
- Health check `/ask/health`

### Arquivos Modificados

#### `apps/api/app/api/routes.py`
- Adicionado import de `graph_ask`
- Registrado router em `/graph` (prefixo)

#### `apps/api/app/services/ai/shared/tool_handlers.py`
- Adicionado handler `handle_ask_graph`
- Registrado em `_register_handlers()`

#### `apps/api/app/services/ai/shared/unified_tools.py`
- Adicionada tool `ASK_GRAPH_TOOL` com schema completo
- IncluÃ­da em `ALL_UNIFIED_TOOLS`

### SeguranÃ§a

- âœ… Sem Cypher arbitrÃ¡rio (apenas templates fixos)
- âœ… Tenant/scope injetados pelo backend (nÃ£o pelo usuÃ¡rio)
- âœ… Limites de `max_hops` (â‰¤6) e `limit` (â‰¤100)
- âœ… Timeout de 5s por query
- âœ… Blocklist de operaÃ§Ãµes perigosas nÃ£o se aplica (nÃ£o hÃ¡ Cypher livre)

### Uso pelos Agentes

A tool `ask_graph` estÃ¡ disponÃ­vel automaticamente para Claude, GPT e Gemini via Tool Gateway:

```python
# Exemplo de chamada pelo agente
ask_graph({
    "operation": "path",
    "params": {
        "source_id": "art_5_CF",
        "target_id": "sumula_473_STF",
        "max_hops": 4
    }
})
```

### CorreÃ§Ãµes de SeguranÃ§a (GPT Review)

ApÃ³s revisÃ£o do GPT, foram aplicadas correÃ§Ãµes importantes:

#### 1. ContextVar para isolamento (`sdk_tools.py`)
- Mudou de variÃ¡vel global para `contextvars.ContextVar`
- Evita vazamento de tenant/case entre requests concorrentes

#### 2. OrgContext no endpoint (`graph_ask.py`)
- Usa `ctx.tenant_id` (organization_id) em vez de `user.id`
- Verifica `UserRole.ADMIN` para `show_template`

#### 3. ValidaÃ§Ãµes de scope (`graph_ask_service.py`)
- Bloqueia `scope=group` (evita bypass RBAC)
- Exige `case_id` quando `scope=local`
- Adiciona filtro `sigilo IS NULL OR sigilo = false` em todas queries

#### 4. Tool no Claude SDK (`sdk_tools.py`)
- `ask_graph` registrada em `_ALL_TOOLS` (7 tools total)
- Usa ContextVar para tenant/case isolados

#### 5. InjeÃ§Ã£o de contexto no executor (`executor.py`)
- `set_iudex_tool_context()` chamado antes do loop do SDK
- Resolve `tenant_id` via `organization_id` quando hÃ¡ db

#### 6. ToolExecutionContext com tenant_id (`tool_handlers.py`)
- Adicionado campo `tenant_id` ao contexto
- Handler usa `ctx.tenant_id` com fallback para `ctx.user_id`

---

## 2026-02-04 â€” SessÃ£o 119: AnÃ¡lise Neo4j Aura Agent vs Sistema Iudex

### Objetivo
AnÃ¡lise holÃ­stica comparando o novo Neo4j Aura Agent com a arquitetura atual de GraphRAG, agentes LangGraph e visualizaÃ§Ã£o de grafos do Iudex.

### Resultado da AnÃ¡lise

**ConclusÃ£o Principal:** Neo4j Aura Agent **nÃ£o substitui** o sistema atual do Iudex.

#### Motivos:
| LimitaÃ§Ã£o Aura Agent | Sistema Iudex |
|---------------------|---------------|
| Schema genÃ©rico | Schema jurÃ­dico customizado (Claim, Evidence, Actor, Issue) |
| Agente Ãºnico | LangGraph com 22+ nÃ³s e debate multi-modelo |
| Sem HIL | 6 pontos de Human-in-the-Loop |
| Cloud-only | Self-hosted possÃ­vel |
| Retrieval simples | RRF fusion (lexical + vector + graph) |

#### Valor potencial:
- **MCP Server** para expor grafo via Claude Desktop/Cursor
- Usar `mcp-neo4j-cypher` (open-source) em vez de Aura Agent

### Arquivos Analisados
- `apps/api/app/services/rag/core/neo4j_mvp.py` â€” GraphRAG Neo4j MVP
- `apps/api/app/services/ai/langgraph_legal_workflow.py` â€” Workflow 22+ nÃ³s
- `apps/api/app/services/ai/claude_agent/executor.py` â€” Claude Agent autÃ´nomo
- `apps/web/src/app/(dashboard)/graph/page.tsx` â€” VisualizaÃ§Ã£o NVL

### DocumentaÃ§Ã£o Gerada
- `.claude/plans/buzzing-whistling-spindle.md` â€” AnÃ¡lise completa com tabelas comparativas

### Fontes Consultadas
- [Neo4j Aura Agent - Developer Guide](https://neo4j.com/developer/genai-ecosystem/aura-agent/)
- [Neo4j MCP Server - GitHub](https://github.com/neo4j-contrib/mcp-neo4j)
- [LangGraph + Neo4j Tutorial](https://neo4j.com/blog/developer/neo4j-graphrag-workflow-langchain-langgraph/)

---

## 2026-02-04 â€” SessÃ£o 118: InferÃªncia AutomÃ¡tica de PapÃ©is + RemoÃ§Ã£o de Enrollment

### Objetivo
Substituir enrollment de voz por inferÃªncia automÃ¡tica de papÃ©is via LLM para audiÃªncias/reuniÃµes.

### Arquivos Modificados

#### `apps/api/app/services/transcription_service.py`
- Nova funÃ§Ã£o `_infer_speaker_roles_with_llm()` â€” infere papÃ©is (Juiz, Advogado, Testemunha, etc.) baseado no conteÃºdo das falas
- Pipeline de audiÃªncias agora usa inferÃªncia LLM em vez de matching de embeddings de voz
- Removido warning "sem_match_enrollment"

#### `apps/api/app/api/endpoints/transcription.py`
- Removido endpoint `POST /hearing/enroll` (deprecado)

#### `apps/web/src/app/(dashboard)/transcription/page.tsx`
- Removidos estados: `enrollName`, `enrollRole`, `enrollFile`, `isEnrolling`
- Removida funÃ§Ã£o `handleEnrollSpeaker()`
- Removida seÃ§Ã£o de UI "Enrollment de voz"
- Removida referÃªncia ao warning "sem_match_enrollment"

#### `apps/web/src/lib/api-client.ts`
- Removida funÃ§Ã£o `enrollHearingSpeaker()`

#### `mlx_vomo.py`
- Atualizado `_segments_to_text()` (v2.29) para agrupar segmentos por intervalo de 60s em APOSTILA/FIDELIDADE
- Fix: timestamps nÃ£o mais repetidos para cada palavra

### Como Funciona a InferÃªncia de PapÃ©is

```python
# Prompt para o LLM analisa amostras de cada speaker
prompt = """Analise as falas de uma audiÃªncia judicial e identifique o PAPEL de cada falante.
PAPÃ‰IS POSSÃVEIS: Juiz, Advogado, Promotor, Defensor, Testemunha, Perito, Parte, EscrivÃ£o, Outro

FALAS POR SPEAKER:
SPEAKER 1:
  - "Bom dia. Declaro aberta a audiÃªncia."
  - "Defiro a juntada do documento."
SPEAKER 2:
  - "JoÃ£o da Silva Santos."

Responda em JSON: {"roles": {"SPEAKER 1": "Juiz", "SPEAKER 2": "Testemunha"}}
"""
```

### BenefÃ­cios
- NÃ£o requer cadastro prÃ©vio de vozes
- Funciona automaticamente com qualquer backend (Whisper, AssemblyAI, ElevenLabs)
- InferÃªncia baseada em contexto real das falas
- Reduz complexidade do pipeline

---

## 2026-02-04 â€” SessÃ£o 117: RecuperaÃ§Ã£o de TranscriÃ§Ãµes AssemblyAI/ElevenLabs

### Objetivo
Adicionar funcionalidade para recuperar transcriÃ§Ãµes que ficaram pendentes ou perdidas devido a desconexÃ£o com AssemblyAI/ElevenLabs.

### Arquivos Modificados

#### `apps/api/app/api/endpoints/transcription.py`
- Novo schema `PendingTranscription` para listar transcriÃ§Ãµes pendentes
- Endpoint `GET /transcription/pending` â€” lista todas transcriÃ§Ãµes em cache
- Endpoint `POST /transcription/resume` â€” retoma polling de transcriÃ§Ã£o AssemblyAI
- Endpoint `DELETE /transcription/cache/{file_hash}` â€” limpa cache de transcriÃ§Ã£o

#### `apps/web/src/app/(dashboard)/transcription/page.tsx`
- Novos estados: `recoveryDialogOpen`, `pendingTranscriptions`, `isLoadingPending`, `isResuming`
- FunÃ§Ã£o `loadPendingTranscriptions()` â€” busca transcriÃ§Ãµes pendentes da API
- FunÃ§Ã£o `handleResumeTranscription()` â€” retoma polling no AssemblyAI
- FunÃ§Ã£o `handleClearTranscriptionCache()` â€” limpa cache local
- BotÃ£o "Recuperar transcriÃ§Ã£o anterior" abaixo do botÃ£o "Transcrever"
- DiÃ¡logo modal para visualizar e gerenciar transcriÃ§Ãµes pendentes

### Funcionalidades

1. **Listar Pendentes**: Mostra todas transcriÃ§Ãµes em cache (processando, completas, erro)
2. **Retomar AssemblyAI**: Reconecta ao polling do transcript_id salvo
3. **Limpar Cache**: Remove cache de transcriÃ§Ã£o especÃ­fica
4. **UI Integrada**: BotÃ£o no painel de configuraÃ§Ã£o + diÃ¡logo de gerenciamento

### Uso
1. Clicar em "Recuperar transcriÃ§Ã£o anterior" no painel de nova transcriÃ§Ã£o
2. Visualizar transcriÃ§Ãµes pendentes no diÃ¡logo
3. Clicar "Retomar" para reconectar ao AssemblyAI
4. TranscriÃ§Ã£o recuperada fica disponÃ­vel em cache para reprocessamento

---

## 2026-02-04 â€” SessÃ£o 116: OtimizaÃ§Ã£o Pipeline MLX Vomo para Ãudios Longos

### Objetivo
Resolver 429 RESOURCE_EXHAUSTED no pipeline de transcriÃ§Ã£o e acelerar processamento de Ã¡udios longos com paralelizaÃ§Ã£o.

### Problemas Resolvidos

1. **429 RESOURCE_EXHAUSTED** â€” Rate limit do Gemini excedido
2. **React infinite loop** â€” Loop infinito no quality-panel.tsx ao clicar em Qualidade

### Arquivos Modificados

#### `audit_fidelity_preventive.py`
- Adicionada funÃ§Ã£o `_call_gemini_with_retry()` com backoff exponencial (4s, 8s, 16s, 32s, 64s)
- ParalelizaÃ§Ã£o da auditoria com `ThreadPoolExecutor` (IUDEX_PARALLEL_AUDIT)
- Nova constante `PARALLEL_AUDIT_WORKERS = 3`

#### `mlx_vomo.py`
- Nova constante `PARALLEL_CHUNKS` para paralelizaÃ§Ã£o de chunks (v2.40)
- FunÃ§Ã£o helper `_process_single_chunk()` para processamento isolado
- Modo paralelo com `asyncio.gather()` + semÃ¡foro quando `IUDEX_PARALLEL_CHUNKS > 1`
- Split de revisÃ£o leve para docs > 400k chars (v2.3 em `ai_structure_review_lite`)

#### `apps/web/src/components/dashboard/quality-panel.tsx`
- Removida dependÃªncia circular no useEffect (linha 536)
- Usando `uiStateRef.current` em vez de `storedUiState` para evitar loop

### Novas VariÃ¡veis de Ambiente

```bash
IUDEX_PARALLEL_CHUNKS=1        # Chunks simultÃ¢neos (default: 1 = sequencial)
IUDEX_PARALLEL_AUDIT=3         # Auditorias simultÃ¢neas (default: 3)
IUDEX_SPLIT_REVIEW_THRESHOLD=400000  # Chars para split review
```

### Impacto Estimado

| CenÃ¡rio | Antes | Depois | Speedup |
|---------|-------|--------|---------|
| Ãudio 2h (20 chunks) | ~15 min | ~5 min | 3x |
| Auditoria 20 chunks | ~5 min | ~1.5 min | 3-4x |
| Rate limit 429 | Falha | Retry com backoff | âœ“ |

### VerificaÃ§Ã£o
- `python3 -m py_compile audit_fidelity_preventive.py` âœ…
- `python3 -m py_compile mlx_vomo.py` âœ…
- `pnpm lint` âœ…

---

## 2026-02-04 â€” SessÃ£o 115: Whisper Server para RunPod (GPU Externa)

### Objetivo
Implementar integraÃ§Ã£o completa com servidor Whisper em GPU externa (RunPod) com processamento assÃ­ncrono (job_id + polling) e recuperaÃ§Ã£o de jobs interrompidos.

### Arquivos Criados

#### `scripts/whisper_server_runpod.py`
Servidor FastAPI completo para deploy no RunPod:
- `POST /transcribe` â€” Submit arquivo, retorna job_id
- `GET /status/{job_id}` â€” Status e progresso (0-100%)
- `GET /result/{job_id}` â€” Resultado da transcriÃ§Ã£o
- `DELETE /job/{job_id}` â€” Cancela job
- `GET /health` â€” Health check

Features:
- AutenticaÃ§Ã£o via Bearer token
- Processamento assÃ­ncrono com semÃ¡foro (max concurrent jobs)
- Limpeza automÃ¡tica de jobs antigos
- Suporte a faster-whisper com GPU

### Arquivos Modificados

#### `app/services/transcription_service.py`
Novos mÃ©todos de integraÃ§Ã£o (~350 linhas):
- `_get_whisper_server_url()` / `_get_whisper_server_key()` â€” Config
- `_is_whisper_server_available()` â€” Verifica disponibilidade
- `_transcribe_whisper_server_with_progress()` â€” VersÃ£o async com SSE
- `_poll_whisper_server_job()` â€” Polling async
- `_format_whisper_server_result()` â€” Formata resultado
- `_transcribe_whisper_server_sync()` â€” VersÃ£o sÃ­ncrona
- `_poll_whisper_server_job_sync()` â€” Polling sÃ­ncrono

#### `app/core/config.py`
Novas configuraÃ§Ãµes:
- `WHISPER_SERVER_URL` â€” URL do servidor (ex: https://pod-8080.runpod.net)
- `WHISPER_SERVER_API_KEY` â€” API key
- `WHISPER_SERVER_MODEL` â€” Modelo padrÃ£o (large-v3)

### Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    IUDEX (Cliente)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Verificar cache (hash + config)                         â”‚
â”‚     â”œâ”€ COMPLETO â†’ Retorna resultado                         â”‚
â”‚     â””â”€ PROCESSING â†’ Retoma polling com job_id               â”‚
â”‚                                                              â”‚
â”‚  2. Upload arquivo â†’ POST /transcribe                        â”‚
â”‚     â””â”€ Retorna job_id                                        â”‚
â”‚                                                              â”‚
â”‚  3. SALVAR CACHE IMEDIATAMENTE (job_id, status=processing)  â”‚
â”‚                                                              â”‚
â”‚  4. Polling â†’ GET /status/{job_id}                          â”‚
â”‚     â””â”€ Atualiza progresso no frontend                       â”‚
â”‚                                                              â”‚
â”‚  5. Resultado â†’ GET /result/{job_id}                        â”‚
â”‚     â””â”€ Atualiza cache (status=completed)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 RUNPOD (Servidor GPU)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  POST /transcribe                                            â”‚
â”‚    â†’ Salva arquivo temporÃ¡rio                                â”‚
â”‚    â†’ Cria job (status=queued)                                â”‚
â”‚    â†’ Agenda processamento em background                      â”‚
â”‚    â†’ Retorna job_id                                          â”‚
â”‚                                                              â”‚
â”‚  Background Task:                                            â”‚
â”‚    â†’ Carrega Whisper (lazy)                                  â”‚
â”‚    â†’ Transcreve (atualiza progress)                         â”‚
â”‚    â†’ Salva resultado                                         â”‚
â”‚    â†’ Limpa arquivo temporÃ¡rio                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Deploy no RunPod

```bash
# 1. Criar Pod com GPU (RTX 4090 ou A100)
# 2. Instalar dependÃªncias
pip install fastapi uvicorn faster-whisper python-multipart aiofiles

# 3. Configurar variÃ¡veis
export WHISPER_API_KEY="sua-chave-secreta"
export WHISPER_MODEL="large-v3"
export WHISPER_DEVICE="cuda"

# 4. Iniciar servidor
uvicorn whisper_server_runpod:app --host 0.0.0.0 --port 8080

# 5. Configurar no .env do Iudex
WHISPER_SERVER_URL=https://your-pod-8080.proxy.runpod.net
WHISPER_SERVER_API_KEY=sua-chave-secreta
```

### VerificaÃ§Ã£o
- `python3 -m py_compile` â€” OK para todos os arquivos

---

## 2026-02-04 â€” SessÃ£o 114: Redesign Chat Input (Estilo Perplexity) + CorreÃ§Ãµes

### Objetivo
Redesenhar a UI do chat input inspirado no Perplexity Pro, mantendo todos os Ã­cones originais.

### Arquivos Criados
- `apps/web/src/components/chat/sources-badge.tsx` â€” Badge com Ã­cones das fontes ativas + dropdown checkboxes
- `apps/web/src/components/chat/deep-research-button.tsx` â€” BotÃ£o dedicado Deep Research
- `apps/web/src/components/chat/context-usage-bar.tsx` â€” Barra de % uso do contexto

### Arquivos Modificados
- `apps/web/src/components/chat/chat-input.tsx` â€” IntegraÃ§Ã£o + botÃ£o Mic adicionado
- `apps/web/src/stores/chat-store.ts` â€” Estado `sourceSelection` granular

### Layout Final
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Digite sua mensagem...                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[Columns2] [ModelSelector] [FileText Template] [Canvas] | [SourcesBadge] [DeepResearch] | [Params]
[Paperclip] [AtSign] [Hash] [Mic]                                              [Send]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“Š Contexto: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 42% (84K / 200K tokens)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Ãcones Mantidos
- Columns2 â€” Comparar modelos
- FileText â€” Template selector
- PanelRight â€” Canvas
- SlidersHorizontal â€” ParÃ¢metros
- Paperclip â€” Anexar
- AtSign â€” MenÃ§Ã£o @
- Hash â€” Tag #
- Mic â€” Ãudio (NOVO)
- Send â€” Enviar

### ValidaÃ§Ã£o
- Lint: OK
- Type-check: OK

---

## 2026-02-04 â€” SessÃ£o 113: Sistema de Cache para RecuperaÃ§Ã£o de TranscriÃ§Ãµes AssemblyAI

### Objetivo
Implementar sistema de cache para persistir `transcript_id` do AssemblyAI imediatamente apÃ³s submit, permitindo recuperaÃ§Ã£o de transcriÃ§Ãµes interrompidas por crash, timeout ou perda de conexÃ£o.

### Problema Resolvido
- Quando um job de transcriÃ§Ã£o usando AssemblyAI era interrompido, o `transcript_id` era perdido (estava apenas em memÃ³ria)
- A transcriÃ§Ã£o jÃ¡ processada no AssemblyAI nÃ£o podia ser recuperada
- O usuÃ¡rio precisava reenviar o Ã¡udio (custo duplicado ~$0.37/hora de Ã¡udio)

### Arquivos Modificados

#### `apps/api/app/services/transcription_service.py`
Novos mÃ©todos de cache AAI (linhas ~4590-4760):
- `_get_aai_cache_dir()` â€” Retorna diretÃ³rio de cache (`storage/aai_transcripts/`)
- `_get_aai_cache_path(file_hash)` â€” Retorna caminho do cache para um arquivo
- `_get_aai_config_hash(...)` â€” Calcula hash da configuraÃ§Ã£o para invalidaÃ§Ã£o
- `_save_aai_cache(...)` â€” Persiste transcript_id imediatamente apÃ³s submit
- `_update_aai_cache_status(...)` â€” Atualiza status do cache
- `_fetch_aai_transcript_status(transcript_id)` â€” Busca status no AAI
- `_check_aai_cache(file_path, config_hash)` â€” Verifica cache existente

ModificaÃ§Ãµes em `_transcribe_assemblyai_with_progress()`:
- Verifica cache antes do upload
- Se cache completo, retorna resultado cacheado
- Se cache processando, retoma polling
- Persiste transcript_id imediatamente apÃ³s obtÃª-lo

Novos mÃ©todos auxiliares:
- `_extract_aai_result_from_response()` â€” Extrai resultado de resposta AAI (async)
- `_poll_aai_transcript()` â€” Polling para retomar transcriÃ§Ãµes (async)
- `_extract_aai_result_sync()` â€” VersÃ£o sÃ­ncrona do extrator
- `_poll_aai_transcript_sync()` â€” Polling sÃ­ncrono para retomar

ModificaÃ§Ãµes em `_transcribe_assemblyai_with_roles()`:
- Mesma lÃ³gica de cache para mÃ©todo sÃ­ncrono

#### `apps/api/app/api/endpoints/transcription.py`
ModificaÃ§Ã£o em `_write_vomo_job_result()`:
- Adicionados campos `transcript_id` e `transcription_backend` ao result.json

### Estrutura do Cache
```
storage/aai_transcripts/{file_hash}.json
{
  "file_hash": "sha256...",
  "file_name": "audio.mp3",
  "file_size_bytes": 54000000,
  "transcript_id": "43bf26d5-...",
  "audio_url": "https://cdn.assemblyai.com/...",
  "submitted_at": "2026-02-04T14:26:00Z",
  "completed_at": "2026-02-04T14:26:58Z",
  "status": "completed",
  "config_hash": "abc12345",
  "result_cached": true
}
```

### BenefÃ­cios
| CenÃ¡rio | Antes | Depois |
|---------|-------|--------|
| Crash durante polling | Perde transcriÃ§Ã£o, paga novamente | Recupera do cache |
| Reenvio do mesmo arquivo | Upload + transcriÃ§Ã£o duplicados | Retorna cacheado |
| Erro de rede temporÃ¡rio | Job falha, precisa recriar | Retoma de onde parou |

### VerificaÃ§Ã£o
- `python3 -m py_compile` â€” OK para ambos arquivos

### PrÃ³ximos Passos (Opcional)
- Endpoint `/jobs/{job_id}/recover-aai` para recuperaÃ§Ã£o manual
- Recovery on-boot para jobs com status="running"
- Limpeza automÃ¡tica de cache antigo (>30 dias)

---

## 2026-02-04 â€” SessÃ£o 113b: Cache para ElevenLabs e Whisper Server

### Objetivo
Estender o sistema de cache para outros motores de transcriÃ§Ã£o: ElevenLabs (sÃ­ncrono) e preparar estrutura para Whisper em servidor externo (RunPod).

### AnÃ¡lise dos Motores

| Motor | Tipo | Cache Implementado |
|-------|------|-------------------|
| AssemblyAI | Async (job_id + polling) | âœ… RecuperaÃ§Ã£o de jobs |
| ElevenLabs | SÃ­ncrono (resultado direto) | âœ… Cache de resultados |
| Whisper Server (RunPod) | Futuro - async ou sync | âœ… Estrutura preparada |
| Whisper Local (MLX) | Local | N/A (nÃ£o hÃ¡ servidor) |

### Arquivos Modificados

#### `apps/api/app/services/transcription_service.py`

**Novos mÃ©todos de cache ElevenLabs** (linhas ~5260-5340):
- `_get_elevenlabs_cache_dir()` â€” Retorna `storage/elevenlabs_transcripts/`
- `_get_elevenlabs_cache_path(file_hash)` â€” Caminho do cache
- `_get_elevenlabs_config_hash(...)` â€” Hash para invalidaÃ§Ã£o
- `_save_elevenlabs_cache(...)` â€” Salva resultado completo
- `_check_elevenlabs_cache(...)` â€” Verifica cache existente

**Novos mÃ©todos de cache Whisper Server** (linhas ~5350-5480):
- `_get_whisper_server_cache_dir()` â€” Retorna `storage/whisper_server_transcripts/`
- `_get_whisper_server_cache_path(file_hash)` â€” Caminho do cache
- `_get_whisper_server_config_hash(...)` â€” Hash para invalidaÃ§Ã£o
- `_save_whisper_server_cache(...)` â€” Salva resultado ou job_id
- `_check_whisper_server_cache(...)` â€” Verifica cache existente
- `_update_whisper_server_cache_status(...)` â€” Atualiza status

**ModificaÃ§Ãµes em `_transcribe_elevenlabs_scribe()`**:
- Verifica cache antes de processar
- Salva resultado no cache apÃ³s completar

### Estrutura dos Caches

**ElevenLabs** (`storage/elevenlabs_transcripts/{file_hash}.json`):
```json
{
  "file_hash": "sha256...",
  "config_hash": "abc12345",
  "cached_at": "2026-02-04T...",
  "backend": "elevenlabs",
  "result": { "text": "...", "segments": [...] }
}
```

**Whisper Server** (`storage/whisper_server_transcripts/{file_hash}.json`):
```json
{
  "file_hash": "sha256...",
  "config_hash": "abc12345",
  "job_id": "runpod-job-xxx",
  "status": "processing|completed",
  "backend": "whisper_server",
  "result": { ... }
}
```

### BenefÃ­cios

| Motor | BenefÃ­cio do Cache |
|-------|-------------------|
| ElevenLabs | Evita reprocessamento do mesmo arquivo (economia ~$0.10/min) |
| Whisper Server | RecuperaÃ§Ã£o de jobs + evita reprocessamento |

### VerificaÃ§Ã£o
- `python3 -m py_compile` â€” OK

---

## 2026-02-04 â€” SessÃ£o 112: Redesign do Chat Input (Estilo Perplexity)

### Objetivo
Redesenhar a UI do chat input inspirado no Perplexity Pro, com badge de fontes, Deep Research dedicado, e barra de uso de contexto.

### Arquivos Criados
- `/apps/web/src/components/chat/sources-badge.tsx` â€” Badge com Ã­cones das fontes ativas + dropdown com checkboxes granulares
- `/apps/web/src/components/chat/deep-research-button.tsx` â€” BotÃ£o dedicado para Deep Research com menu Standard/Hard
- `/apps/web/src/components/chat/context-usage-bar.tsx` â€” Barra de progresso mostrando % uso da janela de contexto

### Arquivos Modificados
- `/apps/web/src/components/chat/chat-input.tsx` â€” IntegraÃ§Ã£o dos novos componentes
- `/apps/web/src/components/chat/index.ts` â€” Exports dos novos componentes
- `/apps/web/src/stores/chat-store.ts` â€” Novo estado `sourceSelection` com seleÃ§Ã£o granular de fontes

### Funcionalidades Implementadas

1. **SourcesBadge**:
   - Badge com mini-Ã­cones das fontes ativas (ğŸ“œâš–ï¸ğŸ›ï¸ğŸ“ğŸŒ)
   - Dropdown com seÃ§Ãµes: Web Search, Anexos do Caso, Corpus Global, Corpus Privado, Conectores MCP
   - Checkboxes granulares por arquivo/categoria/projeto/conector
   - Substitui: RAG Scope (radio), DecisÃ£o pesquisa, Modo busca

2. **DeepResearchButton**:
   - BotÃ£o dedicado ğŸ”¬ Deep Research
   - Modos: Standard (1 provider) vs Hard (Multi-Provider)
   - Seletores: Provider (Auto/Google/Perplexity/OpenAI), EsforÃ§o (Low/Medium/High)
   - Hard mode: checkboxes para Gemini, Perplexity, OpenAI, RAG Global, RAG Local

3. **ContextUsageBar**:
   - Barra de progresso: "ğŸ“Š Contexto: â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 42% (84K / 200K)"
   - Cores: Verde (0-50%), Amarelo (51-80%), Vermelho (81-100%)
   - Tooltip com breakdown: sistema, histÃ³rico, anexos, RAG, reserva resposta

4. **Novo estado no chat-store**:
   - `sourceSelection` com seleÃ§Ã£o granular por categoria
   - Helpers: `getActiveSourcesCount()`, `getActiveSourceIcons()`
   - Actions: `toggleSource()`, `selectAllInCategory()`, `deselectAllInCategory()`

### Elementos Mantidos (sem alteraÃ§Ã£o)
- Model Selector com Ã­cones por provider
- Modal de Pontos/Tarifas [?]
- Toggles Standard/Multi-model [âš¡][âš–]
- Barra de ParÃ¢metros (reasoning, thinking budget, verbosity)
- Context Selector inferior (abas: Arquivos, Biblioteca, Ãudio, Link, Juris)
- Footer Corpus Global/Privado
- Ãcones: ğŸ“ Anexar, ğŸ¤ Ãudio, ğŸ“ Canvas, â¤ Enviar

### Comandos Executados
- `npm run lint --workspace=apps/web` â€” OK
- `npm run type-check --workspace=apps/web` â€” OK

### Layout Final
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Digite sua mensagem...                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   ğŸ“  ğŸ¤  ğŸ“  â¤
â”‚ğŸ“œâš–ï¸ğŸ›ï¸ğŸ“ Fontes 5â”‚ â”‚ğŸ”¬ Deep R.â”‚ â”‚[â—] Claude 4.5 â–¼[?]âš¡âš–â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“Š Contexto: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 42% (84K / 200K tokens)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2026-02-04 â€” Sessao 111: Cleanup de UI Obsoleta no ChatInput

### Objetivo
Remover elementos de UI obsoletos do `chat-input.tsx` que foram migrados para o novo componente `SourcesBadge`.

### Arquivos Alterados
- `/apps/web/src/components/chat/chat-input.tsx` â€” RemoÃ§Ã£o de seÃ§Ãµes de UI obsoletas
- `/apps/web/src/stores/chat-store.ts` â€” MarcaÃ§Ã£o de variÃ¡veis de estado como deprecated

### MudanÃ§as Realizadas

1. **SeÃ§Ãµes de UI removidas/comentadas**:
   - "DecisÃ£o de pesquisa" (Auto/Manual) - `researchPolicy` UI
   - "Modo de busca" (Compartilhada/Nativa/HÃ­brida) - `searchMode` radio buttons
   - "Multi-query" toggle - `multiQuery` state UI
   - "Breadth-first" toggle - `breadthFirst` state UI
   - "RAG Scope selector" (SÃ³ Caso/Caso+Global/SÃ³ Global) - `ragScope` UI (agora checkboxes granulares em SourcesBadge)

2. **ComentÃ¡rios DEPRECATED adicionados**:
   - Nos locais onde UI foi removida, adicionados comentÃ¡rios `// DEPRECATED: moved to SourcesBadge`
   - Nos imports de estado, marcados os que nÃ£o tÃªm mais UI neste arquivo

3. **VariÃ¡veis de estado em chat-store.ts marcadas como @deprecated**:
   - `multiQuery: boolean` - UI moved to SourcesBadge
   - `breadthFirst: boolean` - UI moved to SourcesBadge
   - `searchMode` - UI moved to SourcesBadge
   - `researchPolicy` - UI moved to SourcesBadge
   - `ragScope` - UI moved to SourcesBadge with granular checkboxes

### Elementos MANTIDOS (conforme especificaÃ§Ã£o)
- Model selector e toda sua funcionalidade
- Model parameters UI (reasoning level, thinking budget, etc.)
- Points/pricing modal
- Standard/Multi-model toggles
- Canvas button
- Attach button
- Audio button
- Send button
- Context Selector (bottom tabs)
- Corpus footer (Global/Private display)

### DecisÃµes TÃ©cnicas
- Estado mantido no store para compatibilidade com API backend
- Imports mantidos mas comentados para indicar depreciaÃ§Ã£o
- Lint e type-check passando sem erros

---

## 2026-02-04 â€” Sessao 110: Integracao dos Novos Componentes no ChatInput

### Objetivo
Integrar os novos componentes `SourcesBadge`, `DeepResearchButton` e `ContextUsageBar` no arquivo `chat-input.tsx`, reorganizando o layout do toolbar conforme o design spec.

### Arquivos Alterados
- `/apps/web/src/components/chat/chat-input.tsx` â€” Integracao dos novos componentes

### Mudancas Realizadas

1. **Imports adicionados**:
   - `SourcesBadge` from '@/components/chat/sources-badge'
   - `DeepResearchButton` from '@/components/chat/deep-research-button'
   - `ContextUsageBar` from '@/components/chat/context-usage-bar'

2. **Novo layout do toolbar** (linhas 879-886):
   - Substituido o grande Popover de "AI Controls" (Web Search/Deep Research) pelos novos componentes
   - `<SourcesBadge />` â€” Seletor unificado de fontes (web search, MCP, RAG scope)
   - `<DeepResearchButton />` â€” Controles de Deep Research

3. **ContextUsageBar adicionado** (linhas 2640-2643):
   - Posicionado abaixo do toolbar de botoes
   - Mostra uso de contexto em tempo real

4. **Codigo legado preservado**:
   - O antigo Popover de AI Controls foi envolto em `{false && (...)}` para preservar referencia
   - Marcado como "Legacy AI Controls Popover - hidden but preserved for reference"
   - Pode ser removido em cleanup futuro

### Layout Final
```
+------------------------------------------------------------------+
| Textarea de mensagem                                              |
+------------------------------------------------------------------+
| [Compare] [Modelâ–¼] [Templateâ–¼] [Canvas] | [Fontesâ–¼] [Deep Res.â–¼] |
|                                         | [Paramsâ–¼] [ğŸ“] [@] [#] |
+------------------------------------------------------------------+
| Context: [========] 42% (84K / 200K tokens)                       |
+------------------------------------------------------------------+
```

### Decisoes Tecnicas
- Preservado codigo legado (comentado) para referencia durante transicao
- Mantido segundo Popover de "Parametros por modelo" ativo (nao migrado ainda)
- ContextUsageBar usa modo normal (nao compacto) para melhor visibilidade

### Comandos Executados
- `npm run lint --workspace=apps/web` â€” OK
- `npx tsc --noEmit` â€” OK (sem erros de tipo)

---

## 2026-02-04 â€” Sessao 109: Granular Source Selection State no Chat Store

### Objetivo
Adicionar estado de selecao granular de fontes no chat-store para permitir que usuarios selecionem individualmente quais fontes de dados usar em consultas (web search, anexos, corpus global, corpus privado, conectores MCP).

### Arquivos Alterados
- `/apps/web/src/stores/chat-store.ts` â€” Adicionado sourceSelection state e actions

### Funcionalidades Implementadas

1. **Novos Tipos Exportados**:
   - `CorpusGlobalSelection` â€” Interface para selecao de categorias do corpus global
   - `SourceSelection` â€” Interface principal com todas as categorias de fontes
   - `SourceCategory` â€” Union type das categorias disponiveis

2. **Estado `sourceSelection`** com estrutura:
   ```typescript
   {
     webSearch: boolean,
     attachments: Record<string, boolean>, // fileId -> enabled
     corpusGlobal: {
       legislacao: boolean,
       jurisprudencia: boolean,
       pecasModelo: boolean,
       doutrina: boolean,
       sei: boolean
     },
     corpusPrivado: Record<string, boolean>, // projectId -> enabled
     mcpConnectors: Record<string, boolean> // label -> enabled
   }
   ```

3. **Actions Implementadas**:
   - `setSourceSelection(selection)` â€” Substitui toda a selecao
   - `toggleSource(category, id?)` â€” Toggle individual por categoria/id
   - `selectAllInCategory(category)` â€” Seleciona todos em uma categoria
   - `deselectAllInCategory(category)` â€” Deseleciona todos em uma categoria
   - `setAttachmentEnabled(fileId, enabled)` â€” Controle individual de anexo
   - `setCorpusGlobalEnabled(key, enabled)` â€” Controle individual de corpus global
   - `setCorpusPrivadoEnabled(projectId, enabled)` â€” Controle individual de corpus privado
   - `setMcpConnectorEnabled(label, enabled)` â€” Controle individual de conector MCP
   - `getActiveSourcesCount()` â€” Retorna quantidade de fontes ativas
   - `getActiveSourceIcons()` â€” Retorna array de emojis das fontes ativas

4. **Persistencia**:
   - Estado salvo em localStorage com key `iudex_source_selection`
   - Funcoes `loadSourceSelection()` e `persistSourceSelection()` para gerenciamento

5. **Icones por Categoria**:
   - webSearch: ğŸŒ
   - attachments: ğŸ“
   - legislacao: ğŸ“œ
   - jurisprudencia: âš–ï¸
   - pecasModelo: ğŸ“„
   - doutrina: ğŸ“š
   - sei: ğŸ›ï¸
   - corpusPrivado: ğŸ”’
   - mcpConnectors: ğŸ”Œ

### Decisoes Tecnicas
- Mantem compatibilidade com `ragScope` existente
- Valores default: corpusGlobal todo habilitado, outros vazios/desabilitados
- Persistencia automatica em toda alteracao
- Funcoes helper para contagem e icones sao getters (nao state)

### Comandos Executados
- `npm run type-check` â€” OK (erros pre-existentes em outros packages)
- `npm run lint --workspace=apps/web` â€” OK

---

## 2026-02-04 â€” Sessao 108: Criacao do ContextUsageBar para Chat

### Objetivo
Criar componente React `ContextUsageBar` para mostrar visualmente o uso da janela de contexto no chat.

### Arquivos Criados
- `/apps/web/src/components/chat/context-usage-bar.tsx` â€” Componente principal

### Arquivos Alterados
- `/apps/web/src/components/chat/index.ts` â€” Export do novo componente

### Funcionalidades Implementadas
1. **Barra de progresso visual** mostrando % de contexto usado
2. **Formato**: "Contexto: [barra] 42% (84K / 200K tokens)"
3. **Cores por nivel**:
   - 0-50%: Verde (emerald-500)
   - 51-80%: Amarelo (amber-500)
   - 81-100%: Vermelho (red-500) com alerta pulsante
4. **Tooltip detalhado** com breakdown:
   - Nome do modelo e tamanho da janela
   - Sistema + historico: XXK (X%)
   - Anexos (N arquivos): XXK (X%)
   - RAG chunks: XXK (X%)
   - Reserva resposta: XXK (X%)
   - Total usado / Disponivel
5. **Modo compacto** para espacos reduzidos
6. **Calculo dinamico** baseado em:
   - Modelo selecionado (usa menor janela em multi-model)
   - Historico de mensagens
   - Arquivos anexados (context-store)
   - Escopo RAG (case_only, case_and_global, global_only)

### Decisoes Tecnicas
- Estimativa de tokens: ~4 chars = 1 token (aproximacao padrao)
- Reserva de 4096 tokens para resposta
- System prompt estimado em 2000 tokens
- Arquivos anexados: ~2000 tokens cada (media)
- RAG chunks: ~1500 tokens cada

### Comandos Executados
- `npm run lint --workspace=apps/web` â€” OK
- `npm run type-check --workspace=apps/web` â€” Erros pre-existentes em chat-store.ts (nao relacionados)

---

## 2026-02-04 â€” Sessao 107: Criacao do Componente DeepResearchButton

### Objetivo
Criar um componente React dedicado `DeepResearchButton` para a interface de chat do Iudex, extraindo a funcionalidade de Deep Research que estava embutida no `chat-input.tsx`.

### Arquivos Criados
- `apps/web/src/components/chat/deep-research-button.tsx` â€” Novo componente

### Arquivos Alterados
- `apps/web/src/components/chat/index.ts` â€” Adicionado export do novo componente

### Funcionalidades Implementadas

#### 1. Botao Principal com Popover
- Botao compacto "Deep Res." com icone de microscopio
- Indicador visual quando Deep Research esta ativado (verde emerald)
- Popover com configuracoes completas

#### 2. Configuracoes no Popover
- **Toggle principal**: Ativa/desativa Deep Research com badge ALPHA
- **Seletor de modo**: Standard vs Hard (Multi-Provider)
- **Seletor de provider** (modo Standard): Auto, Perplexity, Google, OpenAI
- **Effort level**: Low, Medium, High

#### 3. Modo Hard (Multi-Provider)
- Info box explicando que Claude orquestra multiplos agentes
- Seletor de fontes com checkboxes:
  - Gemini Deep Research
  - Perplexity Sonar
  - ChatGPT Deep Research
  - RAG Global (legislacao, jurisprudencia)
  - RAG Local (documentos do caso)
- Botoes "Todas" e "Nenhuma" para selecao rapida

#### 4. Parametros Avancados (Perplexity)
- Search focus: Auto, Web, Academico, SEC
- Domain filter, datas de publicacao/atualizacao
- Localizacao: Country, Latitude, Longitude

### Comandos Executados
- `npm run lint --workspace=apps/web` â€” OK
- `npx tsc --noEmit` â€” OK (sem erros no novo componente)

### Decisoes Tomadas
- Componente usa diretamente o `useChatStore` para estado (consistencia com arquitetura existente)
- Mantida mesma estrutura visual e UX do UI original em chat-input.tsx
- Botao fecha o popover ao clicar "Deep Research Ativado" para UX fluida

---

## 2026-02-04 â€” Sessao 106: Correcao de observacoes_gerais na Auditoria Preventiva de Fidelidade

### Objetivo
Corrigir o campo `observacoes_gerais` que estava sendo gerado com numeros inventados pela IA (ex: "taxa de compressao 43%") quando os dados reais mostravam valores diferentes (ex: 108.1% de retencao = expansao de 8%).

### Problema
- A IA estava inventando porcentagens de compressao em vez de usar os valores reais calculados
- Exemplo: Metricas reais mostravam `taxa_retencao: 1.081` (108.1% = expansao de 8%)
- Mas `observacoes_gerais` dizia "Apesar da taxa de compressao parecer alta (43%)..."
- O prompt nao fornecia as metricas pre-calculadas para a IA

### Arquivos Alterados
- `/Users/nicholasjacob/Documents/Aplicativos/Iudex/audit_fidelity_preventive.py` â€” Correcao do prompt e logica

### Mudancas Implementadas

#### 1. Nova secao "METRICAS REAIS DO DOCUMENTO" no prompt
- Adicionada secao com metricas pre-calculadas no inicio do prompt
- Inclui: modo, palavras_raw, palavras_fmt, taxa_retencao, dispositivos legais
- Inclui interpretacao clara: "EXPANSAO de X%" ou "COMPRESSAO de X%"

#### 2. Instrucoes explicitas para nao inventar numeros
- Prompt agora diz: "NÃƒO invente ou estime outros valores. Use EXATAMENTE estes numeros"
- Secao "ANALISE AUTOMATICA DE METRICAS" reescrita para enfatizar uso de valores fornecidos
- Explicacao de como interpretar taxa_retencao (>100% = expansao, <100% = compressao)

#### 3. Atualizacao do schema JSON
- Campo `observacoes_gerais` agora inclui instrucao: "Use APENAS os valores da secao METRICAS REAIS"
- Exemplo de formato correto incluido no prompt

#### 4. Codigo que monta o prompt
- Criada variavel `metricas_info` com string formatada das metricas reais
- Inclui texto descritivo: "EXPANSAO de X%" ou "COMPRESSAO de X%" baseado no valor
- Passada para o prompt via parametro `metricas_info`

### Comandos Executados
- `python3 -m py_compile audit_fidelity_preventive.py` â€” OK (sintaxe valida)

### Decisoes Tomadas
- Metricas sao calculadas deterministicamente ANTES de chamar o LLM
- LLM recebe as metricas prontas e deve apenas usa-las, nao recalcular
- Texto interpretativo (expansao/compressao) incluido para evitar confusao da IA

---

## 2026-02-04 â€” SessÃ£o 105: CorreÃ§Ã£o SincronizaÃ§Ã£o Word-Audio na TranscriÃ§Ã£o

### Objetivo
Corrigir a sincronizaÃ§Ã£o entre clique nas palavras e reproduÃ§Ã£o de Ã¡udio na aba "raw" da pÃ¡gina de transcriÃ§Ã£o.

### Problema
- Clique na palavra levava para timestamp errado no Ã¡udio
- Highlight da palavra ativa nÃ£o correspondia ao Ã¡udio durante playback
- Problema ocorria em uploads locais e jobs carregados do servidor

### Arquivos Alterados
- `apps/web/src/components/dashboard/word-level-transcript-viewer.tsx` â€” RefatoraÃ§Ã£o completa da lÃ³gica de sincronizaÃ§Ã£o

### MudanÃ§as Implementadas

#### 1. SubstituiÃ§Ã£o de Binary Search por Busca Linear ProblemÃ¡tica
- Implementado `useMemo` com binary search para encontrar palavra ativa
- Busca retorna correspondÃªncia exata (start â‰¤ time â‰¤ end) ou Ãºltima palavra antes do tempo atual

#### 2. MemoizaÃ§Ã£o de Ãndices Globais
- Removida variÃ¡vel `globalWordIndex` mutÃ¡vel que causava problemas em re-renders
- Criado `wordGlobalIndices` com `useMemo` para prÃ©-calcular mapeamento Ã­ndice â†’ palavra

#### 3. Throttling do Evento `timeupdate`
- Adicionado `requestAnimationFrame` para limitar atualizaÃ§Ãµes
- Evita re-renders excessivos durante playback
- Cleanup adequado do RAF no unmount

#### 4. OtimizaÃ§Ã£o do Auto-scroll
- Alterado `behavior: 'smooth'` para `behavior: 'auto'` durante playback
- Evita scroll lag quando Ã¡udio avanÃ§a rapidamente

### Comandos Executados
- `npm run lint --workspace=apps/web` â€” OK
- `npm run type-check --workspace=apps/web` â€” OK

### DecisÃµes Tomadas
- Mantido `setCurrentTime` em `handleSeek` para feedback imediato ao usuÃ¡rio (responsividade)
- Usado `useMemo` para `activeWordIndex` ao invÃ©s de `useEffect` + state (evita re-renders intermediÃ¡rios)

### AtualizaÃ§Ã£o: Suporte a DiarizaÃ§Ã£o

#### MudanÃ§as Adicionais
- `groupWordsIntoBlocks` agora agrupa por **mudanÃ§a de speaker** quando diarizaÃ§Ã£o estÃ¡ ativa
- Respeita breaks naturais das frases do Whisper (nÃ£o forÃ§a intervalo de 60s)
- Exibe **label do falante** como badge antes do texto de cada bloco

#### LÃ³gica de Agrupamento
- Com diarizaÃ§Ã£o: novo bloco a cada mudanÃ§a de `word.speaker`
- Sem diarizaÃ§Ã£o: mantÃ©m agrupamento por intervalo de tempo (default 60s)

---

## 2026-02-04 â€” SessÃ£o 104: RefatoraÃ§Ã£o PÃ¡gina de Casos - Layout Minuta

### Objetivo
Refatorar a pÃ¡gina de casos (`/cases/[id]`) para espelhar a experiÃªncia da pÃ¡gina de minutas, substituindo o GeneratorWizard pelo chat jurÃ­dico com canvas integrado.

### Arquivos Alterados
- `apps/web/src/app/(dashboard)/cases/[id]/page.tsx` â€” RefatoraÃ§Ã£o completa

### MudanÃ§as Implementadas

#### 1. Central de Contexto (Aba "Arquivos / Autos")
- Layout em grid: documentos do caso (2/3) + sidebar de corpus (1/3)
- Adicionado seletor de Escopo RAG (Apenas Caso | Caso + Corpus | Corpus)
- Integrado Corpus Global via `useCorpusCollections`
- Integrado Corpus Privado via `useCorpusProjects`

#### 2. Nova Aba "Gerar PeÃ§a" (Substituiu GeneratorWizard)
- Layout resizÃ¡vel com Chat + Canvas lado a lado
- Toolbar compacta com:
  - Toggle de modo (RÃ¡pido vs ComitÃª Multi-Agente)
  - Toggle de layout (Chat | Canvas)
  - BotÃ£o "Gerar" para iniciar geraÃ§Ã£o
  - BotÃ£o de configuraÃ§Ãµes
- `MinutaSettingsDrawer` com 70+ configuraÃ§Ãµes de qualidade, modelos, HIL, etc.
- Barra de progresso dos agentes durante geraÃ§Ã£o
- Popover de Corpus integrado no chat panel

#### 3. Funcionalidades Herdadas da Minuta
- Layout resizÃ¡vel via divider arrastÃ¡vel
- SincronizaÃ§Ã£o de modo com `setUseMultiAgent`
- Handlers de resize (`handleDividerPointerDown/Move/Up`)
- HIL modal (`OutlineApprovalModal`) para aprovaÃ§Ã£o de estrutura
- Todos os handlers de geraÃ§Ã£o (`handleGenerate`, `handleOutlineApprove/Reject`)

### Comandos Executados
- `npm run lint` â€” OK
- `npx tsc --noEmit` â€” OK

### DecisÃµes Tomadas
- Removido `GeneratorWizard` em favor do layout integrado Chat+Canvas
- Reutilizados componentes existentes (`MinutaSettingsDrawer`, `CanvasContainer`, `ChatInterface`)
- Mantida aba "Chat JurÃ­dico" separada para consultas que nÃ£o sÃ£o geraÃ§Ã£o de documentos

---

## 2026-02-04 â€” SessÃ£o 103: Bug Parte 1 Vazia em Batch + Tratamento de Erro

### Problema
Na transcriÃ§Ã£o em lote (batch), a Parte 1 de um arquivo de 5h22min (309MB) ficou vazia no `raw.txt`.

### InvestigaÃ§Ã£o
1. Verificado `raw.txt`: Parte 1 tinha apenas o header, conteÃºdo estava todo na Parte 2
2. Verificado duraÃ§Ã£o dos arquivos:
   - Parte 1: 19.353 segundos (5h22min) - arquivo extremamente longo
   - Parte 2: 929 segundos (15min) - arquivo normal
3. Identificado que `mlx_vomo.py` **jÃ¡ tem** suporte a chunking para Ã¡udios > 2h
4. PorÃ©m, nÃ£o havia try/except ao redor da chamada `transcribe_file` no batch

### Causa Raiz
O cÃ³digo em `process_batch_with_progress()`:
- NÃ£o tinha tratamento de exceÃ§Ã£o ao chamar `vomo.transcribe_file()`
- NÃ£o validava se `transcription_text` estava vazio
- Se o Whisper falhasse silenciosamente (timeout, memÃ³ria), texto ficava vazio

### CorreÃ§Ã£o (v2.34)

**Arquivo 1:** `apps/api/app/services/transcription_service.py`
1. **Adicionado try/except** ao redor de `vomo.transcribe_file()` (linhas 4185-4228)
2. **Fallback para AssemblyAI** se Whisper falhar e AAI key disponÃ­vel
3. **ValidaÃ§Ã£o de conteÃºdo** apÃ³s transcriÃ§Ã£o (`len(text) < 50` = warning)
4. **Logs de erro** detalhados para debug

**Arquivo 2:** `mlx_vomo.py` - DetecÃ§Ã£o de duraÃ§Ã£o mais robusta
1. **`_get_audio_duration()`** melhorado com:
   - Timeout de 30s no ffprobe
   - ValidaÃ§Ã£o do resultado do ffprobe
   - Fallback via `wave` module para arquivos WAV
   - Fallback por estimativa de tamanho de arquivo
2. **Logging detalhado** quando chunking Ã© ativado/desativado:
   - `ğŸ“ DuraÃ§Ã£o detectada: X.XXh (limite: 2h)`
   - `âš ï¸ ATIVANDO CHUNKING` quando duraÃ§Ã£o > 2h
   - `âŒ AVISO: DuraÃ§Ã£o nÃ£o detectada!` quando duraÃ§Ã£o = 0

### Arquivos Existentes que Suportam Ãudios Longos
- `mlx_vomo.py`: Chunking automÃ¡tico para Ã¡udios > 2h (v2.32+)
- `scripts/transcribe_long_raw.py`: Script CLI para chunking manual

### Melhorias no Chunking (v2.34)

**Arquivo:** `mlx_vomo.py`

1. **Overlap aumentado**: 30s â†’ 45s (mais seguro para frases longas)
2. **Merge melhorado** - 4 estratÃ©gias de detecÃ§Ã£o de duplicatas:
   - Texto exatamente igual
   - Substring (um contÃ©m o outro)
   - Similaridade Jaccard > 80%
   - Primeiras 8 palavras iguais
3. **Logging detalhado**: `ğŸ”— Merge: 150 â†’ 142 segmentos (removidas duplicatas do overlap)`

**LimitaÃ§Ã£o conhecida - DiarizaÃ§Ã£o:**
- Speaker IDs podem resetar entre chunks (SPEAKER 1 no chunk A pode virar SPEAKER 2 no chunk B)
- Para diarizaÃ§Ã£o consistente em Ã¡udios longos, recomenda-se usar AssemblyAI
- Alternativa: fazer diarizaÃ§Ã£o no Ã¡udio inteiro separadamente e alinhar depois

### PrÃ³ximos Passos
- Reiniciar API para aplicar correÃ§Ãµes
- Retestar arquivo de 5h+ - agora deve aparecer log de chunking ativado

---

## 2026-02-04 â€” SessÃ£o 102: CorreÃ§Ã£o do Seletor de Motor de TranscriÃ§Ã£o

### Problema
O seletor de motor de transcriÃ§Ã£o (Whisper vs AssemblyAI) nÃ£o estava funcionando corretamente:
1. O seletor sÃ³ era visÃ­vel para o tipo `apostila`, nÃ£o para audiÃªncias e legendas
2. Ao mudar de tipo, o engine era resetado para 'whisper' automaticamente
3. O parÃ¢metro `transcription_engine` nÃ£o era passado para os endpoints de hearing
4. O serviÃ§o `process_hearing_with_progress` nÃ£o aceitava o parÃ¢metro

### Arquivos Alterados

**Frontend (`apps/web/src/app/(dashboard)/transcription/page.tsx`):**
- Expandido `showEngineSelector` para todos os tipos de transcriÃ§Ã£o (apostila, hearing, legenda)
- Removido useEffect que resetava engine para 'whisper'
- Adicionado `transcription_engine: transcriptionEngine` a todas as chamadas de hearing (4 ocorrÃªncias)

**Frontend (`apps/web/src/lib/api-client.ts`):**
- Adicionado `transcription_engine` ao payload de `startHearingJob()`
- Adicionado `transcription_engine` ao payload de `startHearingJobFromUrl()`

**Backend (`apps/api/app/api/endpoints/transcription.py`):**
- Adicionado `transcription_engine: str = Form("whisper")` ao endpoint `/hearing/jobs`
- Adicionado `transcription_engine` ao config de hearing
- Adicionado `transcription_engine` Ã  chamada de `process_hearing_with_progress`
- Adicionado `transcription_engine` ao schema `UrlHearingJobRequest`
- Adicionado `transcription_engine` ao config e chamada no endpoint `/hearing/jobs/url`

**Backend (`apps/api/app/services/transcription_service.py`):**
- Adicionado parÃ¢metro `transcription_engine: str = "whisper"` em `process_hearing_with_progress`
- Adicionada lÃ³gica `_use_aai_hearing` para respeitar a escolha do usuÃ¡rio
- Modificada condiÃ§Ã£o para usar AAI apenas quando `_use_aai_hearing and aai_key`

### Comportamento Corrigido
- Motor de transcriÃ§Ã£o agora Ã© selecionÃ¡vel para apostilas, audiÃªncias e legendas
- A escolha do motor Ã© preservada ao trocar de tipo de transcriÃ§Ã£o
- AssemblyAI sÃ³ Ã© usado quando explicitamente selecionado pelo usuÃ¡rio (nÃ£o mais como padrÃ£o automÃ¡tico)

### ElevenLabs para Legendas
- Adicionado `elevenlabs` como terceira opÃ§Ã£o de motor de transcriÃ§Ã£o
- BotÃ£o ElevenLabs aparece apenas no modo Legendas (`isLegenda`)
- ElevenLabs Scribe v2 Ã© especializado em legendas com timestamps precisos
- IdentificaÃ§Ã£o automÃ¡tica de eventos sonoros (mÃºsica, aplausos, etc.)
- Fallback para AssemblyAI â†’ Whisper se ElevenLabs falhar

**Arquivos adicionais:**
- Atualizado tipo de `transcriptionEngine` para `'whisper' | 'assemblyai' | 'elevenlabs'`
- Atualizado `api-client.ts` para suportar `transcription_engine: 'elevenlabs'`
- Modificada lÃ³gica em `transcription_service.py` para usar ElevenLabs apenas quando selecionado

---

## 2026-02-03 â€” SessÃ£o 101: Seletor de Motor de TranscriÃ§Ã£o (Whisper vs AssemblyAI)

### Objetivo
Adicionar seletor na UI de apostilas para escolher entre Whisper (local) e AssemblyAI (nuvem) como motor de transcriÃ§Ã£o.

### Arquivos Alterados

**Frontend:**
- `apps/web/src/app/(dashboard)/transcription/page.tsx`:
  - Estado `transcriptionEngine` ('whisper' | 'assemblyai')
  - UI toggle com botÃµes para selecionar motor
  - Popover explicativo das diferenÃ§as
  - Desabilita "Alta PrecisÃ£o" quando AssemblyAI selecionado
  - Passa `transcription_engine` no objeto `options`

**Backend - Schemas:**
- `apps/api/app/schemas/transcription.py`:
  - Tipo `TranscriptionEngineType = Literal["whisper", "assemblyai"]`
  - Campo `transcription_engine` em `TranscriptionRequest`

**Backend - Endpoints:**
- `apps/api/app/api/endpoints/transcription.py`:
  - `transcription_engine` em `UrlVomoJobRequest`
  - ParÃ¢metro Form em `/vomo/jobs`, `/vomo`, `/vomo/stream`, `/vomo/batch/stream`
  - Passa para service nas chamadas `process_file`, `process_file_with_progress`, `process_batch_with_progress`

**Backend - Service:**
- `apps/api/app/services/transcription_service.py`:
  - ParÃ¢metro `transcription_engine` em `process_file`, `process_file_with_progress`, `process_batch_with_progress`
  - LÃ³gica `_engine_aai = transcription_engine == "assemblyai"` para forÃ§ar uso de AssemblyAI

### Comportamento
- Whisper (padrÃ£o): Processamento local no Mac via MLX, gratuito e privado
- AssemblyAI: API na nuvem, mais rÃ¡pido para arquivos longos, custo por minuto
- Seletor visÃ­vel apenas para apostilas (modo `!isHearing`)

---

## 2026-02-03 â€” SessÃ£o 100: Speaker Identification por Nome/Papel (AssemblyAI)

### Objetivo
Implementar suporte completo ao Speaker Identification do AssemblyAI, permitindo identificar falantes por **nome** (ex: "Dr. JoÃ£o Silva") ou **papel** (ex: "Juiz", "Advogado").

### Arquivos Alterados

**Backend:**
- `apps/api/app/schemas/transcription.py` â€” campos `speaker_id_type` e `speaker_id_values`
- `apps/api/app/services/transcription_service.py` â€” envio de `speech_understanding.speaker_identification` no payload
- `apps/api/app/api/endpoints/transcription.py` â€” Form fields para receber os valores

**Frontend:**
- `apps/web/src/app/(dashboard)/transcription/page.tsx` â€” toggle UI para escolher entre "Nome" e "Papel"
- `apps/web/src/lib/api-client.ts` â€” tipos e envio dos parÃ¢metros

### Estrutura API AssemblyAI
```json
{
  "speech_understanding": {
    "request": {
      "speaker_identification": {
        "speaker_type": "role",
        "known_values": ["Juiz", "Advogado", "Testemunha"]
      }
    }
  }
}
```

### UI
Toggle na seÃ§Ã£o "Participantes" permite escolher entre:
- **Papel**: Identifica por funÃ§Ã£o (Juiz, Advogado, Professor)
- **Nome**: Identifica por nome real (Dr. JoÃ£o Silva, Maria Santos)

---

## 2026-02-03 â€” SessÃ£o 99: Chunking automÃ¡tico para Ã¡udios longos (v2.32)

### Problema
TranscriÃ§Ã£o de Ã¡udio de ~5.6h (`12_Trabalho_Empresarial_Publico_Parte1e2.mp3`) retornou apenas pontos (`. . . .`) em vez de texto real. O MLX-Whisper degrada silenciosamente quando processa arquivos muito longos de uma vez.

### DiagnÃ³stico
1. O arquivo de saÃ­da `_RAW.txt` continha apenas timestamps com pontuaÃ§Ã£o
2. Testei trechos individuais do mesmo arquivo - transcriÃ§Ã£o funcionou perfeitamente a partir de 2min
3. O inÃ­cio do arquivo tem pouca fala (aplausos/mÃºsica), mas isso nÃ£o explica a falha completa
4. **Causa raiz**: MLX-Whisper entra em estado de degradaÃ§Ã£o com Ã¡udios > 3-4h

### SoluÃ§Ã£o Implementada
Adicionado chunking automÃ¡tico no `mlx_vomo.py` (v2.32):

1. **Novas constantes**:
   - `AUDIO_MAX_DURATION_SECONDS = 3 * 60 * 60` (3h)
   - `AUDIO_CHUNK_OVERLAP_SECONDS = 30`

2. **Novas funÃ§Ãµes**:
   - `_get_audio_duration()` - obtÃ©m duraÃ§Ã£o via ffprobe
   - `_split_audio_into_chunks()` - divide Ã¡udio longo em WAVs temporÃ¡rios
   - `_cleanup_audio_chunks()` - remove arquivos temporÃ¡rios
   - `_merge_chunk_segments()` - mescla segmentos removendo duplicatas do overlap
   - `_transcribe_chunked()` - orquestra transcriÃ§Ã£o em chunks

3. **ModificaÃ§Ã£o em `transcribe()`**:
   - Verifica duraÃ§Ã£o do Ã¡udio antes de processar
   - Se > 3h, redireciona para `_transcribe_chunked()`
   - Timestamps sÃ£o ajustados automaticamente para cada chunk

### Arquivos Alterados
- `mlx_vomo.py` â€” chunking automÃ¡tico de Ã¡udio longo

### Comandos Executados
- Testes de transcriÃ§Ã£o em diferentes offsets do Ã¡udio (OK)
- VerificaÃ§Ã£o de importaÃ§Ã£o do mÃ³dulo (OK)

### ObservaÃ§Ã£o
UsuÃ¡rio tambÃ©m criou `scripts/transcribe_long_raw.py` como alternativa standalone para re-processar arquivos com problema.

---

## 2026-02-03 â€” SessÃ£o 98: Word-level timestamps para player interativo

### Objetivo
Implementar timestamps por palavra (word-level) no player de transcriÃ§Ã£o, permitindo clicar em qualquer palavra para ir ao momento exato do Ã¡udio.

### Arquitetura Implementada

**Backend (`transcription_service.py`):**
1. Modificado `_transcribe_with_progress_stream()` para usar `transcribe_file_full()`
2. Retorno agora Ã© `{text, words}` em vez de apenas `str`
3. Adicionado `transcription_words: list` para armazenar timestamps por palavra
4. `words` incluÃ­do no retorno de `process_file_with_progress()`

**mlx_vomo.py (jÃ¡ existente):**
- `transcribe_file_full()` retorna `{text, words, segments}`
- `words` Ã© lista de `{word, start, end, speaker}` para cada palavra

**Frontend (`transcription/page.tsx`):**
1. Novo estado: `transcriptionWords` para armazenar lista de words
2. ExtraÃ§Ã£o de `payload.words` nos handlers de resultado
3. ImportaÃ§Ã£o de `WordLevelTranscriptViewer`
4. RenderizaÃ§Ã£o condicional: usa `WordLevelTranscriptViewer` quando `transcriptionWords.length > 0`

**Componente `WordLevelTranscriptViewer`:**
- Cada palavra Ã© clicÃ¡vel e faz seek no Ã¡udio
- Timestamps visuais a cada 60s (configurÃ¡vel via `timestampInterval`)
- Highlighting da palavra ativa durante reproduÃ§Ã£o
- Auto-scroll para palavra em reproduÃ§Ã£o

### LÃ³gica de Timestamps Visuais
| Modo | Intervalo |
|------|-----------|
| APOSTILA, FIDELIDADE | 60s |
| AUDIENCIA, REUNIAO, LEGENDA | 0 (por utterance) |

### Arquivos Alterados
- `apps/api/app/services/transcription_service.py`:
  - `_transcribe_with_progress_stream()`: usa `transcribe_file_full()`, retorna dict
  - `process_file_with_progress()`: retorna `words` no payload
- `apps/web/src/app/(dashboard)/transcription/page.tsx`:
  - Estado `transcriptionWords`
  - ExtraÃ§Ã£o de words do payload
  - RenderizaÃ§Ã£o condicional com `WordLevelTranscriptViewer`

### Compatibilidade
- RetrocompatÃ­vel: `SyncedTranscriptViewer` usado quando `words` nÃ£o disponÃ­vel
- Frontend detecta automaticamente qual viewer usar

---

## 2026-02-03 â€” SessÃ£o 97: Progresso tqdm + OtimizaÃ§Ã£o de Ã¡udio para cloud

### Parte 1: Progresso tqdm na UI

**Problema:** UsuÃ¡rio nÃ£o via progresso detalhado do tqdm na UI durante transcriÃ§Ãµes.

**Causa Raiz:** tqdm escreve diretamente no file descriptor stderr, nÃ£o passa por `sys.stderr` do Python.

**SoluÃ§Ã£o:** Reescrita de `_transcribe_with_progress_stream` usando `os.pipe()` + `os.dup2()` para interceptar fd 2.

### Parte 2: OtimizaÃ§Ã£o de Ã¡udio para AssemblyAI

**Problema:** Upload de WAV 16kHz para AssemblyAI era lento (690MB para 6h de Ã¡udio).

**AnÃ¡lise de Tamanhos (6h de Ã¡udio):**
| Formato | Tamanho | Upload |
|---------|---------|--------|
| WAV 16kHz (atual) | ~690MB | Lento |
| **MP3 64kbps (novo)** | ~173MB | **4x mais rÃ¡pido** |
| VÃ­deo original MP4 | 2-8GB | Muito lento |

**SoluÃ§Ã£o:** Novas funÃ§Ãµes para extraÃ§Ã£o otimizada:
1. `_extract_audio_for_cloud()` - Extrai MP3 64kbps mono para upload
2. `_should_extract_audio_for_cloud()` - Decide quando extrair:
   - VÃ­deos: sempre extrair (descarta dados de vÃ­deo)
   - Arquivos > 2GB: obrigatÃ³rio (limite AssemblyAI = 2.2GB)
   - Ãudios lossless > 100MB: extrair compactado
   - Ãudios compactos: enviar direto

### Arquivos Alterados
- `apps/api/app/services/transcription_service.py`:
  - `_transcribe_with_progress_stream`: reescrita com fd redirect
  - `_extract_audio_for_cloud`: nova funÃ§Ã£o para MP3 64kbps
  - `_should_extract_audio_for_cloud`: lÃ³gica de decisÃ£o
  - Chamadas AAI/ElevenLabs: agora usam `cloud_audio_path`

### Impacto
- **Upload 4x mais rÃ¡pido** para AssemblyAI (173MB vs 690MB para 6h)
- **Progresso detalhado na UI** durante transcriÃ§Ãµes locais

---

## 2026-02-03 â€” SessÃ£o 96: Fix Ã¢ncoras fake no mlx_vomo.py (v2.33)

### Problema
O Vertex AI estava gerando Ã¢ncoras ABRE/FECHA usando os **tÃ­tulos** dos tÃ³picos em vez de **citaÃ§Ãµes verbatim** do texto da transcriÃ§Ã£o. Resultado: 0% de cobertura de Ã¢ncoras.

### Causa Raiz
O modelo nÃ£o seguia a instruÃ§Ã£o de copiar frases literais do texto. Gerava:
```
1. Credenciamento | ABRE: "O Credenciamento na Nova Lei" | FECHA: "..."
```
Quando deveria gerar:
```
1. Credenciamento | ABRE: "bom dia pessoal vamos falar sobre o credenciamento" | FECHA: "..."
```

### SoluÃ§Ã£o (v2.33)
Adicionadas 2 funÃ§Ãµes em [mlx_vomo.py](mlx_vomo.py):

1. **`_similaridade_palavras(a, b)`**: Calcula overlap de palavras entre dois textos (Jaccard). Se > 60%, Ã¢ncora Ã© "fake".

2. **`_buscar_ancora_no_texto(texto, titulo, transcricao)`**: Fallback inteligente com 3 estratÃ©gias:
   - Busca sequÃªncia de 2-3 palavras-chave do tÃ­tulo
   - Busca frases de transiÃ§Ã£o ("vamos agora", "passemos para") + palavra-chave
   - Busca apenas a palavra mais significativa do tÃ­tulo

### Fluxo Corrigido
```
1. Extrai Ã¢ncora ABRE do modelo
2. Calcula similaridade com tÃ­tulo
3. Se > 60%: marca como "fake", pula busca direta
4. Tenta fallback inteligente no texto real
5. Se encontrar: usa como ponto de corte
```

### Arquivos Alterados
- `mlx_vomo.py` â€” funÃ§Ãµes `_similaridade_palavras`, `_buscar_ancora_no_texto`, lÃ³gica em `dividir_sequencial`

### Output Esperado
```
âš ï¸  Ã‚ncora fake detectada (sim=85%): 'introduÃ§Ã£o aos procedimentos...'
ğŸ” Ã‚ncora via busca por tÃ­tulo: 'IntroduÃ§Ã£o aos Procedimentos...' @ 1234
```

---

## 2026-02-03 â€” SessÃ£o 95: Area e KeyTerms para AssemblyAI (Unificado)

### Objetivo
Implementar suporte a `area` (Ã¡rea de conhecimento) e `custom_keyterms` (termos especÃ­ficos) para melhorar a transcriÃ§Ã£o ASR via AssemblyAI, com arquitetura unificada.

### Arquitetura Escolhida
FunÃ§Ã£o `_get_assemblyai_prompt_for_mode` retorna tupla `(prompt, keyterms)` unificando:
- Prompt de texto para o modelo
- Lista de keyterms por Ã¡rea + custom do usuÃ¡rio

### Arquivos Alterados
- `apps/api/app/schemas/transcription.py`
  - `AreaType = Literal["juridico", "medicina", "ti", "engenharia", "financeiro", "geral"]`
  - Campos `area` e `custom_keyterms` em `TranscriptionRequest` e `HearingTranscriptionRequest`

- `apps/api/app/services/transcription_service.py`
  - `AREA_KEYTERMS`: dicionÃ¡rio com termos especÃ­ficos por Ã¡rea (classe)
  - `_get_assemblyai_prompt_for_mode`: **refatorado** para retornar `tuple[str, list[str]]`
    - Aceita `area` e `custom_keyterms`
    - Combina keyterms da Ã¡rea + custom (limite 200)
    - Prompts focados em transcriÃ§Ã£o bruta fiel
  - `_transcribe_assemblyai_with_progress`: aceita `area`, `custom_keyterms`, passa keyterms no payload
  - `_transcribe_assemblyai_with_roles`: aceita `area`, `custom_keyterms`, passa keyterms no payload
  - `_run_assemblyai_transcription`: usa SDK com `keyterms_prompt` (lÃ³gica prÃ³pria)
  - `process_file` e `process_file_with_progress`: aceitam `area` e `custom_keyterms`

- `apps/api/app/api/endpoints/transcription.py`
  - `transcribe_vomo`, `transcribe_vomo_stream`, `create_vomo_job`: aceitam e passam `area` e `custom_keyterms`

### Fluxo de Dados
```
UI â†’ Form(area, custom_keyterms)
    â†’ Endpoint (parsing)
    â†’ Service.process_file_with_progress(area, custom_keyterms)
    â†’ _get_assemblyai_prompt_for_mode(area, custom_keyterms)
    â†’ (prompt, keyterms)
    â†’ REST API: {prompt, keyterms_prompt}
```

### BenefÃ­cios da Arquitetura Unificada
- **Encapsulamento**: toda lÃ³gica de prompt/keyterms em 1 funÃ§Ã£o
- **ReutilizaÃ§Ã£o**: qualquer mÃ©todo pode usar a mesma funÃ§Ã£o
- **Testabilidade**: fÃ¡cil testar unitariamente
- **ManutenÃ§Ã£o**: mudanÃ§as centralizadas

---

## 2026-02-03 â€” SessÃ£o 94: Fix Timestamps AssemblyAI por Modo

### Problema
AssemblyAI retornava apenas 1 utterance para Ã¡udios single-speaker, perdendo granularidade de timestamps.

### SoluÃ§Ã£o
- Quando `len(utterances) <= 2 and len(words) > 50`, usa `words` para construir segmentos
- Intervalos controlados por `_get_timestamp_interval_for_mode()`:
  - **APOSTILA/FIDELIDADE**: 60s (Ã¡udios de aula)
  - **REUNIAO/AUDIENCIA/FILME**: 0 (por utterance/speaker)

### Arquivos Alterados
- `apps/api/app/services/transcription_service.py` â€” lÃ³gica de agrupamento de words (linhas 1280-1318)

---

## 2026-02-03 â€” SessÃ£o 93: Whisper PrimÃ¡rio para Aulas/Apostilas

### Objetivo
Configurar Whisper como provedor de transcriÃ§Ã£o primÃ¡rio para modos APOSTILA e FIDELIDADE (aulas).

### MudanÃ§a Implementada
Modificada a lÃ³gica de seleÃ§Ã£o do provedor em `transcription_service.py`:

**Antes**: AAI era usado como primÃ¡rio quando havia `speaker_roles` e `diarization` habilitados, independente do modo.

**Depois**: Para modos APOSTILA e FIDELIDADE, Whisper Ã© SEMPRE o primÃ¡rio, mesmo com speaker_roles e diarization. AAI primÃ¡rio agora sÃ³ se aplica a AUDIENCIA e REUNIAO.

### Arquivos Alterados
- `apps/api/app/services/transcription_service.py`
  - Adicionada condiÃ§Ã£o `_mode_upper not in ("APOSTILA", "FIDELIDADE")` na lÃ³gica de `_aai_primary`
  - Mesma mudanÃ§a aplicada ao fluxo SSE (`_aai_primary_sse`)
  - Atualizadas mensagens de log para refletir que AAI primÃ¡rio Ã© para audiÃªncia/reuniÃ£o

### LÃ³gica Atual de SeleÃ§Ã£o
```
1. ElevenLabs primÃ¡rio: subtitle_format + ElevenLabs key
2. AAI primÃ¡rio: diarizaÃ§Ã£o + speaker_roles + AAI key + modo â‰  APOSTILA/FIDELIDADE
3. Whisper primÃ¡rio (padrÃ£o): todos os outros casos (incluindo APOSTILA/FIDELIDADE)
```

---

## 2026-02-03 â€” SessÃ£o 92: CorreÃ§Ã£o de AlucinaÃ§Ãµes na Auditoria de Fidelidade

### Objetivo
Corrigir falsos positivos na auditoria de fidelidade que incorretamente identificava nomes de pessoas como "alucinaÃ§Ãµes" quando eles existiam no RAW completo mas em chunks diferentes.

### Problema Identificado
A auditoria de fidelidade (`audit_fidelity_preventive.py`) estava reportando que "Nelson Rosenwald" era uma alucinaÃ§Ã£o adicionada ao texto formatado, quando na verdade o nome existia no RAW original. Isso ocorria porque:
1. O sistema divide RAW e formatado em chunks proporcionais para anÃ¡lise
2. O LLM analisa cada par de chunks separadamente
3. Se um nome aparece em um chunk do formatado mas o chunk correspondente do RAW nÃ£o contÃ©m esse nome (porque estÃ¡ em outro lugar), o LLM erroneamente reporta como alucinaÃ§Ã£o

### SoluÃ§Ã£o Implementada (Camada 1: GeraÃ§Ã£o)
Adicionadas duas novas funÃ§Ãµes em `audit_fidelity_preventive.py`:

#### 1. `_extract_names_from_text(text: str) -> set`
- Extrai nomes prÃ³prios (sequÃªncias de 2+ palavras capitalizadas)
- Usado para identificar nomes em textos

#### 2. `_filter_hallucination_false_positives(raw_text: str, alucinacoes: list) -> list`
- Verifica se os nomes/trechos reportados como alucinaÃ§Ãµes existem no RAW completo
- Remove falsos positivos causados por chunk boundaries
- Reduz confianÃ§a de itens suspeitos ao invÃ©s de removÃª-los completamente

### SoluÃ§Ã£o Implementada (Camada 2: ConsolidaÃ§Ã£o)
Adicionada validaÃ§Ã£o extra em `fidelity_matcher.py` e `audit_pipeline.py`:

#### 3. `FidelityMatcher.validate_hallucination_issue()` (fidelity_matcher.py)
- MÃ©todo especÃ­fico para validar alucinaÃ§Ãµes de nomes/autores
- Verifica se trecho exato existe no RAW
- Extrai e verifica nomes prÃ³prios no RAW completo
- Verifica palavras-chave significativas (70%+ presentes = falso positivo)

#### 4. IntegraÃ§Ã£o no audit_pipeline.py
- Issues de categoria "alucinacao" agora usam `validate_hallucination_issue()` ao invÃ©s de `validate_issue()`
- Garante dupla validaÃ§Ã£o: na geraÃ§Ã£o (preventiva) e na consolidaÃ§Ã£o (pipeline)

### Pipeline de Auditoria Mapeado
```
1. GeraÃ§Ã£o (mlx_vomo.py â†’ audit_fidelity_preventive.py)
   â””â”€â”€ Auditoria preventiva por chunks + filtro de falsos positivos

2. Processamento (transcription_service.py)
   â””â”€â”€ quality_service.validate_document_full() â†’ validation_report
   â””â”€â”€ quality_service.analyze_structural_issues() â†’ analysis_result

3. ConsolidaÃ§Ã£o (audit_pipeline.py)
   â””â”€â”€ PreventiveFidelityPlugin + ValidationPlugin + StructuralAnalysisPlugin
   â””â”€â”€ FidelityMatcher valida issues (referÃªncias legais + nomes)
   â””â”€â”€ Salva audit_summary.json

4. UI (quality-panel.tsx)
   â””â”€â”€ Exibe score, omissions, distortions, observations
```

### Arquivos Alterados
- `audit_fidelity_preventive.py` â€” Filtro de alucinaÃ§Ãµes na geraÃ§Ã£o
- `fidelity_matcher.py` â€” Novo mÃ©todo `validate_hallucination_issue()`
- `audit_pipeline.py` â€” IntegraÃ§Ã£o do novo mÃ©todo para alucinaÃ§Ãµes

### Comandos Executados
- `python3 -c "import audit_fidelity_preventive"` â€” OK
- `python3 -c "from app.services.fidelity_matcher import FidelityMatcher; from app.services.audit_pipeline import run_audit_pipeline"` â€” OK

### VerificaÃ§Ãµes
- Confirmado que "Nelson Rosenwald" existe 1x no raw.txt
- Dados de qualidade exibidos corretamente na aba "Qualidade (Resumo)"
- Fluxo completo RAW vs formatado funcionando em todas as camadas

### Problema de DesconexÃ£o Identificado e Corrigido

**DiagnÃ³stico:**
Quando o documento Ã© revalidado (apÃ³s aplicar correÃ§Ãµes), a UI mostrava score atualizado (8.46), mas os arquivos de auditoria mantinham o score original (5.44).

| Fonte | Score | Status |
|-------|-------|--------|
| result.json (UI) | 8.46 | Atualizado apÃ³s revalidaÃ§Ã£o |
| audit_summary.json | 5.44 | NÃƒO atualizado |
| _FIDELIDADE.json | 5.44 | NÃƒO atualizado |

**CorreÃ§Ã£o em** `transcription.py`:
ApÃ³s revalidaÃ§Ã£o bem-sucedida, agora sincroniza automaticamente:
1. `_FIDELIDADE.json` â€” atualizado com dados do novo `validation_report`
2. `audit_summary.json` â€” atualizado com novo score e timestamp de revalidaÃ§Ã£o

### Arquivos Adicionais Alterados
- `apps/api/app/api/endpoints/transcription.py` â€” SincronizaÃ§Ã£o de arquivos de auditoria apÃ³s revalidaÃ§Ã£o

---

## 2026-02-03 â€” SessÃ£o 91: CorreÃ§Ã£o de Contraste Dark Mode

### Objetivo
Corrigir problemas de contraste no tema escuro onde vÃ¡rios widgets e pÃ¡ginas ainda mostravam fundos claros.

### MudanÃ§as Realizadas

#### 1. globals.css â€” Classes CSS com variantes `dark:`
- `.chat-markdown` â€” texto, blockquote, tabelas, links, citaÃ§Ãµes
- `.ProseMirror` e `.editor-output` â€” texto, code, blockquote, tabelas
- `.tiptap-*` â€” code blocks, mermaid blocks
- `.doc-theme-classic`, `.doc-theme-minimal`, `.doc-theme-executive`, `.doc-theme-academic`
- `.table-style-*` â€” compact, grid, minimal, zebra
- `.panel-card` â€” borda

#### 2. chat-message.tsx â€” BalÃµes de Chat
- Avatar do bot: `bg-white dark:bg-slate-800`
- Bubble do usuÃ¡rio: gradiente `from-slate-800 to-slate-900` em dark
- Bubble do bot: `bg-white dark:bg-slate-900`
- Labels de modelo e badges
- BotÃµes de aÃ§Ã£o (copiar, regerar)

#### 3. minuta/page.tsx â€” Toolbar e PainÃ©is
- Toolbar colapsÃ¡vel: `bg-white/90 dark:bg-slate-900/90`
- BotÃµes de modo: active states com `dark:bg-slate-700`
- Settings toggle: `dark:bg-slate-800` quando ativo
- Painel de chat: `bg-white/50 dark:bg-slate-900/50`
- Painel canvas: `bg-white dark:bg-slate-900`
- Divider de resize: `dark:before:bg-slate-700/80`
- BotÃµes de sugestÃ£o e RAG scope

### Arquivos Alterados
- `src/styles/globals.css` â€” ~50 regras CSS com dark: variants
- `src/components/chat/chat-message.tsx` â€” avatars, bubbles, badges, buttons
- `src/app/(dashboard)/minuta/page.tsx` â€” toolbar, painÃ©is, botÃµes

### Comandos Executados
- `npm run lint` â€” OK
- `npm run type-check` â€” OK

---

## 2026-02-03 â€” SessÃ£o 90: RemoÃ§Ã£o de Chips Superiores do Chat

### Objetivo
Remover elementos redundantes da parte superior do chat input para simplificar a UI.

### MudanÃ§as Realizadas

#### Elementos Removidos (`chat-input.tsx`)
- Chip "Anexos Auto (count)"
- BotÃ£o toggle "Web"
- BotÃ£o toggle "Deep research"
- BotÃ£o toggle "MCP"
- Campo "Objetivo" (input de tese)

#### Limpeza de CÃ³digo
- Removidas variÃ¡veis nÃ£o utilizadas: `contextChipBase`, `contextChipActive`, `contextChipInactive`

### Arquivos Alterados
- `src/components/chat/chat-input.tsx`

### Comandos Executados
- `npm run lint` â€” OK
- `npm run type-check` â€” OK

---

## 2026-02-03 â€” SessÃ£o 89: Toolbar ColapsÃ¡vel + Dropdown Menu

### Objetivo
Otimizar o layout da pÃ¡gina de minutas para gerar mais espaÃ§o Ãºtil para chat e canvas, sem perder funcionalidades.

### MudanÃ§as Realizadas

#### 1. Toolbar ColapsÃ¡vel (`minuta/page.tsx`)
- Adicionado estado `toolbarCollapsed` para controlar modo da toolbar
- **Modo expandido**: Mostra toggle de modo, playbook, layout, gerar, configuraÃ§Ãµes e menu "..."
- **Modo colapsado**: Mostra apenas tÃ­tulo, botÃ£o configuraÃ§Ãµes e botÃ£o gerar (~28px altura)
- Economia de ~20-30px de espaÃ§o vertical quando colapsado

#### 2. Dropdown Menu para AÃ§Ãµes SecundÃ¡rias
- Importados componentes DropdownMenu do shadcn/ui
- AÃ§Ãµes movidas para dropdown "...":
  - Auditoria
  - Nova Minuta
  - Tela Cheia
  - Minimizar/Expandir Toolbar

#### 3. RemoÃ§Ã£o de Override no Chat Input
- Removidas seÃ§Ãµes "RaciocÃ­nio (override)" e "Verbosidade (override)"
- Controles agora centralizados apenas no drawer de configuraÃ§Ãµes

### Arquivos Alterados
- `src/app/(dashboard)/minuta/page.tsx` â€” toolbar colapsÃ¡vel + dropdown
- `src/components/chat/chat-input.tsx` â€” remoÃ§Ã£o de overrides

### Novos Imports
```typescript
import { MoreHorizontal, PanelTopClose, PanelTop } from 'lucide-react';
import { DropdownMenu, DropdownMenuContent, DropdownMenuItem, DropdownMenuSeparator, DropdownMenuTrigger } from '@/components/ui/dropdown-menu';
```

### Comandos Executados
- `npm run lint` â€” OK
- `npm run type-check` â€” OK

---

## 2026-02-03 â€” SessÃ£o 88: RestauraÃ§Ã£o NÃ­vel de RaciocÃ­nio no Drawer

### Objetivo
Restaurar "NÃ­vel de RaciocÃ­nio" (RÃ¡pido/MÃ©dio/Profundo) no drawer de configuraÃ§Ãµes, mantendo no chat-input como override.

### MudanÃ§as Realizadas

#### 1. Drawer (`minuta-settings-drawer.tsx`)
- Adicionadas props `reasoningLevel` e `setReasoningLevel`
- Adicionada seÃ§Ã£o "NÃ­vel de RaciocÃ­nio" na Ã¡rea de Qualidade (cor violeta)
- Atualizado `qualitySummary` para incluir o nÃ­vel de raciocÃ­nio

#### 2. PÃ¡gina Minuta (`minuta/page.tsx`)
- Passadas props `reasoningLevel` e `setReasoningLevel` ao drawer

#### 3. Chat Input (`chat-input.tsx`)
- Mantida seÃ§Ã£o de "RaciocÃ­nio" mas renomeada para "RaciocÃ­nio (override)"
- Adicionada indicaÃ§Ã£o "Sobrescreve config"
- Cor alterada para violeta (consistente com drawer)
- "Verbosidade" tambÃ©m marcada como override

### Arquivos Alterados
- `src/components/dashboard/minuta-settings-drawer.tsx`
- `src/app/(dashboard)/minuta/page.tsx`
- `src/components/chat/chat-input.tsx`

### Fluxo
1. UsuÃ¡rio define padrÃ£o no drawer de configuraÃ§Ãµes
2. Pode sobrescrever temporariamente no chat-input (popover ADV)

### Comandos Executados
- `npm run lint` â€” OK
- `npm run type-check` â€” OK

---

## 2026-02-03 â€” SessÃ£o 87: SimplificaÃ§Ã£o UI Anexos no Contexto

### Objetivo
Remover opÃ§Ãµes manuais de "Anexos no contexto" do chat-input, jÃ¡ que a lÃ³gica automÃ¡tica (`resolveAutoAttachmentMode`) foi implementada na SessÃ£o 85.

### MudanÃ§as Realizadas

#### 1. RemoÃ§Ã£o de UI Manual de Anexos
- Removido toggle "Auto/AvanÃ§ado"
- Removidas opÃ§Ãµes manuais "RAG Local" e "InjeÃ§Ã£o direta"
- Mantida apenas indicaÃ§Ã£o visual de "Auto" com explicaÃ§Ã£o
- Mantidos os limites informativos por modelo

#### 2. SimplificaÃ§Ã£o do Chip de Anexos
- BotÃ£o que mudava modo para `rag_local` convertido em span informativo
- Label fixo "Anexos Auto" em vez de dinÃ¢mico

#### 3. Limpeza de CÃ³digo
- Removido state `attachmentAdvanced` (nÃ£o mais usado)
- Removido `setAttachmentMode` das importaÃ§Ãµes do store

### Arquivos Alterados
- `src/components/chat/chat-input.tsx` â€” simplificaÃ§Ã£o da seÃ§Ã£o de anexos

### LÃ³gica Mantida
A funÃ§Ã£o `resolveAutoAttachmentMode()` em `attachment-limits.ts` continua funcionando:
- Modelos â‰¥500K tokens + â‰¤10 arquivos â†’ injeÃ§Ã£o direta
- Modelos â‰¥200K tokens + â‰¤5 arquivos â†’ injeÃ§Ã£o direta
- Caso contrÃ¡rio â†’ RAG local

### Comandos Executados
- `npm run lint` â€” OK
- `npm run type-check` â€” OK

---

## 2026-02-03 â€” SessÃ£o 86: VerificaÃ§Ã£o de Work ChatGPT + CorreÃ§Ã£o de Todos Lint Warnings

### Objetivo
1. Verificar trabalho realizado pelo ChatGPT (E2E tests, lint fixes, type fixes)
2. Corrigir TODOS os warnings de lint restantes

### MudanÃ§as Realizadas

#### 1. CorreÃ§Ã£o de Lint Warnings
- `vorbium-nav.tsx` â€” SubstituÃ­do `<img>` por `<Image>` do Next.js com `unoptimized` prop
- `use-vorbium-paint.ts` â€” JÃ¡ havia sido corrigido para remover `any` cast no ctxOptions

#### 2. CorreÃ§Ã£o de Erros de Tipo
- `use-vorbium-paint.ts` â€” Adicionado guard `|| !ctx` no inÃ­cio da funÃ§Ã£o `frame()` para narrowing de tipo

### Arquivos Alterados
- `src/components/vorbium/vorbium-nav.tsx` â€” Image do Next.js
- `src/hooks/use-vorbium-paint.ts` â€” null check em frame()

### Comandos Executados
- `npm run lint` â€” OK (0 erros, 0 warnings)
- `npm run type-check` â€” OK
- `npx playwright test` â€” OK (5/5 testes passaram)

### Status Final
| Check | Resultado |
|-------|-----------|
| Lint | âœ… 0 erros, 0 warnings |
| Type-check | âœ… Passa |
| E2E Tests | âœ… 5/5 passaram |

---

## 2026-02-03 â€” SessÃ£o 85: UnificaÃ§Ã£o de ConfiguraÃ§Ãµes da Minuta + Auto Attachment Mode

### Objetivo
1. Remover redundÃ¢ncias nas configuraÃ§Ãµes da pÃ¡gina de minuta (drawer)
2. Implementar lÃ³gica automÃ¡tica de decisÃ£o entre injeÃ§Ã£o direta e RAG para anexos

### MudanÃ§as Realizadas

#### 1. RemoÃ§Ã£o de "NÃ­vel de RaciocÃ­nio" do Drawer
- Removida prop `reasoningLevel` e `setReasoningLevel` de `MinutaSettingsDrawerProps`
- Removido bloco de UI "NÃ­vel de RaciocÃ­nio" (RÃ¡pido/MÃ©dio/Profundo) da seÃ§Ã£o Qualidade
- Removidas props passadas ao drawer em `minuta/page.tsx`

**Motivo:** Cada modelo tem seus prÃ³prios parÃ¢metros especÃ­ficos (Thinking Level para Gemini, Reasoning Effort para GPT, Thinking Budget para Claude) que sÃ£o configurados no popover "ADV" do chat-input.

#### 2. ImplementaÃ§Ã£o de Auto Attachment Mode
- Criada funÃ§Ã£o `resolveAutoAttachmentMode()` em `attachment-limits.ts`
- Integrada em todos os 5 pontos do `chat-store.ts` onde `attachment_mode` Ã© enviado ao backend

**LÃ³gica de DecisÃ£o:**
- Modelos com contexto â‰¥500K tokens + â‰¤10 arquivos â†’ injeÃ§Ã£o direta
- Modelos com contexto â‰¥200K tokens + â‰¤5 arquivos â†’ injeÃ§Ã£o direta
- Caso contrÃ¡rio â†’ RAG local (mais seguro para precisÃ£o e custo)

### Arquivos Alterados
- `src/components/dashboard/minuta-settings-drawer.tsx` â€” removido reasoningLevel
- `src/app/(dashboard)/minuta/page.tsx` â€” removidas props reasoningLevel
- `src/lib/attachment-limits.ts` â€” adicionada funÃ§Ã£o resolveAutoAttachmentMode
- `src/stores/chat-store.ts` â€” integraÃ§Ã£o da lÃ³gica em 5 pontos de envio

### Comandos Executados
- `rm -rf .next` â€” limpeza de cache
- `npx tsc --noEmit` â€” verificaÃ§Ã£o de tipos (OK)

---

## 2026-02-03 â€” SessÃ£o 84: Fix 422 Error on Transcription File Upload

### Objetivo
Corrigir erro 422 "Unprocessable Entity" quando usuÃ¡rio tenta transcrever arquivos no modo apostila.

### Problema Identificado
O axios estava configurado com `Content-Type: application/json` como header padrÃ£o. Quando enviando FormData, esse header sobrescrevia o content-type correto (`multipart/form-data` com boundary), causando o FastAPI a nÃ£o reconhecer os arquivos.

### CorreÃ§Ã£o Aplicada
Adicionado `headers: { 'Content-Type': undefined }` em todas as chamadas axios.post que usam FormData para permitir que o axios defina automaticamente o content-type correto.

### Arquivos Alterados
- `apps/web/src/lib/api-client.ts`:
  - `startTranscriptionJob()` â€” adicionado Content-Type: undefined
  - `startHearingJob()` â€” adicionado Content-Type: undefined
  - `uploadDocumentFromUrl()` â€” adicionado Content-Type: undefined
  - `indexDocuments()` â€” adicionado Content-Type: undefined
  - `extractTemplateVariables()` â€” adicionado Content-Type: undefined
  - `applyTemplate()` â€” adicionado Content-Type: undefined
  - `/transcription/vomo` endpoint â€” adicionado Content-Type: undefined

- `apps/web/src/app/(dashboard)/transcription/page.tsx`:
  - Adicionado logs de debug para rastrear arquivos sendo enviados

- `apps/web/src/app/api/[...path]/route.ts`:
  - Adicionado log do Content-Type no proxy para debug

### LiÃ§Ã£o Aprendida
Quando axios Ã© configurado com um Content-Type padrÃ£o no construtor, esse header Ã© enviado mesmo para FormData, corrompendo o multipart/form-data. A soluÃ§Ã£o Ã© definir explicitamente `Content-Type: undefined` em chamadas que usam FormData.

---

## 2026-02-03 â€” Sessao 83: Frontend UI for Review Tables (Dynamic Columns, Ask Table, Cell Verification)

### Objetivo
Implementar a interface frontend completa para Review Tables, incluindo Dynamic Columns, Ask Table (chat), Cell Verification com indicadores de confianca, e tabela virtual para suporte a 2000+ documentos.

### Arquivos Criados

**Tipos TypeScript:**
- `apps/web/src/types/review-table.ts`:
  - Tipos para DynamicColumn, CellExtraction, ReviewTable, ExtractionJob
  - Enums ExtractionType, CellStatus, JobStatus, FilterOperator
  - Interfaces para AskTable (chat), VerificationStats, FilterValue
  - Estado completo ReviewTableState para a store

**Store Zustand:**
- `apps/web/src/stores/review-table-store.ts`:
  - Estado centralizado para tabela, colunas, celulas, documentos
  - UI state: visibleColumns, sortColumn, filters, showVerifiedOnly
  - Actions: loadTable, addColumn, updateCell, setFilter, etc.
  - Getters computados: getFilteredDocuments, getSortedDocuments, getVisibleColumns

**Componentes de Review Tables:**
- `apps/web/src/components/review-tables/table-cell.tsx`:
  - Indicador de confianca color-coded (verde >0.8, amarelo 0.5-0.8, vermelho <0.5)
  - Badge de verificacao, modo de edicao para correcoes
  - Popover com fonte, acoes de verificar/corrigir

- `apps/web/src/components/review-tables/column-builder-modal.tsx`:
  - Input de linguagem natural para prompt de extracao
  - Preview em documento de amostra
  - Seletor de tipo de extracao (text, number, date, boolean, currency, list, entity)
  - Sugestoes de perguntas pre-definidas

- `apps/web/src/components/review-tables/ask-table-drawer.tsx`:
  - Interface de chat similar ao chat principal
  - Sugestoes dinamicas baseadas nas colunas
  - Display estruturado (tabelas, listas, charts)
  - Referencias a documentos nas respostas

- `apps/web/src/components/review-tables/manage-columns-panel.tsx`:
  - Lista de colunas com drag-to-reorder
  - Toggle show/hide por coluna
  - Acoes: reprocessar, excluir coluna

- `apps/web/src/components/review-tables/verification-stats.tsx`:
  - Barra de progresso de verificacao
  - Contadores: verificadas, pendentes, baixa confianca
  - Filtros rapidos por status

- `apps/web/src/components/review-tables/extraction-progress.tsx`:
  - Progress bar com percentual e ETA
  - Botoes pause/resume/cancel
  - Lista de erros expansivel
  - Polling automatico de status

- `apps/web/src/components/review-tables/virtual-table.tsx`:
  - Virtualizacao para 2000+ linhas (ROW_HEIGHT=48, OVERSCAN=5)
  - Scroll horizontal para muitas colunas
  - Selecao de linhas com checkbox
  - Ordenacao por clique no header

**Paginas:**
- `apps/web/src/app/(dashboard)/review-tables/page.tsx`:
  - Lista de tabelas com cards
  - Criar nova tabela (dialog)
  - Busca/filtro, delete com confirmacao

- `apps/web/src/app/(dashboard)/review-tables/[id]/page.tsx`:
  - Toolbar: Ask Table, Nova Coluna, filtros, export
  - Dropdown de colunas visiveis
  - VerificationStats bar
  - ExtractionProgress quando job ativo
  - VirtualTable como componente principal

**UI Components adicionados:**
- `apps/web/src/components/ui/separator.tsx`
- `apps/web/src/components/ui/collapsible.tsx`

**API Client:**
- `apps/web/src/lib/api-client.ts`: +50 metodos adicionados
  - Review Tables: get, list, create, delete
  - Dynamic Columns: create, list, update, delete, reprocess, reorder, preview
  - Cells: get, verify, bulkVerify, getLowConfidence
  - Ask Table: ask, getChatHistory, clearHistory
  - Extraction Jobs: start, get, list, pause, resume, cancel
  - Export: CSV, XLSX, JSON

### Comandos Executados
- `npm install @radix-ui/react-separator` â€” OK
- `npm run lint` â€” OK (apenas warnings pre-existentes)
- `npm run type-check` â€” OK

### Decisoes Tecnicas
1. Virtualizacao manual com CSS (ROW_HEIGHT constante) para evitar dependencia extra
2. Store Zustand com Map para celulas (key: `${docId}:${colId}`) para acesso O(1)
3. Polling de job status a cada 2s durante extracao
4. Filtros aplicados no frontend para responsividade

### Performance
- VirtualTable renderiza apenas ~20 linhas visiveis + 5 overscan
- Scroll suave com spacers virtuais
- Celulas carregadas em background apos load inicial

---

## 2026-02-03 â€” Sessao 82: Scalable Batch Processing for 2000+ Documents

### Objetivo
Implementar processamento em lote escalavel para Review Tables que suporte 2000+ documentos, com job queue assincrono, tracking de progresso, pause/resume e retry com backoff exponencial.

### Arquivos Criados
- `apps/api/app/models/extraction_job.py`:
  - `ExtractionJobStatus` enum: pending, running, paused, completed, failed, cancelled
  - `ExtractionJobType` enum: full_extraction, column_extraction, reprocess, incremental
  - `DocumentExtractionStatus` enum: pending, queued, processing, completed, failed, skipped
  - `ExtractionJob` model: Job de extracao em lote com tracking de progresso
    - `total_documents`, `processed_documents`, `failed_documents`, `skipped_documents`
    - `progress_percent`, `documents_per_second` para rate tracking
    - `started_at`, `completed_at`, `paused_at` para timing
    - `max_concurrent`, `batch_size`, `max_retries` para configuracao
    - Property `estimated_time_remaining` para ETA
    - Property `can_resume` para verificar se pode retomar
  - `ExtractionJobDocument` model: Status por documento
    - `retry_count`, `next_retry_at` para backoff exponencial
    - `processing_time_ms`, `queue_position`

- `apps/api/app/services/batch_extraction_service.py`:
  - `BatchExtractionService` com metodos:
    - `create_extraction_job()` â€” Cria job e enfileira documentos
    - `process_job()` â€” Loop principal de processamento com semaphore
    - `_process_documents()` â€” Processa documentos em batches
    - `_process_single_document()` â€” Extracao individual com retry
    - `_extract_row_with_retry()` â€” Extrai todas colunas em paralelo
    - `pause_job()`, `resume_job()`, `cancel_job()` â€” Controle de job
    - `get_job_progress()` â€” Progresso detalhado com status por documento
    - `list_jobs_for_table()` â€” Listar jobs de uma tabela
    - `get_next_pending_job()` â€” Para worker background
  - Constantes: MAX_CONCURRENT=10, BATCH_SIZE=50, MAX_RETRIES=3
  - Backoff exponencial: base 5s, max 5min

- `apps/api/app/workers/tasks/extraction_tasks.py`:
  - `process_extraction_job_task` â€” Celery task para processamento
  - `start_extraction_job_task` â€” Celery task para criar e iniciar job
  - `ExtractionWorker` class â€” Worker async alternativo ao Celery
  - `process_job_background()` â€” Para FastAPI BackgroundTasks

- `apps/api/app/api/endpoints/extraction_jobs.py`:
  - Schemas: StartExtractionRequest, ExtractionJobResponse, JobProgressResponse, JobListResponse
  - Endpoints (prefix /review-tables):
    - `POST /{table_id}/extract` â€” Iniciar job de extracao
    - `GET /{table_id}/jobs` â€” Listar jobs
    - `GET /{table_id}/jobs/{job_id}` â€” Detalhes do job
    - `GET /{table_id}/jobs/{job_id}/progress` â€” Progresso detalhado
    - `POST /{table_id}/jobs/{job_id}/pause` â€” Pausar job
    - `POST /{table_id}/jobs/{job_id}/resume` â€” Retomar job
    - `POST /{table_id}/jobs/{job_id}/cancel` â€” Cancelar job
    - `GET /{table_id}/jobs/{job_id}/stream` â€” SSE para progresso em tempo real

- `apps/api/alembic/versions/x6y7z8a9b0c1_add_extraction_jobs_tables.py`:
  - Cria tabelas `extraction_jobs` e `extraction_job_documents`
  - Enums para PostgreSQL
  - Indices para queries de status e progresso

### Arquivos Alterados
- `apps/api/app/models/__init__.py`: Exports dos novos modelos
- `apps/api/app/core/database.py`: Import dos novos modelos no init_db()
- `apps/api/app/api/routes.py`: Incluido extraction_jobs router
- `apps/api/app/workers/tasks/__init__.py`: Exports das novas tasks

### Decisoes Tecnicas
1. Semaphore para controlar concorrencia (padrao 10 docs em paralelo)
2. Commits em batch (padrao 50 docs) para reducao de I/O
3. Resultados incrementais salvos a cada batch
4. SSE endpoint para progresso em tempo real (atualiza a cada 2s)
5. Backoff exponencial para retries (5s, 10s, 20s... max 5min)
6. Job pode ser pausado/retomado preservando progresso
7. Worker pode rodar via Celery ou async standalone

### Performance Esperada
- 2000 documentos: ~15-20 minutos (com 10 docs paralelos)
- Rate: ~2-3 docs/segundo por coluna
- Memory: constante (processa em batches)

### Proximos Passos
- Frontend: UI para monitorar jobs com progress bar
- Notificacoes: Email/webhook quando job completa
- Otimizacao: Batch LLM calls onde possivel

---

## 2026-02-03 â€” Sessao 81: Dynamic Column Builder via Natural Language Prompts

### Objetivo
Implementar o Dynamic Column Builder para Review Tables, permitindo que usuarios criem colunas de extracao via perguntas em linguagem natural (similar ao Harvey AI).

### Arquivos Criados
- `apps/api/app/models/dynamic_column.py`:
  - `ExtractionType` enum: text, boolean, number, date, currency, enum, list, verbatim, risk_rating, compliance_check
  - `VerificationStatus` enum: pending, verified, rejected, corrected
  - `DynamicColumn` model: Coluna criada via prompt com schema inferido
  - `CellExtraction` model: Valor extraido com confianca, fonte e verificacao

- `apps/api/app/services/column_builder_service.py`:
  - `ColumnBuilderService` com metodos:
    - `infer_column_schema()` â€” Usa LLM para inferir tipo e nome da coluna a partir do prompt
    - `create_column_from_prompt()` â€” Cria coluna com schema inferido ou fornecido
    - `extract_for_document()` â€” Extrai valor de um documento para uma coluna
    - `extract_column_for_all_documents()` â€” Processa todos docs em paralelo (semaphore)
    - `reprocess_column()` â€” Reprocessa extracoes (todos ou docs especificos)
    - `get_column_extractions()` â€” Lista extracoes com filtros
    - `verify_cell()` â€” Verifica/corrige uma celula

### Arquivos Alterados
- `apps/api/app/models/__init__.py`:
  - Adicionados exports: DynamicColumn, CellExtraction, ExtractionType, VerificationStatus

- `apps/api/app/core/database.py`:
  - Adicionado import dos novos modelos no init_db()

- `apps/api/app/api/endpoints/review_tables.py`:
  - Adicionados schemas: CreateDynamicColumnRequest, DynamicColumnResponse, etc.
  - Novos endpoints:
    - `POST /{table_id}/dynamic-columns` â€” Criar coluna via prompt
    - `GET /{table_id}/dynamic-columns` â€” Listar colunas dinamicas
    - `GET /{table_id}/dynamic-columns/{col_id}` â€” Obter coluna com extracoes e stats
    - `DELETE /{table_id}/dynamic-columns/{col_id}` â€” Soft/hard delete
    - `POST /{table_id}/dynamic-columns/{col_id}/reprocess` â€” Reprocessar extracoes
  - Background tasks: `_extract_column_background()`, `_reprocess_column_background()`
  - Helper: `_dynamic_column_to_response()` com contagens de extracoes

### Decisoes Tecnicas
1. Schema inference usa LLM para determinar extraction_type e column_name
2. Fallback para tipo "text" se LLM falhar
3. Processamento em paralelo com semaphore (MAX_CONCURRENT_EXTRACTIONS=5)
4. Extracoes existentes sao atualizadas (upsert) ao reprocessar
5. Soft delete por padrao para colunas (preserva dados)

### Proximos Passos
- Frontend: UI para criar colunas dinamicas
- Batch processing: Otimizar para 2000+ documentos
- Export: Incluir colunas dinamicas no XLSX/CSV

---

## 2026-02-03 â€” Sessao 80: Cell-Level Verification and Confidence Scores

### Objetivo
Implementar verificacao a nivel de celula com scores de confianca para Review Tables, inspirado no Harvey AI "verified cells" toggle.

### Arquivos Criados
- `apps/api/app/services/cell_verification_service.py`:
  - `CellVerificationService` com metodos:
    - `verify_cell()` â€” Verificar/rejeitar/corrigir uma celula individual
    - `bulk_verify()` â€” Verificar multiplas celulas de uma vez
    - `get_verification_stats()` â€” Estatisticas: total, verified, rejected, corrected, pending, avg_confidence
    - `get_low_confidence_cells()` â€” Celulas abaixo do threshold para revisao humana
    - `get_cell_by_position()` â€” Buscar celula por (review_table, document, column)
    - `get_cells_by_dynamic_column()` â€” Celulas de uma coluna dinamica
    - `get_cells_for_document()` â€” Todas celulas de um documento
    - `get_cells_for_review_table()` â€” Todas celulas com filtros
    - `recalculate_confidence()` â€” Recalcular score de confianca
  - `calculate_confidence()` â€” Funcao que calcula confianca baseado em:
    - Confianca base do LLM
    - Tamanho do source snippet
    - Validacao de tipo (date, boolean, currency, etc.)
    - Deteccao de incerteza no reasoning
  - `VerificationStats` dataclass para respostas estruturadas

- `apps/api/alembic/versions/x6y7z8a9b0c1_add_dynamic_columns_cell_extractions.py`:
  - Migracao para criar tabelas `dynamic_columns` e `cell_extractions`
  - Enums `extractiontype` e `verificationstatus` (PostgreSQL)
  - Indices para performance em queries frequentes

### Arquivos Alterados
- `apps/api/app/models/dynamic_column.py`:
  - Adicionados campos ao `CellExtraction`:
    - `correction_note` â€” Nota explicando a correcao
    - `source_char_start`, `source_char_end` â€” Posicao no documento
    - `extraction_model` â€” Modelo de IA usado
    - `extraction_reasoning` â€” Raciocinio do modelo
    - `column_name` â€” Para colunas de template (nao dinamicas)
    - `created_at` â€” Timestamp de criacao
  - `dynamic_column_id` agora e nullable (para colunas de template)
  - Adicionada property `is_verified` â€” True se verified ou corrected
  - Atualizado `to_dict()` com todos os novos campos

- `apps/api/app/api/endpoints/review_tables.py`:
  - Adicionados schemas:
    - `VerifyCellRequest` â€” { verified, correction?, note? }
    - `BulkVerifyRequest` â€” { cell_ids, verified }
    - `BulkVerifyResponse` â€” { success, updated_count }
    - `CellExtractionResponse` â€” Representacao completa de uma celula
    - `VerificationStatsResponse` â€” Estatisticas de verificacao
    - `CellSourceResponse` â€” Detalhes da fonte de uma celula
  - Adicionados endpoints:
    - `PATCH /{table_id}/cells/{cell_id}/verify` â€” Verificar celula individual
    - `POST /{table_id}/cells/bulk-verify` â€” Verificar em lote
    - `GET /{table_id}/verification-stats` â€” Estatisticas de verificacao
    - `GET /{table_id}/cells/low-confidence` â€” Celulas de baixa confianca
    - `GET /{table_id}/cells/{cell_id}/source` â€” Detalhes da fonte
    - `GET /{table_id}/cells` â€” Listar todas celulas com filtros

### Decisoes Tecnicas
1. **Celulas de template vs dinamicas**: O modelo `CellExtraction` suporta ambos os tipos. Para colunas de template, `dynamic_column_id` e null e `column_name` e preenchido.

2. **Calculo de confianca**: A funcao `calculate_confidence()` usa multiplos fatores:
   - Confianca base do LLM (0.1-0.95)
   - Boost de +0.1 se source snippet > 150 chars
   - Boost de +0.1 se valor passa validacao de tipo
   - Penalidade de -0.15 se reasoning contem marcadores de incerteza
   - Penalidade de -0.2 se valor e vazio/erro

3. **Verificacao em lote**: O `bulk_verify` usa UPDATE com IN para performance, atualizando ate 100 celulas de uma vez.

4. **Audit logging**: Todas as acoes de verificacao sao logadas na tabela `audit_logs`.

### Endpoints Adicionados
```
PATCH /review-tables/{table_id}/cells/{cell_id}/verify
POST  /review-tables/{table_id}/cells/bulk-verify
GET   /review-tables/{table_id}/verification-stats
GET   /review-tables/{table_id}/cells/low-confidence?threshold=0.7
GET   /review-tables/{table_id}/cells/{cell_id}/source
GET   /review-tables/{table_id}/cells?status=pending&min_confidence=0.5
```

### Proximos Passos
- [ ] Integrar calculo de confianca no `review_table_service.process_review()`
- [ ] Criar CellExtraction para cada celula extraida (atualmente em JSON)
- [ ] Frontend: Toggle de "Show verified only" na UI
- [ ] Frontend: Indicadores visuais de confianca (cores, badges)

---

## 2026-02-03 â€” Sessao 79: Ask Table Chat Feature para Review Tables

### Objetivo
Implementar a funcionalidade "Ask Table" para Review Tables, permitindo que usuarios facam perguntas em linguagem natural sobre os dados extraidos (similar ao "Ask Harvey" do Harvey AI).

### Arquivos Criados
- `apps/api/app/models/table_chat.py`:
  - Modelo `TableChatMessage` para armazenar historico de chat
  - Enum `MessageRole` (user, assistant, system)
  - Enum `QueryType` (filter, aggregation, comparison, summary, specific, general)
  - Indices para performance em queries por table_id e created_at

- `apps/api/app/services/table_chat_service.py`:
  - `TableChatService` com metodos:
    - `ask_table()` â€” Processa perguntas em linguagem natural
    - `get_chat_history()` â€” Retorna historico de mensagens
    - `clear_chat_history()` â€” Limpa historico
    - `execute_data_query()` â€” Queries estruturadas (filter, aggregation)
    - `get_table_statistics()` â€” Estatisticas resumidas da tabela
  - Prompts especializados para analise de dados tabulares
  - Deteccao automatica de tipo de query
  - Sugestao de visualizacao (bar_chart, pie_chart, table, list)

- `apps/api/alembic/versions/x6y7z8a9b0c1_add_table_chat_messages.py`:
  - Migracao para criar tabela `table_chat_messages`
  - Enums `messagerole` e `querytype`
  - Indices para performance

### Arquivos Alterados
- `apps/api/app/models/__init__.py`:
  - Adicionado import de `TableChatMessage`, `MessageRole`, `QueryType`

- `apps/api/app/core/database.py`:
  - Adicionado import de `TableChatMessage` no init_db

- `apps/api/app/api/endpoints/review_tables.py`:
  - Adicionados schemas: `AskTableRequest`, `AskTableResponse`, `DocumentReference`, `ChatMessageResponse`, `ChatHistoryResponse`, `TableStatisticsResponse`
  - Adicionados endpoints:
    - `POST /{table_id}/chat` â€” Ask Table principal
    - `GET /{table_id}/chat/history` â€” Historico de chat
    - `DELETE /{table_id}/chat/history` â€” Limpar historico
    - `GET /{table_id}/chat/statistics` â€” Estatisticas da tabela
  - Endpoint `/query` marcado como deprecated em favor de `/chat`

### Tipos de Query Suportados
1. **FILTER**: "Quais documentos tem Demand Rights?"
2. **AGGREGATION**: "Quantos/qual porcentagem tem blackout provisions?"
3. **COMPARISON**: "Compare prioridades entre documentos"
4. **SUMMARY**: "Resuma os achados principais"
5. **SPECIFIC**: "O que documento X diz sobre Y?"
6. **GENERAL**: Perguntas gerais

### Formato de Resposta
```python
{
  "answer": "Resposta em linguagem natural",
  "query_type": "filter|aggregation|...",
  "documents": [{"id": "...", "name": "...", "relevance": "..."}],
  "data": {"type": "count|list|...", "data": ...},
  "visualization_hint": "bar_chart|pie_chart|table|list",
  "message_id": "uuid-da-mensagem"
}
```

### Verificacoes
- Sintaxe Python validada para todos os arquivos
- Migracao Alembic criada corretamente

### Status
- [x] Modelo TableChatMessage
- [x] TableChatService com todos os metodos
- [x] Endpoints de chat
- [x] Migracao Alembic
- [x] Validacao de sintaxe

---

## 2026-02-03 â€” Sessao 78: Extracao de Legendas (SRT/VTT) + ElevenLabs Scribe v2

### Objetivo
Implementar novo modo de transcricao para extracao de legendas de filmes/videos. Gera arquivos SRT e VTT a partir de segments com timestamps. ElevenLabs Scribe v2 como backend primario, AssemblyAI e Whisper como fallbacks. Suporte a traducao e idiomas expandidos.

### Arquivos Alterados
- `mlx_vomo.py`:
  - Expandido `SUPPORTED_LANGUAGES` de 6 para 21 idiomas (pt, en, es, fr, de, it, ja, ko, zh, ru, ar, hi, nl, pl, tr, sv, da, fi, no, uk)

- `apps/api/app/core/config.py`:
  - Adicionado `ELEVENLABS_API_KEY: Optional[str] = None` para Scribe v2

- `apps/api/app/services/transcription_service.py`:
  - Adicionado `_format_timestamp_srt()` â€” formata seconds para `HH:MM:SS,mmm`
  - Adicionado `_format_timestamp_vtt()` â€” formata seconds para `HH:MM:SS.mmm`
  - Adicionado `_generate_srt()` â€” gera conteudo SRT com speaker prefix
  - Adicionado `_generate_vtt()` â€” gera conteudo WebVTT com voice tags `<v SPEAKER>`
  - Adicionado `_get_elevenlabs_key()` â€” obtem API key do config ou env
  - Adicionado `_transcribe_elevenlabs_scribe()` â€” transcricao via ElevenLabs API com word-level timestamps, agrupa palavras em segments por speaker/pausas
  - Modificado `_persist_transcription_outputs()` â€” aceita `segments` e `subtitle_format`, salva .srt/.vtt/.json
  - Modificado `process_file()` â€” param `subtitle_format`, logica ElevenLabs primario para legendas
  - Modificado `process_file_with_progress()` â€” param `subtitle_format`, logica ElevenLabs primario para legendas
  - Coleta de segments prioriza: ElevenLabs > AAI > Whisper

- `apps/api/app/api/endpoints/transcription.py`:
  - Adicionado `subtitle_format` param nos 4 endpoints vomo (/vomo, /vomo/jobs, /vomo/jobs/url, /vomo/stream)
  - Adicionado media types: `.srt` (application/x-subrip), `.vtt` (text/vtt)
  - Adicionado `subtitle_format` em `UrlVomoJobRequest`

- `apps/web/src/lib/api-client.ts`:
  - Adicionado tipo `subtitle_format?: 'srt' | 'vtt' | 'both'` em funcoes de transcricao

- `apps/web/src/app/(dashboard)/transcription/page.tsx`:
  - Adicionado tipo de transcricao "Legendas (SRT/VTT)"
  - Adicionado seletor de formato (SRT/VTT/Ambos)
  - Expandido dropdown de idiomas de 6 para 21 opcoes
  - Adicionados botoes de download SRT/VTT na aba export

### Fluxo de Transcricao para Legendas
```
Legenda (qualquer idioma):
  â”œâ”€â”€ ElevenLabs Scribe v2 (primario, word-level timestamps, diarizacao)
  â”œâ”€â”€ AssemblyAI (fallback, speaker_labels=True)
  â”œâ”€â”€ Whisper (fallback final, segments locais)
  â”œâ”€â”€ Gera SRT e/ou VTT a partir dos segments
  â””â”€â”€ Salva: _RAW.txt, .srt, .vtt, _segments.json
```

### Decisoes Tomadas
- ElevenLabs como primario para legendas devido a word-level timestamps de alta qualidade
- Agrupamento de palavras em segments usa: mudanca de speaker OU pausa > 1.5s
- Fallback chain (ElevenLabs > AAI > Whisper) para robustez
- SRT usa formato `HH:MM:SS,mmm` (virgula), VTT usa `HH:MM:SS.mmm` (ponto)
- Speaker em SRT: prefixo "SPEAKER: texto", em VTT: voice tag `<v SPEAKER>texto`

### Verificacoes
- Sintaxe Python validada
- Sintaxe TypeScript validada
- Endpoints com tipagem correta

### Status
- [x] Expandir idiomas em mlx_vomo.py
- [x] Adicionar geracao SRT/VTT
- [x] Implementar ElevenLabs Scribe v2 como primario
- [x] Modificar endpoints com subtitle_format
- [x] Atualizar UI com tipo "Legendas"
- [x] Validar sintaxe

---

## 2026-02-03 â€” Sessao 77: Gaps 9, 10, 11, 12 â€” Word Online + Prompt Library + Historico + Recomendacoes

### Objetivo
Implementar gaps 9-12 do Word Add-in: suporte a Word Online (fallback), biblioteca de prompts curados, historico de analises e recomendacao de playbooks.

### Arquivos Criados
- `apps/office-addin/src/data/prompt-library.ts` â€” Biblioteca com 23 prompts curados para edicao juridica, organizados por categoria (editing, drafting, analysis, translation, compliance)
- `apps/office-addin/src/components/prompts/PromptLibrary.tsx` â€” Componente de UI para selecao de prompts com busca e filtros por categoria, inclui modal e seletor rapido
- `apps/office-addin/src/components/playbook/HistoryPanel.tsx` â€” Painel de historico de analises com restauracao de runs, inclui modal e botao

### Arquivos Alterados
- `apps/office-addin/src/office/redline-engine.ts`:
  - Adicionada funcao `isWordOnline()` â€” detecta se esta no Word Online
  - Adicionada funcao `getOfficePlatform()` â€” retorna plataforma atual (online/windows/mac/ios/android)
  - Adicionada funcao `supportsFullOOXML()` â€” verifica se suporta tracked changes OOXML
  - Adicionada funcao `applyRedlineAsFallback()` â€” fallback com comentarios + highlight para Word Online
  - Modificada funcao `applyRedlineAsTrackedChange()` â€” detecta Word Online e usa fallback automatico
  - Adicionado campo `method` em `RedlineResult` â€” indica metodo usado (ooxml/fallback/comment)
- `apps/office-addin/src/components/drafting/DraftPanel.tsx`:
  - Adicionado import de `PromptLibraryModal` e `PromptTemplate`
  - Adicionado estado `showPromptLibrary` e handler `handlePromptSelect`
  - Adicionado botao para abrir biblioteca de prompts
  - Adicionado modal da biblioteca no render
- `apps/office-addin/src/api/client.ts`:
  - Adicionados tipos para Gap 11: `PlaybookRunHistoryItem`, `PlaybookRunHistoryResponse`, `RestorePlaybookRunResponse`
  - Adicionadas funcoes: `getPlaybookRunHistory()`, `restorePlaybookRun()`
  - Adicionados tipos para Gap 12: `RecommendPlaybookRequest`, `RecommendedPlaybook`, `RecommendPlaybookResponse`
  - Adicionada funcao `recommendPlaybook()`
- `apps/office-addin/src/components/playbook/PlaybookPanel.tsx`:
  - Adicionados imports de `HistoryButton`, `HistoryModal`, `recommendPlaybook`, `useDocumentStore`
  - Adicionados estados para historico e recomendacoes
  - Adicionado efeito para carregar recomendacoes baseado no documento
  - Adicionada UI para mostrar playbooks recomendados com score de relevancia
  - Adicionado botao de historico e modal
- `apps/api/app/api/endpoints/word_addin.py`:
  - Adicionados imports: `BaseModel`, `Field`, `List`, `Optional`
  - **Gap 11**: Adicionado endpoint `GET /user/playbook-runs` â€” lista historico de execucoes do usuario
  - **Gap 12**: Adicionado endpoint `POST /playbook/recommend` â€” recomenda playbooks baseado no documento
  - Adicionada funcao `classify_document_type()` â€” classifica tipo de documento usando heuristicas
  - Adicionada funcao `rank_playbooks_by_relevance()` â€” rankeia playbooks por relevancia
  - Adicionado mapeamento `DOCUMENT_TYPE_TO_AREA` para relacionar tipos de documento a areas de playbook

### Decisoes Tomadas
- Word Online fallback usa comentarios com sugestoes de alteracao manual (OOXML nao e confiavel)
- Biblioteca de prompts com 23 templates em 5 categorias focadas em contexto juridico brasileiro
- Historico limitado a 10 execucoes mais recentes (configuravel)
- Recomendacao usa heuristicas simples (keywords) para classificacao rapida; em producao pode usar LLM
- Excerpt de 2000 caracteres para classificacao de documento (suficiente para identificar tipo)

### Verificacoes
- Arquivos TypeScript criados com sintaxe valida
- Endpoints Python com tipagem correta
- Integracao com stores existentes

### Status
- [x] Gap 9: Suporte a Word Online com fallback automatico
- [x] Gap 10: Prompt Library com 23 prompts curados
- [x] Gap 11: Historico de analises anteriores
- [x] Gap 12: Recomendacao de playbooks baseada no documento

---

## 2026-02-03 â€” Sessao 76: Gaps 1, 2 e 3 â€” Cache de Redlines + Endpoints Apply Funcionais

### Objetivo
Corrigir os gaps 1, 2 e 3 do Word Add-in: implementar cache de redlines (PlaybookRunCache) e tornar os endpoints de apply funcional com OOXML real.

### Arquivos Criados
- `apps/api/app/models/playbook_run_cache.py` â€” Modelo SQLAlchemy para cache temporÃ¡rio de execuÃ§Ãµes de playbook (TTL 24h)
- `apps/api/alembic/versions/v4w5x6y7z8a9_add_playbook_run_cache_table.py` â€” Migration Alembic para tabela `playbook_run_cache`

### Arquivos Alterados
- `apps/api/app/models/__init__.py` â€” Adicionado export de `PlaybookRunCache`
- `apps/api/app/schemas/word_addin.py`:
  - Adicionado campo `cache_results: bool` em `RunPlaybookRequest`
  - Adicionado campo `playbook_run_id: str` em `RunPlaybookResponse`
  - Adicionado campo `playbook_run_id: str` em `ApplyRedlineRequest`, `RejectRedlineRequest`, `ApplyAllRedlinesRequest`
  - Adicionado schema `RestorePlaybookRunResponse`
- `apps/api/app/api/endpoints/word_addin.py`:
  - Adicionados imports: `hashlib`, `json`, `timedelta`, `delete`, `PlaybookRunCache`
  - Adicionada funÃ§Ã£o `_cleanup_expired_caches()` â€” limpa caches expirados
  - Adicionada funÃ§Ã£o `_get_cached_run()` â€” recupera cache por ID
  - Modificado endpoint `POST /playbook/run`:
    - Salva resultados no cache se `cache_results=True`
    - Retorna `playbook_run_id` para uso posterior
  - Adicionado endpoint `GET /playbook/run/{playbook_run_id}/restore`:
    - Recupera redlines e resultados do cache
    - Permite continuar revisÃ£o sem re-executar anÃ¡lise
  - **Gap 1 corrigido**: `POST /redline/apply`:
    - Recupera redlines do cache pelo `playbook_run_id`
    - Gera OOXML real para cada redline usando `redline_service.generate_single_redline_ooxml()`
    - Persiste estado como `applied` usando `RedlineState`
    - Retorna mapa `ooxml_data: {redline_id: ooxml_string}`
  - Modificado `POST /redline/reject`:
    - Valida existÃªncia do cache
    - Persiste estado como `rejected` usando `RedlineState`
  - **Gap 2 corrigido**: `POST /redline/apply-all`:
    - Recupera redlines do cache
    - Filtra pendentes (nÃ£o aplicados/rejeitados)
    - Gera OOXML package completo com `redline_service.generate_ooxml_redlines()`
    - Suporta filtro por `redline_ids` opcionais
    - Persiste estados como `applied`
    - Retorna `ooxml_package` com todos tracked changes

### DecisÃµes Tomadas
- TTL de 24 horas para cache de redlines
- Limpeza automÃ¡tica de caches expirados a cada execuÃ§Ã£o de playbook
- Hash SHA256 do documento armazenado para identificaÃ§Ã£o futura
- `cache_results=True` por padrÃ£o em `RunPlaybookRequest`
- Redlines armazenados como JSON serializado (compacto)
- IntegraÃ§Ã£o com `RedlineState` para persistir applied/rejected

### VerificaÃ§Ãµes
- Python syntax OK (todos os arquivos compilam)
- Module import OK: `PlaybookRunCache`, endpoints word_addin

### Status
- [x] Gap 1: Endpoint Apply Individual funcional com OOXML real
- [x] Gap 2: Endpoint Apply All funcional com OOXML package
- [x] Gap 3: Cache de redlines com TTL 24h
- [x] Endpoint Restore para recuperar anÃ¡lise

---

## 2026-02-03 â€” Sessao 75: Gap 4 â€” PersistÃªncia de Estado de Redlines

### Objetivo
Implementar persistÃªncia de estado de redlines no backend para permitir que o usuÃ¡rio feche e reabra o Word Add-in sem perder o progresso da revisÃ£o.

### Arquivos Criados
- `apps/api/app/models/redline_state.py` â€” Modelo SQLAlchemy para persistir estados de redlines (pending, applied, rejected) com Ã­ndices e constraints
- `apps/api/alembic/versions/w5x6y7z8a9b0_add_redline_states_table.py` â€” Migration Alembic para criar a tabela `redline_states`

### Arquivos Alterados
- `apps/api/app/models/__init__.py` â€” Adicionado export de `RedlineState` e `RedlineStatus`
- `apps/api/app/core/database.py` â€” Adicionado import do modelo `RedlineState` no `init_db()`
- `apps/api/app/schemas/word_addin.py` â€” Adicionados schemas: `RedlineStateData`, `RedlineStateResponse`, `GetRedlineStatesResponse`
- `apps/api/app/api/endpoints/word_addin.py`:
  - Adicionados imports de `RedlineState`, `RedlineStatus` e novos schemas
  - Adicionado endpoint `POST /word-addin/redline/state/{playbook_run_id}/{redline_id}/applied`
  - Adicionado endpoint `POST /word-addin/redline/state/{playbook_run_id}/{redline_id}/rejected`
  - Adicionado endpoint `GET /word-addin/redline/state/{playbook_run_id}`
- `apps/office-addin/src/api/client.ts`:
  - Adicionados types: `RedlineStateData`, `RedlineStateResponse`, `GetRedlineStatesResponse`
  - Adicionado `playbook_run_id` em `RunPlaybookResponse`
  - Adicionadas funÃ§Ãµes: `persistRedlineApplied()`, `persistRedlineRejected()`, `getRedlineStates()`
- `apps/office-addin/src/stores/playbook-store.ts`:
  - Adicionados imports das novas funÃ§Ãµes de API
  - Adicionadas actions: `loadSavedRedlineStates()`, `persistAppliedState()`, `persistRejectedState()`
  - Modificado `runPlaybookAnalysis()` para usar `playbook_run_id` do backend e carregar estados salvos
  - Modificado `markRedlineApplied()` para chamar `persistAppliedState()`
  - Modificado `markRedlineRejected()` para chamar `persistRejectedState()`

### DecisÃµes Tomadas
- Upsert (criar ou atualizar) para operaÃ§Ãµes de estado
- Ãndice composto em `(playbook_run_id, status)` para performance de busca
- UniqueConstraint em `(playbook_run_id, redline_id)` para garantir unicidade
- PersistÃªncia fire-and-forget (nÃ£o bloqueia UI se API falhar)
- Carregamento de estados salvos Ã© assÃ­ncrono apÃ³s anÃ¡lise

### VerificaÃ§Ãµes
- Python syntax OK (models, schemas, endpoints)
- TypeScript sem erros nos arquivos modificados
- Model import OK: `RedlineState`, `RedlineStatus`
- Schema import OK: `RedlineStateData`, `RedlineStateResponse`, `GetRedlineStatesResponse`
- Endpoint import OK: router word_addin

---

## 2026-02-03 â€” Sessao 74: ExtraÃ§Ã£o de Legendas (SRT/VTT) com AssemblyAI

### Objetivo
Implementar nova funcionalidade de extraÃ§Ã£o de legendas (SRT/VTT) de filmes/vÃ­deos usando AssemblyAI como backend principal, com suporte a traduÃ§Ã£o e idiomas expandidos.

### Arquivos Alterados
- `mlx_vomo.py` â€” Expandido `SUPPORTED_LANGUAGES` de 6 para 21 idiomas (incluindo japonÃªs, coreano, chinÃªs, russo, Ã¡rabe, hindi, etc.)
- `apps/api/app/services/transcription_service.py`:
  - Adicionados mÃ©todos estÃ¡ticos `_format_timestamp_srt()`, `_format_timestamp_vtt()`, `_generate_srt()`, `_generate_vtt()`
  - Modificado `_persist_transcription_outputs()` para aceitar `segments` e `subtitle_format`, salvando arquivos `.srt`, `.vtt` e `_segments.json`
  - Adicionado param `subtitle_format` em `process_file()` e `process_file_with_progress()`
  - LÃ³gica para coletar segments (de AAI ou Whisper) e passÃ¡-los ao persist
- `apps/api/app/api/endpoints/transcription.py`:
  - Adicionado `subtitle_format` em `UrlVomoJobRequest`
  - Adicionado param `subtitle_format` nos 4 endpoints vomo (`/vomo`, `/vomo/jobs`, `/vomo/jobs/url`, `/vomo/stream`)
  - Registrados media types `.srt` (application/x-subrip) e `.vtt` (text/vtt) no download endpoint
- `apps/web/src/lib/api-client.ts` â€” Adicionado `subtitle_format?: 'srt' | 'vtt' | 'both'` em `startTranscriptionJob()` e `startTranscriptionJobFromUrl()`
- `apps/web/src/app/(dashboard)/transcription/page.tsx`:
  - Expandido `transcriptionType` para incluir `'legenda'`
  - Adicionado estado `subtitleFormat`
  - Nova opÃ§Ã£o "ğŸ¬ Legendas (SRT/VTT)" no seletor de tipo de transcriÃ§Ã£o
  - SeÃ§Ã£o de configuraÃ§Ã£o de legendas (formato SRT/VTT/Ambos) quando isLegenda
  - Expandidos dropdowns de idioma de 6 para 21 opÃ§Ãµes
  - BotÃµes de download SRT/VTT na aba export quando disponÃ­veis

### DecisÃµes Tomadas
- AssemblyAI como backend principal para legendas (melhor precisÃ£o de timestamps)
- Whisper como fallback (tambÃ©m tem segments com timestamps)
- Formato SRT usa vÃ­rgula como separador decimal (padrÃ£o SubRip): `HH:MM:SS,mmm`
- Formato VTT usa ponto como separador decimal (padrÃ£o WebVTT): `HH:MM:SS.mmm`
- VTT usa tags `<v SPEAKER>` para identificaÃ§Ã£o de falantes
- SRT usa prefixo `SPEAKER: ` no texto
- Segments sÃ£o salvos tambÃ©m como `_segments.json` para possÃ­vel uso futuro

### VerificaÃ§Ãµes
- Python syntax OK (transcription_service.py, endpoints/transcription.py, mlx_vomo.py)
- TypeScript sem erros (tsc --noEmit)

---

## 2026-02-03 â€” Sessao 73: Gaps 5 e 6 â€” Sincronizacao entre abas + Tracking de modificacoes

### Objetivo
Implementar Gap 5 (sincronizacao de estado de redlines entre abas do Word) e Gap 6 (tracking de modificacoes no documento apos analise) no Office Add-in.

### Arquivos Alterados
- `apps/office-addin/src/office/document-bridge.ts` â€” Adicionadas funcoes `getDocumentHash()` (calcula SHA-256 do texto do documento via Web Crypto API) e `checkDocumentModified()` (compara hash atual com esperado).
- `apps/office-addin/src/stores/playbook-store.ts` â€” Adicionados: constantes SYNC_KEY, TAB_ID_KEY, POLLING_INTERVAL; funcao `getTabId()` (gera/recupera UUID da aba via sessionStorage); funcao `broadcastStateChange()` (envia mudanca para outras abas via localStorage); interface `RedlineApplication`; novos campos de estado (playbookRunId, documentHashBeforeAnalysis, documentHashAfterRedlines, documentModified, redlineApplications); metodos `markRedlineApplied()` agora async (captura hash apos aplicacao e faz broadcast), `markRedlineRejected()` agora faz broadcast, `syncRedlineState()`, `initSyncListener()` (listener de storage events + polling fallback), `checkDocumentModification()`, `updateDocumentHash()`, `clearModificationWarning()`.
- `apps/office-addin/src/components/playbook/PlaybookPanel.tsx` â€” Adicionado useRef para interval de verificacao; useEffect para inicializar sync listener entre abas; useEffect para verificar modificacoes periodicamente (10s) quando em estado results; handlers `handleReanalyze()` e `handleIgnoreModification()`; componente de warning visual (banner amber com icone, mensagem e botoes Reanalisar/Ignorar).

### Decisoes Tomadas
- Gap 5: localStorage para broadcast entre abas (storage event) + polling fallback (30s) para casos onde storage event nao funciona (ex: iframes)
- Gap 5: sessionStorage para tabId unico por aba (persiste apenas na aba atual)
- Gap 5: playbookRunId UUID gerado a cada execucao para garantir que sync so ocorre entre abas analisando o mesmo playbook run
- Gap 6: SHA-256 via Web Crypto API (nativo, sem dependencias externas)
- Gap 6: Hash capturado antes da analise e atualizado apos cada redline aplicado
- Gap 6: Verificacao periodica a cada 10s quando em resultados
- Gap 6: UI warning com opcoes Reanalisar (re-executa playbook) ou Ignorar (atualiza hash baseline)

### Verificacoes
- TypeScript sem erros nos arquivos modificados (tsc --noEmit)
- Nota: erro pre-existente em Toast.tsx (nao relacionado a esta implementacao)

---

## 2026-02-02 â€” Sessao 72: Busca Cross-Collection (Legacy + Novas Collections Qdrant)

### Objetivo
Resolver o problema critico de documentos ja ingeridos nas collections legadas (lei, juris, doutrina, pecas_modelo, sei, local_chunks) nao serem buscaveis pelo smart-search do embedding_router, que so buscava nas collections novas (legal_br, legal_international, legal_eu, general).

### Arquivos Alterados
- `apps/api/app/services/rag/embedding_router.py` â€” Adicionados: constante LEGACY_COLLECTIONS (mapeamento jurisdicao -> collections legadas), constante LEGACY_EMBEDDING_DIMENSIONS, funcao `reciprocal_rank_fusion()` para merge de rankings, campo `include_legacy` no SmartSearchRequest, campo `collections_searched` no SmartSearchResponse, metodo `_search_legacy_collections()` que busca em paralelo nas collections legadas usando embedding OpenAI 3072d, metodo `migrate_collection()` para re-ingestao futura. O metodo `search_with_routing()` agora busca nas collections novas E legadas, fazendo merge via RRF.
- `apps/api/app/api/endpoints/rag.py` â€” Endpoint `/smart-search` agora passa `include_legacy` ao router e retorna `collections_searched` na response.

### Decisoes Tomadas
- Legacy search sempre usa embedding OpenAI 3072d (independente do provider do routing) pois e o que as collections legadas usam
- RRF com k=60 (valor padrao da literatura) para merge justo entre fontes com scores de escalas diferentes
- Busca nas collections legadas eh feita em paralelo (asyncio.gather) para minimizar latencia
- Flag `include_legacy=True` como default para nao quebrar nada; pode ser desabilitado para buscar apenas nas collections novas
- `migrate_collection()` criado mas nao executa automaticamente; para uso futuro controlado
- Collections legadas NAO sao modificadas

### Verificacoes
- Sintaxe Python OK em ambos os arquivos (ast.parse)

---

## 2026-02-02 â€” Sessao 71: Correcao de 3 problemas menores da auditoria

### Objetivo
Corrigir 3 problemas identificados na auditoria: QdrantClient sem connection pooling, EMBEDDING_DIMENSION inconsistente, e CITATION_PATTERNS duplicado.

### Arquivos Alterados
- `apps/api/app/services/rag/embedding_router.py` â€” QdrantClient agora e compartilhado (lazy init via `_get_qdrant_client`) ao inves de criado a cada chamada de `_search_qdrant`. Adicionados `_qdrant_client` e `_qdrant_lock` ao `__init__`.
- `apps/api/app/core/config.py` â€” Adicionado comentario explicativo em `EMBEDDING_DIMENSION` (768) referenciando que e para provider local/fallback e apontando para `rag/config.py`.
- `apps/api/app/services/rag/config.py` â€” Adicionado comentario explicativo em `embedding_dimensions` (3072) referenciando que e para provider primario e apontando para `core/config.py`.
- `apps/api/app/services/jurisprudence_verifier.py` â€” Removida duplicacao de CITATION_PATTERNS. Agora importa de `legal_vocabulary.py` e converte via `_adapt_citation_patterns()` com mapeamento `_NAME_TO_CTYPE`. Pattern exclusivo `acordao` mantido como adicao.

### Decisoes Tomadas
- QdrantClient usa double-checked locking (mesmo padrao de `_get_provider`)
- Valores de EMBEDDING_DIMENSION nao alterados, apenas documentados
- Para CITATION_PATTERNS, criado adaptador que mapeia nomes do legal_vocabulary para os ctypes esperados por `_normalize_citation`
- Pattern `acordao` generico mantido exclusivamente no verifier (cobertura mais ampla que legal_vocabulary)

### Verificacoes
- Sintaxe Python OK em todos os 4 arquivos (ast.parse)

---

## 2026-02-02 â€” Sessao 70: Correcao de 2 problemas da auditoria (Migration + RoutingDecision duplicado)

### Objetivo
Corrigir 2 problemas identificados na auditoria anterior: migration Alembic ausente para `citation_verifications` e nome duplicado `RoutingDecision`.

### Arquivos Alterados
- `apps/api/alembic/versions/u3v4w5x6y7z8_add_citation_verifications_table.py` â€” CRIADO: migration para tabela `citation_verifications` com ForeignKeys para `documents.id` e `users.id`, indices compostos (user+status, citation_type), downgrade com drop_table. down_revision aponta para `t2u3v4w5x6y7` (head atual).
- `apps/api/app/services/rag/embedding_router.py` â€” Renomeado `RoutingDecision` para `EmbeddingRoutingDecision` (todas as 15+ ocorrencias no arquivo)
- `apps/api/app/api/endpoints/rag.py` â€” Atualizado import de `RoutingDecision` para `EmbeddingRoutingDecision` e stub de fallback

### Decisoes Tomadas
- Migration criada manualmente (sem autogenerate) para evitar problemas de config do Alembic
- Nome `EmbeddingRoutingDecision` escolhido para diferenciar claramente da `RoutingDecision` dataclass do `hybrid_router.py`
- `hybrid_router.py` e `core/__init__.py` NAO foram alterados (existentes, sem risco de quebra)
- Verificado que nenhum outro arquivo importa `RoutingDecision` do `embedding_router`

### Verificacoes
- Sintaxe Python OK em todos os 3 arquivos (ast.parse)
- Cadeia de migrations verificada: 491a07bb915f -> ... -> t2u3v4w5x6y7 -> u3v4w5x6y7z8

---

## 2026-02-02 â€” Sessao 69: Code Review Rigoroso do Sistema RAG (Embeddings + Routing + Verifier)

### Objetivo
Code review completo dos arquivos recentes do sistema RAG: embedding_router, voyage_embeddings, legal_embeddings, legal_vocabulary, kanon_embeddings, jurisbert_embeddings, jurisprudence_verifier, model_router, citation_verification.

### Correcoes Aplicadas
1. `legal_embeddings.py` â€” Singleton `get_legal_embeddings_service()` corrigido para thread-safety com `threading.Lock()` (double-check locking). Antes nao tinha lock, risco de race condition em FastAPI.
2. `legal_embeddings.py` â€” `asyncio.get_event_loop()` deprecado substituido por `asyncio.get_running_loop()` com try/except RuntimeError (2 ocorrencias).
3. `core/embeddings.py` â€” Mesmo fix de `asyncio.get_event_loop()` deprecado para `asyncio.get_running_loop()`.
4. `jurisprudence_verifier.py` â€” Migrado de SDK antigo `google.generativeai` (genai.configure + GenerativeModel) para SDK novo `google.genai` (genai.Client + client.models.generate_content), consistente com o resto do projeto (2 ocorrencias).
5. `kanon_embeddings.py` â€” Docstring corrigido: dimensoes nativas sao 1792, usamos 1024 via Matryoshka (antes dizia "1792 default" o que confundia com o default do codigo que e 1024).

### Problemas Identificados (requerem decisao humana)
- Migration Alembic ausente para `citation_verifications` (models/citation_verification.py)
- RoutingDecision nome duplicado: Pydantic BaseModel em embedding_router.py vs dataclass em core/hybrid_router.py
- Sistema de collections paralelo: collections existentes (lei, juris, pecas) com 3072d vs novas (legal_br 768d, legal_international 1024d, legal_eu 1024d)
- core/config.py EMBEDDING_DIMENSION=768 vs rag/config.py embedding_dimensions=3072
- Duplicacao funcional entre legal_embeddings.py e pipeline RAG existente (query expansion, HyDE)
- QdrantClient criado por busca em embedding_router._search_qdrant (sem connection pooling)

### Verificacoes
- Imports: todos os modulos referenciados existem e sao importaveis
- web_search_service.search_legal: confirmado que existe
- record_api_call: confirmado que existe
- requirements.txt: voyageai, isaacus, langdetect, rank-bm25 presentes
- Endpoints rag.py: imports lazy com try/except, nao quebram se modulos ausentes

---

## 2026-02-02 â€” Sessao 68: Routing Multi-Embedding por Jurisdicao (JurisBERT, Kanon 2, Voyage, OpenAI)

### Arquivos Criados
- `apps/api/app/services/rag/kanon_embeddings.py` â€” Provider Kanon 2 Embedder (Isaacus): #1 no MLEB benchmark, 1024d Matryoshka, 16K tokens, SDK async + REST fallback, retry com backoff, fallback para voyage-law-2, cache LRU, cost tracker
- `apps/api/app/services/rag/jurisbert_embeddings.py` â€” Provider JurisBERT para direito BR: modelo juridics/bertlaw-base-portuguese-sts-scale (768d), self-hosted via sentence-transformers, lazy loading, GPU support (CUDA/MPS), fallback para voyage-multilingual-2, thread-safe
- `apps/api/app/services/rag/embedding_router.py` â€” Router multi-embedding com 3 camadas: (1) heuristica rapida por keywords/idioma/regex <1ms, (2) LLM routing via Gemini Flash quando incerto, (3) fallback OpenAI. Roteamento: BRâ†’JurisBERT, US/UK/INTâ†’Kanon2, EUâ†’Voyage, GENERALâ†’OpenAI. Collections Qdrant separadas por jurisdicao. Schemas Pydantic para smart-search e smart-ingest.

### Arquivos Alterados
- `apps/api/app/api/endpoints/rag.py` â€” Novos endpoints: POST /smart-search (busca com routing automatico), POST /smart-ingest (ingestao com classificacao automatica), GET /embedding-router/stats (metricas de todos os providers). Endpoints existentes NAO alterados.
- `apps/api/requirements.txt` â€” Adicionados: `isaacus>=0.1.0` (SDK Kanon 2), `langdetect>=1.0.9` (deteccao de idioma)
- `apps/api/.env.example` â€” Adicionadas variaveis: ISAACUS_API_KEY, JURISBERT_MODEL_NAME, JURISBERT_DEVICE, SMART_SKIP_RAG_CHARS

### Decisoes Tomadas
- Modelo JurisBERT verificado no HuggingFace: `juridics/bertlaw-base-portuguese-sts-scale` (768d, sentence-transformer, STS para PT-BR juridico)
- Kanon 2 Embedder confirmado via docs Isaacus: modelo "kanon-2-embedder", tasks "retrieval/document" e "retrieval/query", dimensoes Matryoshka 1792â†’1024â†’768â†’512â†’256 (usamos 1024 como default)
- Router usa heuristica com threshold 0.8 antes de chamar LLM (economia de custo)
- Collections Qdrant separadas: legal_br (768d), legal_international (1024d), legal_eu (1024d), general (3072d)
- Skip RAG para docs < 400K chars (~100 pgs) - envio direto ao LLM
- Todos os providers com cadeia de fallback em cascata
- Endpoints smart-search e smart-ingest sao NOVOS, nao quebram endpoints existentes

### Verificacoes
- Sintaxe de todos os arquivos Python validada com ast.parse: OK
- kanon_embeddings.py, jurisbert_embeddings.py, embedding_router.py, rag.py: todos OK

---

## 2026-02-02 â€” Sessao 67: Integracao Voyage AI como provider primario de embeddings juridicos

### Arquivos Criados
- `apps/api/app/services/rag/voyage_embeddings.py` â€” Provider completo Voyage AI: VoyageEmbeddingsProvider com suporte a voyage-law-2 (juridico), voyage-3-large (geral), voyage-3-lite (rapido); cache LRU thread-safe; retry com backoff exponencial; fallback automatico Voyage -> OpenAI; tracking de custos; batch processing com rate limit

### Arquivos Alterados
- `apps/api/requirements.txt` â€” Adicionado `voyageai>=0.3.2` como dependencia
- `apps/api/app/services/rag/legal_embeddings.py` â€” Integrado Voyage AI como provider primario: LegalEmbeddingConfig com opcoes Voyage; cadeia de fallback Voyage -> OpenAI -> SentenceTransformers; input_type assimetrico (document vs query); modelo voyage-law-2 para legal_mode=True, voyage-3-large para legal_mode=False
- `apps/api/app/services/rag/core/embeddings.py` â€” EmbeddingsService agora suporta provider "voyage" via RAG_EMBEDDINGS_PROVIDER; auto-detection de VOYAGE_API_KEY; metodo _embed_voyage para chamadas async; fallback transparente
- `apps/api/app/services/rag/.env.example` â€” Adicionadas variaveis Voyage AI (VOYAGE_API_KEY, VOYAGE_DEFAULT_MODEL, VOYAGE_FALLBACK_MODEL, RAG_EMBEDDINGS_PROVIDER)
- `apps/api/.env.example` â€” Adicionada secao Voyage AI com documentacao

### Decisoes Tomadas
- Voyage AI e opt-in: funciona sem VOYAGE_API_KEY, cai automaticamente no OpenAI
- Provider "auto" prioriza: Voyage > OpenAI > SentenceTransformers local
- Cache LRU separado no VoyageEmbeddingsProvider (2048 entradas) para nao conflitar com TTLCache do EmbeddingsService
- input_type assimetrico ("document" vs "query") e passado ao Voyage para otimizacao de retrieval
- Dimensoes ajustadas automaticamente quando Voyage esta ativo (1024 vs 3072 do OpenAI)
- Retry com backoff exponencial (3 tentativas) antes de cair no fallback

### Verificacoes
- Sintaxe de todos os arquivos Python validada com ast.parse: OK

---

## 2026-02-02 â€” Sessao 66: Vorbium Fase 2 â€” Redlines OOXML + Run Playbook no Word

### Arquivos Criados
- `apps/api/app/services/redline_service.py` â€” Servico completo de redlines OOXML: geracao de tracked changes (w:ins, w:del, w:commentRangeStart/End), RedlineItem dataclass, build de pacotes OOXML, run_playbook_on_word_document() integrando com PlaybookService, apply/reject operations

### Arquivos Alterados
- `apps/api/app/schemas/word_addin.py` â€” Adicionados schemas Fase 2: RedlineData, ClauseData, PlaybookRunStats, RunPlaybookRequest/Response, ApplyRedlineRequest/Response, RejectRedlineRequest/Response, ApplyAllRedlinesRequest/Response, PlaybookListItem, PlaybookListResponse
- `apps/api/app/api/endpoints/word_addin.py` â€” Adicionados 5 endpoints: POST /playbook/run, POST /redline/apply, POST /redline/reject, POST /redline/apply-all, GET /playbook/list
- `apps/office-addin/src/api/client.ts` â€” Adicionadas interfaces e funcoes API Fase 2: RedlineData, ClauseData, PlaybookRunStats, runPlaybook (120s timeout), getPlaybooksForAddin, applyRedlines, rejectRedlines, applyAllRedlines
- `apps/office-addin/src/stores/playbook-store.ts` â€” Reescrito para Fase 2: suporte a redlines/clauses separados, review tabs (All/Reviewed/Pending), filtros por classificacao e severidade, toRedlineOperations(), reviewProgress(), getRedlineForClause()
- `apps/office-addin/src/components/playbook/PlaybookPanel.tsx` â€” Reescrito: risk score, barra de progresso de revisao, review tabs, filtros, acoes batch (Apply All, Comentar tudo, Destacar tudo), acoes individuais com tracked changes
- `apps/office-addin/src/components/playbook/ClauseCard.tsx` â€” Reescrito: suporte a ClauseData + RedlineData, classificacoes novas e legacy, barra de confianca, botoes Apply/Preview/Rejeitar
- `apps/office-addin/src/components/playbook/RedlinePreview.tsx` â€” Reescrito: ClauseData + RedlineData, labels de severidade/classificacao, confianca, raciocinio da IA, indicador OOXML
- `apps/office-addin/src/office/redline-engine.ts` â€” Adicionado campo `ooxml?: string` ao RedlineOperation, applyRedlineAsTrackedChange agora prefere OOXML pre-gerado pelo servidor, highlightClauses suporta classificacao 'compliant'

### Decisoes Tomadas
- OOXML do servidor tem prioridade sobre geracao client-side no redline-engine.ts
- Classificacoes legacy (conforme/nao_conforme/ausente/parcial) mantidas no frontend para backward compatibility
- Store usa getPlaybooksForAddin() (novo endpoint com filtro de acesso) em vez de getPlaybooks()
- Timeout de 120s para runPlaybook (analise pode ser demorada)
- Tracked changes como estrategia primaria, fallback para highlight+comentario quando OOXML nao suportado

### Verificacoes
- `npx tsc --noEmit` â€” OK (zero erros de tipo)
- ESLint nao configurado para office-addin (eslint.config.js ausente) â€” nao bloqueante

---

## 2026-02-02 â€” Sessao 65: Embeddings Juridicos Brasileiros Especializados

### Arquivos Alterados
- `apps/api/app/services/rag/legal_vocabulary.py` â€” **NOVO** Vocabulario juridico brasileiro completo: 204 abreviacoes, 47 grupos de sinonimos (193 termos), 75 termos preservados, 19 padroes de citacao regex, 61 stopwords juridicas, hierarquia normativa, funcoes de extracao de citacoes e deteccao de nivel normativo
- `apps/api/app/services/rag/legal_embeddings.py` â€” **NOVO** Servico de embeddings juridicos: preprocessamento (normalizacao, expansao de abreviacoes, remocao de ruido), segmentacao inteligente respeitando artigos/clausulas, BM25 com vocabulario juridico, query augmentation (HyDE juridico, multi-query, sinonimos), integracao plug-and-play com pipeline RAG existente
- `apps/api/app/api/endpoints/rag.py` â€” Adicionado `legal_mode` flag em SearchRequest, LocalIngestRequest e GlobalIngestRequest. Novo endpoint POST /embeddings/compare para comparar resultados com e sem otimizacao juridica. Integracao de preprocessing juridico nos fluxos de busca e ingestao

### Decisoes Tomadas
- Estrategia multi-embedding: OpenAI text-embedding-3-large como primario, SentenceTransformers multilingual como fallback, BM25 como lexico
- Modo juridico e opt-in (legal_mode=True) para backward compatibility total
- Preprocessamento juridico expande abreviacoes (art. -> artigo, STF -> Supremo Tribunal Federal) e remove ruido processual
- Segmentacao inteligente respeita limites de artigos/clausulas em vez de quebrar mecanicamente por tamanho
- Score combinado usa peso 70% semantico + 30% BM25 para busca hibrida juridica
- Endpoint /embeddings/compare permite avaliar impacto da otimizacao lado a lado

### Comandos Executados
- `python3 -c "import ast; ..."` â€” Verificacao de sintaxe dos 3 arquivos (OK)
- Testes de funcionalidade: extracao de citacoes, preprocessamento, segmentacao, query augmentation (OK)

---

## 2026-02-02 â€” Sessao 64: Column Builder para Review Tables (estilo Harvey AI)

### Arquivos Alterados
- `apps/api/app/models/review_table.py` â€” Adicionados 7 novos tipos de coluna ao enum ColumnType: summary, date_extraction, yes_no_classification, verbatim_extraction, risk_rating, compliance_check, custom
- `apps/api/app/services/review_table_service.py` â€” Reescrito com novas funcionalidades: generate_columns() (Column Builder via IA), fill_table() (preenchimento incremental), exportacao XLSX avancada com 3 abas (dados, resumo, metadados), color coding por tipo de coluna (risk_rating, compliance_check), mapeamento completo COLUMN_TYPE_DESCRIPTIONS
- `apps/api/app/api/endpoints/review_tables.py` â€” Adicionados 5 novos endpoints: POST /columns/generate (standalone), POST /{id}/columns/generate (por review), POST /{id}/fill, POST /{id}/export/xlsx, POST /{id}/export/csv. Novos schemas: ColumnGenerateRequest, ColumnGenerateResponse, FillTableRequest, FillTableResponse. Nova background task _fill_table_background. Refatorado export com _do_export() compartilhado.

### Decisoes Tomadas
- Column Builder usa prompt especializado (COLUMN_BUILDER_PROMPT) que instrui a IA a gerar 3-15 colunas com tipos e prompts de extracao
- fill_table() e incremental: pode adicionar novos documentos a uma tabela existente sem perder resultados anteriores
- Exportacao XLSX agora tem 3 abas: dados (com color coding por tipo), resumo (estatisticas), metadados (definicoes)
- Color coding especifico para risk_rating (verde/amarelo/vermelho/critico) e compliance_check (conforme/parcialmente/nao conforme)
- Validacao de tipos de coluna contra enum ColumnType ao gerar colunas via IA
- Background tasks para fill_table com mesma pattern de process_review

### Testes Executados
- Validacao de sintaxe Python (ast.parse) dos 3 arquivos â€” OK

---

## 2026-02-02 â€” Sessao 63: Verificacao de Vigencia de Jurisprudencia (Shepardizacao BR)

### Arquivos Criados
- `apps/api/app/services/jurisprudence_verifier.py` â€” Servico completo de shepardizacao brasileira: extrai citacoes (regex + LLM), verifica vigencia via web search + analise LLM, classifica status (vigente/superada/revogada/alterada/inconstitucional), cache em disco com TTL de 7 dias
- `apps/api/app/models/citation_verification.py` â€” Modelo SQLAlchemy para persistencia de verificacoes (CitationVerification, CitationStatus, CitationType)
- `apps/api/app/schemas/citation_verification.py` â€” Schemas Pydantic para request/response dos endpoints (VerifyCitationsRequest, ShepardizeRequest, etc.)

### Arquivos Alterados
- `apps/api/app/api/endpoints/knowledge.py` â€” Adicionados 2 endpoints: POST /knowledge/verify-citations (texto ou lista de citacoes) e POST /knowledge/shepardize (por document_id)

### Decisoes Tomadas
- Regex como primeira camada de extracao (rapido, sem custo) + LLM para cobertura extra
- Web search via web_search_service.search_legal() (fontes juridicas BR) como fonte primaria de verificacao
- Gemini Flash como LLM de analise (custo baixo, rapido)
- Cache em disco com TTL 7 dias para evitar re-verificacoes desnecessarias
- Concorrencia controlada (semaphore max_concurrent=3) para nao sobrecarregar APIs
- Padroes de regex cobrem: sumulas, sumulas vinculantes, leis, artigos, CF, decretos, MPs, processos CNJ, acordaos (REsp, RE, HC, ADI, etc.)

### Testes Executados
- Validacao de sintaxe Python (ast.parse) de todos os 4 arquivos â€” OK

---

## 2026-02-02 â€” Sessao 62: Implementacao Model Router (Roteamento Inteligente de Modelos)

### Arquivos Criados
- `apps/api/app/services/ai/model_router.py` â€” Servico de roteamento inteligente de modelos por tipo de tarefa (inspirado Harvey AI). Define 8 categorias de tarefa juridica, tabela de roteamento com fallbacks cross-provider, metricas in-memory, suporte a override do usuario, filtro por janela de contexto
- `apps/api/app/api/endpoints/models.py` â€” Endpoints REST: POST /models/route, GET /models/routes, GET /models/metrics, GET /models/available

### Arquivos Alterados
- `apps/api/app/api/routes.py` â€” Registrado router de models com prefix="/models"
- `apps/api/app/services/ai/__init__.py` â€” Exportado model_router, ModelRouter, TaskCategory
- `apps/api/app/services/ai/model_registry.py` â€” pick_model_for_job() atualizado para aceitar parametro task= e delegar ao ModelRouter quando informado (backward compatible)

### Decisoes Tomadas
- Tabela de roteamento estatica (nao ML) por simplicidade e previsibilidade
- Fallbacks sempre cross-provider para resiliencia
- Override do usuario tem prioridade absoluta sobre o router
- Metricas in-memory (sem persistencia) para MVP â€” pode evoluir para Redis/DB
- Singleton model_router para compartilhar metricas entre requests

### Testes Executados
- Import e execucao do router via python3.11 â€” OK
- DRAFTING -> claude-4.5-opus (anthropic) com fallbacks [claude-4.5-sonnet, gpt-5.2]
- RESEARCH (fast) -> gemini-3-flash
- SUMMARIZATION (override gpt-5.2) -> gpt-5.2 (is_override=True)
- Metricas de chamada e error_rate â€” OK
- Route table com 8 categorias â€” OK

---

## 2026-02-02 â€” Sessao 61: AtualizaÃ§Ã£o Claude Models (4.5 family) + Model Registry Fix

### Arquivos Alterados
- `apps/api/app/services/ai/claude_agent/executor.py` â€” `CLAUDE_AGENT_DEFAULT_MODEL` atualizado de `claude-sonnet-4-20250514` para `claude-sonnet-4-5`. `MODEL_CONTEXT_WINDOWS` atualizado com toda famÃ­lia 4.5 (Opus/Sonnet/Haiku) + aliases + legacy models
- `apps/api/app/services/ai/model_registry.py` â€” Claude 4.5 Opus: `thinking_category` de `xml` para `native`, `max_output_tokens` de 8192 para 64000. Claude 4.5 Sonnet: `max_output_tokens` de 8192 para 64000. Claude 4.5 Haiku: `for_agents` True, `thinking_category` de `agent` para `native`, `max_output_tokens` 64000, capabilities atualizadas

### VerificaÃ§Ã£o contra docs oficiais (platform.claude.com/docs/en/about-claude/models/overview)
- **NÃ£o existe "Claude Haiku 4"** â€” modelo atual Haiku Ã© **4.5** (`claude-haiku-4-5-20251001`)
- Todos os modelos 4.5 suportam extended thinking (incluindo Haiku)
- Max output: 64K tokens para todos os 4.5
- 3.5 Haiku deprecated (Jan 2026), 3.7 Sonnet deprecated (Nov 2025)

---

## 2026-02-02 â€” Sessao 60: Code Review Completo + CorreÃ§Ã£o de 117 Issues (Corpus & Playbooks)

### Resumo
RevisÃ£o completa da implementaÃ§Ã£o Corpus + Playbooks seguida de correÃ§Ã£o massiva em paralelo.
4 agentes de review encontraram 117 issues â†’ 6 agentes de fix corrigiram em paralelo.

### Agente 1: Auth Guards em Endpoints Desprotegidos
- `auth.py` â€” Guard de ambiente em `/login-test`
- `chat.py` â€” Auth em `create_thread`, `list_threads`, `get_thread`
- `advanced.py` â€” Auth em todos os 10 endpoints
- `transcription.py` â€” Auth em todos os 26 endpoints
- `health.py` â€” Auth + admin check em `reset-circuits`
- `webhooks.py` â€” ValidaÃ§Ã£o de webhook secret

### Agente 2: MigraÃ§Ãµes Alembic Faltantes
- `t0u1v2w3x4y5_add_shared_spaces_tables.py` â€” shared_spaces + space_invites + space_resources
- `t1u2v3w4x5y6_fix_guest_sessions_chain.py` â€” guest_sessions re-encadeada
- `t2u3v4w5x6y7_add_missing_model_tables.py` â€” rag_eval_metrics, rag_ingestion_events, etc.
- `ef2c21b089eb_restore_missing_columns.py` â€” try/except para colunas existentes
- Removido `d9a3f7e2c1b4_add_guest_sessions_table.py` (orphaned, substituÃ­do por t1u2)

### Agente 3: SeguranÃ§a Backend
- `url_scraper_service.py` â€” ProteÃ§Ã£o SSRF (bloqueia IPs privados)
- `user.py` â€” CPF/CNPJ removidos de UserResponse (LGPD)
- `workflow.py` â€” webhook_secret removido de to_dict()
- `marketplace.py` â€” Escape de wildcards SQL em search
- `shared_space.py` â€” Token removido de SpaceInviteResponse
- SanitizaÃ§Ã£o de erros em auth, cases, word_addin, chat_integration

### Agente 4: Frontend Bugs CrÃ­ticos
- `analyze/page.tsx` â€” State-during-render fixado com useEffect
- `alert-dialog.tsx` â€” Novo componente shadcn/ui AlertDialog
- `playbooks/page.tsx`, `playbook-card.tsx`, `playbook-rule-editor.tsx` â€” AlertDialog em deletes
- `playbooks/hooks.ts` â€” Mapeamento de campos corrigido

### Agente 5: Frontend API Client
- `api-client.ts` â€” 25 console.logs protegidos com NODE_ENV check, Content-Type removido de uploads
- `use-corpus.ts` â€” Toasts de sucesso/erro em 6 mutations

### Agente 6: Frontend Search + Review
- `corpus-global-tab.tsx`, `corpus-private-tab.tsx` â€” Busca client-side funcional
- `corpus-private-tab.tsx` â€” confirm()/prompt() substituÃ­dos por AlertDialog/Dialog
- `playbook-share-dialog.tsx` â€” try/catch no clipboard
- `playbooks/[id]/page.tsx` â€” try/catch com toasts em save

### VerificaÃ§Ãµes Finais
- `npx tsc --noEmit` â€” OK (sem erros)
- Cadeia Alembic â€” 28 migraÃ§Ãµes, linear, sem forks
- Fork `d9a3f7e2c1b4` removido (era duplicate apontando para b7c42f)

---

## 2026-02-02 â€” Sessao 59: Security - Authentication Guards on Unprotected Endpoints

### Arquivos Alterados

**Backend:**
- `apps/api/app/api/endpoints/auth.py` â€” Added environment check to `/auth/login-test`: returns 404 when `DEBUG=False` and `ENVIRONMENT != "development"`.
- `apps/api/app/api/endpoints/chat.py` â€” Added `current_user: User = Depends(get_current_user)` to `create_thread`, `list_threads`, and `get_thread` endpoints.
- `apps/api/app/api/endpoints/advanced.py` â€” Added auth imports and `current_user` dependency to all 10 endpoints (renumber, audit-structure, consistency-check, verify-citation, dry-run-analysis, cross-file-duplicates, apply-structural-fixes, transcribe-advanced, audit-with-rag, diarization/align).
- `apps/api/app/api/endpoints/transcription.py` â€” Added auth imports (`Depends`, `get_current_user`, `User`) and `current_user` dependency to all 26 endpoints.
- `apps/api/app/api/endpoints/health.py` â€” Added auth imports and `current_user` dependency to `POST /health/rag/reset-circuits` with admin role check (403 if not admin).
- `apps/api/app/api/endpoints/webhooks.py` â€” Implemented webhook secret validation using `settings.TRIBUNAIS_WEBHOOK_SECRET`. Rejects with 401 if secret is set and doesn't match. Logs warning if secret is not configured.

### DecisÃµes Tomadas
- login-test: Returns generic 404 (not 403) in production to avoid information leakage.
- health reset-circuits: Checks `role.value` with fallback to string comparison for enum flexibility.
- webhooks: Uses `getattr` with fallback for settings access safety. Logs warning when secret not configured instead of blocking.
- All changes are additive auth guards only -- no business logic was modified.

---

## 2026-02-02 â€” Sessao 59: RevisÃ£o completa Code Execution (todos providers) + CorreÃ§Ãµes crÃ­ticas

### Erros Encontrados e Corrigidos

**OpenAI:**
1. **SDK version**: `openai==1.55.3` NÃƒO tem `client.responses` (Responses API). Precisa `>=1.66.0` â†’ Atualizado em `requirements.txt`
2. **Event name errado**: `response.code_interpreter_call.code.delta` â†’ correto: `response.code_interpreter_call_code.delta` (underscore, nÃ£o ponto)
3. **Event inexistente**: `response.code_interpreter_call_output.done` nÃ£o existe â†’ outputs vÃªm em `response.code_interpreter_call.completed`
4. **GPT-5.2 variantes**: Adicionados `gpt-5.2-instant`, `gpt-5.2-pro`, `gpt-5.2-codex` no MODEL_CONTEXT_WINDOWS do executor
5. **include param**: Adicionado `include=["code_interpreter_call.outputs"]` para garantir outputs completos

**Anthropic:**
1. **effort NÃƒO vai na tool definition**: Movido de `ce_tool["effort"]` para `output_config: {"effort": "medium"}` no body da request
2. **effort requer beta header separado**: `effort-2025-11-24` (alÃ©m de `code-execution-2025-08-25`)
3. **effort sÃ³ Opus 4.5**: Adicionado check `model.startswith("claude-opus-4")`
4. **Modelos compatÃ­veis**: Adicionados `claude-sonnet-4-5`, `claude-opus-4-5`, `claude-opus-4-1`. Corrigido `claude-3-5-haiku-latest` â†’ `claude-3-5-haiku` (prefix match mais correto)

### Arquivos Alterados
- `apps/api/requirements.txt` â€” `openai==1.55.3` â†’ `openai>=1.66.0`
- `apps/api/app/services/ai/agent_clients.py` â€” Responses API event names corrigidos, effort movido para output_config + beta header, model compat lists atualizadas
- `apps/api/app/services/ai/claude_agent/executor.py` â€” effort movido de tool def para output_config + effort beta header, model compat lists atualizadas
- `apps/api/app/services/ai/executors/openai_agent.py` â€” MODEL_CONTEXT_WINDOWS com GPT-5.2 variantes

---

## 2026-02-02 â€” Sessao 58: OpenAI Code Interpreter via Responses API + Container Reuse

### Arquivos Alterados

**Backend:**
- `apps/api/app/services/ai/agent_clients.py` â€” `stream_openai_async()`: adicionados params `enable_code_interpreter` e `container_id`. Quando habilitado e Responses API disponÃ­vel, usa `client.responses.create(stream=True)` com `tools=[{"type":"code_interpreter","container":{"type":"auto"}}]` em vez de Chat Completions. Processa eventos streaming: `response.output_text.delta`, `response.code_interpreter_call.code.delta`, `response.code_interpreter_call_output.done`, `response.completed` (para extrair container_id). Fallback para Chat Completions se Responses API falhar.
- `apps/api/app/services/ai/executors/openai_agent.py` â€” `HOSTED_TOOLS["code_interpreter"]`: atualizado para incluir `"container": {"type": "auto"}` (container reusÃ¡vel).
- `apps/api/app/api/endpoints/chats.py` â€” Handler GPT: leitura de `openai_container_id` do `chat.context`, passa como param. Handlers para `code_execution`, `code_execution_result` e `container_id` chunks. Container_id persistido em `chat.context["openai_container_id"]`.

### Problema Detectado
- `stream_openai_async` usava apenas Chat Completions API, que NÃƒO suporta code_interpreter
- Agora usa Responses API quando code_interpreter estÃ¡ habilitado, com fallback para Chat Completions

### DecisÃµes Tomadas
- Responses API como path primÃ¡rio quando code_interpreter habilitado (Chat Completions como fallback)
- Container mode "auto" para reuso automÃ¡tico de containers
- Container_id persistido em `chat.context["openai_container_id"]` (sem migration)
- Containers OpenAI expiram apÃ³s 20min idle â€” tratados como efÃªmeros

---

## 2026-02-02 â€” Sessao 57: Gemini Code Execution + Fallback Vertex AI para Claude

### Arquivos Alterados

**Backend:**
- `apps/api/app/services/ai/agent_clients.py`:
  - `stream_vertex_gemini_async()`: adicionado filtro de compatibilidade (`flash-lite` nÃ£o suporta code execution)
  - `get_async_claude_direct_client()`: **NOVA FUNÃ‡ÃƒO** â€” client direto (non-Vertex) para features nÃ£o suportadas no Vertex AI
  - `stream_anthropic_async()`: quando client Ã© Vertex e code execution estÃ¡ habilitado, faz **fallback automÃ¡tico** para client direto via `ANTHROPIC_API_KEY`
- `apps/api/app/services/ai/executors/google_agent.py` â€” `_convert_tools_to_gemini_format()`: filtro de modelo `flash-lite` + cascading fallback para `ToolCodeExecution` class ref (novo SDK) antes de `{}` (SDK antigo)

### Problema Detectado (CRÃTICO)
- **Code execution do Claude (`code_execution_20250825`) NÃƒO Ã© suportado no Vertex AI** â€” apenas na API direta da Anthropic e Amazon Bedrock
- O sistema prioriza `AsyncAnthropicVertex` quando `GOOGLE_CLOUD_PROJECT` estÃ¡ configurado, o que desabilitava silenciosamente o code execution para Claude no chat comum
- O executor do Claude Agent (`ClaudeAgentExecutor`) jÃ¡ usava API direta (`AsyncAnthropic`) â€” sem problema
- **SoluÃ§Ã£o**: dual-client â€” Vertex como padrÃ£o, fallback para client direto quando code execution Ã© necessÃ¡rio

### VerificaÃ§Ã£o Gemini
- `types.Tool(code_execution=types.ToolCodeExecution)` â€” corretamente implementado com cascading fallback
- Vertex AI path funciona nativamente para Gemini (code execution suportado)
- Multi-turn no Gemini preserva estado automaticamente (sem container_id explÃ­cito)
- Flash Lite nÃ£o suporta code execution â€” filtro adicionado
- Modelos Gemini 3.0 Pro/Flash jÃ¡ registrados

### DecisÃµes Tomadas
- Dual-client para Claude: Vertex padrÃ£o + fallback direto para code execution
- Requer `ANTHROPIC_API_KEY` configurada alÃ©m do `GOOGLE_CLOUD_PROJECT` para code execution funcionar
- Gemini code execution funciona normalmente no Vertex â€” sem necessidade de fallback

---

## 2026-02-02 â€” Sessao 56: Effort Parameter + Container Reuse (Anthropic Code Execution)

### Arquivos Alterados

**Backend:**
- `apps/api/app/services/ai/claude_agent/executor.py` â€” `AgentConfig`: adicionado `code_execution_effort: str = "medium"`. `AgentState`: adicionado `container_id: Optional[str] = None`. `_call_claude()`: aceita `container_id`, passa `effort` na tool definition e `container` no kwargs da API. ExtraÃ§Ã£o de `container_id` da resposta (`response.container.id`) em ambos os loops do agente. `to_dict()` inclui `container_id`.
- `apps/api/app/services/ai/agent_clients.py` â€” `stream_anthropic_async()`: novos params `code_execution_effort` e `container_id`. Tool definition inclui campo `effort`. Container passado nos kwargs quando disponÃ­vel. Emite `('container_id', value)` ao final da stream (capturado de `message_stop` event ou `get_final_message()`).
- `apps/api/app/api/endpoints/chats.py` â€” Leitura de `anthropic_container_id` do `chat.context` antes de cada chamada. Handler para `container_id` chunks que persiste o valor no `chat.context` via DB.

### DecisÃµes Tomadas
- Container reuse persistido no campo `chat.context` (JSON) do modelo Chat, sem necessidade de migration
- Effort default = "medium" (equilÃ­brio custo/qualidade)
- Container passado apenas quando existir (primeira chamada nÃ£o envia, recebe de volta)
- ExtraÃ§Ã£o do container_id usa `message_stop` event + fallback `get_final_message()`

---

## 2026-02-02 â€” Sessao 55: Code Execution no Chat Comum (todos os providers)

### Arquivos Alterados

**Backend:**
- `apps/api/app/services/ai/agent_clients.py` â€” `stream_anthropic_async()`: adicionado param `enable_code_execution=True`, tool `code_execution_20250825` injetada, chamada migrada para `client.beta.messages.stream()` com beta header; processamento de `content_block_start` (server_tool_use) e `content_block_stop` (bash/text_editor results). `stream_vertex_gemini_async()`: adicionado param `enable_code_execution=True`, `Tool(code_execution)` injetada no config; `_yield_parts()` atualizado para processar `executable_code` e `code_execution_result`.
- `apps/api/app/api/endpoints/chats.py` â€” Handlers SSE atualizados para Claude e Gemini: novos tipos `code_execution` e `code_execution_result` emitidos via SSE para o frontend.

### DecisÃµes Tomadas
- OpenAI Chat Completions API nÃ£o suporta code_interpreter nativamente (sÃ³ Responses API/Assistants API) â€” code_interpreter habilitado apenas no OpenAI Agent executor
- Claude e Gemini habilitados tanto no chat comum quanto no agent mode
- Eventos SSE de code execution seguem mesmo formato nos dois caminhos (agent + chat)

---

## 2026-02-02 â€” Sessao 54: Correcao de conflitos Alembic + TypeScript

### Arquivos Alterados

**Alembic Migrations (chain fix):**
- `p7q8r9s0t1u2_add_folder_path_to_corpus_docs.py` â€” down_revision corrigido: o5p6... â†’ p6q7...
- `q7r8s9t0u1v2_add_audit_logs_table.py` â€” down_revision corrigido: p6q7... â†’ p7q8...
- `r8s9t0u1v2w3_enhance_dms_integrations.py` â†’ renomeado para `s0t1u2v3w4x5_enhance_dms_integrations.py` (revision e down_revision atualizados)
- `q7r8s9t0u1v2_add_party_perspective_cell_history.py` â†’ renomeado para `s9t0u1v2w3x4_add_party_perspective_cell_history.py` (revision e down_revision atualizados)

**Frontend TypeScript fix:**
- `apps/web/src/app/(dashboard)/corpus/components/corpus-private-tab.tsx` â€” Import de `CorpusDocument`, fix tipo `sortDocuments` (conditional type `never` â†’ `CorpusDocument[]`)

### Decisoes Tomadas
- Cadeia linear Alembic: ...o5p6 â†’ p6q7 â†’ p7q8 â†’ q7r8 â†’ r8s9 â†’ s0t1 â†’ s9t0
- IDs duplicados resolvidos com novos IDs unicos (s0t1u2v3w4x5, s9t0u1v2w3x4)

### Comandos Executados
- `npx tsc --noEmit` â€” 7 erros antes, 0 apos fix (OK)

---

## 2026-02-02 â€” Sessao 53: Playbook UX Improvements (4 Tasks)

### Arquivos Alterados

**Backend:**
- `apps/api/app/schemas/playbook_analysis.py` â€” Adicionado campo `comment` (Optional[str]) ao ClauseAnalysisResult
- `apps/api/app/services/playbook_prompts.py` â€” Atualizado CLAUSE_ANALYSIS_PROMPT para gerar campo `comment`
- `apps/api/app/services/playbook_service.py` â€” Atualizado analyze_clause para parsear e propagar `comment`
- `apps/api/app/api/endpoints/playbooks.py` â€” Endpoint GET /{id}/versions, helper _create_version_snapshot, auto-versioning
- `apps/api/app/models/playbook.py` â€” Novo modelo PlaybookVersion
- `apps/api/app/models/__init__.py` â€” Export de PlaybookVersion
- `apps/api/app/schemas/playbook.py` â€” PlaybookVersionResponse e PlaybookVersionListResponse
- `apps/api/alembic/versions/r8s9t0u1v2w3_add_playbook_versions_table.py` â€” Migration playbook_versions

**Frontend:**
- `apps/web/src/app/(dashboard)/playbooks/hooks.ts` â€” comment field, PlaybookVersionEntry, usePlaybookVersions
- `apps/web/src/app/(dashboard)/playbooks/components/playbook-analysis-panel.tsx` â€” CommentBubble, StatusFilterChips
- `apps/web/src/app/(dashboard)/playbooks/[id]/page.tsx` â€” PlaybookVersionTimeline, botao Historico

### Decisoes Tomadas
- Task 2 (Mark as Reviewed) ja implementada â€” sem alteracao
- Comment Bubbles: icone clicavel com popover
- Status Filter: chips com contadores, dual-filter com revisao
- Version History: timeline vertical, auto-versioning em create/update/delete rule

---

## 2026-02-02 â€” Sessao 52: Habilitar Code Interpreter/Execution em Todos os Agentes

### Arquivos Alterados

**Backend:**
- `apps/api/app/services/ai/executors/openai_agent.py` â€” `enable_code_interpreter` mudado de `False` para `True` no default da config
- `apps/api/app/services/ai/executors/google_agent.py` â€” Adicionado campo `enable_code_execution: bool = True` na config; `_convert_tools_to_gemini_format()` reescrito para incluir `Tool(code_execution={})`; processamento de `executable_code` e `code_execution_result` adicionado nos modos chat e ADK
- `apps/api/app/services/ai/claude_agent/executor.py` â€” Adicionado `enable_code_execution: bool = True`; chamada API migrada para `client.beta.messages.create()` com beta header `code-execution-2025-08-25`; tool `code_execution_20250825` injetada; `_extract_response_content()` expandido para processar `server_tool_use`, `bash_code_execution_tool_result`, `text_editor_code_execution_tool_result`; tratamento de `pause_turn` stop reason
- `apps/api/app/services/ai/shared/sse_protocol.py` â€” Novos tipos SSE: `CODE_EXECUTION`, `CODE_EXECUTION_RESULT`
- `apps/api/app/services/ai/orchestration/router.py` â€” `enable_code_interpreter=True` no OpenAI config; `enable_code_execution=True` no Google config
- `apps/api/requirements.txt` â€” `anthropic>=0.50.0` (permitir upgrade para suporte ao beta)

**Frontend:**
- `apps/web/src/stores/chat-store.ts` â€” Handlers para eventos SSE `code_execution` e `code_execution_result`

### DecisÃµes Tomadas
- OpenAI: Usa `code_interpreter` hosted tool (jÃ¡ implementado, sÃ³ precisava habilitar)
- Google/Gemini: Usa `Tool(code_execution={})` nativa do SDK
- Claude/Anthropic: Usa beta API `code-execution-2025-08-25` com `code_execution_20250825` server tool
- Frontend: Eventos de code execution mapeados para `lastToolCall` store (reutiliza UI de tool calls)

---

## 2026-02-02 â€” Sessao 51: Folder Hierarchy + Multiple Views para Corpus

### Arquivos Alterados

**Backend:**
- `apps/api/app/models/corpus_project.py` â€” Adicionado campo `folder_path` (String, nullable) ao modelo CorpusProjectDocument + indice composto (project_id, folder_path)
- `apps/api/alembic/versions/p7q8r9s0t1u2_add_folder_path_to_corpus_docs.py` â€” Nova migration Alembic adicionando coluna folder_path
- `apps/api/app/schemas/corpus_project.py` â€” Novos schemas: FolderNode, FolderTreeResponse, MoveDocumentRequest, CreateFolderRequest. Atualizado CorpusProjectDocumentAdd e CorpusProjectDocumentResponse com folder_path
- `apps/api/app/api/endpoints/corpus_projects.py` â€” 4 novos endpoints: GET folders, POST folders, GET documents (com filtro por pasta/status/sort), PATCH move document

**Frontend:**
- `apps/web/src/lib/api-client.ts` â€” 4 novos metodos: getCorpusProjectFolders, createCorpusProjectFolder, getCorpusProjectDocuments, moveCorpusProjectDocument
- `apps/web/src/app/(dashboard)/corpus/hooks/use-corpus.ts` â€” Novos tipos (FolderNode, FolderTreeResponse, ProjectDocumentResponse) + 4 novos hooks (useProjectFolders, useProjectDocuments, useCreateProjectFolder, useMoveProjectDocument)
- `apps/web/src/app/(dashboard)/corpus/components/corpus-folder-tree.tsx` â€” Novo componente: arvore de pastas colapsavel com criacao de pastas e contagem de docs
- `apps/web/src/app/(dashboard)/corpus/components/corpus-view-controls.tsx` â€” Novo componente: toggle de views (Lista/Grade/Agrupado) + dropdown de ordenacao, com persistencia em localStorage
- `apps/web/src/app/(dashboard)/corpus/components/corpus-document-views.tsx` â€” Novo componente: 3 views (ListView, GridView, GroupedView) com acoes de delete/reindex/mover
- `apps/web/src/app/(dashboard)/corpus/components/corpus-private-tab.tsx` â€” Reescrita integrando folder tree sidebar, breadcrumb navigation, view controls, e sorting

### Decisoes Tomadas
- Pastas virtuais (derivadas de folder_path nos documentos, sem tabela propria) â€” simples e flexivel
- Arvore de pastas reconstruida no endpoint GET /folders a partir de folder_paths distintos
- View preference persistida em localStorage para manter entre sessoes
- 3 views: Lista (padrao), Grade (cards), Agrupado (por pasta)
- 3 opcoes de ordenacao: Mais recentes, Mais antigos, Ordem alfabetica
- Breadcrumb para navegacao de pastas + sidebar colapsavel em telas grandes
- Mover documentos via prompt simples (pode ser melhorado com dialog dedicado)

---

## 2026-02-02 â€” Sessao 50: Dashboard Homepage Personalizada

### Arquivos Alterados
- `apps/api/app/api/endpoints/dashboard.py` â€” Novo endpoint GET /dashboard/recent-activity com atividade recente e stats do usuario
- `apps/api/app/api/routes.py` â€” Registro do router dashboard com prefix /dashboard
- `apps/web/src/lib/api-client.ts` â€” Novo metodo getDashboardRecentActivity()
- `apps/web/src/app/(dashboard)/dashboard/page.tsx` â€” Reescrita completa com welcome section, quick actions, stats bar, e grid 2x2 de atividade recente

### Decisoes Tomadas
- Endpoint unico /dashboard/recent-activity retorna tudo em uma chamada (playbooks, corpus, chats, reviews + stats)
- Playbooks com rule_count via LEFT JOIN + GROUP BY para evitar N+1
- Frontend usa useState + useCallback em vez de React Query (padrao existente do projeto)
- Loading skeletons dedicados para cada secao (welcome, stats, activity grid)
- Labels em portugues brasileiro, datas relativas (agora mesmo, Xmin atras, ontem, etc.)
- Quick actions apontam para rotas existentes (/minuta, /playbooks, /corpus, /workflows)
- Empty states com CTA para criacao quando nao ha dados

### Comandos Executados
- Leitura extensiva de modelos, endpoints, componentes e stores existentes

---

## 2026-02-02 â€” Sessao 49: Inline Cell Editing + Natural Language Query para Review Tables

### Arquivos Alterados
- `apps/api/app/api/endpoints/review_tables.py` â€” Novos endpoints PATCH `/{id}/cell` (editar celula) e POST `/{id}/query` (consulta LLM)
- `apps/api/app/services/review_table_service.py` â€” Metodo `query_review_table` + `_format_table_for_query` para consulta em linguagem natural
- `apps/web/src/app/(dashboard)/corpus/review/page.tsx` â€” Celulas editaveis inline (click-to-edit), checkbox de verificacao, barra de consulta em linguagem natural com exibicao de resposta e fontes

### Decisoes Tomadas
- Cell edits sao rastreados em campo `_edits` dentro do JSON results (metadata por celula: edited_by, edited_at, verified)
- Optimistic updates com rollback no frontend para melhor UX
- Query usa formatacao textual da tabela como contexto para o LLM, com truncamento em 25000 chars para tabelas grandes
- Resposta do LLM em JSON estruturado com answer + referenced_documents

### Comandos Executados
- Leitura e analise de arquivos existentes (OK)
- Edicao de 3 arquivos backend + frontend (OK)

---

## 2026-02-02 â€” Sessao 48: Review Table Export â€” Color Coding XLSX + Loading States

### Arquivos Alterados
- `apps/api/app/services/review_table_service.py` â€” XLSX export com color coding (verde/vermelho/amarelo), borders, freeze panes, font bold no documento
- `apps/web/src/app/(dashboard)/corpus/review/page.tsx` â€” Loading state nos botÃµes de export, filename dinÃ¢mico do header Content-Disposition, botÃµes com labels em PT-BR ("Exportar Excel", "Exportar CSV"), botÃµes de CSV e Excel na list view

### DecisÃµes Tomadas
- Color coding por conteÃºdo da cÃ©lula: verde para valores extraÃ­dos com sucesso, vermelho para erros/nÃ£o encontrado, amarelo para "nÃ£o"/"n/a", cinza para vazio
- Freeze panes em B2 para fixar header e coluna Documento ao scrollar
- Max column width aumentado de 50 para 60 chars
- Frontend extrai filename do header Content-Disposition para nome correto do arquivo

---

## 2026-02-02 â€” Sessao 47: Pesquisa Harvey AI + RelatÃ³rio Comparativo

### Contexto
Pesquisa extensiva sobre Harvey AI (Vault, Playbooks, Workflows) usando 5 agentes paralelos: documentaÃ§Ã£o, help center, blog posts, Playwright screenshots e UI details.

### Arquivos Criados
- `docs/HARVEY_VS_IUDEX_COMPARISON.md` â€” RelatÃ³rio comparativo completo Harvey vs Iudex

### Resultados da Pesquisa
- Harvey Vault: 100k arquivos/vault, 7 tipos de coluna em Review Tables, workflows one-click com 96-99% recall
- Harvey Playbooks: classificaÃ§Ã£o 3 nÃ­veis, Word Add-In nativo, "Winning Language" extraction
- Harvey Workflows: builder visual no-code com 19k+ workflows criados
- Harvey Design System: tokens semÃ¢nticos, Shadcn + custom, Cursor AI rules

### AnÃ¡lise de Gaps
- **Paridade**: Knowledge bases, review tables, playbooks 3 nÃ­veis, compartilhamento, guest accounts
- **P1 Gaps**: Export Review Tables, workflows one-click, AI auto-geraÃ§Ã£o de regras
- **P2 Gaps**: EdiÃ§Ã£o inline, query NL sobre tabelas, views mÃºltiplas, SAML SSO
- **P3 Gaps**: Workflow builder, DMS profundo, mobile apps, audit logs

### DecisÃµes
- Diferencial Iudex = especializaÃ§Ã£o mercado jurÃ­dico brasileiro (LGPD, PJe, legislaÃ§Ã£o BR)
- Foco P1 em: export com cores, workflows para contratos BR, geraÃ§Ã£o automÃ¡tica de playbooks

---

## 2026-02-02 â€” Sessao 46: CorreÃ§Ã£o de Todos os Issues Restantes

### Arquivos Criados
- `apps/api/app/core/credential_encryption.py` â€” Fernet encrypt/decrypt com prefixo `enc:`

### CorreÃ§Ãµes Aplicadas
- **Encryption**: Senha PJe agora encriptada (Fernet) antes de salvar, descriptografada ao ler
- **Admin Role**: Endpoints admin usam `require_role("ADMIN")` (via `security.py`)
- **HIL Checkpointer**: `MemorySaver` adicionado ao `graph.compile()` para HIL resume
- **Upload Limit**: 10MB max por arquivo, UUID validation + path traversal check no delete
- **Published App**: LÃ³gica `allow_org` corrigida (False = sÃ³ owner)
- **BudgetExceededError**: Handling especÃ­fico com mensagem user-friendly
- **BNP Singleton**: Token cache OAuth2 reutilizado entre chamadas
- **Corpus Session**: Results processados dentro do `async with` DB session
- **Limits**: `_load_legal_db`, `_load_corpus`, `_load_bnp` clamped 1-20
- **Frontend**: Unused import removido, corpus max 2 validado no onConfirm

### Build: Python 7/7 OK, TypeScript compiled successfully

---

## 2026-02-02 â€” Revisao Critica e Correcoes (Word Add-in)

### Objetivo
Auditoria completa do codebase do Office Add-in. 43 issues identificadas, correcoes aplicadas.

### Issues Corrigidas (12 criticas/medias)
1. **XSS â€” ChatMessage.tsx**: DOMPurify agora usa whitelist restrita de tags (ALLOWED_TAGS, ALLOWED_ATTR, ALLOW_DATA_ATTR:false)
2. **Race condition â€” chat-store.ts**: abortController movido para closure do store (nao mais module-level), abort automatico do stream anterior ao iniciar novo
3. **Stale closure â€” ChatPanel.tsx**: initChat protegido com useRef para executar apenas uma vez, handleSend com useCallback e acesso via getState()
4. **Race condition â€” drafting-store.ts**: guard contra edits concorrentes (abort automatico), try/catch envolvendo streamEditContent + loadSelection
5. **Error handling â€” PlaybookPanel.tsx**: try/catch em todos os handlers de batch (highlightAll, batchComments, clearHighlights)
6. **Inconsistencia â€” redline-engine.ts**: padronizado search text slice para 200 chars em applyRedlineAsComment (era 100)
7. **extraContext â€” chat-store.ts**: contexto do corpus agora consumido automaticamente no sendMessage e limpo apos uso

### Dead Code Removido
- `src/hooks/useSSEStream.ts` â€” hook nunca importado (deletado)
- `getPlaybookPrompt()` â€” funcao nunca chamada (removida de client.ts)
- `EditContentRequest` interface â€” tipo nao usado (removido de client.ts)
- `TranslateRequest` interface â€” tipo nao usado (removido de client.ts)

### Issues Conhecidas (aceitas/nao-criticas)
- localStorage para JWT: documentado como aceitavel no contexto iframe do Office Add-in (HTTPS obrigatorio, origem isolada)
- `insertOoxml()`, `getTableCount()`, `getParagraphs()` em document-bridge: mantidos como API publica para uso futuro
- LCS diff O(n^2) com MAX=500: aceitavel para textos de clausulas juridicas (geralmente < 500 palavras)

### Verificacao Final
- `tsc --noEmit` â€” OK (zero erros)
- `vite build` â€” OK (322KB JS, 18KB CSS)
- 32 arquivos fonte, 0 dead code hooks

---

## 2026-02-02 â€” Fase 5: Workflows Avancados (Word Add-in)

### Objetivo
Adicionar aba "Ferramentas" com workflows automatizados: traducao juridica (SSE streaming) e anonimizacao LGPD.

### Arquivos Criados
- `apps/office-addin/src/components/workflows/WorkflowPanel.tsx` â€” Menu de workflows com cards clicaveis, navegacao para sub-formularios
- `apps/office-addin/src/components/workflows/TranslationForm.tsx` â€” Traducao com SSE: seletor de idiomas (6 idiomas), swap, preview streaming, substituir/inserir apos/copiar/descartar, abort
- `apps/office-addin/src/components/workflows/AnonymizationForm.tsx` â€” Anonimizacao LGPD: seletor de entidades (CPF/nome/endereco/telefone/email/RG/OAB), escopo selecao/documento inteiro, tabela de entidades encontradas com aplicacao individual, preview do texto anonimizado, aplicar tudo em batch

### Arquivos Alterados
- `apps/office-addin/src/api/client.ts` â€” Adicionado types e funcao `anonymizeContent()` para POST /word-addin/anonymize
- `apps/office-addin/src/api/sse-client.ts` â€” Adicionado `streamTranslateContent()` para POST /word-addin/translate (SSE)
- `apps/office-addin/src/components/layout/TabNavigation.tsx` â€” Nova tab 'workflows' com label "Ferramentas"
- `apps/office-addin/src/components/layout/TaskPane.tsx` â€” Import e render do WorkflowPanel

### Verificacao
- `tsc --noEmit` â€” OK (zero erros)
- `vite build` â€” OK (321KB JS, 18KB CSS)

---

## 2026-02-02 â€” Fase 4: Corpus/RAG Integration (Word Add-in)

### Objetivo
Aprimorar a aba "Corpus" com store dedicado, componentes separados, filtros, selecao multipla e integracao com chat.

### Arquivos Criados
- `apps/office-addin/src/stores/corpus-store.ts` â€” Store com busca, historico, filtros, selecao multipla
- `apps/office-addin/src/components/corpus/ReferenceCard.tsx` â€” Card com checkbox, score, 4 acoes

### Arquivos Alterados
- `apps/office-addin/src/components/corpus/CorpusPanel.tsx` â€” Refatorado com corpus-store, filtros, batch insert
- `apps/office-addin/src/stores/chat-store.ts` â€” Adicionado `extraContext` + `setDocumentContext()`

### Verificacao
- `tsc --noEmit` + `vite build` â€” OK (309KB JS)

---

## 2026-02-02 â€” Fase 3: Drafting/Editing com IA (Word Add-in)

### Objetivo
Aprimorar a aba "Editar" do Word Add-in com modos de edicao pre-definidos, diff visual word-by-word, historico de edicoes e abort de stream.

### Arquivos Criados
- `apps/office-addin/src/stores/drafting-store.ts` â€” Zustand store com: 6 modos de edicao (custom, improve, simplify, formalize, rewrite, insert-after), abort via AbortController, historico de edicoes (20 entradas), replay de historico.
- `apps/office-addin/src/components/drafting/DiffPreview.tsx` â€” Dois componentes: `DiffPreview` (inline word-level diff com LCS algorithm, cores vermelho/verde) e `SideBySideDiff` (original vs editado lado a lado). Inclui stats de palavras adicionadas/removidas.

### Arquivos Alterados
- `apps/office-addin/src/components/drafting/DraftPanel.tsx` â€” Refatorado para usar drafting-store. Adicionado: chips de modo de edicao, toggle inline/side-by-side diff, Cmd+Enter para enviar, botao de abort durante streaming, historico de edicoes com replay, sugestoes rapidas contextuais.

### Verificacao
- `tsc --noEmit` â€” OK (zero erros)
- `vite build` â€” OK (302KB JS, 17KB CSS)

---

## 2026-02-02 â€” Fase 2: Playbook Analysis + Redlines (Word Add-in)

### Objetivo
Implementar a Fase 2 do Word Add-in Vorbium: anÃ¡lise de playbooks com redlines OOXML, navegaÃ§Ã£o de clÃ¡usulas, filtros e operaÃ§Ãµes em batch.

### Arquivos Criados
- `apps/office-addin/src/office/redline-engine.ts` â€” Motor de redlines com 4 estratÃ©gias: comentÃ¡rio, highlight, substituiÃ§Ã£o direta, tracked changes OOXML (`<w:ins>/<w:del>`). Inclui navegaÃ§Ã£o, highlight de clÃ¡usulas em batch e limpeza.
- `apps/office-addin/src/stores/playbook-store.ts` â€” Zustand store com estado de anÃ¡lise, filtros (classificaÃ§Ã£o/severidade), tracking de redlines aplicados, computed filteredClauses e toRedlineOperations.
- `apps/office-addin/src/components/playbook/ClauseCard.tsx` â€” Card individual de clÃ¡usula com badges de severidade/classificaÃ§Ã£o, texto original, sugestÃ£o de redline, e menu de aÃ§Ãµes (comentÃ¡rio/destacar/preview/substituir).
- `apps/office-addin/src/components/playbook/RedlinePreview.tsx` â€” Modal de preview mostrando diff visual (original em vermelho, sugerido em verde) com aceitar/rejeitar.

### Arquivos Alterados
- `apps/office-addin/src/components/playbook/PlaybookPanel.tsx` â€” Refatorado para usar playbook-store, ClauseCard, RedlinePreview. Adicionado: filtros por classificaÃ§Ã£o/severidade, barra de stats, aÃ§Ãµes em batch (destacar tudo, comentar tudo, limpar destaques), navegaÃ§Ã£o clÃ¡usulaâ†’documento.

### VerificaÃ§Ã£o
- `tsc --noEmit` â€” OK (zero erros)
- `vite build` â€” OK (294KB JS, 17KB CSS)

### DecisÃµes
- Redlines OOXML usam fallback para highlight+comentÃ¡rio quando o formato tracked changes nÃ£o Ã© suportado (ex: Word Online)
- AplicaÃ§Ã£o em batch Ã© sequencial (nÃ£o paralela) para evitar conflitos no Office.js context.sync()
- Filtros sÃ£o toggle no chip de severidade (clique duplo remove filtro)

---

## 2026-02-02 â€” ImplementaÃ§Ã£o Corpus (RAG) + Playbooks (Harvey AI Parity)

### Objetivo
Implementar features equivalentes ao Harvey AI Vault ("Corpus") e Playbook no Iudex, incluindo backend completo, frontend, integraÃ§Ã£o com chat/minuta e verificaÃ§Ã£o de paridade.

### Arquivos Criados (Backend)
- `apps/api/app/models/playbook.py` â€” Modelos Playbook, PlaybookRule, PlaybookShare, PlaybookAnalysis
- `apps/api/app/models/corpus_project.py` â€” CorpusProject, CorpusProjectDocument, CorpusProjectShare
- `apps/api/app/models/corpus_retention.py` â€” CorpusRetentionConfig
- `apps/api/app/models/review_table.py` â€” ReviewTableTemplate, ReviewTable
- `apps/api/app/schemas/playbook.py` â€” Schemas CRUD para Playbook e regras
- `apps/api/app/schemas/playbook_analysis.py` â€” Schemas de anÃ¡lise, classificaÃ§Ã£o, import/export
- `apps/api/app/schemas/corpus.py` â€” Schemas Corpus (stats, search, admin, retention)
- `apps/api/app/schemas/corpus_project.py` â€” Schemas para projetos e knowledge bases
- `apps/api/app/services/playbook_service.py` â€” ServiÃ§o de anÃ¡lise, geraÃ§Ã£o, import/export
- `apps/api/app/services/playbook_prompts.py` â€” 8 prompts PT-BR para anÃ¡lise contratual
- `apps/api/app/services/corpus_service.py` â€” ServiÃ§o agregando OpenSearch + Qdrant + PostgreSQL
- `apps/api/app/services/corpus_chat_tool.py` â€” IntegraÃ§Ã£o Corpus â†” Chat (auto-search + fallback)
- `apps/api/app/services/review_table_service.py` â€” ExtraÃ§Ã£o estruturada multi-documento
- `apps/api/app/services/review_table_templates.py` â€” 5 templates jurÃ­dicos BR
- `apps/api/app/api/endpoints/playbooks.py` â€” 20+ endpoints (CRUD, share, analyze, import/export)
- `apps/api/app/api/endpoints/corpus.py` â€” 16 endpoints (CRUD + admin)
- `apps/api/app/api/endpoints/corpus_projects.py` â€” 10 endpoints (projetos + knowledge bases)
- `apps/api/app/api/endpoints/review_tables.py` â€” 9 endpoints (templates + reviews + export)
- `apps/api/app/core/rate_limit.py` â€” Rate limiting Redis para Corpus/Playbook
- `apps/api/app/tasks/corpus_cleanup.py` â€” Cleanup de documentos expirados
- 5 migraÃ§Ãµes Alembic

### Arquivos Criados (Frontend)
- `apps/web/src/app/(dashboard)/corpus/page.tsx` â€” PÃ¡gina principal (3 tabs: Global/Privado/Local)
- `apps/web/src/app/(dashboard)/corpus/hooks/use-corpus.ts` â€” 19 hooks React Query
- `apps/web/src/app/(dashboard)/corpus/admin/page.tsx` â€” Dashboard admin
- `apps/web/src/app/(dashboard)/corpus/review/page.tsx` â€” Review Tables
- 8 componentes Corpus (stats, tabs, upload, admin panels)
- `apps/web/src/app/(dashboard)/playbooks/page.tsx` â€” Lista de playbooks
- `apps/web/src/app/(dashboard)/playbooks/[id]/page.tsx` â€” Editor de regras
- `apps/web/src/app/(dashboard)/playbooks/[id]/analyze/page.tsx` â€” AnÃ¡lise de contratos
- `apps/web/src/app/(dashboard)/playbooks/hooks.ts` â€” 15+ hooks com mapeamento backend
- 9 componentes Playbook (card, rule-editor, share, analysis-panel, etc.)

### Arquivos Alterados
- `apps/web/src/lib/api-client.ts` â€” ~30 novos mÃ©todos API
- `apps/web/src/stores/chat-store.ts` â€” IntegraÃ§Ã£o Playbook no chat
- `apps/web/src/components/layout/sidebar-pro.tsx` â€” Links Corpus e Playbooks
- `apps/web/src/app/(dashboard)/minuta/page.tsx` â€” PlaybookSelector no toolbar
- `apps/api/app/schemas/chat.py` â€” Campo playbook_prompt
- `apps/api/app/api/endpoints/chats.py` â€” InjeÃ§Ã£o playbook + corpus fallback
- `apps/api/app/services/ai/langgraph_legal_workflow.py` â€” Playbook no state
- `apps/api/app/services/rag/pipeline_adapter.py` â€” Auto-fill RAG sources
- `apps/api/app/models/__init__.py` â€” Registro dos novos modelos

### VerificaÃ§Ãµes
- Python syntax check: 18/18 OK
- TypeScript check: 0 erros
- Todas as integraÃ§Ãµes (Corpusâ†”Chat, Playbookâ†”Minuta) conectadas

### AnÃ¡lise de Gap vs Harvey AI
- Corpus: 3 âœ…, 8 âš ï¸, 14 âŒ â†’ Implementados todos P0+P1
- Playbook: 5 âœ…, 6 âš ï¸, 7 âŒ â†’ Implementados todos P0+P1

### ExploraÃ§Ã£o de Features P2
VerificaÃ§Ã£o completa do codebase revelou que **todas as 6 features P2 jÃ¡ existiam**:
- DMS Integrations (Google Drive, SharePoint/OneDrive)
- Caching multi-camada (RAG, embeddings, HTTP, Redis, React Query)
- 23+ tipos de arquivo com OCR hÃ­brido
- Workflow Builder visual completo (React Flow â†’ LangGraph, 11 node types)
- CitaÃ§Ãµes com grounding, ABNT, provenance tracking
- Shared Spaces + Guest Sessions

### DecisÃµes Tomadas
- Nome "Corpus" (de corpus juris) para o sistema RAG
- Corpus e Biblioteca mantidos como features separadas
- Playbookâ†”Minuta via frontend (Option B: prompt no payload)
- Corpusâ†”Chat via 2 camadas (pipeline auto-fill + chat tool fallback)
- Review Tables com extraÃ§Ã£o paralela (semaphore MAX_CONCURRENT=5)

---

## 2026-02-02 â€” Arquitetura HÃ­brida: Fail-Fast, Agent Fallback, Self-Healing

### Objetivo
Implementar arquitetura hÃ­brida nos packages `tribunais-playwright` e `sei-playwright`: fail-fast (timeout 3s), agent fallback via Claude API, self-healing de seletores com persistÃªncia em JSON, e execuÃ§Ã£o especulativa opcional.

### Arquivos Criados
- `packages/tribunais-playwright/src/core/resilience.ts` â€” Motor de resiliÃªncia (failFast, withRetry, classifyError)
- `packages/tribunais-playwright/src/core/selector-store.ts` â€” PersistÃªncia de seletores descobertos (JSON)
- `packages/tribunais-playwright/src/core/agent-fallback.ts` â€” IntegraÃ§Ã£o Claude API para descoberta de seletores
- `packages/sei-playwright/src/core/resilience.ts` â€” Mesma lÃ³gica para SEI
- `packages/sei-playwright/src/core/selector-store.ts` â€” Mesma lÃ³gica para SEI
- `packages/sei-playwright/src/core/agent-fallback.ts` â€” Mesma lÃ³gica para SEI

### Arquivos Alterados
- `packages/tribunais-playwright/src/types/index.ts` â€” Adicionados tipos ResilienceConfig, AgentFallbackConfig, SelectorStoreEntry
- `packages/tribunais-playwright/src/core/base-client.ts` â€” MÃ©todos *Smart agora seguem cascata: ARIA â†’ CSS â†’ Store â†’ Agent
- `packages/tribunais-playwright/src/index.ts` â€” Exporta novos mÃ³dulos
- `packages/tribunais-playwright/package.json` â€” Adicionado @anthropic-ai/sdk como optionalDependency
- `packages/sei-playwright/src/types.ts` â€” Adicionados mesmos tipos
- `packages/sei-playwright/src/browser/client.ts` â€” MÃ©todos *Smart com cascata de resiliÃªncia
- `packages/sei-playwright/src/index.ts` â€” Exporta novos mÃ³dulos
- `packages/sei-playwright/package.json` â€” Adicionado @anthropic-ai/sdk como optionalDependency

### Comandos Executados
- `npm install` â€” InstalaÃ§Ã£o de dependÃªncias (OK)
- `npx tsup` em tribunais-playwright â€” Build OK (ESM + CJS + DTS)
- `npx tsup` em sei-playwright â€” Build OK (ESM + CJS + DTS)

### DecisÃµes Tomadas
- `@anthropic-ai/sdk` como optionalDependency (nÃ£o quebra quem nÃ£o usa agent fallback)
- Lazy-load do SDK via dynamic import (sÃ³ carrega quando agentFallback.enabled = true)
- SelectorStore persiste em `~/.tribunais-playwright/selector-cache.json` e `~/.sei-playwright/selector-cache.json`
- ExecuÃ§Ã£o especulativa via `Promise.all` (nÃ£o `Promise.race`) para evitar descarte de resultados
- Fail-fast timeout padrÃ£o: 3000ms (configurÃ¡vel)

---

## 2026-02-02 â€” Compound Legal Citation Parsing

### Objetivo
Implementar extraÃ§Ã£o de citaÃ§Ãµes jurÃ­dicas compostas (hierÃ¡rquicas) no LegalEntityExtractor, cobrindo padrÃµes como "Lei 8.666/1993, Art. 23, Â§ 1Âº, inciso II" e "Art. 5Âº, caput, da ConstituiÃ§Ã£o Federal".

### Arquivos Alterados
- `apps/api/app/services/rag/core/neo4j_mvp.py` â€” Adicionado dataclass CompoundCitation, mapa de cÃ³digos brasileiros (CODE_MAP), regex COMPOUND_PATTERN e COMPOUND_PATTERN_INVERTED, mÃ©todos extract_compound_citations() e extract_all()
- `apps/api/app/services/ai/citations/grounding.py` â€” Adicionado status PARTIAL, funÃ§Ãµes extract_compound_citations_from_response() e verify_compound_against_context(), integraÃ§Ã£o no verify_citations()

### Arquivos Criados
- `apps/api/tests/test_compound_citations.py` â€” 48 testes cobrindo backward compatibility, citaÃ§Ãµes compostas, normalizaÃ§Ã£o de IDs, edge cases (parÃ¡grafo Ãºnico, caput, numerais romanos)

### Comandos Executados
- `pytest tests/test_compound_citations.py` â€” 48 passed (OK)
- `py_compile` nos arquivos alterados â€” OK

### DecisÃµes Tomadas
- Regex compounds sÃ£o complementares Ã  extraÃ§Ã£o simples (backward compat mantida)
- normalized_id segue padrÃ£o: `{lei/codigo}_{art}_{paragrafo}_{inciso}_{alinea}`
- Pontos em nÃºmeros de lei (8.666) removidos na normalizaÃ§Ã£o
- PadrÃ£o invertido ("Art. X da Lei Y") tratado separadamente
- Status PARTIAL no grounding para citaÃ§Ãµes compostas com match parcial (confidence 0.6)

---

## 2026-02-02 â€” React Query Prefetching para Navegacao

### Objetivo
Implementar prefetch de dados via React Query ao passar o mouse sobre links de navegacao e ao mudar de rota, reduzindo latencia percebida.

### Arquivos Criados
- `apps/web/src/lib/prefetch.ts` â€” Hook `usePrefetchOnHover`, funcoes de prefetch centralizadas, `prefetchForRoute`
- `apps/web/src/components/providers/prefetch-provider.tsx` â€” Provider que escuta mudancas de rota e prefetcha dados

### Arquivos Alterados
- `apps/web/src/components/layout/sidebar-pro.tsx` â€” Adicionado prefetch on hover nos nav items (Corpus, Playbooks, Workflows, Biblioteca)
- `apps/web/src/components/providers/index.tsx` â€” Integrado PrefetchProvider dentro do QueryProvider
- `apps/web/src/app/(dashboard)/workflows/page.tsx` â€” Prefetch de detalhe do workflow on hover na lista
- `apps/web/src/app/(dashboard)/playbooks/components/playbook-card.tsx` â€” Prefetch de detalhe do playbook on hover no card

### Decisoes Tomadas
- Debounce de 200ms no hover para evitar prefetches excessivos
- Todas as chamadas de prefetch falham silenciosamente (try/catch vazio)
- Query keys de playbooks reutilizam os mesmos patterns dos hooks existentes
- Workflows e Library nao tinham hooks React Query, entao as query keys foram definidas em `prefetch.ts`
- PrefetchProvider usa `usePathname()` do Next.js App Router (sem router events do Pages Router)

---

## 2026-02-02 â€” Verbatim Mode + Source Provenance

### Objetivo
Implementar modo verbatim (extraÃ§Ã£o literal de trechos) e proveniÃªncia de fontes (pÃ¡gina, linha, arquivo) no pipeline de citaÃ§Ãµes do Iudex.

### Arquivos Alterados
- `apps/api/app/services/document_processor.py` â€” Adicionados `PageText`, `extract_pages_from_pdf()`, `extract_paragraphs_from_docx()` com metadados de pÃ¡gina/linha; `chunk_by_pages` inclui `page_number`
- `apps/api/app/services/rag/utils/ingest.py` â€” `Chunk` dataclass expandido com `line_start`, `line_end`, `source_file`, `doc_id`; `chunk_document()` e `chunk_pdf()` agora emitem `page_number`, `line_start`, `line_end`, `source_file` nos dicts
- `apps/api/app/services/ai/citations/grounding.py` â€” Adicionado `CitationProvenance` dataclass; `CitationVerification` recebe `provenance`; `verify_citations()` aceita `rag_chunks` e popula provenance via index de chunks; `to_dict()` serializa provenance
- `apps/api/app/services/ai/citations/base.py` â€” `Source` expandido com `page_number`, `line_start`, `line_end`, `source_file`, `doc_id`; `sources_to_citations()` inclui provenance
- `apps/api/app/schemas/corpus.py` â€” Adicionados `VerbatimExcerpt`, `VerbatimRequest`, `VerbatimResponse`
- `apps/api/app/api/endpoints/corpus.py` â€” Adicionado endpoint `POST /corpus/verbatim`
- `apps/web/src/components/workflows/citations-panel.tsx` â€” Adicionado `CitationProvenance` interface; `formatProvenance()` helper; exibiÃ§Ã£o de proveniÃªncia (Fonte, pÃ¡gina, linhas) no painel expandido
- `apps/web/src/components/editor/extensions/citation-mark.ts` â€” Adicionados atributos `pageNumber`, `lineStart`, `lineEnd`, `sourceFile`; tooltip inclui proveniÃªncia

### DecisÃµes Tomadas
- ProveniÃªncia Ã© opcional (campos nullable) para compatibilidade retroativa
- `extract_pages_from_pdf` usa `pdfplumber.page.page_number` nativo
- Para DOCX, Ã­ndice do parÃ¡grafo Ã© usado como proxy de "pÃ¡gina" (DOCX nÃ£o tem pÃ¡ginas nativas)
- Endpoint verbatim reutiliza busca existente do CorpusService sem LLM
- UI em portuguÃªs brasileiro conforme convenÃ§Ã£o do projeto

---

## 2026-02-02 â€” Implementacao de Guest Accounts (Acesso Anonimo/Temporario)

### Objetivo
Implementar sistema de contas guest (visitante) com acesso anonimo, temporario e somente leitura para o Iudex. Permite que usuarios externos visualizem recursos compartilhados via SharedSpaces sem necessidade de cadastro.

### Arquivos Criados
- `apps/api/app/models/guest_session.py` â€” Modelo SQLAlchemy GuestSession (token, permissoes, expiracao, vinculo com space)
- `apps/api/app/schemas/guest.py` â€” Schemas Pydantic para guest (create, response, info)
- `apps/api/app/api/endpoints/guest_auth.py` â€” Endpoints REST: POST /auth/guest, POST /auth/guest/from-share/{token}, GET /auth/guest/me, POST /auth/guest/invalidate
- `apps/api/app/tasks/guest_cleanup.py` â€” Tarefa de limpeza de sessoes expiradas
- `apps/api/alembic/versions/d9a3f7e2c1b4_add_guest_sessions_table.py` â€” Migration Alembic
- `apps/web/src/app/guest/[token]/page.tsx` â€” Pagina de acesso guest via link de compartilhamento
- `apps/web/src/components/guest-banner.tsx` â€” Banner de visitante com countdown e CTA "Criar conta"

### Arquivos Alterados
- `apps/api/app/core/security.py` â€” Adicionados: create_guest_token(), UserOrGuest dataclass, get_current_user_or_guest(), require_authenticated_user()
- `apps/api/app/core/database.py` â€” Registro do modelo GuestSession no init_db
- `apps/api/app/api/routes.py` â€” Registro do router guest_auth
- `apps/api/app/api/endpoints/spaces.py` â€” Endpoints get_space e list_resources aceitam guests
- `apps/web/src/stores/auth-store.ts` â€” Novos: isGuest, guestSession, loginAsGuest(), checkGuestExpiration()
- `apps/web/src/lib/api-client.ts` â€” Novos: loginAsGuest(), createGuestSession(), getGuestInfo()
- `apps/web/src/components/layout/main-layout.tsx` â€” Integrado GuestBanner

### Decisoes Tomadas
- GuestSession como tabela separada (nao campos no User) para isolamento e limpeza facil
- JWT guest com claim `is_guest=true` e mesma chave de assinatura (simplifica decodificacao)
- Sessoes guest expiram em 24h por padrao, somente leitura
- Guest vinculado a SpaceInvite token para rastreabilidade
- Backward compatible: todos os endpoints existentes continuam funcionando com auth regular

---

## 2026-02-02 â€” Implementacao de Integracoes DMS (Google Drive, SharePoint, OneDrive)

### Objetivo
Implementar sistema completo de integraÃ§Ãµes com Document Management Systems (DMS) para permitir que usuÃ¡rios conectem Google Drive, SharePoint e OneDrive e importem/sincronizem documentos para o Corpus.

### Arquivos Criados
- `apps/api/app/models/dms_integration.py` â€” Modelo SQLAlchemy para integraÃ§Ãµes DMS
- `apps/api/app/schemas/dms.py` â€” Schemas Pydantic (providers, connect, files, import, sync)
- `apps/api/app/services/dms_service.py` â€” Service com DMSProvider abstrato, GoogleDriveProvider, SharePointProvider e facade DMSService
- `apps/api/app/api/endpoints/dms.py` â€” Endpoints REST (providers, connect, callback, integrations CRUD, files, import, sync)
- `apps/api/alembic/versions/p6q7r8s9t0u1_add_dms_integrations_table.py` â€” Migration Alembic
- `apps/web/src/components/settings/dms-integrations.tsx` â€” Componente de configuraÃ§Ã£o DMS na Settings
- `apps/web/src/components/corpus/dms-file-browser.tsx` â€” File browser com navegaÃ§Ã£o, busca e importaÃ§Ã£o

### Arquivos Alterados
- `apps/api/app/core/config.py` â€” Adicionadas variÃ¡veis DMS OAuth (GOOGLE_DRIVE_CLIENT_ID/SECRET, MICROSOFT_CLIENT_ID/SECRET/TENANT_ID, DMS_OAUTH_REDIRECT_URL)
- `apps/api/app/models/__init__.py` â€” Registrado DMSIntegration
- `apps/api/app/api/routes.py` â€” Registrado router DMS em `/dms`
- `apps/web/src/lib/api-client.ts` â€” Adicionados mÃ©todos DMS (getDMSProviders, startDMSConnect, getDMSIntegrations, disconnectDMS, getDMSFiles, importDMSFiles, triggerDMSSync)
- `apps/web/src/app/(dashboard)/settings/page.tsx` â€” Adicionada seÃ§Ã£o DMS Integrations

### DecisÃµes Tomadas
- PadrÃ£o Strategy com providers abstratos para facilitar adiÃ§Ã£o de novos DMS
- OneDrive reutiliza SharePointProvider (mesma Microsoft Graph API)
- Credenciais OAuth encriptadas com Fernet (derivado do SECRET_KEY), fallback base64 em dev
- OAuth flow via popup no frontend com postMessage callback
- Import de arquivos salva no storage local; integraÃ§Ã£o com Corpus RAG pipeline fica para prÃ³xima fase

---

## 2026-02-02 â€” CDN/Edge Caching, Compression Headers e Service Worker

### Objetivo
Implementar cache headers, compression, service worker e offline fallback para melhorar performance e experiencia offline.

### Arquivos Alterados
- `apps/web/next.config.js` â€” Adicionado `headers()` com Cache-Control para assets estaticos, fonts, imagens + security headers (X-Content-Type-Options, X-Frame-Options, Referrer-Policy)
- `apps/web/src/app/layout.tsx` â€” Adicionado link para manifest.json e meta theme-color
- `apps/web/public/sw.js` â€” Service Worker com cache-first (assets), network-first (API), stale-while-revalidate (catalogs/stats), offline fallback
- `apps/web/public/offline.html` â€” Pagina offline em portugues
- `apps/web/public/manifest.json` â€” Web App Manifest para PWA
- `apps/web/src/lib/register-sw.ts` â€” Helper de registro/desregistro do SW com toast de atualizacao
- `apps/web/src/components/providers/sw-provider.tsx` â€” Provider que registra SW no mount
- `apps/web/src/components/providers/index.tsx` â€” Wiring do ServiceWorkerProvider
- `apps/api/app/middleware/__init__.py` â€” Init do modulo middleware
- `apps/api/app/middleware/cache_headers.py` â€” Middleware Cache-Control + ETag para respostas da API
- `apps/api/app/main.py` â€” Adicionado CacheHeadersMiddleware (GZipMiddleware ja existia)

### Decisoes Tomadas
- GZipMiddleware ja existia no main.py, mantido como estava (minimum_size=1000)
- SSE/streaming endpoints excluidos do cache e do SW
- SW so registra em producao (opt-in via NEXT_PUBLIC_SW_DEV em dev)
- ETag gerado apenas para respostas GET < 10MB com suporte a 304 Not Modified
- Cache rules no FastAPI baseadas em regex de path

---

## 2026-02-02 â€” Sessao 45: Corpus + Playbook (Harvey AI Parity) + Gap Analysis

### Objetivo
Implementar features equivalentes ao Harvey AI Vault ("Corpus") e Playbook no Iudex, com verificaÃ§Ã£o do que jÃ¡ existia antes de implementar.

### Fase 1: ImplementaÃ§Ã£o Inicial (5 agentes paralelos)
- Backend: Playbook model/migration/API (13 endpoints), Playbook AI Service + prompts
- Frontend: Corpus page (3 tabs), Playbooks pages
- Backend: Corpus API (11 endpoints)

### Fase 2: Review + Fixes
- 4 agentes de review encontraram 5 critical, 7 moderate, 34 minor issues
- 2 agentes de fix resolveram todos os critical/moderate

### Fase 3: Gap Analysis contra Harvey AI
- Corpus vs Harvey Vault: 3 âœ…, 8 âš ï¸, 14 âŒ (de 25 features)
- Playbook vs Harvey Playbook: 5 âœ…, 6 âš ï¸, 7 âŒ (de 20 features)

### Fase 4: P0 Implementations (6 agentes)
- P0: Corpus hooks â†’ API, Playbook hooks â†’ API
- P0: Corpus â†” Chat integration, Playbook â†” Minuta integration
- P1: Playbook analysis persistence, import/export

### Fase 5: P1 Implementations (6 agentes)
- Corpus Projects + Knowledge Bases, Rate limiting + Retention
- Review tracking UI, Playbook permission enforcement
- Corpus Admin Dashboard, Review Tables (extraction)

### Fase 6: VerificaÃ§Ã£o do que jÃ¡ existia (6 agentes exploraÃ§Ã£o)
Resultado â€” features que JÃ EXISTIAM:
- âœ… Workflow Builder completo (ReactFlow, 11 nÃ³s, NL-to-Graph, LangGraph, HIL)
- âœ… Shared Spaces (SharedSpace model, SpaceInvite, share links)
- âœ… Citation Grounding (RAG + Neo4j, ABNT, multi-provider, CitationMark)
- âœ… Caching (Redis service, ResultCache, React Query, file cache)
- âœ… File Types (PDF, DOCX, DOC, ODT, TXT, RTF, HTML, imagens OCR, Ã¡udio, vÃ­deo, ZIP)
- âŒ DMS Integrations (nenhuma â€” iManage, NetDocuments, SharePoint, Google Drive)

### Gaps Restantes (P2-P3)
1. P2: Verbatim Mode (extraÃ§Ã£o exata + page/line ref)
2. P2: Compound Citation Parsing
3. P2: Source Provenance Chain
4. P2: React Query Prefetching
5. P3: Guest Accounts, DMS Integrations, CDN/Edge, Redis Cache migration

### Arquivos Criados/Modificados (~60 arquivos)
**Backend:** models/playbook.py, corpus_project.py, corpus_retention.py, review_table.py; schemas/playbook.py, playbook_analysis.py, corpus.py, corpus_project.py; services/playbook_service.py, playbook_prompts.py, corpus_service.py, corpus_chat_tool.py, review_table_service.py; endpoints/playbooks.py, corpus.py, corpus_projects.py, review_tables.py; core/rate_limit.py; tasks/corpus_cleanup.py; 5 Alembic migrations
**Frontend:** corpus/ (page + 5 components + hooks + admin + review), playbooks/ (3 pages + 9 components + hooks), playbook-selector.tsx, playbook-active-badge.tsx
**Modified:** api-client.ts (~30 novos mÃ©todos), chat-store.ts, sidebar-pro.tsx, routes.py, models/__init__.py, database.py, chats.py, jobs.py, chat.py schema, pipeline_adapter.py, langgraph_legal_workflow.py, minuta/page.tsx

### Build
- Python syntax check: 18/18 OK
- TypeScript: 0 errors

---

## 2026-02-02 â€” Sessao 45: Auditoria Completa + CorreÃ§Ãµes de SeguranÃ§a

### Objetivo
RevisÃ£o completa de todos os 152 arquivos implementados. Auditoria de seguranÃ§a e lÃ³gica. CorreÃ§Ã£o de 17 issues HIGH e 10 MEDIUM.

### Arquivos Alterados
- `apps/api/app/api/endpoints/users.py` â€” PUT response agora redata senha; validaÃ§Ã£o contra senha vazia
- `apps/api/app/api/endpoints/workflows.py` â€” Auth no clone (template/own/same-org); admin endpoints scopados por org; approve verifica org; webhook injeta user_id; HIL resume passa user_id
- `apps/api/app/services/ai/knowledge_source_loader.py` â€” Vault permission fix (user_id=None â†’ sÃ³ shared); PJe erro sanitizado; STJ URL quote_plus; BNP passa tribunal + limit clamped
- `apps/api/app/services/ai/workflow_compiler.py` â€” Erro de LLM sanitizado (sem detalhes internos)
- `apps/api/app/services/ai/workflow_runner.py` â€” resume_after_hil recebe e injeta user_id
- `apps/web/src/app/(dashboard)/settings/page.tsx` â€” pjeSenhaSet atualizado apÃ³s save

### Issues Corrigidos (HIGH)
1. PUT /preferences retornava senha em plaintext â†’ redatada
2. Vault file/folder acessÃ­vel sem user_id â†’ sÃ³ shared items
3. Clone sem autorizaÃ§Ã£o â†’ requer template/own/same-org
4. Admin endpoints sem scope â†’ filtrados por org
5. Approve sem verificaÃ§Ã£o de org â†’ 403 se outra org
6. Webhook trigger sem user_id â†’ injeta wf.user_id
7. HIL resume perdia user_id â†’ param explÃ­cito + injection
8. Senha vazia podia sobrescrever existente â†’ removida antes do merge

### Issues Corrigidos (MEDIUM)
1. PJe/LLM erros expunham detalhes internos â†’ mensagens genÃ©ricas
2. STJ URL sem encoding â†’ quote_plus
3. BNP sem param tribunal â†’ passado ao client
4. BNP limit sem clamp â†’ min 1, max 20
5. pjeSenhaSet nÃ£o atualizava apÃ³s save â†’ corrigido

### Issues Conhecidos (nÃ£o corrigidos - arquiteturais)
- Senha PJe em plaintext no JSON preferences (precisa encryption layer)
- HIL checkpointer ausente no LangGraph (resume pode nÃ£o funcionar corretamente)
- Falta role admin formal (usando org_id como proxy)

### Build
- Python syntax: 5/5 OK
- TypeScript: 0 erros
- `npx next build`: Compiled successfully

---

## 2026-02-02 â€” Sessao 44: PJe Credenciais Per-User + Pipeline user_id

### Objetivo
Completar correÃ§Ã£o de credenciais PJe per-user. Cada advogado tem seu prÃ³prio CPF/senha MNI, que nÃ£o pode ser global via env vars.

### Arquivos Alterados
- `apps/api/app/services/ai/workflow_compiler.py` â€” Adicionado `user_id: Optional[str]` ao `WorkflowState`; passado `user_id` para `load_sources()`
- `apps/api/app/services/ai/workflow_runner.py` â€” `initial_state` agora inclui `user_id` de `input_data`
- `apps/api/app/api/endpoints/workflows.py` â€” Endpoints `run_workflow` e `test_workflow` injetam `current_user.id` no `input_data`
- `apps/web/src/app/(dashboard)/settings/page.tsx` â€” Nova seÃ§Ã£o "Credenciais PJe" com campos CPF e senha MNI, salva em `preferences.pje_credentials`

### DecisÃµes Tomadas
- Credenciais PJe usam fallback de 3 nÃ­veis: source config â†’ user preferences â†’ env vars
- `user_id` Ã© propagado: endpoint â†’ input_data â†’ WorkflowState â†’ load_sources â†’ _load_pje
- Senha PJe nÃ£o Ã© exibida apÃ³s salva (placeholder "jÃ¡ configurada"), sÃ³ o CPF Ã© carregado no load

### Build
- `npx next build` â€” OK, sem erros

---

## 2026-02-02 â€” Sessao 43: Microsoft Word Office Add-in (Harvey AI Parity)

### Objetivo
Criar integraÃ§Ã£o do Iudex com Microsoft 365 via Word Office Add-in, inspirado no Harvey AI.
O add-in Ã© uma React SPA carregada em task pane (sidebar) no Word, usando Office.js para
interagir com o documento e a API REST/SSE do Iudex para IA.

### Pesquisa Realizada
- Analisado como Harvey AI integra com Word, Outlook, SharePoint
- Harvey usa Office Add-ins (task pane) servidos via HTTPS
- Features: drafting, redlines, playbook reviews, Q&A, knowledge sources
- Arquitetura: React + Office.js + API REST/SSE

### Arquivos Criados

**Office Add-in (`apps/office-addin/`):**
- `package.json` â€” Deps: React 18, Office.js, Fluent UI, Zustand, Vite, TailwindCSS
- `manifest.xml` â€” Manifesto Office Add-in (Word host, task pane, ribbon)
- `vite.config.ts` â€” Vite com HTTPS (dev-certs)
- `tsconfig.json`, `tailwind.config.ts`, `postcss.config.js` â€” Config
- `index.html` â€” Entry point HTML com Office.js script
- `src/main.tsx` â€” Entry React com Office.onReady + FluentProvider
- `src/App.tsx` â€” Root com auth guard
- `src/office/document-bridge.ts` â€” Bridge Office.js (getDocumentText, getSelectedText, replaceText, addComment, etc.)
- `src/api/client.ts` â€” HTTP client com JWT auto-refresh
- `src/api/sse-client.ts` â€” SSE streaming consumer
- `src/stores/auth-store.ts` â€” Zustand auth com persist
- `src/stores/chat-store.ts` â€” Zustand chat com streaming
- `src/stores/document-store.ts` â€” Estado do documento Word
- `src/components/layout/TaskPane.tsx` â€” Layout principal (header + tabs)
- `src/components/layout/TabNavigation.tsx` â€” Tabs: Chat, Playbook, Corpus, Editar
- `src/components/layout/Header.tsx` â€” Header com user info
- `src/components/auth/LoginForm.tsx` â€” Login email/senha
- `src/components/auth/AuthGuard.tsx` â€” Guard de autenticaÃ§Ã£o
- `src/components/chat/ChatPanel.tsx` â€” Chat Q&A com contexto do documento
- `src/components/chat/ChatInput.tsx` â€” Input com envio + streaming
- `src/components/chat/ChatMessage.tsx` â€” RenderizaÃ§Ã£o de mensagens
- `src/components/playbook/PlaybookPanel.tsx` â€” AnÃ¡lise com playbooks + redlines
- `src/components/corpus/CorpusPanel.tsx` â€” Busca no corpus RAG
- `src/components/drafting/DraftPanel.tsx` â€” EdiÃ§Ã£o com IA + diff preview
- `src/hooks/useOfficeDocument.ts` â€” Hook para document bridge
- `src/hooks/useSSEStream.ts` â€” Hook genÃ©rico SSE
- `src/styles/globals.css` â€” TailwindCSS + Office theme

**Backend (API):**
- `apps/api/app/schemas/word_addin.py` â€” Schemas Pydantic (InlineAnalyze, EditContent, Translate, Anonymize)
- `apps/api/app/services/word_addin_service.py` â€” WordAddinService (analyze, edit, translate, anonymize)
- `apps/api/app/api/endpoints/word_addin.py` â€” 4 endpoints: analyze-content, edit-content (SSE), translate (SSE), anonymize

### Arquivos Alterados
- `apps/api/app/core/config.py` â€” Adicionado CORS origins para Office Add-in (localhost:3100)
- `apps/api/app/api/routes.py` â€” Registrado router /word-addin

### DecisÃµes Tomadas
- React + Vite (nÃ£o webpack) para o add-in â€” mais rÃ¡pido, moderno
- Manifest XML (nÃ£o unified JSON) â€” compatibilidade mais ampla com Word desktop/Mac/Online
- Fluent UI para look-and-feel nativo do Office
- JWT em localStorage (seguro no contexto do iframe isolado do Office Add-in)
- Reutilizar PlaybookService existente para anÃ¡lise inline
- SSE para streaming (mesmo padrÃ£o do apps/web)

### PrÃ³ximos Passos
- Instalar dependÃªncias (`cd apps/office-addin && npm install`)
- Gerar dev certs (`npx office-addin-dev-certs install`)
- Testar sideload no Word desktop
- Implementar Fase 2: Playbook analysis com redlines OOXML avanÃ§ados
- Implementar Fase 5: Workflows (traduÃ§Ã£o, anonimizaÃ§Ã£o, template fill)

---

## 2026-02-02 â€” Sessao 42: Review Tables (Extracao Estruturada de Documentos)

### Objetivo
Implementar Review Tables inspiradas no Harvey AI Vault: templates pre-construidos para extracao de dados estruturados de documentos em formato tabular. Permite extrair party names, datas, valores, clausulas de N documentos automaticamente.

### Arquivos Criados

**Backend (API):**
- `apps/api/app/models/review_table.py` â€” Modelos ReviewTableTemplate e ReviewTable (SQLAlchemy)
- `apps/api/app/services/review_table_templates.py` â€” 5 templates pre-construidos (trabalhista, TI, societario, imobiliario, franquia)
- `apps/api/app/services/review_table_service.py` â€” ReviewTableService com create, process, export (CSV/XLSX), seed
- `apps/api/app/api/endpoints/review_tables.py` â€” 8 endpoints REST completos
- `apps/api/alembic/versions/n4o5p6q7r8s9_add_review_table_models.py` â€” Migration Alembic

**Frontend (Web):**
- `apps/web/src/app/(dashboard)/corpus/review/page.tsx` â€” Pagina completa com 4 views (list, templates, create, detail/spreadsheet)

### Arquivos Alterados
- `apps/api/app/models/__init__.py` â€” Registrado ReviewTable e ReviewTableTemplate
- `apps/api/app/core/database.py` â€” Import do modelo na init_db
- `apps/api/app/api/routes.py` â€” Registrado router /review-tables
- `apps/web/src/app/(dashboard)/corpus/page.tsx` â€” Adicionado botao "Review Tables" no header

### Decisoes Tomadas
- Background processing via FastAPI BackgroundTasks para nao bloquear request
- Extracao coluna-por-coluna com IA (Gemini Flash + fallback Claude) para maior precisao
- Templates system com is_system=True, seed idempotente
- Export XLSX com openpyxl (headers estilizados), CSV com BOM UTF-8
- Frontend como pagina separada /corpus/review com navegacao de volta ao corpus
- Schemas inline no endpoint (seguindo padrao simples do projeto)

### Comandos Executados
- `python3 -c "import ast; ast.parse(...)"` â€” Verificacao de sintaxe de todos os arquivos (OK)

---

## 2026-02-02 â€” Sessao 41: Corpus Admin Dashboard

### Objetivo
Criar painel administrativo completo para o Corpus, inspirado no Harvey AI, dando visibilidade total sobre documentos, usuarios e atividades da organizacao.

### Arquivos Alterados

**Backend (API):**
- `apps/api/app/schemas/corpus.py` â€” Adicionados schemas admin: CorpusAdminOverview, CorpusAdminUserStats, CorpusAdminUserList, CorpusAdminActivity, CorpusAdminActivityList, CorpusTransferRequest, CorpusTransferResponse
- `apps/api/app/services/corpus_service.py` â€” Adicionados metodos admin: get_admin_overview, get_corpus_users, get_user_documents, transfer_ownership, get_corpus_activity
- `apps/api/app/api/endpoints/corpus.py` â€” Adicionados 5 endpoints admin: /admin/overview, /admin/users, /admin/users/{user_id}/documents, /admin/transfer/{document_id}, /admin/activity

**Frontend (Web):**
- `apps/web/src/lib/api-client.ts` â€” Adicionados metodos admin: getCorpusAdminOverview, getCorpusAdminUsers, getCorpusAdminUserDocuments, transferCorpusDocument, getCorpusAdminActivity
- `apps/web/src/app/(dashboard)/corpus/hooks/use-corpus.ts` â€” Adicionados types e hooks admin: useCorpusAdminOverview, useCorpusAdminUsers, useCorpusAdminUserDocuments, useCorpusAdminActivity, useTransferDocumentOwnership
- `apps/web/src/app/(dashboard)/corpus/admin/page.tsx` â€” Pagina admin com tabs (Visao Geral, Usuarios, Atividade)
- `apps/web/src/app/(dashboard)/corpus/admin/corpus-admin-overview.tsx` â€” Cards de stats, top contribuidores, atividade recente, distribuicao por colecao
- `apps/web/src/app/(dashboard)/corpus/admin/corpus-admin-users.tsx` â€” Tabela de usuarios com linhas expansiveis mostrando documentos e opcao de transferir propriedade
- `apps/web/src/app/(dashboard)/corpus/admin/corpus-admin-activity.tsx` â€” Feed de atividades com filtros por acao e paginacao
- `apps/web/src/app/(dashboard)/corpus/page.tsx` â€” Adicionado botao "Painel Admin" visivel apenas para admins

### Comandos Executados
- `python3 -m py_compile` em todos os arquivos Python â€” OK
- `npx tsc --noEmit` â€” OK (zero erros)

### Decisoes Tomadas
- Endpoints admin verificam UserRole.ADMIN via _require_admin_org helper
- Reutilizou CorpusDocumentList para documentos de usuario (visao admin)
- Transferencia de propriedade verifica se novo dono pertence a mesma org
- Activity log derivado dos metadados dos documentos (status, timestamps)
- Frontend com proteÃ§Ã£o client-side: redirect se nao admin + UI placeholder

---

## 2026-02-02 â€” Sessao 40: Dynamic Corpus Projects com Knowledge Base

### Objetivo
Implementar projetos dinamicos de corpus (similar ao "Vault Projects" do Harvey AI) com suporte a Knowledge Base para consulta workspace-wide.

### Arquivos Criados
- `apps/api/app/models/corpus_project.py` â€” Modelos SQLAlchemy: CorpusProject, CorpusProjectDocument, CorpusProjectShare com enums e relationships
- `apps/api/app/schemas/corpus_project.py` â€” Schemas Pydantic: Create, Update, Response, List, DocumentAdd, Share, Transfer
- `apps/api/app/api/endpoints/corpus_projects.py` â€” Endpoints REST completos: CRUD de projetos, gerenciamento de documentos, compartilhamento e transferencia
- `apps/api/alembic/versions/o5p6q7r8s9t0_add_corpus_projects_tables.py` â€” Migration para 3 tabelas: corpus_projects, corpus_project_documents, corpus_project_shares

### Arquivos Alterados
- `apps/api/app/models/__init__.py` â€” Registrado CorpusProject, CorpusProjectDocument, CorpusProjectShare
- `apps/api/app/core/database.py` â€” Import dos novos modelos em init_db()
- `apps/api/app/api/routes.py` â€” Registrado router corpus_projects em /corpus/projects
- `apps/web/src/lib/api-client.ts` â€” 10 novos metodos para API de projects (CRUD, documents, share, transfer)
- `apps/web/src/app/(dashboard)/corpus/hooks/use-corpus.ts` â€” 7 novos hooks React Query para projects
- `apps/web/src/app/(dashboard)/corpus/components/corpus-private-tab.tsx` â€” Secao de Projects com cards, dialog de criacao, e badge de Knowledge Base

### Decisoes Tomadas
- Soft-delete para projetos (is_active flag) em vez de hard-delete
- collection_name auto-gerado como slug unico para OpenSearch/Qdrant
- Projects visÃ­veis: proprios + compartilhados + KB da organizacao
- Migration encadeada apos n4o5p6q7r8s9 (retention configs)

### Comandos Executados
- `python3 -m py_compile` em todos os arquivos Python â€” OK
- `npx tsc --noEmit` â€” OK (exit 0)

---

## 2026-02-02 â€” Sessao 39: BNP (Banco Nacional de Precedentes) MCP Server

### Objetivo
Criar servidor MCP customizado para o BNP/Pangea, integrado na plataforma Iudex como servidor built-in, endpoint HTTP e knowledge source para workflows.

### Arquivos Criados
- `apps/api/app/services/mcp_servers/__init__.py` â€” Init do modulo mcp_servers
- `apps/api/app/services/mcp_servers/bnp_server.py` â€” BNPClient (OAuth2 client_credentials) + BNPMCPServer (JSON-RPC handler) com 3 tools: search_precedentes, search_recursos_repetitivos, search_repercussao_geral
- `apps/api/app/api/endpoints/mcp_bnp.py` â€” Endpoint FastAPI JSON-RPC para o BNP MCP server

### Arquivos Alterados
- `apps/api/app/services/mcp_config.py` â€” Adicionado BUILTIN_MCP_SERVERS config e load_builtin_mcp_servers() para servidores MCP in-process
- `apps/api/app/services/mcp_hub.py` â€” Suporte a servidores built-in: _is_builtin(), _get_builtin_handler(), roteamento direto em _rpc() sem HTTP
- `apps/api/app/api/routes.py` â€” Registrado mcp_bnp router
- `apps/api/app/services/ai/knowledge_source_loader.py` â€” Adicionado source_type "bnp" com metodo _load_bnp()
- `apps/web/src/components/workflows/properties-panel.tsx` â€” Adicionado BNP como opcao de knowledge source (icone, label, dropdown, handler)

### Decisoes Tomadas
- BNP registrado como servidor built-in (url builtin://bnp) para evitar overhead HTTP quando chamado internamente pelo MCPHub
- Endpoint HTTP /mcp/bnp/rpc tambem disponivel para consumo externo
- OAuth2 token cacheado com margem de 30s antes da expiracao
- Busca "todos" faz merge de recursos repetitivos + repercussao geral
- Knowledge source usa BNPClient diretamente (sem passar pelo MCP) para eficiencia

---

## 2026-02-02 â€” Sessao 38: Rate Limiting Corpus/Playbook + Retention Policy Persistence

### Objetivo
Implementar rate limiting nos endpoints de Corpus e Playbook (inspirado nos limites da Harvey AI), e tornar as retention policies persistiveis por organizacao no banco de dados.

### Arquivos Criados
- `apps/api/app/core/rate_limit.py` â€” Dependencias reutilizaveis de rate-limiting (RateLimitDep) com limites pre-configurados para Corpus e Playbook
- `apps/api/app/models/corpus_retention.py` â€” Modelo SQLAlchemy CorpusRetentionConfig para persistencia de politicas de retencao por organizacao
- `apps/api/app/tasks/__init__.py` â€” Init do modulo de tasks
- `apps/api/app/tasks/corpus_cleanup.py` â€” Background task para limpeza automatica de documentos expirados com base nas retention policies
- `apps/api/alembic/versions/n4o5p6q7r8s9_add_corpus_retention_configs.py` â€” Migration para tabela corpus_retention_configs

### Arquivos Alterados
- `apps/api/app/api/endpoints/corpus.py` â€” Adicionado rate limiting (Depends) a todos os endpoints: 10/min search, 30/min reads, 5/min writes
- `apps/api/app/api/endpoints/playbooks.py` â€” Adicionado rate limiting: 30/min reads, 10/min writes, 5/min analyze, 3/min generate
- `apps/api/app/services/corpus_service.py` â€” get_retention_policies() agora busca politicas no banco com fallback para RAGConfig; update_retention_policy() agora persiste via upsert
- `apps/api/app/models/__init__.py` â€” Registrado CorpusRetentionConfig
- `apps/api/app/core/database.py` â€” Registrado CorpusRetentionConfig no init_db

### Decisoes Tomadas
- Rate limiting usa o RateLimiter existente (core/rate_limiter.py) via Redis, com dependency injection (Depends) em vez de decorators manuais
- Limites por endpoint-scope evitam que um tipo de operacao afete outro (ex: buscas nao competem com escritas)
- Retention policies usam UniqueConstraint (org_id, scope, collection) para garantir uma policy por combinacao
- Cleanup task projetada como funcao async standalone para flexibilidade (Celery, BackgroundTasks, cron)

---

## 2026-02-02 â€” Sessao 37: IntegraÃ§Ã£o PJe via TecJustiÃ§a REST API

### Objetivo
Integrar a API REST TecJustiÃ§a como fonte de conhecimento (knowledge source) no sistema de workflows do Iudex, permitindo consultar dados de processos do PJe diretamente nos prompts.

### Arquivos Alterados
- `apps/api/app/services/ai/knowledge_source_loader.py` â€” Adicionado tipo `pje` no dispatch table, mÃ©todos `_load_pje`, `_format_pje_processo` e `_format_pje_capa`, documentaÃ§Ã£o de env vars
- `apps/web/src/components/workflows/properties-panel.tsx` â€” Adicionada opÃ§Ã£o PJe no dropdown de fontes, Ã­cone no SOURCE_ICONS, label no display, handler no onChange

### DecisÃµes Tomadas
- AutenticaÃ§Ã£o via headers (X-API-KEY, X-MNI-CPF, X-MNI-SENHA) configurada por env vars, seguindo padrÃ£o de seguranÃ§a do projeto
- ExtraÃ§Ã£o automÃ¡tica de nÃºmero CNJ do query via regex quando nÃ£o especificado na config da source
- Modo `auto` consulta dados do processo + lista de documentos + capa; modos `processo`, `documentos` e `capa` disponÃ­veis
- Ãcone `Scale` reutilizado para PJe (consistente com outras fontes jurÃ­dicas)

### Comandos Executados
- `python3 -m py_compile` â€” OK (sem erros de sintaxe)
- `npx tsc --noEmit` â€” OK (sem erros de tipo no arquivo modificado)

---

## 2026-02-02 â€” Sessao 36: Shared Spaces (Workspaces para Clientes Externos)

### Objetivo
Implementar feature "Shared Spaces" â€” workspaces branded onde organizacoes podem convidar clientes externos (guests) com acesso controlado a workflows, documentos e runs.

### Arquivos Criados
- `apps/api/app/models/shared_space.py` â€” Modelos SQLAlchemy: SharedSpace, SpaceInvite, SpaceResource com enums SpaceRole e InviteStatus
- `apps/api/app/schemas/shared_space.py` â€” Schemas Pydantic para request/response dos endpoints
- `apps/api/app/api/endpoints/spaces.py` â€” API completa com 12 endpoints: CRUD de spaces, convites, join por token, recursos
- `apps/web/src/app/(dashboard)/spaces/page.tsx` â€” Pagina de listagem de spaces com grid de cards e dialog de criacao
- `apps/web/src/app/(dashboard)/spaces/[id]/page.tsx` â€” Pagina de detalhes com tabs: Recursos, Membros, Configuracoes

### Arquivos Alterados
- `apps/api/app/api/routes.py` â€” Registrado spaces.router com prefix "/spaces"
- `apps/api/app/models/__init__.py` â€” Exportados SharedSpace, SpaceInvite, SpaceResource, SpaceRole, InviteStatus
- `apps/api/app/core/database.py` â€” Importados modelos para auto-criacao de tabelas no init_db
- `apps/web/src/components/layout/sidebar-pro.tsx` â€” Adicionado link "Spaces" com icone Share2 na navegacao principal

### Decisoes Tomadas
- Modelos SQLAlchemy proprios (nao JSONB) seguindo padrao existente do projeto para Organization/Team
- Convites via token unico (secrets.token_urlsafe) para seguranca â€” nao depende de email magic link
- Acesso verificado por: membro da org dona do space OU convite aceito com role adequada
- Soft delete para spaces (is_active=False) mantendo historico
- Frontend usa apiClient.request() generico (nao metodos dedicados) para simplificar integracao inicial
- SpaceResource armazena resource_name cacheado para exibicao sem necessidade de join com tabelas de recursos

---

## 2026-02-02 â€” Sessao 35: Custom Published Workflows (Standalone App URLs)

### Objetivo
Permitir que organizacoes publiquem workflows como apps standalone com URLs dedicadas (/app/{slug}) acessiveis diretamente por usuarios internos ou externos.

### Arquivos Criados
- `apps/web/src/components/workflows/publish-dialog.tsx` â€” Dialog para publicar/despublicar workflow com slug customizavel
- `apps/web/src/app/app/[slug]/page.tsx` â€” Pagina standalone do app publicado com runner UI
- `apps/api/alembic/versions/m3n4o5p6q7r8_add_workflow_published_app.py` â€” Migracao para campos published_slug e published_config

### Arquivos Alterados
- `apps/api/app/models/workflow.py` â€” Adicionados campos published_slug (String unique indexed) e published_config (JSON)
- `apps/api/app/core/security.py` â€” Adicionada dependency get_current_user_optional para endpoints com auth opcional
- `apps/api/app/api/endpoints/workflows.py` â€” Endpoint publish reescrito com suporte a slug/config; adicionados endpoints unpublish e GET /app/{slug}; WorkflowResponse atualizado com campos de publicacao
- `apps/web/src/lib/api-client.ts` â€” Interface WorkflowResponse atualizada com published_slug e published_config
- `apps/web/src/components/workflows/workflow-builder.tsx` â€” Botao "Publicar" na toolbar com PublishDialog integrado

### Decisoes Tomadas
- Slug armazenado como campo unico indexado no modelo Workflow (nao em JSON generico) para performance de lookup
- Auth opcional via get_current_user_optional que retorna None em vez de 403
- Endpoint publish aceita workflows em qualquer status (nao exige aprovacao previa) para flexibilidade
- Pagina standalone (/app/[slug]) e completamente independente do layout do dashboard

### Comandos Executados
- `python3 -c "import ast; ..."` â€” Validacao de sintaxe Python (OK)
- `npx tsc --noEmit` â€” Verificacao de tipos TypeScript (OK)

---

## 2026-02-02 â€” Sessao 34: Assistente Contextual (Harvey AI Assistant Parity)

### Objetivo
Implementar feature de Assistente Contextual que permite ao usuario conversar com IA dentro de qualquer workflow, documento ou corpus com contexto persistente.

### Arquivos Criados
- `apps/api/app/api/endpoints/assistant.py` â€” Endpoint POST /assistant/chat com SSE streaming
- `apps/web/src/components/assistant/assistant-panel.tsx` â€” Painel slide-over com chat
- `apps/web/src/components/assistant/index.ts` â€” Barrel export

### Arquivos Alterados
- `apps/api/app/api/routes.py` â€” Registro do router assistant
- `apps/web/src/components/workflows/workflow-builder.tsx` â€” Botao "Assistente" + AssistantPanel

### Decisoes Tomadas
- OpenAI como provider primario com fallback para Claude
- Panel fixo no lado direito (400px) com minimizacao
- SSE streaming seguindo padrao existente do codebase

---

## 2026-02-02 â€” Sessao 33: Audit Trail para Workflow Runs

### Objetivo
Implementar audit trail completo para execucoes de workflows: endpoint de auditoria paginado no backend e componente visual no frontend.

### Arquivos Criados
- `apps/web/src/components/workflows/audit-trail.tsx` â€” Componente AuditTrail com lista expandivel de execucoes, paginacao, detalhes de input/output/erro por entrada

### Arquivos Alterados
- `apps/api/app/api/endpoints/workflows.py` â€” Adicionado import de Query, novo endpoint GET `/{workflow_id}/audit` com join User+WorkflowRun, paginacao, summaries de input/output, duracao
- `apps/web/src/components/workflows/workflow-builder.tsx` â€” Importados AuditTrail e VersionHistory, renderizados no painel lateral direito quando nenhum no esta selecionado
- `apps/web/src/components/workflows/index.ts` â€” Adicionado export do AuditTrail

### Decisoes Tomadas
- Reutilizou o modelo WorkflowRun existente (ja possui user_id, input_data, output_data, started_at, completed_at, error_message, trigger_type)
- Endpoint de audit faz JOIN com User para retornar nome/email de quem executou
- Summaries de input/output truncados em 200 chars para nao sobrecarregar a resposta
- AuditTrail e VersionHistory ficam no painel direito quando nenhum no esta selecionado, evitando poluir a interface
- Paginacao com load-more no frontend (10 itens por pagina)

### Comandos Executados
- TypeScript type-check â€” OK (sem erros)
- Python syntax check â€” OK

---

## 2026-02-02 â€” SessÃ£o 32: Vault Analytics Dashboard

### Objetivo
Implementar dashboard de Analytics inspirado no Harvey AI Vault Analytics, com metricas de Corpus, Workflows e Documentos.

### Arquivos Criados
- `apps/api/app/api/endpoints/analytics.py` â€” 5 endpoints de analytics (corpus/overview, corpus/trending, corpus/usage-over-time, workflows/stats, documents/insights)
- `apps/web/src/app/(dashboard)/analytics/page.tsx` â€” Pagina de dashboard com cards de resumo, graficos de uso, trending topics, e stats de workflows

### Arquivos Alterados
- `apps/api/app/api/routes.py` â€” Registro do router de analytics
- `apps/web/src/components/layout/sidebar-pro.tsx` â€” Link de navegacao "Analytics" com icone BarChart3

### Decisoes Tomadas
- Usa RAGTraceEvent como fonte primaria de dados de busca, com fallback para ChatMessage como proxy
- Usa COLLECTION_DISPLAY do corpus_service para manter consistencia nos nomes das colecoes
- Endpoints usam get_org_context para suporte multi-tenant
- Frontend usa fetchWithAuth nativo (sem axios) para chamadas simples de GET

### Comandos Executados
- Import test do analytics router â€” OK
- TypeScript type-check do analytics page â€” OK (sem erros)

---

## 2026-02-02 â€” SessÃ£o 31: Mega-sessÃ£o Corpus + Playbook (Harvey AI Parity)

### Objetivo
Implementar dois mÃ³dulos completos inspirados no Harvey AI: **Corpus** (equivalente ao Vault â€” RAG unificado) e **Playbook** (regras estruturadas para revisÃ£o de contratos). Inclui criaÃ§Ã£o, revisÃ£o, correÃ§Ã£o de bugs, gap analysis contra documentaÃ§Ã£o oficial do Harvey, e implementaÃ§Ã£o de P0/P1.

### Fases da SessÃ£o

**Fase 1 â€” ImplementaÃ§Ã£o inicial (5 agentes em paralelo)**
- Backend Playbook: modelo + migration + 13 endpoints CRUD
- Playbook AI Service: anÃ¡lise de contratos + geraÃ§Ã£o automÃ¡tica + 6 prompts PT-BR
- Frontend Corpus: pÃ¡gina `/corpus` com 3 tabs (Global/Privado/Local)
- Frontend Playbooks: editor de regras, wizard de geraÃ§Ã£o, painel de anÃ¡lise
- Backend Corpus API: 11 endpoints + serviÃ§o unificado dos 3 backends RAG

**Fase 2 â€” RevisÃ£o de cÃ³digo (4 agentes em paralelo)**
- 5 issues crÃ­ticos encontrados e corrigidos (imports errados, bug order==0, tipo incompatÃ­vel)
- 7 issues moderados corrigidos (enums, stale state, imports nÃ£o usados)
- 34 issues menores documentados

**Fase 3 â€” Gap Analysis vs Harvey AI (2 agentes em paralelo)**
- Corpus: 3 âœ…, 8 âš ï¸ parciais, 14 âŒ ausentes (de 25 features)
- Playbook: 5 âœ…, 6 âš ï¸ parciais, 7 âŒ ausentes (de 20 features)

**Fase 4 â€” P0 + P1 (6 agentes em paralelo)**
- P0: Hooks frontend conectados Ã  API real (zero mock data)
- P0: Corpus â†” Chat (auto-busca com heurÃ­stica jurÃ­dica)
- P0: Playbook â†” Minuta (seletor + injeÃ§Ã£o no agente)
- P1: PersistÃªncia de anÃ¡lises (modelo + migration + review tracking)
- P1: Import de playbook existente (PDF/Word â†’ regras via IA)
- P1: Export (JSON/PDF/DOCX com reportlab + python-docx)

### Arquivos Criados (~40 novos)

**Backend:**
- `app/models/playbook.py` â€” Playbook, PlaybookRule, PlaybookShare, PlaybookAnalysis
- `app/schemas/playbook.py` â€” Schemas CRUD
- `app/schemas/playbook_analysis.py` â€” Schemas de anÃ¡lise + import/export
- `app/schemas/corpus.py` â€” 12 schemas do Corpus
- `app/api/endpoints/playbooks.py` â€” 20+ endpoints
- `app/api/endpoints/corpus.py` â€” 11 endpoints
- `app/services/playbook_service.py` â€” AnÃ¡lise, geraÃ§Ã£o, import, export
- `app/services/playbook_prompts.py` â€” 8 prompts PT-BR
- `app/services/corpus_service.py` â€” AgregaÃ§Ã£o OpenSearch + Qdrant + PostgreSQL
- `app/services/corpus_chat_tool.py` â€” IntegraÃ§Ã£o Corpus â†” Chat
- 2 migrations Alembic (playbooks + playbook_analyses)

**Frontend:**
- `/corpus/` â€” page + 5 componentes + hooks
- `/playbooks/` â€” 3 pages + 9 componentes + hooks
- `playbook-selector.tsx` + `playbook-active-badge.tsx` (integraÃ§Ã£o /minuta)

**Modificados (~15):**
- `api/routes.py`, `models/__init__.py`, `core/database.py`
- `sidebar-pro.tsx`, `api-client.ts`, `chat-store.ts`
- `minuta/page.tsx`, `chats.py`, `jobs.py`, `chat.py` schema
- `pipeline_adapter.py`, `langgraph_legal_workflow.py`

### VerificaÃ§Ã£o Final
- Python: 18/18 arquivos OK (py_compile)
- TypeScript: 0 erros (tsc --noEmit)

### DecisÃµes Tomadas
- Nome "Corpus" em vez de "Vault" (remete a corpus juris, mais adequado ao mercado BR)
- Corpus e Biblioteca mantidos separados (funÃ§Ãµes distintas: IA vs usuÃ¡rio)
- Playbook â†” Minuta usa Option B (frontend busca prompt e envia no payload)
- Corpus â†” Chat usa heurÃ­stica + fallback (2 camadas de integraÃ§Ã£o)
- `CORPUS_AUTO_SEARCH=true` como default (controlÃ¡vel por env)

### Gap Analysis Pendente (P1/P2 para prÃ³ximas sessÃµes)
- Projetos dinÃ¢micos no Corpus + Knowledge Bases ilimitadas
- Admin dashboard cross-org
- Sharing com permissÃµes granulares (Corpus + enforcement no Playbook)
- Review Tables (extraÃ§Ã£o one-click com templates BR)
- Upload paralelo + per-file status tracking (SSE)
- Rate limiting (slowapi)
- Tracking de revisÃ£o na UI (reviewed/unreviewed no analysis panel)
- DMS integrations (Google Drive, SharePoint)

---

## 2026-02-02 â€” Sessao 30: Integrar Playbook na pagina /minuta

### Objetivo
Permitir que usuarios selecionem um Playbook ao revisar contratos em /minuta, injetando as regras no system prompt do agente de IA.

### Arquivos Editados

**Frontend:**
- `apps/web/src/stores/chat-store.ts` â€” Adicionados campos `selectedPlaybookId`, `selectedPlaybookName`, `selectedPlaybookPrompt`, `isPlaybookLoading` no ChatState, com setters `setSelectedPlaybook()` e `clearPlaybook()`. Injetado `playbook_prompt` nos payloads de `sendMessage`, `startAgentGeneration` (legacy) e `startLangGraphJob`.
- `apps/web/src/app/(dashboard)/playbooks/hooks.ts` â€” Adicionados `usePlaybookPrompt()` (busca prompt formatado via GET /playbooks/{id}/prompt) e `useActivePlaybooks()`.
- `apps/web/src/app/(dashboard)/playbooks/components/playbook-selector.tsx` â€” Novo componente dropdown para selecao de playbook na toolbar do /minuta.
- `apps/web/src/app/(dashboard)/playbooks/components/playbook-active-badge.tsx` â€” Novo componente badge inline mostrando playbook ativo no painel de chat.
- `apps/web/src/app/(dashboard)/minuta/page.tsx` â€” Integrado PlaybookSelector na toolbar e PlaybookActiveBadge no painel de chat.

**Backend:**
- `apps/api/app/schemas/chat.py` â€” Adicionado campo `playbook_prompt: Optional[str]` ao MessageCreate.
- `apps/api/app/api/endpoints/chats.py` â€” Injecao do playbook_prompt no base_instruction antes do streaming.
- `apps/api/app/api/endpoints/jobs.py` â€” Passagem do playbook_prompt no state do LangGraph job.
- `apps/api/app/services/ai/langgraph_legal_workflow.py` â€” Adicionado `playbook_prompt` ao LegalWorkflowState TypedDict. Injecao em 4 pontos do workflow (planner, web search, drafter, committee).

### Decisoes Tomadas
- **Option B (Frontend fetches prompt)**: O frontend busca o prompt formatado via GET /playbooks/{id}/prompt e o envia como `playbook_prompt` nos payloads. Mais simples e desacoplado.
- O prompt e injetado em TODOS os caminhos de geracao: chat streaming, LangGraph jobs, e geracao legacy.
- O playbook_prompt e concatenado ao system_instruction, nao o substitui.

### Comandos Executados
- `npx tsc --noEmit` â€” OK
- `npx eslint` â€” OK
- `python3 -c "import ast; ast.parse(...)"` â€” OK (todos os .py)

---

## 2026-02-02 â€” SessÃ£o 29: Implementar Import/Export de Playbooks

### Objetivo
Implementar duas features inspiradas no Harvey AI que estavam faltando nos Playbooks:
1. **Import**: Upload de um documento existente (PDF/DOCX) e extraÃ§Ã£o de regras via IA
2. **Export**: Download do playbook como PDF, DOCX ou JSON

### Arquivos Editados

**Backend:**
- `apps/api/app/services/playbook_prompts.py` â€” Adicionado `PLAYBOOK_IMPORT_PROMPT` para extraÃ§Ã£o de regras de documentos existentes
- `apps/api/app/services/playbook_service.py` â€” Adicionados mÃ©todos `import_playbook_from_document()` e `export_playbook()` com helpers `_export_as_json()`, `_export_as_pdf()` (reportlab) e `_export_as_docx()` (python-docx)
- `apps/api/app/schemas/playbook_analysis.py` â€” Adicionados schemas `PlaybookImportRequest` e `PlaybookImportResponse`
- `apps/api/app/api/endpoints/playbooks.py` â€” Adicionados endpoints `POST /playbooks/import` e `GET /playbooks/{id}/export?format=json|pdf|docx`

**Frontend:**
- `apps/web/src/app/(dashboard)/playbooks/hooks.ts` â€” Adicionados `useImportPlaybook()` hook e `getPlaybookExportUrl()` helper
- `apps/web/src/app/(dashboard)/playbooks/components/create-playbook-dialog.tsx` â€” Adicionada 4a opÃ§Ã£o "Importar de documento" com formulÃ¡rio completo
- `apps/web/src/app/(dashboard)/playbooks/[id]/page.tsx` â€” Adicionado dropdown "Exportar" com opÃ§Ãµes JSON/PDF/DOCX

### DecisÃµes Tomadas
- Usou `reportlab` (jÃ¡ no requirements.txt) para PDF e `python-docx` (jÃ¡ no requirements.txt) para DOCX
- Export endpoint retorna `Response` com `Content-Disposition: attachment` para download direto
- Import segue mesmo padrÃ£o de `generate_playbook_from_contracts` mas com prompt dedicado
- Frontend usa `<a href download>` para export (sem hook, download direto)

### Comandos Executados
- `python3 -m py_compile` em todos os 4 arquivos backend â€” OK
- `npx tsc --noEmit` â€” OK (apenas 1 erro pre-existente nÃ£o relacionado)

---

## 2026-02-02 â€” SessÃ£o 28: Integrar busca do Corpus no chat (RAG automÃ¡tico)

### Objetivo
Fazer o agente de chat buscar automaticamente no Corpus (base RAG) quando o usuÃ¡rio faz perguntas, sem precisar selecionar fontes manualmente. Sem isso, o Corpus ficava inutilizado no chat.

### Arquivos Criados
- `apps/api/app/services/corpus_chat_tool.py` â€” Novo mÃ³dulo com funÃ§Ãµes `search_corpus_for_chat()`, `format_corpus_context()`, `should_search_corpus()` e `_search_corpus_direct()`. Busca hÃ­brida (lexical + vetorial) no Corpus e formata resultados como contexto XML para injeÃ§Ã£o no prompt.

### Arquivos Editados
- `apps/api/app/api/endpoints/chats.py` â€” Import do `corpus_chat_tool`. Adicionada busca automÃ¡tica do Corpus em 2 pontos: (1) fluxo streaming `send_message_stream` apÃ³s `build_rag_context` quando `rag_context` estÃ¡ vazio, (2) fluxo simples `send_message` antes do budget check. Ambos usam `should_search_corpus()` para decidir e `search_corpus_for_chat()` para buscar.
- `apps/api/app/services/rag/pipeline_adapter.py` â€” Adicionado fallback automÃ¡tico de fontes: quando `rag_sources` estÃ¡ vazio e nÃ£o Ã© `adaptive_routing`, usa fontes padrÃ£o do Corpus (`lei`, `juris`, `doutrina`, `pecas_modelo`, `sei`). Controlado por env `CORPUS_AUTO_SEARCH` (default: true).

### DecisÃµes Tomadas
- Abordagem dupla: (1) pipeline_adapter auto-sources e (2) corpus_chat_tool como fallback no chat
- `should_search_corpus()` usa heurÃ­sticas (palavras-chave jurÃ­dicas, interrogativas, tamanho) para evitar buscas desnecessÃ¡rias em saudaÃ§Ãµes
- Formato de contexto usa XML com tags `<corpus_context>` e `<chunk>` com metadados para citaÃ§Ãµes
- Busca pode ser desativada via `CORPUS_AUTO_SEARCH=false`
- NÃ£o duplica busca: se `rag_sources` foi selecionado explicitamente, o fluxo normal cuida

### Comandos Executados
- `python3 -c "import ast; ast.parse(...)"` para cada arquivo â€” OK (sem erros de sintaxe)

---

## 2026-02-02 â€” SessÃ£o 27: Conectar hooks do Corpus ao backend real

### Objetivo
Substituir todos os dados mock nos hooks do Corpus por chamadas reais Ã  API backend.

### Arquivos Editados
- `apps/web/src/lib/api-client.ts` â€” Adicionados 7 mÃ©todos de Corpus Ã  classe ApiClient (getCorpusStats, getCorpusCollections, getCorpusDocuments, ingestCorpusDocuments, deleteCorpusDocument, promoteCorpusDocument, extendCorpusDocumentTTL)
- `apps/web/src/app/(dashboard)/corpus/hooks/use-corpus.ts` â€” SubstituÃ­dos todos os mocks por chamadas reais via apiClient; tipos alinhados com schemas backend (CorpusStats, CorpusCollectionInfo, CorpusDocument, CorpusDocumentList, CorpusIngestResponse, CorpusPromoteResponse, CorpusExtendTTLResponse)
- `apps/web/src/app/(dashboard)/corpus/components/corpus-stats.tsx` â€” Adaptado para novos campos (storage_size_mb, pending_ingestion, failed_ingestion em vez de storage_used_bytes, ingestion_queue, total_collections)
- `apps/web/src/app/(dashboard)/corpus/components/corpus-global-tab.tsx` â€” Adaptado para CorpusCollectionInfo sem slug/id/last_updated_at; usa name/display_name
- `apps/web/src/app/(dashboard)/corpus/components/corpus-local-tab.tsx` â€” Adaptado doc.size_bytes em vez de doc.file_size; removido doc.created_at
- `apps/web/src/app/(dashboard)/corpus/components/corpus-private-tab.tsx` â€” Adaptado size_bytes, file_type, remoÃ§Ã£o de token_count/created_at, paginaÃ§Ã£o calculada
- `apps/web/src/app/(dashboard)/corpus/components/corpus-upload-dialog.tsx` â€” Adaptado payload para usar document_ids em vez de File

### DecisÃµes Tomadas
- Tipos frontend alinhados 1:1 com schemas Pydantic do backend (corpus.py)
- useCorpusCollections() nÃ£o recebe mais parÃ¢metro scope (backend nÃ£o aceita)
- PaginaÃ§Ã£o total_pages calculada no frontend (backend retorna apenas total/per_page)
- Upload dialog adaptado para enviar document_ids (backend nÃ£o aceita file upload direto no /ingest)

### Comandos Executados
- `npx tsc --noEmit | grep corpus` â€” OK (0 erros relacionados ao corpus)

---

## 2026-02-02 â€” SessÃ£o 26: Fechar Gaps Iudex vs Harvey AI (6 Batches)

### Objetivo
Implementar 6 batches de melhorias para fechar gap de cobertura de ~68% para ~90% comparado ao Harvey AI.

### Arquivos Criados
- `apps/api/app/scripts/__init__.py` â€” Pacote scripts
- `apps/api/app/scripts/seed_workflow_templates.py` â€” 12 workflow templates prÃ©-built (seed data)
- `apps/web/src/components/workflows/corpus-picker-modal.tsx` â€” Modal para selecionar coleÃ§Ãµes do Corpus
- `apps/web/src/components/library/workflow-picker-modal.tsx` â€” Modal para selecionar workflow a partir da biblioteca

### Arquivos Editados
- `apps/api/app/services/ai/knowledge_source_loader.py` â€” Handler `corpus` (busca hÃ­brida OpenSearch + Qdrant)
- `apps/api/app/api/endpoints/workflows.py` â€” Endpoints `clone` e `share-org`
- `apps/web/src/components/workflows/properties-panel.tsx` â€” Corpus picker, Ã­cones por tipo, counter 0/2, warning max, botÃ£o duplicar, drag-to-reorder sections
- `apps/web/src/components/workflows/workflow-builder.tsx` â€” Bulk select (Shift+drag), performance warning >25 nÃ³s, SelectionMode
- `apps/web/src/app/(dashboard)/workflows/catalog/page.tsx` â€” BotÃ£o "Instalar" (clone), fix apiClient.fetch â†’ getWorkflowCatalog
- `apps/web/src/components/workflows/run-viewer.tsx` â€” Toggle "Toda organizaÃ§Ã£o" no share dialog
- `apps/web/src/components/dashboard/library-sidebar.tsx` â€” Menu item "Executar workflow"
- `apps/web/src/lib/api-client.ts` â€” 4 novos mÃ©todos: shareRunWithOrg, getWorkflowCatalog, cloneWorkflowTemplate

### Bugs PrÃ©-Existentes Corrigidos
- `version-history.tsx` â€” `apiClient.axios` (private) â†’ `apiClient.fetchWithAuth`
- `[id]/test/page.tsx` â€” `apiClient.fetch` â†’ `apiClient.fetchWithAuth`

### VerificaÃ§Ã£o
- `npx next build` â€” OK (compilaÃ§Ã£o + type check passou)
- `python -c "from app.services.ai.knowledge_source_loader import KnowledgeSourceLoader"` â€” OK
- `python -c "from app.scripts.seed_workflow_templates import TEMPLATES"` â€” 12 templates OK

---

## 2026-02-02 â€” Sessao 25: Bug fixes criticos em corpus, playbooks e modelos

### Objetivo
Corrigir 9 issues identificadas: imports errados, bugs logicos, imports nao utilizados, enums nao aplicados nos modelos, e registro de modelos no init_db.

### Arquivos Alterados
- `apps/api/app/services/corpus_service.py` â€” Corrigido `get_pipeline` -> `get_rag_pipeline` e `get_embedding` -> `get_embeddings_service().embed_query()`
- `apps/api/app/api/endpoints/playbooks.py` â€” Fix order==0 bug (2 ocorrencias), removidos imports nao usados (selectinload, PlaybookGenerateRequest), adicionado `# noqa: E712`
- `apps/api/app/services/playbook_service.py` â€” Removido import nao usado `selectinload`
- `apps/api/app/schemas/playbook.py` â€” Removida classe duplicada `PlaybookGenerateRequest` (versao correta em playbook_analysis.py)
- `apps/api/app/models/playbook.py` â€” Enums agora usados nas colunas via SQLEnum (scope, action_on_reject, severity, permission)
- `apps/api/app/core/database.py` â€” Registrados modelos Playbook, PlaybookRule, PlaybookShare no init_db()
- `apps/api/app/api/endpoints/corpus.py` â€” Removidos imports nao usados (get_current_user, require_org_role)

### Comandos Executados
- `python3 -m py_compile` em todos os 7 arquivos â€” OK

### Decisoes Tomadas
- `get_embeddings_service()` retorna `EmbeddingsService` com metodo sincrono `embed_query()`, entao substituicao direta sem await
- Enums aplicados com SQLEnum para validacao no banco (padrao consistente com outros modelos do projeto)
- `PlaybookGenerateRequest` removido de playbook.py pois playbook_analysis.py tem a versao completa usada pelo endpoint

---

## 2026-02-02 â€” Sessao 24: Follow-ups e Compartilhamento de Runs â€” P2 #14 e #16

### Objetivo
Implementar follow-ups (perguntas sobre resultado de runs concluidos) e compartilhamento de runs com outros usuarios, itens P2 #14 e #16 do plano Harvey AI parity.

### Arquivos Alterados
- `apps/api/app/api/endpoints/workflows.py` â€” Endpoints POST /runs/{run_id}/follow-up (streaming via Claude) e POST /runs/{run_id}/share; Request models FollowUpRequest e ShareRunRequest
- `apps/web/src/lib/api-client.ts` â€” Metodos followUpRun (SSE streaming) e shareRun no apiClient
- `apps/web/src/components/workflows/run-viewer.tsx` â€” Chat de follow-up com streaming progressivo, botao Compartilhar com popover para IDs/emails e mensagem

### Decisoes Tomadas
- Follow-up usa stream_anthropic_async (mesmo padrao do orchestration router) para streaming de tokens
- Compartilhamento armazena registros em output_data._shares (JSON simples, sem tabela nova)
- Follow-up so disponivel para runs com status COMPLETED
- Chat inline abaixo do log de eventos, com input e respostas progressivas via SSE
- Botao Compartilhar com popover mostrando input de IDs/emails e mensagem opcional

### Comandos Executados
- `eslint run-viewer.tsx` â€” OK
- `eslint api-client.ts` â€” OK
- `tsc --noEmit` â€” OK (sem erros nos arquivos modificados)
- `python3 ast.parse workflows.py` â€” Syntax OK

---

## 2026-02-02 â€” Sessao 23: Words to Workflows (NL to Graph) â€” P2 #11

### Objetivo
Implementar feature "Words to Workflows" que converte descricoes em linguagem natural em grafos de workflow visuais usando IA.

### Arquivos Criados
- `apps/api/app/services/ai/nl_to_graph.py` â€” NLToGraphParser com suporte a Claude, OpenAI e Gemini
- `apps/web/src/components/workflows/nl-input-dialog.tsx` â€” Dialog com textarea, exemplos clicaveis e geracao via IA

### Arquivos Alterados
- `apps/api/app/api/endpoints/workflows.py` â€” Endpoint POST /generate-from-nl adicionado antes de /{workflow_id}
- `apps/web/src/lib/api-client.ts` â€” Metodo generateWorkflowFromNL no apiClient
- `apps/web/src/components/workflows/workflow-builder.tsx` â€” Botao "Criar com IA" e NLInputDialog integrado
- `apps/web/src/components/workflows/index.ts` â€” Export do NLInputDialog

### Decisoes Tomadas
- Parser usa chamadas diretas aos SDKs (anthropic, openai, google-genai) seguindo padrao do agent_clients.py
- Retry com correcao automatica: se grafo falha validacao, reenvia erros ao LLM para corrigir (max 2 retries)
- System prompt detalha todos os 9 tipos de no com configs esperadas
- Endpoint colocado antes de /{workflow_id} para evitar conflito de rotas FastAPI
- Botao com estilo violet para destacar feature de IA

---

## 2026-02-02 â€” SessÃ£o 22: Draft Editor (Rich Text) para Workflows

### Objetivo
Implementar o editor de rascunhos (P2 #18 do plano Harvey AI parity) para ediÃ§Ã£o de outputs de workflow runs.

### Arquivos Criados
- `apps/web/src/components/workflows/draft-editor.tsx` â€” Componente TipTap com toolbar, modo leitura/ediÃ§Ã£o, salvar/descartar

### Arquivos Alterados
- `apps/web/src/components/workflows/index.ts` â€” Adicionado export do DraftEditor

### DecisÃµes Tomadas
- Reutilizado TipTap (ja instalado) com StarterKit + Underline + Placeholder
- Toolbar simplificada vs DocumentEditor (sem tabelas, alinhamento, mermaid) â€” foco em ediÃ§Ã£o de output
- `immediatelyRender: false` para compatibilidade SSR conforme CLAUDE.md
- Labels em portugues: "Salvar EdiÃ§Ãµes", "Descartar", "Editando", "Leitura"
- Status bar "AlteraÃ§Ãµes nÃ£o salvas" para feedback visual

### Comandos Executados
- `npx tsc --noEmit` â€” OK (0 erros no draft-editor; erros pre-existentes em run-viewer.tsx)

---

## 2026-02-02 â€” SessÃ£o 21: PlaybookService â€” AnÃ¡lise de Contratos com IA

### Objetivo
Criar o serviÃ§o PlaybookService para anÃ¡lise de contratos usando regras de Playbook, inspirado no Harvey AI Playbook.

### Arquivos Criados
- `apps/api/app/schemas/playbook_analysis.py` â€” Schemas Pydantic para resultados de anÃ¡lise
- `apps/api/app/services/playbook_prompts.py` â€” 6 prompts especializados em pt-BR
- `apps/api/app/services/playbook_service.py` â€” ServiÃ§o principal com analyze, generate e prompt

### Arquivos Alterados
- `apps/api/app/api/endpoints/playbooks.py` â€” ImplementaÃ§Ã£o real do /generate e novos endpoints /analyze e /prompt
- `apps/api/app/schemas/playbook.py` â€” Docstring atualizada

### DecisÃµes Tomadas
- Gemini Flash primÃ¡rio, Claude fallback; Gemini Pro para geraÃ§Ã£o
- ConcorrÃªncia limitada a 5 anÃ¡lises paralelas via Semaphore
- Risk score com pesos severidade x classificaÃ§Ã£o
- Redlines apenas para action_on_reject = redline|suggest
- GET /prompt retorna texto para injeÃ§Ã£o no system prompt do agente /minuta

---

## 2026-02-02 â€” SessÃ£o 20: Export Functionality (Word/Excel/PDF) para Workflow Runs (P2 #13)

### Objetivo
Implementar funcionalidade de exportaÃ§Ã£o de resultados de workflow runs em formato Word (.docx), Excel (.xlsx) e PDF (.pdf) â€” item P2 #13 do plano de paridade Harvey AI.

### Arquivos Alterados
- `apps/api/app/services/workflow_export_service.py` (NOVO) â€” ServiÃ§o com mÃ©todos export_to_docx, export_to_xlsx, export_to_pdf
- `apps/api/app/api/endpoints/workflows.py` â€” Adicionado endpoint GET /runs/{run_id}/export/{format}
- `apps/api/requirements.txt` â€” Adicionado reportlab==4.1.0 para geraÃ§Ã£o de PDF
- `apps/web/src/components/workflows/run-viewer.tsx` â€” Dropdown de exportaÃ§Ã£o no header (Word/Excel/PDF)

### DecisÃµes Tomadas
- python-docx e openpyxl jÃ¡ estavam no requirements.txt; apenas reportlab precisou ser adicionado
- Endpoint posicionado antes do /runs/{run_id}/resume para evitar conflitos de rota
- Export service usa import dinÃ¢mico com try/except para mensagens de erro claras se deps faltarem
- Frontend usa window.open() para download direto (evita complexidade de blob handling)
- Dropdown aparece apenas quando runStatus === 'completed'
- Labels em portuguÃªs no backend (seÃ§Ãµes do documento)
- PDF usa ReportLab (mais leve que weasyprint, sem deps de sistema)
- Excel com 3 sheets: Resumo, Resultado, Logs â€” com headers estilizados
- Word com headings hierÃ¡rquicos e formataÃ§Ã£o de seÃ§Ãµes

---

## 2026-02-02 â€” SessÃ£o 19: Progress Indicators para Workflow Execution (P2 #12)

### Objetivo
Implementar indicadores de progresso na execuÃ§Ã£o de workflows, item P2 #12 do plano de paridade Harvey AI.

### Arquivos Alterados
- `apps/api/app/services/ai/workflow_runner.py` â€” Adicionado tracking de progresso (step_number, total_steps, elapsed_seconds) nos eventos SSE de workflow
- `apps/web/src/components/workflows/run-viewer.tsx` â€” Adicionada barra de progresso visual com "Etapa X de Y" e resumo de conclusÃ£o com tempo

### DecisÃµes Tomadas
- Contagem de steps baseada em graph_json nodes (total_steps) com incremento em on_chain_start (current_step)
- step_number e total_steps incluÃ­dos tanto nos eventos workflow_node_start quanto workflow_node_end
- elapsed_seconds calculado com time.time() e incluÃ­do no done_event metadata
- Frontend usa useMemo para derivar progresso dos runEvents (sem estado extra)
- Barra de progresso com bg-blue-500 e transition-all para animaÃ§Ã£o suave
- Resumo de conclusÃ£o mostra total de etapas e tempo formatado (Xm Ys)
- Labels em portuguÃªs: "Etapa X de Y", "ConcluÃ­do em N etapas"

---

## 2026-02-02 â€” SessÃ£o 18: Playbook Backend (Model + Migration + CRUD API)

### Objetivo
Implementar o backend completo de Playbooks para revisÃ£o de contratos, inspirado no Harvey AI Playbook. Inclui modelo de dados, schemas Pydantic, API RESTful completa e migraÃ§Ã£o Alembic.

### Arquivos Criados
- `apps/api/app/models/playbook.py` â€” Modelos SQLAlchemy: Playbook, PlaybookRule, PlaybookShare com enums, relacionamentos e to_dict
- `apps/api/app/schemas/playbook.py` â€” Schemas Pydantic: Create/Update/Response para Playbook, PlaybookRule, PlaybookShare + schemas auxiliares (Reorder, Duplicate, Generate, ListResponse)
- `apps/api/app/api/endpoints/playbooks.py` â€” Router FastAPI completo com 14 endpoints: CRUD de playbooks, gerenciamento de regras, compartilhamento, duplicaÃ§Ã£o e geraÃ§Ã£o (placeholder)
- `apps/api/alembic/versions/k1l2m3n4o5p6_add_playbook_tables.py` â€” MigraÃ§Ã£o Alembic: tabelas playbooks, playbook_rules, playbook_shares com Ã­ndices

### Arquivos Alterados
- `apps/api/app/models/__init__.py` â€” Registrado Playbook, PlaybookRule, PlaybookShare
- `apps/api/app/api/routes.py` â€” Registrado router playbooks no prefix /playbooks

### DecisÃµes Tomadas
- Segui exatamente os padrÃµes existentes de workflow.py (String PKs com uuid4, mapped_column, utcnow, to_dict)
- CRUD inline no router (sem camada crud/ separada) pois o projeto nÃ£o usa essa camada
- Schemas inline no arquivo de schemas (nÃ£o no router) seguindo padrÃ£o de library.py/marketplace.py
- PlaybookShare como tabela separada (nÃ£o reuso de Share genÃ©rica) para suportar org_id e permission=admin
- Endpoint /generate como placeholder â€” futuro job assÃ­ncrono com LLM para extraÃ§Ã£o de regras de contratos
- metadata_ com Column("metadata") para evitar conflito com SQLAlchemy metadata

### Endpoints Implementados
| MÃ©todo | Rota | DescriÃ§Ã£o |
|--------|------|-----------|
| POST | /playbooks | Criar playbook (com regras opcionais) |
| GET | /playbooks | Listar com filtros (scope, area, template, search) |
| GET | /playbooks/{id} | Obter com regras e shares |
| PUT | /playbooks/{id} | Atualizar |
| DELETE | /playbooks/{id} | Deletar (cascade rules/shares) |
| POST | /playbooks/{id}/rules | Adicionar regra |
| PUT | /playbooks/{id}/rules/{rule_id} | Atualizar regra |
| DELETE | /playbooks/{id}/rules/{rule_id} | Deletar regra |
| POST | /playbooks/{id}/rules/reorder | Reordenar regras |
| POST | /playbooks/{id}/share | Compartilhar |
| DELETE | /playbooks/{id}/share/{share_id} | Remover compartilhamento |
| POST | /playbooks/{id}/duplicate | Duplicar playbook + regras |
| POST | /playbooks/generate | Gerar de contratos (placeholder) |

---

## 2026-02-02 â€” SessÃ£o 17: Harvey AI Parity Feature #10 â€” Test Mode + P1 Migration

### Objetivo
Implementar modo de teste de workflow (endpoint + pagina) e migracao Alembic P1 com publishing, versioning, permissions e catalog.

### Arquivos Criados
- `apps/web/src/app/(dashboard)/workflows/[id]/test/page.tsx` â€” Pagina de teste de workflow com SSE streaming, exibicao de eventos e resultado
- `apps/api/alembic/versions/j0k1l2m3n4o5_harvey_parity_p1.py` â€” Migracao P1: campos de publishing, catalog, tabelas workflow_versions, workflow_permissions, workflow_role em org members

### Arquivos Alterados
- `apps/api/app/api/endpoints/workflows.py` â€” Adicionado endpoint POST /{workflow_id}/test para execucao transiente (trigger_type=test)
- `apps/web/src/components/workflows/workflow-builder.tsx` â€” Adicionado botao "Testar" com FlaskConical icon que abre pagina de teste em nova aba

### Decisoes Tomadas
- Test run cria registro no banco com trigger_type="test" para rastreabilidade, mas e marcado como transiente
- Pagina de teste usa SSE streaming identico ao run normal
- Migracao P1 consolida todos os campos que ja existiam no modelo mas faltavam na migracao

---

## 2026-02-02 â€” SessÃ£o 16: Harvey AI Parity Feature #8 â€” Permissions System (2 layers)

### Objetivo
Implementar sistema de permissÃµes de workflow em 2 camadas: roles de workspace (Layer 1) e permissÃµes per-workflow (Layer 2).

### Arquivos Criados
- `apps/api/app/models/workflow_permission.py` â€” Modelo WorkflowPermission + enums (WorkflowBuilderRole, BuildAccess, RunAccess)
- `apps/api/app/services/workflow_permission_service.py` â€” ServiÃ§o centralizado de checagem de permissÃµes (can_build, can_run, can_approve, can_publish, grant/revoke)
- `apps/web/src/components/workflows/permissions-dialog.tsx` â€” Dialog React com tabs (Atuais/Adicionar) para gerenciar permissÃµes

### Arquivos Alterados
- `apps/api/app/models/organization.py` â€” Adicionado campo `workflow_role` em OrganizationMember (Layer 1)
- `apps/api/app/api/endpoints/workflows.py` â€” 3 endpoints: GET/POST /{id}/permissions, DELETE /{id}/permissions/{user_id}
- `apps/api/app/core/database.py` â€” Import de WorkflowPermission em init_db()
- `apps/web/src/components/workflows/index.ts` â€” Export de PermissionsDialog

### DecisÃµes Tomadas
- Layer 1 usa campo `workflow_role` em OrganizationMember (string nullable) em vez de enum SQLAlchemy, para flexibilidade
- Layer 2 usa tabela dedicada `workflow_permissions` com unique constraint (workflow_id, user_id)
- Owner do workflow sempre tem acesso total (bypass de permissÃµes)
- Admin de workflow nÃ£o pode aprovar prÃ³prio workflow (seguranÃ§a)

---

## 2026-02-02 â€” SessÃ£o 15: ImplementaÃ§Ã£o dos 5 Gaps em Paralelo

### Objetivo
Implementar os 5 gaps identificados na verificaÃ§Ã£o da plataforma, lanÃ§ando 5 agentes em paralelo.

### Gap 1 â€” Alembic Migration
- `alembic/env.py` â€” imports de Workflow, WorkflowRun, MarketplaceItem, MarketplaceReview
- `app/core/database.py` â€” imports em init_db()
- `app/models/workflow.py` â€” campos schedule_cron, schedule_enabled, schedule_timezone, last_scheduled_run, webhook_secret, trigger_type
- `alembic/versions/h8i9j0k1l2m3_add_workflows_tables.py` â€” migration completa

### Gap 2 â€” Scheduler/Triggers (Celery Beat)
- `app/workers/tasks/workflow_tasks.py` â€” 3 tasks: run_scheduled_workflow, run_webhook_workflow, sync_workflow_schedules
- `app/workers/celery_app.py` â€” beat_schedule workflow-schedule-sync (cada 5min)
- `app/api/endpoints/workflows.py` â€” GET/PUT /{id}/schedule, POST /{id}/trigger (webhook)
- `requirements.txt` â€” croniter>=2.0.0

### Gap 3 â€” User MCP Server UI
- `app/services/mcp_config.py` â€” load_user_mcp_servers()
- `app/services/mcp_hub.py` â€” with_user_servers() merge
- `app/api/endpoints/mcp.py` â€” CRUD /user-servers + /test
- `apps/web/src/components/settings/mcp-servers-config.tsx` â€” componente React
- `apps/web/src/app/(dashboard)/settings/page.tsx` â€” integraÃ§Ã£o
- `apps/web/src/lib/api-client.ts` â€” 4 mÃ©todos MCP + request() genÃ©rico

### Gap 4 â€” Sandboxing & Hardening
- `app/services/ai/sandbox/` â€” ExecutionLimits, ExecutionBudget, NetworkPolicy, validate_url
- `app/services/ai/workflow_compiler.py` â€” validaÃ§Ã£o de grafo (ciclos, max nodes)
- `app/services/ai/workflow_runner.py` â€” timeout enforcement via budget
- `app/services/ai/tool_gateway/policy_engine.py` â€” cost tracking

### Gap 5 â€” Public Marketplace
- `app/models/marketplace.py` â€” MarketplaceItem, MarketplaceReview, MarketplaceCategory
- `app/schemas/marketplace.py` â€” schemas Pydantic
- `app/api/endpoints/marketplace.py` â€” 8 endpoints (browse, publish, install, review)
- `alembic/versions/i9j0k1l2m3n4_add_marketplace_tables.py` â€” migration
- `apps/web/src/app/(dashboard)/marketplace/page.tsx` â€” pÃ¡gina completa
- `apps/web/src/components/layout/sidebar-pro.tsx` â€” link Marketplace
- `app/api/routes.py` â€” router marketplace registrado
- `app/models/__init__.py` â€” exports marketplace

### DecisÃµes
- Celery Beat escolhido para scheduler (jÃ¡ existia infra Redis)
- MCP user servers prefixados com "user_" para evitar colisÃ£o
- Sandboxing warn-only no compiler para nÃ£o quebrar workflows existentes
- Marketplace usa clone/install (copia recurso) em vez de referÃªncia
- SSRF protection com allowlist de domÃ­nios jurÃ­dicos

### Guia de Planejamento
- `docs/PLAN_GAPS.md` â€” planejamento completo dos 5 gaps

### Fixes PÃ³s-ImplementaÃ§Ã£o
1. **marketplace.py import errado** â€” `from app.api.deps` â†’ `from app.core.security` (crashava API inteira)
2. **Route conflict /workflows** â€” Marketing page movida para `/solucoes/workflows`, links atualizados em vorbium-nav.tsx e footer.tsx
3. **Workflow creation "table has no column schedule_cron"** â€” ALTER TABLE adicionou 5 colunas em workflows + 1 em workflow_runs (migration nÃ£o executada contra SQLite dev)
4. **Model selector no workflow builder** â€” SubstituÃ­do hardcoded 4 modelos â†’ import dinÃ¢mico de MODEL_REGISTRY (26 modelos, 7 providers) com `<optgroup>` por provider

### AnÃ¡lise Harvey AI vs Iudex
- ComparaÃ§Ã£o em 10 dimensÃµes: hierarquia, workflow engine, thinking states, citation engine, agentic search, multi-agent, workflow builder, HIL, eval, seguranÃ§a
- **Implementado (85%+)**: Block types, HIL+checkpoints, Multi-agent orchestration, Agentic search
- **Parcial (50-70%)**: 4-level hierarchy, Thinking states, Citation engine, LLM-as-Judge, Workflow Builder (sÃ³ drag-drop)
- **Faltando (0%)**: Component-level evals
- **Gaps prioritÃ¡rios P0**: NLâ†’Graph parser, Component-level evals, Model/AgentSystem hierarchy

---

## 2026-02-02 â€” SessÃ£o 14: Gap 4 â€” Sandboxing & Hardening

### Objetivo
Implementar limites de execucao, budget tracking, protecao de rede (SSRF) e validacao de grafos de workflow para hardening de producao.

### Arquivos Criados
- `apps/api/app/services/ai/sandbox/__init__.py` â€” Modulo sandbox com exports
- `apps/api/app/services/ai/sandbox/execution_limits.py` â€” ExecutionLimits, ExecutionBudget, BudgetExceededError, validacao de grafo, enforce_workflow_limits
- `apps/api/app/services/ai/sandbox/network_policy.py` â€” NetworkPolicy com allowlist de dominios juridicos, protecao SSRF contra IPs privados, validate_url

### Arquivos Alterados
- `apps/api/app/services/ai/workflow_compiler.py` â€” Adicionada validacao de limites de execucao (warn-only) no metodo compile()
- `apps/api/app/services/ai/workflow_runner.py` â€” Adicionado ExecutionBudget com timeout enforcement no run_streaming()
- `apps/api/app/services/ai/tool_gateway/policy_engine.py` â€” Adicionado cost tracking (record_cost/get_cost) ao PolicyEngine

### Decisoes Tomadas
- Validacao de limites no compiler e warn-only (nao bloqueia) para nao quebrar workflows existentes
- Timeout no runner checa a cada evento do stream
- NetworkPolicy com allowlist especifica para dominios juridicos brasileiros (tribunais, governo, bases juridicas)
- Protecao SSRF bloqueia ranges privados IPv4 e IPv6

---

## 2026-02-01 â€” SessÃ£o 13: Native Tool Calling para Agent Models no Chat

### Objetivo
Habilitar tool calling (web_search, search_jurisprudencia, search_legislacao) para modelos de agente (openai-agent, google-agent, claude-agent) no chat stream.

### Arquivos Criados
- `apps/api/app/services/ai/chat_tools.py` â€” MÃ³dulo de native tool calling com definiÃ§Ãµes de tools, handlers, e tool loops para OpenAI/Claude/Gemini

### Arquivos Alterados
- `apps/api/app/api/endpoints/chats.py` â€” IntegraÃ§Ã£o do native tool calling no chat stream. Flag `use_native_tools` detecta modelos agente. Blocos GPT/Claude/Gemini agora executam tool loop antes do streaming normal.

### Bugs Corrigidos
1. **AsyncOpenAI client**: `gpt_stream_client` Ã© sÃ­ncrono (`openai.OpenAI`), nÃ£o async. `await client.chat.completions.create()` falhava com `'ChatCompletion' object can't be awaited`. Fix: usar `get_async_openai_client()`.
2. **API sem hot-reload**: uvicorn rodava sem `--reload`, mudanÃ§as nÃ£o eram detectadas. Reiniciado com `--reload`.
3. **JWT_SECRET_KEY vs SECRET_KEY**: Token gerado com `SECRET_KEY` era rejeitado. API usa `JWT_SECRET_KEY` para auth.

### Teste de Agent Models com Tools
| Modelo | Status | Tools |
|--------|--------|-------|
| openai-agent (gpt-4o) | âœ… | web_search funcionando (retornou Selic 15% com fontes) |
| google-agent (gemini-3-flash-preview) | âœ… | Tool loop executa, modelo decide se precisa |
| claude-agent | âš ï¸ | CrÃ©ditos Anthropic esgotados |

### Arquitetura
- Tools disponÃ­veis: `web_search` (â†’ WebSearchService/Perplexity), `search_jurisprudencia` (â†’ JurisprudenceService), `search_legislacao` (â†’ LegislationService)
- Native tool calling tem prioridade sobre MCP. Se `use_native_tools=True`, executa primeiro. Se nÃ£o usar tools, cai para streaming normal.
- Deep research intercepta antes do streaming normal para queries complexas (jurisprudÃªncia, etc.)

### DecisÃµes
- Usar native function calling (OpenAI tools API / Claude tool_use / Gemini function calling) em vez de MCP para evitar dependÃªncia de servidores externos
- Subset de 3 tools (web_search, jurisprudencia, legislacao) para chat â€” nÃ£o incluir tools que requerem case_id
- Tool loop nÃ£o-streaming (max 4 rounds) + streaming da resposta final

---

## 2026-02-01 â€” SessÃ£o 12: Performance Chat + Gemini ThinkingLevel Fix

### Objetivo
Corrigir latÃªncia excessiva do chat (18s para "oi") e erro 400 do Gemini Thinking.

### Arquivos Alterados
- `apps/api/app/api/endpoints/chats.py` â€” Fast-path para mensagens triviais (skip RAG), thinking budget reduzido, thinking_mode mapeamento corrigido
- `apps/api/app/services/ai/agent_clients.py` â€” System prompt atualizado, ThinkingConfig construtor (nÃ£o setattr), thinking_level UPPERCASE, LOW/MINIMAL sem thinking_level

### Bugs Corrigidos
1. **ThinkingLevel lowercase**: SDK Gemini espera UPPERCASE (LOW, MEDIUM, HIGH), cÃ³digo passava lowercase â†’ `PydanticSerializationUnexpectedValue`
2. **setattr bypass Pydantic**: `setattr(thinking_config, "thinking_level", "LOW")` nÃ£o converte stringâ†’enum. Corrigido usando construtor: `ThinkingConfig(include_thoughts=True, thinking_level="LOW")`
3. **Vertex rejeita thinking_level**: `gemini-2.5-flash` via Vertex AI nÃ£o suporta `thinking_level` param. Fix: LOW/MINIMAL usam apenas `include_thoughts=True` sem `thinking_level`
4. **RAG pipeline para triviais**: `build_rag_context()` rodava para TODA mensagem (~4.6s). Adicionado fast-path: skip para mensagens â‰¤4 palavras + padrÃ£o de saudaÃ§Ã£o
5. **System prompt errado**: `router.py` nÃ£o Ã© usado pelo chat streaming. O prompt real estÃ¡ em `agent_clients.py:DEFAULT_LEGAL_SYSTEM_INSTRUCTION`

### Resultados de Performance
| Modelo | Antes | Depois | Melhoria |
|--------|-------|--------|----------|
| Gemini 3 Flash "oi" | 18s+ (erro/offline) | 5.4s (latÃªncia do preview) | Funcional |
| Gemini 2.5 Flash "oi" | 18s+ | 3.3s | ~82% |
| GPT-5/4o "oi" | ~8s | 0.5-1.3s | ~86% |
| Preprocessing (RAG) | 4.6s | 7ms | ~99.8% |

### Teste de Todos os Modelos
| Modelo | Status | Nota |
|--------|--------|------|
| gemini-3-flash | âœ… | 5.4s TTFT (latÃªncia inerente do modelo preview) |
| gemini-3-pro | âœ… | 7.1s TTFT |
| gpt-5 (â†’gpt-4o) | âœ… | 0.5s TTFT |
| gpt-4o | âœ… | 1.3s TTFT |
| claude-4.5-sonnet | âš ï¸ | CrÃ©ditos Anthropic esgotados |
| claude-4.5-haiku | âš ï¸ | CrÃ©ditos Anthropic esgotados |

### DecisÃµes
- Para Gemini LOW/MINIMAL thinking: usar `include_thoughts=True` sem `thinking_level` (compatibilidade Vertex)
- Fast-path trivial: â‰¤4 palavras + match set de saudaÃ§Ãµes/despedidas comuns
- Mensagens triviais + reasoning_level low: desabilita thinking no Gemini completamente
- Claude offline por billing (aÃ§Ã£o do usuÃ¡rio: recarregar crÃ©ditos Anthropic)

---

## 2026-02-01 â€” SessÃ£o 11: Melhorias UI/UX Chat (Harvey AI + Perplexity)

### Objetivo
Melhorar a experiÃªncia visual e qualidade do chat, inspirado em Harvey AI e Perplexity.

### Arquivos Alterados
- `apps/api/app/services/ai/orchestration/router.py` â€” Regra de interaÃ§Ã£o no system prompt (respostas naturais a saudaÃ§Ãµes)
- `apps/web/src/components/chat/chat-interface.tsx` â€” Welcome screen estilo Perplexity + follow-up input
- `apps/web/src/components/chat/activity-panel.tsx` â€” Header dinÃ¢mico "Trabalhando...", steps colapsÃ¡veis, barra de progresso
- `apps/web/src/components/chat/chat-message.tsx` â€” Code block copy delegado + ResponseSourcesTabs (Perplexity style)
- `apps/web/src/lib/markdown-parser.ts` â€” Code blocks com header de linguagem + botÃ£o copiar
- `apps/web/src/styles/globals.css` â€” CSS dark code blocks estilo Perplexity

### DecisÃµes
- Welcome screen: grid 2x2 de sugestÃµes jurÃ­dicas clicÃ¡veis que enviam mensagem direto
- ActivityPanel: "Trabalhando..." quando hÃ¡ steps reais, "Pensando" quando sÃ³ thinking
- Code blocks: dark theme (slate-900) com header de linguagem e copy via event delegation
- Follow-up: mini input apÃ³s Ãºltima resposta assistant, submit via handleSendMessage
- Response tabs: tab "Fontes" com favicon, quote e external link (aparece quando ActivityPanel fechado)

---

## 2026-02-01 â€” SessÃ£o 10: DiagnÃ³stico Chat Gemini

### Problema
Chat possivelmente retornando "modo offline" ao selecionar Gemini.

### InvestigaÃ§Ã£o
Testamos todas as rotas de acesso ao Gemini:
- **Vertex AI + service account** (`GOOGLE_APPLICATION_CREDENTIALS`): âœ… Funciona perfeitamente com streaming e thinking
- **Direct API (`GOOGLE_API_KEY`)**: âŒ Quota zero (billing desabilitado)
- **`GEMINI_API_KEY` (antiga)**: âŒ Formato invÃ¡lido (token OAuth, nÃ£o API key)

O fluxo real da API usa `python-dotenv` para carregar `.env` incluindo `GOOGLE_APPLICATION_CREDENTIALS`, e a service account `vertex-express@gen-lang-client-0727883752` tem as permissÃµes corretas para Vertex AI.

### Descobertas
1. O streaming Gemini via `stream_vertex_gemini_async()` funciona com a service account
2. O fallback para API direta (quando Vertex dÃ¡ 404) falha porque a API key nÃ£o tem quota
3. Bug de indentaÃ§Ã£o no endpoint `send_message` (nÃ£o-streaming): `ai_content = None` fora do `except`

### Arquivos Alterados
- `apps/api/app/api/endpoints/chats.py` â€” Fix indentaÃ§Ã£o do bloco except/failsafe
- `apps/api/.env` â€” GEMINI_API_KEY atualizada para key vÃ¡lida do projeto `gen-lang-client-0781186103`
- `apps/web/.env.local` â€” Fix API_PROXY_TARGET de porta 8001 para 8000

### Fix Login Visitante
O login de visitante falhava porque o proxy Next.js (`API_PROXY_TARGET`) apontava para `http://127.0.0.1:8001` mas o backend roda na porta `8000`.

### VerificaÃ§Ã£o Geral de Modelos
Testados todos os modelos:
- **gemini-3-flash / gemini-3-pro**: âœ… Funcionam via Vertex AI + service account
- **gpt-5.2**: âœ… Fix aplicado â€” `OPENAI_FORCE_DIRECT=true` (estava roteando via Vertex AI)
- **claude-4.5-sonnet**: âŒ CrÃ©ditos Anthropic insuficientes (billing)
- **sonar-pro**: âŒ `PERPLEXITY_API_KEY` nÃ£o configurada no .env

### Fix GPT roteamento errado
`init_openai_client()` priorizava Vertex AI quando `GOOGLE_CLOUD_PROJECT` existia, tentando `gpt-4o` no Model Garden do Google (inexistente). Fix: `OPENAI_FORCE_DIRECT=true`.

### Fix Neo4j bloqueante
Driver Neo4j bloqueava o servidor com retries infinitos quando Neo4j nÃ£o rodava. Adicionado port check TCP (1s), health check com timeout (5s), e `max_transaction_retry_time=2`.

### Auditoria SSE Streaming
Issues encontrados e **corrigidos**:
- âœ… Missing "done" event no error path â€” agora `stream_with_session()` envia `done` apÃ³s `error`
- âœ… STREAM_SESSIONS memory leak â€” cleanup agora remove sessÃµes stuck (>15min) + limite absoluto de 200
- âœ… Schema de erro inconsistente â€” evento `error` agora inclui `turn_id` e `request_id`

### Deep Research
Todos os 3 providers implementados:
- **Gemini**: `interactions.create()` com agent deep-research-pro
- **Perplexity**: `sonar-deep-research` com citations nativas
- **OpenAI**: `o4-mini-deep-research` via Responses API
- **Hard mode**: Claude orquestra multi-provider

### Arquivos Alterados Adicionais
- `apps/api/.env` â€” `OPENAI_FORCE_DIRECT=true`
- `apps/api/app/services/rag/core/neo4j_mvp.py` â€” Fix timeout bloqueante

---

## 2026-02-01 â€” SessÃ£o 9: Fix AnimaÃ§Ãµes Safari â€” Todas as PÃ¡ginas

### Problema
AnimaÃ§Ãµes de fundo (CSS Paint Worklets / Houdini API) nÃ£o funcionavam no Safari â€” apenas Chrome/Edge. Afetava:
- Landing page (verbium-particles)
- Todas as marketing pages (nebula-flow via PageHero)
- Login e Register (grid-pulse)

### Causa Raiz
CSS Paint Worklets (`paint()`) nÃ£o sÃ£o suportados no Safari/Firefox. O `backgroundImage: 'paint(worklet-name)'` era descartado silenciosamente, deixando o fundo sem animaÃ§Ã£o. As `@property` + `@keyframes` que alimentam os worklets tambÃ©m nÃ£o funcionam nesses browsers.

### SoluÃ§Ã£o â€” Canvas 2D Fallback para Todos os 4 Worklets
- **RefatoraÃ§Ã£o completa de `use-vorbium-paint.ts`** (~800 linhas):
  - Framework `createCanvasFallback()` compartilhado: canvas setup, DPR, pointer/touch tracking, MutationObserver para tema, animation loop
  - 4 renderers Canvas 2D portados pixel-a-pixel dos worklets JS:
    - `verbium-particles` â€” ring particles, constellation, cursor orbit, ambient/cursor glow
    - `nebula-flow` â€” layered noise grid, cursor attraction, color gradients, central glow
    - `grid-pulse` â€” dot grid, pulse ring, ambient wave, connection lines, cursor glow
    - `wave-field` â€” 7 sine wave layers, cursor distortion, interference dots
  - Sprite caching (offscreen canvas, drawImage 3-5x mais rÃ¡pido que arc+fill)
  - `desynchronized: true` para async rendering no Safari
  - Hook aceita `options: { seed, color }` para customizaÃ§Ã£o por pÃ¡gina

- **Fix `PaintBackground`** â€” CSS `paint()` agora condicional:
  - Chrome: aplica `backgroundImage: paint(worklet)` + animations
  - Safari: aplica apenas `--theme-color`, canvas fallback cuida do resto
  - Passa `seed` e `color` para o hook

- **Z-index explÃ­cito** em todas as camadas de overlay:
  - Canvas fallback: z-0
  - Overlays (dotted grid, noise, gradient mesh): z-[1]
  - Gradient fade: z-[2]
  - ConteÃºdo: z-10

### Arquivos Alterados
- `src/hooks/use-vorbium-paint.ts` â€” Reescrito: framework + 4 renderers Canvas 2D (~800 linhas)
- `src/components/ui/paint-background.tsx` â€” CSS condicional, passa seed/color ao hook
- `src/components/vorbium/hero-section.tsx` â€” z-[1] overlays, z-[2] gradient fade
- `src/components/vorbium/page-hero.tsx` â€” z-[1] no overlay container
- `src/app/(auth)/login/page.tsx` â€” z-[1] no gradient mesh overlay
- `src/app/(auth)/register/page.tsx` â€” z-[1] no gradient mesh overlay

### CorreÃ§Ãµes de Fidelidade Visual (continuaÃ§Ã£o)
- **Orbit ring sempre desenhado**: No worklet, as partÃ­culas do orbit sÃ£o desenhadas sempre (intensity afeta alpha, nÃ£o visibilidade). No canvas, estavam dentro de `if (orbitIntensity > 0.1)`. Corrigido: glow fica condicional, partÃ­culas sempre desenham.
- **PRNG sequence**: `w1Dir` usa `hash(seed+10)` (nÃ£o PRNG), ranges de `randomInt` corrigidos para corresponder ao worklet
- **Timing**: Todos os 4 renderers usam `((elapsed % 6) / 6) * Math.PI * 2` (ciclo de 6s), matching `animTick * 2Ï€`
- **ringBreathe**: AnimaÃ§Ã£o 120â†’200 ease-in-out alternate (12s ciclo completo)
- **Cursor smoothing**: Lerp com `LERP_SPEED = 8` matching Chrome CSS `transition: 0.3s cubic-bezier(...)`
- **Position check**: SÃ³ define `position: relative` se `static`, evitando sobrescrever `absolute` do Tailwind

### VerificaÃ§Ã£o
- `npx tsc --noEmit` â€” zero erros

---

## 2026-02-01 â€” SessÃ£o 8: Gemini Fix + LangGraph Quick Chat + Canvas + Frontend Improvements

### Objetivo
Corrigir Gemini no chat, adicionar quick_chat ao LangGraph para respostas rÃ¡pidas (2-5s), melhorar detecÃ§Ã£o de canvas e otimizar streaming.

### Arquivos Alterados â€” Backend (apps/api)

- `app/services/ai/agent_clients.py` â€” Corrigido retorno silencioso do Gemini:
  - `stream_vertex_gemini_async()`: agora faz yield `("error", msg)` em vez de `return` silencioso
  - `init_vertex_client()`: logs descritivos para Vertex AI vs Direct API

- `app/services/ai/chat_service.py` â€” 3 mudanÃ§as:
  - Tratamento de error tuples do Gemini streaming
  - FunÃ§Ã£o `_detect_canvas_suggestion()`: heurÃ­stica baseada em marcadores estruturais (headings, artigos, clÃ¡usulas, numeraÃ§Ã£o)
  - Todos os 5 pontos de `done` event agora incluem `canvas_suggestion: true/false`

- `app/services/ai/model_registry.py` â€” Atualizado:
  - `gemini-2.5-pro/flash`: adicionado `thinking_category="native"`, `max_output_tokens=8192`
  - `google-agent`: api_model default alterado para `gemini-3-flash-preview`
  - `DEFAULT_CHAT_MODEL` e `DEFAULT_JUDGE_MODEL` = `gemini-3-flash`

- `app/services/ai/executors/google_agent.py` â€” Default model alterado para `gemini-3-flash`
  - `MODEL_CONTEXT_WINDOWS` expandido com entries do Gemini 3.x

- `app/services/ai/langgraph_legal_workflow.py` â€” Adicionado quick_chat bypass:
  - `_is_quick_chat(state)`: detecta mensagens curtas sem keywords de documento
  - `quick_chat_node(state)`: RAG mÃ­nimo (top-3) + LLM direta, target 2-5s
  - `entry_router(state)`: roteia `__start__` â†’ quick_chat | gen_outline
  - Docstring do fluxo atualizada

### Arquivos Alterados â€” Frontend (apps/web)

- `src/components/chat/chat-interface.tsx` â€” Regex `isDocumentRequest()` expandida com 16 novos tipos jurÃ­dicos: embargos, memorial, defesa, impugnaÃ§Ã£o, rÃ©plica, contrarrazÃµes, despacho, sentenÃ§a, acÃ³rdÃ£o, voto, ementa, notÃ­cia, procuraÃ§Ã£o, denÃºncia, queixa, libelo, arguiÃ§Ã£o

- `src/stores/chat-store.ts` â€” 2 mudanÃ§as:
  - Throttle adaptativo do canvas: 40ms (<8k), 100ms (8-20k), 200ms (>20k chars)
  - Handler de `done` event: auto-abre canvas quando `canvas_suggestion: true`

### DecisÃµes
- Apenas Gemini 3 Pro e Flash â€” todos os defaults apontam para esses modelos
- Quick chat usa heurÃ­stica simples: <600 chars + sem keywords de documento â†’ bypass do pipeline de 26 nÃ³s
- Canvas suggestion Ã© heurÃ­stica conservadora: â‰¥3 marcadores estruturais + â‰¥600 chars

### VerificaÃ§Ã£o
- `npx tsc --noEmit` â€” zero erros
- Todos os 3 agentes de implementaÃ§Ã£o completaram sem erros

---

## 2026-02-01 â€” SessÃ£o 7: Streaming UI Harvey.ai Style

### Objetivo
Redesign do painel de atividade/raciocÃ­nio (activity-panel) para estilo Harvey.ai â€” timeline vertical com Ã­cones contextuais, detalhes visÃ­veis por padrÃ£o, chips de busca e fontes com favicons.

### Arquivos Alterados
- `src/components/chat/activity-panel.tsx` â€” Reescrito completo:
  - **Antes**: Card com border, header "Activity", bullet points colapsados, seÃ§Ãµes separadas (Thinking/Steps/Sources)
  - **Depois**: Timeline vertical Harvey.ai style com linha conectora entre steps
  - Header "Trabalhando..." / "Pesquisa concluÃ­da" colapsÃ¡vel (sem card/border)
  - Ãcones circulares por tipo (Search, Globe, Brain, FileText, BookOpen, Scale, Gavel, Eye, etc.)
  - Status visual: azul=running, verde=done, vermelho=error, cinza=pending
  - Detalhes visÃ­veis por padrÃ£o (nÃ£o colapsados)
  - Tags categorizadas automaticamente: domÃ­nios (com favicon) vs termos de busca (chip azul)
  - Fontes consultadas em footer com chips favicon+domÃ­nio+tÃ­tulo+link
  - Auto-scroll durante streaming

### Componentes Novos (internos)
- `TimelineStep` â€” Step da timeline com Ã­cone circular, tÃ­tulo, detalhe, chips
- `ThinkingTimelineStep` â€” Step de raciocÃ­nio com Ã­cone Brain
- `SourceChip` â€” Chip de fonte com favicon + domÃ­nio + link externo
- `SearchTermChip` â€” Chip de termo de busca com Ã­cone Search (azul)
- `SourcesFooter` â€” Grid de fontes consultadas com "ver mais"

### DecisÃµes
- Removido wrapper card/border â€” painel agora Ã© inline no fluxo da mensagem
- Ãcone mapping expandido para contexto jurÃ­dico (Scale=legislaÃ§Ã£o, Gavel=jurisprudÃªncia)
- Tags com "." e sem espaÃ§o = domÃ­nios (mostram favicon), demais = termos de busca

### VerificaÃ§Ã£o
- `npx tsc --noEmit` â€” zero erros

---

## 2026-01-31 â€” SessÃ£o 6: Redesign PÃ¡gina Minuta (Perplexity/ChatGPT-style)

### Objetivo
Redesign da pÃ¡gina de minutas para UI minimalista inspirada em Perplexity e ChatGPT, preservando todas as funcionalidades.

### Arquivos Criados
- `src/components/dashboard/minuta-settings-drawer.tsx` â€” Sheet lateral com todas as ~30 configuraÃ§Ãµes organizadas em 8 seÃ§Ãµes Accordion (Modo, Documento, Qualidade, Pesquisa, Modelos, Controle HIL, AvanÃ§ado, Checklist)

### Arquivos Alterados
- `src/app/(dashboard)/minuta/page.tsx` â€” Reduzido de **2588 para 873 linhas**:
  - Toolbar: de ~15 botÃµes para 5 (RÃ¡pido/ComitÃª + Settings + Layout + Novo Chat + Gerar)
  - Settings panel inline (~1400 linhas) substituÃ­do pelo MinutaSettingsDrawer
  - Empty state: centrado estilo Perplexity com tÃ­tulo "Iudex" + ChatInput + chips de aÃ§Ã£o rÃ¡pida
  - Status bar: removida barra fixa, substituÃ­da por progress horizontal inline (sÃ³ quando agentes rodam)
  - Fontes RAG: compacto, sÃ³ aparece quando hÃ¡ itens
- `src/components/dashboard/index.ts` â€” Adicionado export do MinutaSettingsDrawer
- `components.json` â€” Removido caractere invÃ¡lido no final

### Componentes Instalados
- `src/components/ui/sheet.tsx` â€” jÃ¡ existia
- `src/components/ui/accordion.tsx` â€” atualizado via shadcn CLI

### DecisÃµes
- Todas as configuraÃ§Ãµes movidas para drawer lateral em vez de painel inline que empurrava o conteÃºdo
- Empty state com chips de tipo de documento para onboarding rÃ¡pido
- Toolbar mostra apenas controles essenciais â€” o resto vai no drawer
- Canvas permanece inalterado â€” split panel resizable preservado

### VerificaÃ§Ã£o
- `npx tsc --noEmit` â€” zero erros
- `pnpm dev` â€” compilaÃ§Ã£o OK (5494 modules)

---

## 2026-01-31 â€” SessÃ£o 5: CSS Houdini Paint Worklets â€” Efeitos AvanÃ§ados

### Objetivo
Aprimorar o worklet verbium-particles (mais impressionante como Antigravity) e criar worklets variados para todas as pÃ¡ginas.

### Arquivos Criados
- `public/worklets/nebula-flow.js` â€” Nebulosa fluida com noise 2D multicamada, cursor attraction, cor gradiente (para marketing pages)
- `public/worklets/grid-pulse.js` â€” Grid de pontos com pulso radial do cursor, onda ambiente, linhas de conexÃ£o (para auth/security)
- `public/worklets/wave-field.js` â€” Campo de ondas senoidais com interferÃªncia, distorÃ§Ã£o do cursor, dots nas interseÃ§Ãµes (para customers/workflows)
- `src/components/ui/paint-background.tsx` â€” Componente reutilizÃ¡vel para renderizar qualquer worklet como background

### Arquivos Alterados
- `public/worklets/verbium-particles.js` â€” Enhanced v2: glow ambiente, cursor glow, color pulse (oscilaÃ§Ã£o de cor), constellation connections entre partÃ­culas prÃ³ximas, orbit glow
- `src/hooks/use-vorbium-paint.ts` â€” Refatorado para suportar mÃºltiplos worklets (type WorkletName), carregamento lazy por worklet
- `src/components/vorbium/page-hero.tsx` â€” Props worklet/workletColor/workletSeed + PaintBackground integrado
- `src/app/platform/page.tsx` â€” worklet=nebula-flow (indigo, seed 63)
- `src/app/security/page.tsx` â€” worklet=grid-pulse (emerald #10b981, seed 91)
- `src/app/customers/page.tsx` â€” worklet=wave-field (indigo, seed 88)
- `src/app/assistant/page.tsx` â€” worklet=nebula-flow (purple #8b5cf6, seed 47)
- `src/app/research/page.tsx` â€” worklet=grid-pulse (blue #3b82f6, seed 71)
- `src/app/workflows/page.tsx` â€” worklet=wave-field (amber #f59e0b, seed 29)
- `src/app/collaboration/page.tsx` â€” worklet=nebula-flow (cyan #06b6d4, seed 83)
- `src/app/(auth)/login/page.tsx` â€” PaintBackground grid-pulse (indigo, seed 42)
- `src/app/(auth)/register/page.tsx` â€” PaintBackground grid-pulse (purple #8b5cf6, seed 67)

### Mapeamento de Worklets por PÃ¡gina
| PÃ¡gina | Worklet | Cor | Efeito |
|--------|---------|-----|--------|
| Landing Hero | verbium-particles | indigo | Ring + constellation + glow |
| Platform | nebula-flow | indigo | Nebulosa fluida |
| Assistant | nebula-flow | purple | Nebulosa fluida |
| Collaboration | nebula-flow | cyan | Nebulosa fluida |
| Security | grid-pulse | emerald | Grid + pulso radial |
| Research | grid-pulse | blue | Grid + pulso radial |
| Login | grid-pulse | indigo | Grid + pulso radial |
| Register | grid-pulse | purple | Grid + pulso radial |
| Customers | wave-field | indigo | Ondas + interferÃªncia |
| Workflows | wave-field | amber | Ondas + interferÃªncia |

### Comandos Executados
- `npx tsc --noEmit` â€” OK (sem erros)

---

## 2026-01-31 â€” SessÃ£o 4: CorreÃ§Ãµes de Acentos, Tema e Cotejo CrÃ­tico

### Objetivo
CorreÃ§Ãµes identificadas no cotejo crÃ­tico: acentos faltantes em pÃ¡ginas de marketing, inconsistÃªncia de tema entre login/register.

### Arquivos Alterados
- `src/app/customers/page.tsx` â€” Corrigidos 13 acentos faltantes (mensurÃ¡vel, operaÃ§Ã£o, ReduÃ§Ã£o, jurÃ­dica, etc.)
- `src/app/security/page.tsx` â€” Corrigidos 10 acentos (CertificaÃ§Ãµes, ProteÃ§Ã£o, seguranÃ§a, trÃ¢nsito, etc.)
- `src/app/platform/page.tsx` â€” Corrigidos 3 acentos (ReduÃ§Ã£o, disponÃ­veis, prÃ¡tica jurÃ­dica)
- `src/app/(auth)/register/page.tsx` â€” Unificado tema com login: bg-gradient responsivo em vez de dark hardcoded, Card com bg-white/80 + dark:bg-white/5, labels e inputs com cores theme-aware, selects com tokens CSS do shadcn

### Comandos Executados
- `npx tsc --noEmit` â€” OK (sem erros)

### DecisÃµes
- Register unificado com login: ambos usam `from-primary/10 via-background to-secondary/10`
- SubstituÃ­das cores hardcoded (text-white, text-gray-300, bg-[#0F1115]) por tokens do tema (text-foreground, text-muted-foreground, bg-background)

---

## 2026-01-31 â€” SessÃ£o 3: Harvey/Poe/Antigravity Enhancements

### Objetivo
Melhorias inspiradas em Harvey.ai (mega-menu, security badges), Poe.com (multi-provider) e Antigravity (video demos, screenshots mockups).

### Arquivos Modificados
- `src/components/vorbium/vorbium-nav.tsx` â€” Reescrito com mega-menu Harvey-style (dropdowns Plataforma/Empresa com descriÃ§Ãµes, AnimatePresence, hover com delay, mobile accordion)
- `src/app/page.tsx` â€” SeÃ§Ã£o video demo placeholder + seÃ§Ã£o Multi-Provider AI
- `src/app/assistant/page.tsx` â€” Mockup de interface de chat com browser chrome + fix contraste Limites
- `src/app/research/page.tsx` â€” Mockup de resultados de pesquisa com browser chrome
- `src/app/workflows/page.tsx` â€” Browser chrome wrapper no mockup JSON
- `src/app/platform/page.tsx` â€” SeÃ§Ã£o mÃ©tricas de impacto (70%, 4+, 100%, 24/7)
- `src/app/customers/page.tsx` â€” Cards de impacto visuais, seÃ§Ã£o testimonials, setores melhorados
- `src/app/security/page.tsx` â€” Badge cards (SOC2, ISO 27001, LGPD, GDPR), seÃ§Ã£o proteÃ§Ã£o em camadas
- `src/components/vorbium/footer.tsx` â€” Fix contraste dark mode (gray-700â†’gray-500)

### VerificaÃ§Ã£o
- `npx tsc --noEmit` â€” OK

---

## 2026-01-31 â€” Auditoria de contraste light/dark mode nas marketing pages

### Objetivo
Auditar e corrigir problemas de contraste em todas as 6 marketing pages (research, workflows, collaboration, customers, security, platform) e nos componentes compartilhados (vorbium-nav, footer, page-hero, feature-section).

### Resultado da Auditoria
As 6 pÃ¡ginas de marketing jÃ¡ estavam com classes dual-mode corretas (`text-slate-900 dark:text-white`, `text-slate-600 dark:text-gray-400`, etc.), provavelmente corrigidas durante a criaÃ§Ã£o.

### Problemas encontrados e corrigidos (componentes compartilhados)

#### `src/components/vorbium/vorbium-nav.tsx`
- Links "Resources" e "About" usavam `text-gray-400` sozinho (muito claro em fundo branco)
- Corrigido para `text-gray-500 dark:text-gray-400`

#### `src/components/vorbium/footer.tsx`
- Copyright usava `dark:text-gray-700` (quase invisÃ­vel em fundo escuro)
- Links do rodapÃ© usavam `dark:text-gray-600` (pouco legÃ­vel em fundo escuro)
- Ambos corrigidos para `dark:text-gray-500`

### VerificaÃ§Ã£o
- `npx tsc --noEmit` â€” OK, sem erros

---

## 2026-01-31 â€” UI/UX Premium Completo (Estilo Antigravity/Apple)

### Objetivo
Melhorias abrangentes de UI/UX em TODAS as pÃ¡ginas do Iudex, inspiradas no Google Antigravity e Apple.com. Framer Motion + CSS moderno + Tailwind.

### Arquivos Criados (6)
- `src/components/ui/motion.tsx` â€” Presets Framer Motion (transitions, variants, componentes wrapper)
- `src/components/ui/animated-container.tsx` â€” Scroll-reveal genÃ©rico com useInView (cross-browser)
- `src/components/ui/animated-counter.tsx` â€” Contador numÃ©rico animado com Framer Motion
- `src/hooks/use-tilt.ts` â€” 3D tilt effect para cards (perspective + rotateX/Y)
- `src/hooks/use-scroll-progress.ts` â€” Scroll progress 0-1
- `src/components/providers/page-transition.tsx` â€” AnimatePresence page transitions

### Arquivos Modificados (20+)
**Infraestrutura:**
- `globals.css` â€” shimmer-premium, glow-hover, card-premium, scroll-progress, prefers-reduced-motion
- `tailwind.config.ts` â€” keyframes slide-up-fade, slide-down-fade, scale-in, blur-in, glow-pulse
- `skeleton.tsx` â€” shimmer-premium no lugar de animate-pulse
- `dialog.tsx` â€” backdrop-blur-md, bg-background/95, rounded-2xl

**Dashboard:**
- `(dashboard)/layout.tsx` â€” PageTransition wrapper, loading state premium com logo animado
- `sidebar-pro.tsx` â€” layoutId sliding active indicator, AnimatePresence labels
- `dashboard/page.tsx` â€” StaggerContainer para stat cards, AnimatedCounter
- `quick-actions.tsx` â€” StaggerContainer, card-premium glow-hover
- `stat-card.tsx` â€” value prop ReactNode para AnimatedCounter

**Landing:**
- `hero-section.tsx` â€” Framer Motion stagger, TiltCard 3D, scroll indicator
- `feature-section.tsx` â€” AnimatedContainer cross-browser, glow-hover
- `footer.tsx` â€” StaggerContainer fadeUp
- `page.tsx` (landing) â€” scroll progress bar, AnimatedContainer sections

**Auth:**
- `login/page.tsx` â€” gradient mesh bg animado, MotionDiv scaleIn, focus glow inputs
- `register/page.tsx` â€” gradient mesh bg, scaleIn card, focus glow
- `register-type/page.tsx` â€” gradient mesh, StaggerContainer cards

**Feature pages:**
- `cases/page.tsx` â€” AnimatedContainer, StaggerContainer, card-premium glow-hover
- `documents/page.tsx` â€” AnimatedContainer header
- `legislation/page.tsx` â€” AnimatedContainer header
- `jurisprudence/page.tsx` â€” AnimatedContainer, StaggerContainer resultados
- `library/page.tsx` â€” AnimatedContainer header
- `transcription/page.tsx` â€” AnimatedContainer header

**Marketing:**
- `platform/page.tsx` â€” AnimatedContainer CTA
- `assistant/page.tsx` â€” AnimatedContainer seÃ§Ãµes
- `research/page.tsx` â€” AnimatedContainer seÃ§Ãµes

### DecisÃµes Tomadas
- Framer Motion para animaÃ§Ãµes (cross-browser, jÃ¡ instalado v12.23.24)
- AnimatePresence mode="wait" para page transitions (pathname como key)
- useInView substituindo animationTimeline: 'view()' (Chrome-only)
- layoutId para sidebar active indicator (spring animation)
- 3D tilt cards com perspective(600px) no hero
- prefers-reduced-motion global reset para acessibilidade

### VerificaÃ§Ã£o
- `npx tsc --noEmit` â€” OK (sem erros)
- ESLint com problemas prÃ©-existentes (migraÃ§Ã£o ESLint 9, nÃ£o relacionado)

---

## 2026-01-31 â€” Melhorias Antigravity na Landing Page Vorbium

### Objetivo
Aplicar 3 melhorias de alto impacto visual inspiradas no Google Antigravity Ã  landing page.

### Arquivos Alterados
- `apps/web/src/styles/globals.css` â€” Adicionados keyframes `wobble`, `scale-reveal` e `scroll-fade-up`
- `apps/web/src/components/vorbium/feature-section.tsx` â€” Wobble icons com delay staggered + scroll-driven fade-in (substituiu useInView por animation-timeline: view())
- `apps/web/src/app/page.tsx` â€” CTA final com scale-reveal no scroll + seÃ§Ã£o "Por que" com scroll-driven fade. Removido useInView (nÃ£o mais necessÃ¡rio)

### DecisÃµes Tomadas
- Scroll-driven animations (CSS puras) em vez de IntersectionObserver JS para melhor performance
- Wobble com 4s duration e 0.3s stagger por card para efeito cascata natural
- Scale-reveal de 0.88â†’1.0 com opacity 0.6â†’1.0 para CTA dramÃ¡tico
- CTA envolvido em card com backdrop-blur para profundidade visual

### Tipografia â€” Google Sans Flex
- Expandido range de pesos CDN: 400..800 â†’ 100..900
- Removido import duplicado de Google Sans Text no globals.css
- Adicionada famÃ­lia `font-google-sans` no Tailwind config com Google Sans Flex como primÃ¡ria
- Aplicada no `<body>` via classe Tailwind (removido inline style)
- Adicionados estilos de tipografia variÃ¡vel (eixos `opsz`, `ROND`, `GRAD`) para headings e body text
- Atualizado fallback em `.font-google-sans-text` para incluir Google Sans Flex

### SessÃ£o Anterior (mesmo dia)
- Implementado dual-ring particle system no worklet (anel estÃ¡tico + Ã³rbita dinÃ¢mica)
- Cursor repulsion com cubic falloff no anel central
- Ring breathing animation (120â†’200 radius)
- Drift suave do centro (15% blend com cursor)

---

## 2026-01-28 â€” AdoÃ§Ã£o completa do rag.md para GraphRAG/Neo4j

### Objetivo
Adotar todas as configuraÃ§Ãµes e modo do GraphRAG com Neo4j conforme documentado no `rag.md` (CapÃ­tulo 5).

### Arquivos Modificados

#### `apps/api/docker-compose.rag.yml`
Atualizado serviÃ§o Neo4j:
- **Imagem**: `neo4j:5.15-community` â†’ `neo4j:5.21.0-enterprise`
- **Plugins**: Adicionado `graph-data-science` (GDS) alÃ©m de APOC
- **LicenÃ§a**: `NEO4J_ACCEPT_LICENSE_AGREEMENT=yes` (Developer License)
- **MemÃ³ria**: heap 1G-2G, pagecache 1G (conforme rag.md)
- **Config**: `strict_validation_enabled=false` (necessÃ¡rio para GraphRAG vetorial)
- **APOC**: Habilitado export/import de arquivos
- **Restart**: `unless-stopped`

#### `apps/api/app/services/rag/config.py`
- **graph_backend**: `"networkx"` â†’ `"neo4j"` (default agora Ã© Neo4j)
- **enable_graph_retrieval**: `False` â†’ `True` (Neo4j como 3Âª fonte no RRF por padrÃ£o)

### MudanÃ§as de Comportamento
| Antes | Depois |
|-------|--------|
| NetworkX como backend padrÃ£o (local) | Neo4j como backend padrÃ£o |
| Graph retrieval desabilitado | Graph retrieval habilitado no RRF |
| Neo4j Community 5.15 | Neo4j Enterprise 5.21.0 |
| Apenas APOC | APOC + Graph Data Science |

### Para usar NetworkX (fallback local)
Se nÃ£o tiver Neo4j rodando:
```bash
export RAG_GRAPH_BACKEND=networkx
export RAG_ENABLE_GRAPH_RETRIEVAL=false
```

### ReferÃªncia
Baseado no CapÃ­tulo 5 do `rag.md` - "O RAG em Grafos: GraphRAG"

---

## 2026-01-28 â€” ImplementaÃ§Ã£o Phase 4: Frontend + SSE Events (CogGRAG)

### Objetivo
Implementar Phase 4 do plano CogGRAG: Eventos SSE para visualizaÃ§Ã£o em tempo real da Ã¡rvore de decomposiÃ§Ã£o no frontend.

### Arquivos Criados
- `apps/api/app/services/ai/shared/sse_protocol.py` â€” Adicionados eventos CogGRAG:
  - `COGRAG_DECOMPOSE_START/NODE/COMPLETE` â€” Eventos de decomposiÃ§Ã£o
  - `COGRAG_RETRIEVAL_START/NODE/COMPLETE` â€” Eventos de busca de evidÃªncias
  - `COGRAG_VERIFY_START/NODE/COMPLETE` â€” Eventos de verificaÃ§Ã£o
  - `COGRAG_INTEGRATE_START/COMPLETE` â€” Eventos de integraÃ§Ã£o final
  - Event builders: `cograg_decompose_start_event()`, `cograg_retrieval_node_event()`, etc.
  - Dataclass `CogRAGNodeData` para dados de nÃ³s
- `apps/web/src/components/chat/cograg-tree-viewer.tsx` â€” Novo componente React:
  - VisualizaÃ§Ã£o hierÃ¡rquica da Ã¡rvore de decomposiÃ§Ã£o
  - Estados por nÃ³: pending, decomposing, retrieving, verified, rejected
  - Badges: contagem de evidÃªncias, confidence %, nÃ³s rejeitados
  - Collapsible por nÃ­vel, auto-scroll

### Arquivos Modificados
- `apps/web/src/stores/chat-store.ts`:
  - Tipos exportados: `CogRAGNode`, `CogRAGStatus`, `CogRAGNodeState`
  - Estado: `cogragTree: CogRAGNode[] | null`, `cogragStatus: CogRAGStatus`
  - Handlers SSE para todos eventos CogGRAG (decompose/retrieval/verify/integrate)
  - Reset de estado em `setIsAgentMode(false)`
  - Whitelist de eventos SSE atualizada com CogGRAG events
- `apps/web/src/components/chat/chat-interface.tsx`:
  - Import de `CogRAGTreeViewer`
  - IntegraÃ§Ã£o do viewer no chat (renderiza quando `cogragTree` existe)

### VerificaÃ§Ã£o
- `npm run type-check --workspace=apps/web` â€” OK
- `npm run lint` nos arquivos modificados â€” OK
- `pytest tests/test_cograg*.py` â€” **114 passed**

### DecisÃµes
- VisualizaÃ§Ã£o opt-in: sÃ³ aparece quando `cogragTree.length > 0`
- Cores consistentes com UX existente (cyan para CogGRAG, amber para retrieval, purple para verify)
- SSE events seguem padrÃ£o existente do JobManager v1 envelope

---

## 2026-01-28 â€” ImplementaÃ§Ã£o Phase 3: Reasoning + Verification (Dual-LLM)

### Objetivo
Implementar Phase 3 do plano CogGRAG: Reasoner (geraÃ§Ã£o de respostas bottom-up), Verifier (verificaÃ§Ã£o dual-LLM), Query Rewriter (hallucination loop), e Integrator (sÃ­ntese final).

### Arquivos Criados
- `app/services/rag/core/cograg/nodes/reasoner.py` â€” NÃ³ Reasoner:
  - `LEAF_ANSWER_PROMPT`, `SYNTHESIS_PROMPT` â€” Prompts em portuguÃªs jurÃ­dico
  - `_format_evidence_for_prompt()` â€” Formata evidÃªncias para LLM
  - `_compute_answer_confidence()` â€” Score de confianÃ§a baseado em: qtd evidÃªncias, qualidade, conflitos, substÃ¢ncia
  - `reasoner_node()` â€” Gera respostas para cada sub-questÃ£o (paralelo), extrai citaÃ§Ãµes via regex
- `app/services/rag/core/cograg/nodes/verifier.py` â€” NÃ³ Verifier + Query Rewriter:
  - `VERIFICATION_PROMPT`, `RETHINK_PROMPT` â€” Prompts de verificaÃ§Ã£o
  - `_parse_verification_result()` â€” Parse JSON de resposta do verificador
  - `verifier_node()` â€” Verifica consistÃªncia respostas vs evidÃªncias, detecta alucinaÃ§Ãµes
  - `query_rewriter_node()` â€” Incrementa rethink_count para loop de correÃ§Ã£o
- `app/services/rag/core/cograg/nodes/integrator.py` â€” NÃ³ Integrator:
  - `INTEGRATION_PROMPT`, `ABSTAIN_PROMPT` â€” Prompts de sÃ­ntese
  - `_format_sub_answers()`, `_collect_citations()` â€” Helpers de formataÃ§Ã£o
  - `_rule_based_integration()` â€” Fallback quando LLM falha
  - `integrator_node()` â€” Sintetiza resposta final, coleta citaÃ§Ãµes, suporta abstain mode
- `tests/test_cograg_reasoning.py` â€” 27 testes para Phase 3 nodes

### Arquivos Modificados
- `app/services/rag/core/cograg/nodes/__init__.py` â€” Exports: `reasoner_node`, `verifier_node`, `query_rewriter_node`, `integrator_node`
- `app/services/ai/langgraph/subgraphs/cognitive_rag.py`:
  - Imports lazy para Phase 3 nodes (`_import_reasoner`, `_import_verifier`, `_import_query_rewriter`, `_import_integrator`)
  - SubstituiÃ§Ã£o dos stubs pelos nÃ³s reais no graph builder
  - AdiÃ§Ã£o de `cograg_verification_enabled`, `cograg_abstain_mode` no state e runner
  - Docstring atualizada: "All phases implemented"

### Testes
- `pytest tests/test_cograg*.py` â€” **114/114 passed**

### DecisÃµes
- `cograg_verification_enabled=False` por default â€” verificaÃ§Ã£o dual-LLM Ã© opcional (custo adicional de LLM calls)
- `cograg_abstain_mode=True` por default â€” quando evidÃªncia insuficiente, explica em vez de tentar responder
- Reasoner gera respostas em paralelo para todas sub-questÃµes
- Verifier usa temperatura baixa (0.1) para verificaÃ§Ã£o mais consistente
- Integrator usa LLM para sÃ­ntese mÃºltiplas respostas, com fallback rule-based se LLM falhar
- CitaÃ§Ãµes extraÃ­das via regex (Art., Lei, SÃºmula) sem LLM adicional

### Pipeline Completo CogGRAG
```
planner â†’ theme_activator â†’ dual_retriever â†’ evidence_refiner â†’
memory_check â†’ reasoner â†’ verifier â†’ [query_rewriter â†º | integrator] â†’
memory_store â†’ END
```

---

## 2026-01-28 â€” ImplementaÃ§Ã£o Phase 2.5: Evidence Refiner + Memory Nodes

### Objetivo
Implementar Phase 2.5 do plano CogGRAG: Evidence Refiner (detecÃ§Ã£o de conflitos, quality scoring) e Memory Nodes (check + store para reutilizaÃ§Ã£o de consultas similares).

### Arquivos Criados
- `app/services/rag/core/cograg/nodes/evidence_refiner.py` â€” NÃ³ Evidence Refiner:
  - `_extract_legal_numbers()` â€” ExtraÃ§Ã£o de referÃªncias legais (Art., Lei, SÃºmula, Decreto)
  - `_detect_contradiction_signals()` â€” DetecÃ§Ã£o de sinais de contradiÃ§Ã£o (negaÃ§Ã£o, proibiÃ§Ã£o, conclusÃµes opostas)
  - `_compute_evidence_quality_score()` â€” Score de qualidade (0-1) baseado em: retrieval score, tipo de fonte, tamanho do texto, referÃªncias legais
  - `evidence_refiner_node()` â€” NÃ³ LangGraph que refina evidÃªncias, detecta conflitos intra/cross-node, ordena chunks por qualidade
- `app/services/rag/core/cograg/nodes/memory.py` â€” Memory Nodes:
  - `ConsultationMemory` â€” Backend simples file-based para MVP (JSON files + index)
  - `memory_check_node()` â€” Busca consultas similares por overlap de keywords (Jaccard similarity)
  - `memory_store_node()` â€” Armazena consulta atual para reutilizaÃ§Ã£o futura
- `tests/test_cograg_evidence_refiner.py` â€” 21 testes para refiner
- `tests/test_cograg_memory.py` â€” 18 testes para memory nodes

### Arquivos Modificados
- `app/services/rag/core/cograg/nodes/__init__.py` â€” Exports dos novos nÃ³s
- `app/services/ai/langgraph/subgraphs/cognitive_rag.py`:
  - Imports lazy para Phase 2.5 nodes (`_import_evidence_refiner`, `_import_memory_check`, `_import_memory_store`)
  - SubstituiÃ§Ã£o dos stubs pelos nÃ³s reais no graph builder
  - AdiÃ§Ã£o de `cograg_memory_enabled` no state e runner
  - Stubs mantidos como fallback se imports falharem

### Testes
- `pytest tests/test_cograg*.py` â€” **87/87 passed**

### DecisÃµes
- Memory backend MVP: file-based JSON com keyword similarity (Jaccard). ProduÃ§Ã£o: trocar por vector store + embedding similarity
- Conflict detection heurÃ­stica: detecta contradiÃ§Ãµes por sinais de negaÃ§Ã£o + conclusÃµes opostas sobre mesma referÃªncia legal
- Quality scoring ponderado: 40% retrieval score, 30% tipo de fonte (jurisprudÃªncia > lei > doutrina), 15% tamanho, 15% referÃªncias legais
- `cograg_memory_enabled=False` por default â€” memory Ã© opcional

---

## 2026-01-28 â€” ImplementaÃ§Ã£o Phase 2: Pipeline Integration

### Objetivo
Integrar CogGRAG no pipeline RAG existente com branching condicional e fallback automÃ¡tico.

### Arquivos Criados
- `tests/test_cograg_integration.py` â€” 15 testes para integraÃ§Ã£o no pipeline

### Arquivos Modificados
- `app/services/rag/pipeline/rag_pipeline.py`:
  - Imports lazy: `run_cognitive_rag`, `cograg_is_complex` (try/except pattern)
  - 4 novos valores no enum `PipelineStage`: `COGRAG_DECOMPOSE`, `COGRAG_RETRIEVAL`, `COGRAG_REFINE`, `COGRAG_VERIFY`
  - Branching no `search()`: detecta `use_cograg` (feature flag + query complexa) â†’ chama `_cograg_pipeline()`
  - MÃ©todo `_cograg_pipeline()` (~120 linhas): invoca `run_cognitive_rag()`, fallback se â‰¤1 sub-question, merge de resultados

### Testes
- `pytest tests/test_cograg_integration.py` â€” **15/15 passed**

### DecisÃµes
- Complexidade detectada por: word count > 12 OU patterns (compare, mÃºltiplas conjunÃ§Ãµes, etc.)
- Fallback automÃ¡tico: se CogGRAG retorna â‰¤1 sub-question â†’ pipeline normal
- `enable_cograg=False` por default â€” zero impacto quando desligado

---

## 2026-01-28 â€” ImplementaÃ§Ã£o Phase 1: Core CogGRAG (LangGraph)

### Objetivo
Implementar Phase 1 do plano CogGRAG: data structures, nÃ³s LangGraph (Planner, Theme Activator, Dual Retriever), StateGraph principal, configs, e testes.

### Arquivos Criados
- `app/services/rag/core/cograg/__init__.py` â€” Package exports
- `app/services/rag/core/cograg/mindmap.py` â€” Data structures: `NodeState`, `MindMapNode`, `CognitiveTree`
- `app/services/rag/core/cograg/nodes/__init__.py` â€” Nodes package
- `app/services/rag/core/cograg/nodes/planner.py` â€” NÃ³ Planner: decomposiÃ§Ã£o top-down, heurÃ­stica de complexidade, prompts PT jurÃ­dico
- `app/services/rag/core/cograg/nodes/retriever.py` â€” NÃ³s Theme Activator + Dual Retriever: fan-out paralelo, dedup, Neo4j entity/triple/subgraph
- `app/services/ai/langgraph/subgraphs/cognitive_rag.py` â€” StateGraph principal: `CognitiveRAGState`, 10 nÃ³s (6 stubs para Phase 2.5/3), edges condicionais, `run_cognitive_rag()`
- `tests/test_cograg_mindmap.py` â€” 22 testes para NodeState/MindMapNode/CognitiveTree
- `tests/test_cograg_planner.py` â€” 12 testes para complexity detection + planner node

### Arquivos Modificados
- `app/services/rag/config.py` â€” 14 novos campos CogGRAG no `RAGConfig` + env vars no `from_env()`

### Testes
- `pytest tests/test_cograg_mindmap.py tests/test_cograg_planner.py` â€” **34/34 passed**

### DecisÃµes
- `max_depth` semÃ¢ntica: `>=` (max_depth=3 â†’ levels 0,1,2)
- Phase 2.5/3 nÃ³s como stubs no StateGraph (placeholder â†’ implementaÃ§Ã£o incremental)
- `_call_gemini` isolada no planner (nÃ£o depende de QueryExpansion)
- LegalEntityExtractor reusado para key extraction (zero LLM)

---

## 2026-01-28 â€” Plano: IntegraÃ§Ã£o CogGRAG no Pipeline RAG

### Objetivo
Integrar o padrÃ£o CogGRAG (Cognitive Graph RAG â€” paper 2503.06567v2) como modo alternativo de processamento no pipeline RAG existente, com feature flag `enable_cograg`.

### Pesquisa Realizada
- Leitura completa do paper CogGRAG (2503.06567v2 â€” AAAI 2026): decomposiÃ§Ã£o top-down em mind map, retrieval estruturado local+global, raciocÃ­nio bottom-up com verificaÃ§Ã£o dual-LLM
- Leitura completa do paper MindMap (2308.09729v5): KG prompting com graph-of-thoughts, evidence mining path-based + neighbor-based
- AnÃ¡lise do cÃ³digo-fonte oficial CogGRAG (github.com/cy623/RAG): `mindmap.py`, `retrieval.py`, `Agent.py`, `prompts.json` (6 templates)
- ExploraÃ§Ã£o completa da infraestrutura existente: rag_pipeline.py (10 stages), query_expansion.py, neo4j_mvp.py, orchestrator.py, ClaudeAgentExecutor, LangGraph workflows, parallel_research subgraph, model_registry

### Plano Aprovado (5 Phases)

**Phase 1 â€” Core CogGRAG (standalone)**
- `app/services/rag/core/cograg/mindmap.py` â€” Data structures: `NodeState`, `MindMapNode`, `CognitiveTree`
- `app/services/rag/core/cograg/decomposer.py` â€” `CognitiveDecomposer`: BFS level-by-level com Gemini Flash, heurÃ­stica de complexidade, prompts em portuguÃªs jurÃ­dico
- `app/services/rag/core/cograg/structured_retrieval.py` â€” `StructuredRetriever`: fan-out paralelo por sub-questÃ£o, reusa `LegalEntityExtractor` (regex), Neo4j + Qdrant + OpenSearch

**Phase 2 â€” IntegraÃ§Ã£o no Pipeline**
- `app/services/rag/config.py` â€” 9 novos campos: `enable_cograg`, `cograg_max_depth`, `cograg_similarity_threshold`, etc.
- `app/services/rag/pipeline/rag_pipeline.py` â€” Branching no `search()`: CogGRAG path (Stages COGRAG_DECOMPOSE + COGRAG_STRUCTURED_RETRIEVAL) â†’ Stage 5+ normal. Fallback automÃ¡tico para queries simples

**Phase 3 â€” VerificaÃ§Ã£o Dual-LLM**
- `app/services/rag/core/cograg/reasoner.py` â€” `BottomUpReasoner`: LLM_res gera resposta, LLM_ver verifica, re-think se inconsistente

**Phase 4 â€” Frontend + SSE**
- Novos eventos SSE: `COGRAG_DECOMPOSE_*`, `COGRAG_RETRIEVAL_*`, `COGRAG_VERIFY_*`
- `cograg-tree-viewer.tsx` â€” VisualizaÃ§Ã£o da Ã¡rvore em tempo real

**Phase 5 â€” Testes**
- 4 arquivos: `test_cograg_mindmap.py`, `test_cograg_decomposer.py`, `test_cograg_retrieval.py`, `test_cograg_integration.py`

### DecisÃµes Arquiteturais
- Feature-flagged (`enable_cograg=False` default) â€” zero impacto quando desligado
- Fallback automÃ¡tico: query simples (â‰¤1 folha) â†’ pipeline normal
- Gemini Flash para decomposiÃ§Ã£o (consistente com HyDE/Multi-Query existentes)
- LegalEntityExtractor (regex) para key extraction â€” zero LLM
- Incremental: Phase 1-2 sem Phase 3, cada phase com seu flag
- Budget: decomposiÃ§Ã£o ~2-3 LLM calls, verificaÃ§Ã£o ~2N calls

### Arquivo do Plano
- `/Users/nicholasjacob/.claude/plans/cuddly-herding-crystal.md` â€” Plano detalhado completo

---

## 2026-01-28 â€” Feature: Multi-tenancy Organizacional â€” Fase 1 (P2)

### Objetivo
Adicionar multi-tenancy organizacional (escritÃ³rio â†’ equipes â†’ usuÃ¡rios) sem quebrar usuÃ¡rios existentes. Fase 1: modelos, auth, endpoints, migration.

### Arquitetura
```
Organization (escritÃ³rio) â†’ OrganizationMember (vÃ­nculo + role) â†’ User
Organization â†’ Team (equipe) â†’ TeamMember â†’ User
```

Roles: `admin` (gerencia org), `advogado` (acesso completo), `estagiÃ¡rio` (restrito).
RetrocompatÃ­vel: `organization_id` nullable em tudo. Users sem org continuam funcionando.

### Arquivos Criados
- `app/models/organization.py` â€” Organization, OrganizationMember, OrgRole, Team, TeamMember
- `app/schemas/organization.py` â€” OrgCreate, OrgResponse, MemberResponse, InviteRequest, TeamCreate, etc.
- `app/api/endpoints/organizations.py` â€” 11 endpoints CRUD (org, membros, equipes)
- `alembic/versions/g7h8i9j0k1l2_add_multi_tenancy.py` â€” Migration (4 tabelas + 4 colunas nullable)
- `tests/test_organization.py` â€” 34 testes

### Arquivos Modificados
- `app/models/user.py` â€” Adicionado `organization_id` FK nullable + relationships
- `app/models/case.py` â€” Adicionado `organization_id` FK nullable
- `app/models/chat.py` â€” Adicionado `organization_id` FK nullable
- `app/models/document.py` â€” Adicionado `organization_id` FK nullable
- `app/models/__init__.py` â€” Exports dos novos modelos
- `app/core/security.py` â€” OrgContext dataclass, get_org_context, require_org_role
- `app/api/routes.py` â€” Registrado router `/organizations`
- `app/api/endpoints/auth.py` â€” JWT payload inclui `org_id`

### OrgContext (core do multi-tenancy)
```python
@dataclass
class OrgContext:
    user: User
    organization_id: Optional[str]  # None = single-user mode
    org_role: Optional[str]         # admin/advogado/estagiario
    team_ids: List[str]

    @property
    def tenant_id(self) -> str:
        """org_id se membro, senÃ£o user_id (para RAG/Neo4j)."""
        return self.organization_id or self.user.id
```

### Endpoints
```
POST   /organizations/                    â†’ Criar org (user vira admin)
GET    /organizations/current             â†’ Detalhes da org
PUT    /organizations/current             â†’ Atualizar (admin)
GET    /organizations/members             â†’ Listar membros
POST   /organizations/members/invite      â†’ Convidar (admin)
PUT    /organizations/members/{uid}/role  â†’ Alterar role (admin)
DELETE /organizations/members/{uid}       â†’ Remover (admin)
POST   /organizations/teams              â†’ Criar equipe
GET    /organizations/teams              â†’ Listar equipes
POST   /organizations/teams/{tid}/members â†’ Add membro
DELETE /organizations/teams/{tid}/members/{uid} â†’ Remove
```

### Testes
- 34/34 passando âœ…
- 27/27 citation grounding (regressÃ£o) âœ…

### PrÃ³ximos Passos (Fase 2)
- ~~Migrar endpoints existentes de `get_current_user` â†’ `get_org_context`~~ âœ…
- ~~Data isolation: Cases/Chats/Documents filtrados por org_id~~ âœ…
- ~~Frontend: org store, pÃ¡gina de gestÃ£o, org switcher~~ âœ…

---

## 2026-01-28 â€” Feature: Multi-tenancy â€” Fase 2 (Data Isolation) + Fase 3 (Frontend)

### Objetivo
Migrar todos os endpoints de dados para usar `OrgContext` (isolamento por org) e criar UI de gestÃ£o organizacional no frontend.

### Fase 2 â€” Backend Data Isolation

#### Arquivos Modificados
- `app/core/security.py` â€” Adicionado `build_tenant_filter(ctx, model_class)` helper
- `app/services/case_service.py` â€” Todos mÃ©todos aceitam `Union[OrgContext, str]`, `create_case` seta `organization_id`
- `app/api/endpoints/cases.py` â€” 9 endpoints migrados de `get_current_user` â†’ `get_org_context`
- `app/api/endpoints/chats.py` â€” 10+ endpoints migrados, `create_chat`/`duplicate_chat` setam `organization_id`
- `app/api/endpoints/documents.py` â€” 18+ endpoints migrados, `upload_document` seta `organization_id`
- `app/schemas/user.py` â€” `UserResponse` inclui `organization_id`
- `app/api/endpoints/auth.py` â€” Refresh endpoint inclui `org_id` no JWT

#### PadrÃ£o de MigraÃ§Ã£o
```python
# ANTES
current_user: User = Depends(get_current_user)
query = select(Case).where(Case.user_id == current_user.id)

# DEPOIS
ctx: OrgContext = Depends(get_org_context)
current_user = ctx.user  # alias para retrocompatibilidade
query = select(Case).where(build_tenant_filter(ctx, Case))
```

### Fase 3 â€” Frontend

#### Arquivos Criados
- `stores/org-store.ts` â€” Zustand store para organizaÃ§Ã£o (fetch, CRUD, membros, equipes)
- `app/(dashboard)/organization/page.tsx` â€” PÃ¡gina de gestÃ£o: criar org, membros, equipes, convites

#### Arquivos Modificados
- `stores/auth-store.ts` â€” User interface expandida com `role`, `plan`, `account_type`, `organization_id`
- `stores/index.ts` â€” Export do `useOrgStore`
- `lib/api-client.ts` â€” 11 novos mÃ©todos de organizaÃ§Ã£o (CRUD, membros, equipes)
- `components/layout/sidebar-pro.tsx` â€” Footer dinÃ¢mico com dados do user + indicador de org
- `components/chat/chat-interface.tsx` â€” Sincroniza `tenantId` do chat com `organization_id` do user

### VerificaÃ§Ã£o
- 34/34 testes Python passando âœ…
- TypeScript compila sem erros âœ…

---

## 2026-01-28 â€” OtimizaÃ§Ã£o de LatÃªncia do Pipeline RAG

### Objetivo
Reduzir latÃªncia do pipeline RAG (3 databases em paralelo) com result cache, per-DB timeouts, mÃ©tricas de percentil e warm-start de conexÃµes. Target: P50 < 80ms, P95 < 120ms, P99 < 180ms (retrieval).

### Arquivos Criados
- `app/services/rag/core/result_cache.py` â€” ResultCache thread-safe com TTL, LRU eviction, invalidaÃ§Ã£o por tenant
- `app/services/rag/core/metrics.py` â€” LatencyCollector com sliding window P50/P95/P99 por stage
- `tests/test_result_cache.py` â€” 12 testes (TTL, invalidaÃ§Ã£o, max_size, thread safety)
- `tests/test_latency_collector.py` â€” 7 testes (percentis, sliding window, singleton, thread safety)
- `tests/test_per_db_timeout.py` â€” 5 testes (timeout â†’ [], parallel degradation, min_sources)

### Arquivos Modificados
- `app/services/rag/config.py` â€” 9 novos campos: result cache (enable, ttl, max_size), per-DB timeouts (lexical 0.5s, vector 1.0s, graph 0.5s, min_sources), warmup_on_startup
- `app/services/rag/pipeline/rag_pipeline.py` â€” 3 mudanÃ§as:
  - Cache check apÃ³s trace init (early return se cache hit)
  - `_with_timeout` wrapper com `asyncio.wait_for` nos 3 DB searches (retorna [] no timeout)
  - MÃ©tricas recording das stage durations + cache set antes do return
- `app/api/endpoints/rag.py` â€” Endpoint `GET /rag/metrics` (latency + cache stats), invalidaÃ§Ã£o de cache nos 2 endpoints de ingest
- `app/main.py` â€” Warm-start expandido: health-check paralelo de Qdrant, OpenSearch, Neo4j no boot (5s timeout cada), defaults de preload mudados para `true`

### PadrÃ£o de Timeout
```python
async def _with_timeout(coro, timeout: float, name: str):
    try:
        return await asyncio.wait_for(coro, timeout=timeout)
    except asyncio.TimeoutError:
        return []  # graceful degradation
```

### Testes
- 24/24 novos testes passando âœ…
- 81/81 testes totais passando âœ…

---

## 2026-01-28 â€” Feature: Citation Grounding Rigoroso (P1 â€” Zero Hallucination)

### Objetivo
VerificaÃ§Ã£o pÃ³s-geraÃ§Ã£o de citaÃ§Ãµes jurÃ­dicas na resposta do LLM. Antes de enviar ao usuÃ¡rio, extrai entidades legais do texto e verifica cada uma contra o contexto RAG e o Neo4j.

### Arquitetura
```
ANTES:  LLM gera texto â†’ append references â†’ enviar (sem verificaÃ§Ã£o)
DEPOIS: LLM gera texto â†’ [verify_citations] â†’ annotate + fidelity_index â†’ enviar
```

### Arquivos Criados
- `apps/api/app/services/ai/citations/grounding.py` â€” Core da verificaÃ§Ã£o:
  - `extract_legal_entities_from_response()` â€” Reutiliza LegalEntityExtractor (regex, <1ms)
  - `verify_against_context()` â€” Verifica entidades contra rag_context
  - `verify_against_neo4j()` â€” Batch Cypher lookup (fail-open)
  - `verify_citations()` â€” Orquestrador async principal
  - `annotate_response_text()` â€” Marca [NÃƒO VERIFICADO] + banner de aviso
  - `GroundingResult`, `CitationVerification`, `VerificationStatus` â€” Dataclasses
- `apps/api/tests/test_citation_grounding.py` â€” 27 testes (7 classes)

### Arquivos Modificados
- `apps/api/app/services/rag/config.py` â€” 4 novos campos:
  - `enable_citation_grounding: bool = True`
  - `citation_grounding_threshold: float = 0.85`
  - `citation_grounding_neo4j: bool = True`
  - `citation_grounding_annotate: bool = True`
- `apps/api/app/services/ai/citations/__init__.py` â€” Exports do grounding
- `apps/api/app/api/endpoints/chats.py` â€” IntegraÃ§Ã£o em 2 pontos:
  - Modo multi-modelo (~linha 5209): grounding apÃ³s full_text montado
  - Modo breadth_first (~linha 4170): grounding antes de append_references
  - Metadata persistido com `grounding.to_dict()`

### Scoring
- VERIFIED (contexto + Neo4j) â†’ confidence 1.0
- CONTEXT_ONLY â†’ confidence 0.9
- NEO4J_ONLY â†’ confidence 0.7
- UNVERIFIED â†’ confidence 0.0
- `fidelity_index = verified / total` (sem citaÃ§Ãµes = 1.0)

### Performance
Total <20ms (regex <1ms + context check <5ms + Neo4j batch <10ms)

### Testes
- 27 passed, 0 failed
- 91 passed em test_kg_builder.py (regressÃ£o OK)

### VariÃ¡veis de Ambiente
| VariÃ¡vel | Default | DescriÃ§Ã£o |
|---|---|---|
| `CITATION_GROUNDING_ENABLED` | `true` | Feature flag |
| `CITATION_GROUNDING_THRESHOLD` | `0.85` | Fidelity mÃ­nimo |
| `CITATION_GROUNDING_NEO4J` | `true` | Verificar Neo4j |
| `CITATION_GROUNDING_ANNOTATE` | `true` | Anotar texto |

---

## 2026-01-28 â€” Feature: Graph-Augmented Retrieval (Neo4j como 3Âª fonte RRF)

### Objetivo
Mover Neo4j de "decoraÃ§Ã£o pÃ³s-retrieval" (Stage 9) para **participante ativo do retrieval** (Stage 3c), correndo em paralelo com OpenSearch e Qdrant e contribuindo para o RRF merge.

### Arquitetura
```
ANTES:  Query â†’ [OpenSearch âˆ¥ Qdrant] â†’ RRF(2 sinais) â†’ Rerank â†’ ... â†’ Graph Enrich (Stage 9)
DEPOIS: Query â†’ [OpenSearch âˆ¥ Qdrant âˆ¥ Neo4j] â†’ RRF(3 sinais) â†’ Rerank â†’ ... â†’ Graph Enrich (Stage 9)
```

Neo4j usa `LegalEntityExtractor.extract()` (regex, <1ms) para extrair entidades da query, depois `query_chunks_by_entities()` para encontrar chunks via MENTIONS. Habilitado inclusive para citation queries ("Art. 5 CF") onde entity extraction Ã© especialmente eficaz.

### Arquivos Modificados
- `apps/api/app/services/rag/config.py` â€” 3 novos campos:
  - `enable_graph_retrieval: bool = False` (feature flag, off por padrÃ£o)
  - `graph_weight: float = 0.3` (peso no RRF, menor que lex/vec)
  - `graph_retrieval_limit: int = 20`
- `apps/api/app/services/rag/pipeline/rag_pipeline.py`:
  - Novos enums: `PipelineStage.GRAPH_SEARCH`, `SearchMode.HYBRID_LEX_VEC_GRAPH`, `SearchMode.HYBRID_LEX_GRAPH`
  - Novo mÃ©todo `_stage_graph_search()` â€” Stage 3c, fail-open, trace completo
  - `_compute_rrf_score()` â€” novo parÃ¢metro `graph_rank` (backward-compatible)
  - `_merge_results_rrf()` â€” novo parÃ¢metro `graph_results` com dedup por chunk_uid
  - `_stage_merge_rrf()` â€” propaga `graph_results` e registra `graph_count` no trace
  - `search()` â€” orquestraÃ§Ã£o paralela de 3 tarefas via `asyncio.gather`, unpack fail-open
- `apps/api/tests/test_kg_builder.py` â€” +19 testes em 5 classes:
  - `TestGraphRetrievalConfig` (2): defaults e env vars
  - `TestRRFGraphRank` (6): graph_rank, backward compat, overlap boost, weight=0
  - `TestMergeResultsRRFGraph` (4): 3 sources merge, empty graph, graph-only chunk, no leaks
  - `TestStageGraphSearch` (4): neo4j=None, no entities, fail-open, normalized chunks
  - `TestPipelineEnums` (3): novos enums existem

### DecisÃµes
- **Peso 0.3** (vs 0.5 para lex/vec): graph confirma/boosta, nÃ£o domina
- **Fail-open em todos os pontos**: Neo4j indisponÃ­vel = pipeline continua igual
- **Feature flag off por padrÃ£o**: rollout gradual via `RAG_ENABLE_GRAPH_RETRIEVAL`
- **Preserva `_enrich_from_neo4j`**: complementar (CRAG retry), nÃ£o substitutivo
- **Citation queries incluÃ­das**: graph search funciona especialmente bem com "Art. 5 CF"

### Testes
- 91 passed (test_kg_builder.py), 50 passed + 1 skipped (test_neo4j_mvp.py)

### VariÃ¡veis de Ambiente
| VariÃ¡vel | Default | DescriÃ§Ã£o |
|---|---|---|
| `RAG_ENABLE_GRAPH_RETRIEVAL` | `false` | Feature flag principal |
| `RAG_GRAPH_WEIGHT` | `0.3` | Peso do graph no RRF |
| `RAG_GRAPH_RETRIEVAL_LIMIT` | `20` | Max chunks do Neo4j |

---

## 2026-01-28 â€” Fix: SeparaÃ§Ã£o GraphRAG vs ArgumentRAG (anti-contaminaÃ§Ã£o)

### Objetivo
Corrigir 3 problemas de contaminaÃ§Ã£o entre o grafo de entidades (GraphRAG) e o grafo argumentativo (ArgumentRAG): separaÃ§Ã£o de queries, detecÃ§Ã£o automÃ¡tica de intent, e security trimming para Claim/Evidence.

### Problema Identificado
1. **FIND_PATHS misturava graph spaces**: A query Cypher Ãºnica traversava TANTO edges de entidades (RELATED_TO, MENTIONS) quanto de argumentos (SUPPORTS, OPPOSES, etc.), permitindo que paths de entidades entrassem em Claim/Evidence sem necessidade
2. **Sem detecÃ§Ã£o automÃ¡tica de intent**: O sistema usava flag explÃ­cita `argument_graph_enabled` sem analisar a query â€” queries de debate ("argumentos a favor") nÃ£o ativavam ArgumentRAG automaticamente
3. **Claim/Evidence sem security trimming**: FIND_PATHS verificava escopo de Document para Chunk nodes, mas Claim/Evidence (que tÃªm tenant_id/case_id) passavam sem validaÃ§Ã£o

### Arquivos Modificados
- `apps/api/app/services/rag/core/neo4j_mvp.py` â€” **Fix 1 + Fix 3**:
  - `FIND_PATHS` agora Ã© entity-only (RELATED_TO|MENTIONS|ASSERTS|REFERS_TO apenas, targets: Chunk|Entity)
  - Novo `FIND_PATHS_WITH_ARGUMENTS` inclui todas as edges + targets Claim/Evidence
  - `FIND_PATHS_WITH_ARGUMENTS` tem security trimming para Claim/Evidence: `n.tenant_id = $tenant_id AND ($case_id IS NULL OR n.case_id IS NULL OR n.case_id = $case_id)`
  - `find_paths()` aceita `include_arguments: bool = False` para escolher entre os dois modos
- `apps/api/app/services/rag/pipeline/rag_pipeline.py` â€” **Fix 2**:
  - Nova funÃ§Ã£o `detect_debate_intent(query)` com regex para cues de debate em portuguÃªs (argumentos, tese, contratese, prÃ³s e contras, defesa, contraditÃ³rio, fundamentaÃ§Ã£o, impugnaÃ§Ã£o, etc.)
  - `_stage_graph_enrich()` auto-habilita `argument_graph_enabled` quando intent Ã© debate
  - `find_paths()` recebe `include_arguments=argument_graph_enabled` â€” entity-only para queries factuais, argument-aware para queries de debate
- `apps/api/tests/test_kg_builder.py` â€” +29 testes:
  - `TestFindPathsSeparation` (6 testes): entity-only exclui argument edges/targets, argument-aware inclui tudo, mÃ©todo aceita parÃ¢metro
  - `TestClaimEvidenceSecurityTrimming` (4 testes): tenant_id, case_id, entity-only sem claim security, chunk security preservado
  - `TestDebateIntentDetection` (19 testes): 9 debate cues (argumentos, tese, contratese, etc.), 5 factual queries (Art. 5Âº, Lei 8.666, SÃºmula 331, etc.), empty query, phrase matching, pipeline integration
- `apps/api/tests/test_neo4j_mvp.py` â€” Atualizado: testes de FIND_PATHS agora verificam `FIND_PATHS_WITH_ARGUMENTS` para argument relationships

### Testes
- `pytest tests/test_kg_builder.py -v` â€” 72/72 passed
- `pytest tests/test_neo4j_mvp.py tests/test_kg_builder.py -v` â€” 122 passed, 1 skipped

### DecisÃµes
- Entity-only como default (nÃ£o contamina) â€” argument-aware sÃ³ quando explicitamente habilitado OU auto-detectado via intent
- Intent detection usa regex simples (zero-cost, determinÃ­stico) â€” nÃ£o precisa de LLM
- Security trimming para Claim/Evidence permite `case_id IS NULL` no node (global claims) quando caller nÃ£o filtra por case
- `detect_debate_intent()` reconhece 15+ cues de debate em portuguÃªs jurÃ­dico

---

## 2026-01-28 â€” GraphRAG Phase 3: ArgumentRAG com LLM (Gemini Flash)

### Objetivo
Adicionar extraÃ§Ã£o de argumentos via LLM (Gemini Flash structured output), scoring de evidÃªncias por autoridade de tribunal, e endpoints de visualizaÃ§Ã£o de grafo argumentativo.

### Arquivos Criados
- `apps/api/app/services/rag/core/kg_builder/argument_llm_extractor.py` â€” **ArgumentLLMExtractor**: extraÃ§Ã£o de claims/evidence/actors/issues via Gemini Flash com `response_json_schema`. Schema JSON completo para structured output. MÃ©todo `extract_and_ingest()` para extraÃ§Ã£o + escrita no Neo4j.
- `apps/api/app/services/rag/core/kg_builder/evidence_scorer.py` â€” **EvidenceScorer**: scoring multi-dimensional por autoridade de tribunal (STF=1.0, STJ=0.95, TRF=0.75, TJ=0.6), tipo de evidÃªncia (jurisprudencia=0.9, legislacao=0.85, pericia=0.8), e stance bonus (pro/contra +0.05).

### Arquivos Modificados
- `apps/api/app/services/rag/core/kg_builder/pipeline.py` â€” `_run_argument_extraction()` agora usa `ArgumentLLMExtractor` com fallback para heurÃ­stica (`ArgumentNeo4jService`) se LLM indisponÃ­vel
- `apps/api/app/api/endpoints/graph.py` â€” Novos endpoints:
  - `GET /argument-graph/{case_id}` â€” Retorna grafo argumentativo completo (Claims, Evidence, Actors, Issues + edges)
  - `GET /argument-stats` â€” EstatÃ­sticas de Claims/Evidence/Actors/Issues por tenant
  - Novos schemas: `ArgumentGraphNode`, `ArgumentGraphEdge`, `ArgumentGraphData`
- `apps/api/tests/test_kg_builder.py` â€” +22 testes Phase 3:
  - `TestEvidenceScorer` (10 testes): scoring STF, doutrina, fato, tribunal_authority, capping
  - `TestArgumentLLMExtractor` (7 testes): schema structure, prompt, empty text, default model
  - `TestPipelineLLMIntegration` (5 testes): pipeline imports, fallback, endpoints

### Testes
- `pytest tests/test_kg_builder.py -v` â€” 43/43 passed
- `pytest tests/test_neo4j_mvp.py tests/test_kg_builder.py -v` â€” 92 passed, 1 skipped

### DecisÃµes
- Evidence scoring usa 3 dimensÃµes: base (tipo), authority bonus (tribunal * 0.15), stance bonus (0.05)
- LLM extraction usa Gemini Flash com `response_json_schema` para JSON garantido (~$0.01/doc)
- Pipeline faz fallback automÃ¡tico para heurÃ­stica se google-genai nÃ£o instalado
- Endpoint `/argument-graph/{case_id}` retorna nodes tipados + edges com stance/weight para visualizaÃ§Ã£o

---

## 2026-01-28 â€” GraphRAG Phase 2: KG Builder (neo4j-graphrag-python)

### Objetivo
Adotar `neo4j-graphrag-python` oficial para KG construction, com Components customizados para domÃ­nio jurÃ­dico brasileiro: extraÃ§Ã£o regex (LegalRegexExtractor), schema jurÃ­dico (legal_schema), entity resolution (LegalFuzzyResolver com rapidfuzz), e pipeline composto.

### Arquivos Criados
- `apps/api/app/services/rag/core/kg_builder/` â€” Novo diretÃ³rio com 5 arquivos:
  - `__init__.py` â€” Exports do mÃ³dulo
  - `legal_schema.py` â€” Schema jurÃ­dico completo: 11 node types (Lei, Artigo, Sumula, Tribunal, Processo, Tema, Claim, Evidence, Actor, Issue, SemanticEntity), 15 relationship types, 23 patterns (triplets vÃ¡lidos)
  - `legal_extractor.py` â€” `LegalRegexExtractor` Component wrapping `LegalEntityExtractor` existente. Converte output regex para format Neo4jGraph (nodes + relationships). Cria MENTIONS e RELATED_TO por co-ocorrÃªncia.
  - `fuzzy_resolver.py` â€” `LegalFuzzyResolver` Component para entity resolution via rapidfuzz. NormalizaÃ§Ã£o especÃ­fica para citaÃ§Ãµes jurÃ­dicas brasileiras (Lei nÂº 8.666/93 == Lei 8666/1993). Merge via APOC com fallback.
  - `pipeline.py` â€” `run_kg_builder()`: pipeline composto com dois modos:
    - **Simple mode** (default): LegalRegexExtractor + ArgumentNeo4jService + FuzzyResolver
    - **neo4j-graphrag mode** (`KG_BUILDER_USE_GRAPHRAG=true`): SimpleKGPipeline oficial
- `apps/api/tests/test_kg_builder.py` â€” 21 testes (schema, extractor, resolver, pipeline)

### Arquivos Modificados
- `apps/api/requirements.txt` â€” +`neo4j-graphrag>=1.0.0`, +`rapidfuzz>=3.6.0`
- `apps/api/app/api/endpoints/rag.py` â€” IntegraÃ§Ã£o fire-and-forget do KG Builder apÃ³s ingest via `KG_BUILDER_ENABLED=true`

### ConfiguraÃ§Ã£o (ENV vars)
- `KG_BUILDER_ENABLED=true`: Ativa KG Builder apÃ³s ingest de documentos
- `KG_BUILDER_USE_LLM=true`: Ativa extraÃ§Ã£o de argumentos via ArgumentNeo4jService
- `KG_BUILDER_USE_GRAPHRAG=true`: Usa SimpleKGPipeline oficial em vez de simple mode
- `KG_BUILDER_RESOLVE_ENTITIES=true` (default): Entity resolution com rapidfuzz

### Testes
- `pytest tests/test_kg_builder.py -v` â€” 21/21 passed
- `pytest tests/test_neo4j_mvp.py tests/test_kg_builder.py -v` â€” 70 passed, 1 skipped

### DecisÃµes
- Components tÃªm fallback stubs para import sem `neo4j-graphrag` instalado (graceful degradation)
- Entity resolution usa rapidfuzz (C++, Python 3.14 compatible) em vez de spaCy
- Pipeline roda async (fire-and-forget) para nÃ£o bloquear response do usuÃ¡rio
- Schema seguiu formato oficial neo4j-graphrag: `node_types` com `properties`, `relationship_types`, `patterns`

---

## 2026-01-27 â€” GraphRAG Phase 1: ArgumentRAG Unificado no Neo4j

### Objetivo
Migrar ArgumentRAG (Claims, Evidence, Actors, Issues) do backend legacy NetworkX para Neo4j, com schema unificado, multi-tenant isolation e integraÃ§Ã£o no pipeline RAG via flag `RAG_ARGUMENT_BACKEND`.

### Arquivos Criados
- `apps/api/app/services/rag/core/argument_neo4j.py` â€” **ArgumentNeo4jService** (~900 linhas): Cypher schema (constraints + indexes), MERGE operations para Claims/Evidence/Actor/Issue, `get_debate_context()` para pro/contra, `get_argument_graph()` para visualizaÃ§Ã£o, heurÃ­stica de extraÃ§Ã£o de claims, inferÃªncia de stance
- `apps/api/scripts/migrate_arguments_to_neo4j.py` â€” Script de migraÃ§Ã£o NetworkXâ†’Neo4j (idempotente, `--dry-run`)

### Arquivos Modificados
- `apps/api/app/services/rag/core/neo4j_mvp.py`:
  - Schema `CREATE_CONSTRAINTS`: +4 constraints (Claim, Evidence, Actor, Issue)
  - Schema `CREATE_INDEXES`: +7 indexes (tenant, case, type)
  - `FIND_PATHS`: expandido com `SUPPORTS|OPPOSES|EVIDENCES|ARGUES|RAISES|CITES|CONTAINS_CLAIM`
  - `FIND_PATHS` target: agora inclui `target:Claim OR target:Evidence`
  - Docstring atualizado com schema completo
- `apps/api/app/services/rag/core/graph_hybrid.py` â€” Labels: `claimâ†’Claim`, `evidenceâ†’Evidence`, `actorâ†’Actor`, `issueâ†’Issue`
- `apps/api/app/services/rag/pipeline/rag_pipeline.py` â€” Stage Graph Enrich:
  - `RAG_ARGUMENT_BACKEND=neo4j` (default): usa `ArgumentNeo4jService.get_debate_context()`
  - `RAG_ARGUMENT_BACKEND=networkx`: usa legacy `ARGUMENT_PACK`
  - `RAG_ARGUMENT_BACKEND=both`: tenta Neo4j primeiro, fallback para legacy
- `apps/api/tests/test_neo4j_mvp.py` â€” +13 testes em `TestPhase1ArgumentRAG`

### Testes
- `pytest tests/test_neo4j_mvp.py -v` â€” 49/49 passed, 1 skipped (Neo4j connection)
- Phase 1 testes cobrem: schema, constraints, indexes, FIND_PATHS, hybrid labels, whitelist, claim extraction, stance inference, debate context, pipeline integration

### ConfiguraÃ§Ã£o
- `RAG_ARGUMENT_BACKEND`: `neo4j` (default) | `networkx` | `both`
- Backward compatible: setar `RAG_ARGUMENT_BACKEND=networkx` para manter comportamento anterior

---

## 2026-01-27 â€” GraphRAG Phase 0: Fix Bugs Criticos

### Objetivo
Corrigir bugs criticos no GraphRAG identificados durante analise comparativa com documentacao oficial Neo4j. Parte do plano de maturacao do GraphRAG (5 phases).

### Bugs Corrigidos
1. **link_entities inexistente** â€” `neo4j_mvp.py:1399` chamava `self.link_entities()` (nao existe), corrigido para `self.link_related_entities()`. Relacoes RELATED_TO nunca eram criadas durante ingest semantico.
2. **Mismatch SEMANTICALLY_RELATED vs RELATED_TO** â€” `semantic_extractor.py` criava relacoes `SEMANTICALLY_RELATED` mas `FIND_PATHS` so percorria `RELATED_TO|MENTIONS`. Paths semanticos nunca eram encontrados. Corrigido para usar `RELATED_TO` com `relation_subtype='semantic'`.
3. **Label SEMANTIC_ENTITY incompativel** â€” Alterado para dual label `:Entity:SemanticEntity` (PascalCase), compativel com `FIND_PATHS` que matcha `:Entity`.
4. **FIND_PATHS incompleto** â€” Expandido para `[:RELATED_TO|MENTIONS|ASSERTS|REFERS_TO*1..N]`, habilitando caminhos via Fact nodes.
5. **Cypher injection** â€” Adicionada whitelist `ALLOWED_RELATIONSHIP_TYPES` em `Neo4jAdapter.add_relationship()` no `graph_factory.py`.
6. **requirements.txt** â€” Adicionado `neo4j>=5.20.0`, comentado `spacy==3.8.2` (incompativel com Python 3.14).

### Arquivos Modificados
- `apps/api/app/services/rag/core/neo4j_mvp.py` â€” Fix link_entities, expandir FIND_PATHS
- `apps/api/app/services/rag/core/semantic_extractor.py` â€” RELATED_TO, dual label Entity:SemanticEntity
- `apps/api/app/services/rag/core/graph_factory.py` â€” Whitelist de relationship types
- `apps/api/app/services/rag/core/graph_hybrid.py` â€” Adicionar SemanticEntity label
- `apps/api/requirements.txt` â€” neo4j, spacy comentado

### Arquivos Criados
- `apps/api/scripts/fix_semantic_relationships.py` â€” Migration script (idempotente) para renomear SEMANTICALLY_RELATED->RELATED_TO e SEMANTIC_ENTITY->SemanticEntity no banco
- `apps/api/tests/test_neo4j_mvp.py` â€” 8 testes novos em TestPhase0BugFixes

### Testes
- `pytest tests/test_neo4j_mvp.py::TestPhase0BugFixes -v` â€” 8/8 passed

### Plano Completo
- Phase 0: Fix bugs criticos (CONCLUIDO)
- Phase 1: Schema unificado â€” ArgumentRAG no Neo4j
- Phase 2: Adotar neo4j-graphrag-python (KG Builder)
- Phase 3: ArgumentRAG com LLM (Gemini Flash)
- Phase 4: Production hardening
- Plano detalhado em: `.claude/plans/cuddly-herding-crystal.md`

### Decisoes Tomadas
- ArgumentRAG e feature core: migrar para Neo4j (Phase 1)
- Adotar neo4j-graphrag-python para KG Builder (sem retrievers)
- Extracao de argumentos via LLM (Gemini Flash) com structured output
- Retrieval nao muda (OpenSearch + Qdrant)
- spaCy inviavel em Python 3.14: usar FuzzyMatchResolver (rapidfuzz)

---

## 2026-01-27 â€” Deep Research Hard Mode (Agentic Multi-Provider)

### Objetivo
Criar modo "Deep Research Hard" com loop agentico Claude orquestrando pesquisa paralela em Gemini, ChatGPT, Perplexity + RAG global/local, gerando estudo profissional com citacoes ABNT.

### Arquivos Criados
- `apps/api/app/services/ai/deep_research_hard_service.py` â€” Servico agentico (1091 linhas, 9 tools, 15 iteracoes max)
- `apps/api/app/services/ai/templates/study_template.py` â€” Prompts para estudo ABNT profissional
- `apps/api/app/services/ai/citations/abnt_classifier.py` â€” Classificador e formatador ABNT (web, juris, legislacao, doutrina, artigo)
- `apps/web/src/components/chat/hard-research-viewer.tsx` â€” Viewer multi-provider + eventos agenticos
- `apps/api/tests/test_deep_research_hard.py` â€” 22 testes
- `apps/api/tests/test_abnt_citations.py` â€” 27 testes

### Arquivos Modificados
- `apps/api/app/schemas/chat.py` â€” Campos `deep_research_mode`, `hard_research_providers`
- `apps/api/app/api/endpoints/chats.py` â€” Branch hard mode no SSE + forward de eventos agenticos
- `apps/api/app/services/ai/citations/base.py` â€” Integracao com abnt_classifier
- `apps/api/app/services/ai/deep_research_service.py` â€” Fix temperature para reasoning models OpenAI (o1/o3/o4)
- `apps/web/src/stores/chat-store.ts` â€” Estado hard mode + SSE handler para 18 event types
- `apps/web/src/components/chat/chat-input.tsx` â€” Toggle Standard/Hard + seletor de fontes (5 providers)
- `apps/web/src/components/chat/chat-interface.tsx` â€” Render condicional HardResearchViewer

### Teste de Integracao Real
- Claude agentico: 15 iteracoes, 19 tool calls, 693 eventos SSE, 59.733 chars de estudo
- Gemini: quota esgotada (429) - ambiente
- OpenAI: conta nao verificada para reasoning - ambiente
- RAG: dependencia faltando no venv - ambiente
- Fix: temperature e effort para modelos reasoning OpenAI

### Decisoes
- Reescreveu de fluxo linear para loop agentico completo (usuario pediu interacao mid-research)
- 9 tools: search_gemini, search_perplexity, search_openai, search_rag_global, search_rag_local, analyze_results, ask_user, generate_study_section, verify_citations
- Tools filtradas pela selecao do usuario na UI (checkboxes)

---

## 2026-01-27 â€” Fechamento de 7 Gaps do PLANO_CLAUDE_AGENT_SDK.md

### Contexto
- AnÃ¡lise Codex identificou 7 gaps impedindo plano de estar "cumprido na Ã­ntegra"
- ImplementaÃ§Ã£o em 6 fases paralelas para fechar todos os gaps

### Gaps Fechados

| # | Gap | Status |
|---|-----|--------|
| 1 | jobs.py ignora OrchestrationRouter | âœ… Branch if/else adicionado |
| 2 | Agent IDs nÃ£o estÃ£o no model_registry.py | âœ… 3 entries + helper |
| 3 | workflow.py Ã© placeholder | âœ… ImplementaÃ§Ã£o real com astream() |
| 4 | checkpoint_manager.py e parallel_nodes.py ausentes | âœ… Criados |
| 5 | Componentes frontend nÃ£o plugados | âœ… Plugados no chat-interface |
| 6 | Endpoints /tool-approval e /restore-checkpoint ausentes | âœ… Adicionados |
| 7 | Nenhum teste unitÃ¡rio | âœ… 5 arquivos criados |

### Arquivos Criados

- `app/services/ai/langgraph/improvements/checkpoint_manager.py` â€” CheckpointManager (create/restore/list/delete)
- `app/services/ai/langgraph/improvements/parallel_nodes.py` â€” run_nodes_parallel, fan_out, fan_in
- `app/services/agent_session_registry.py` â€” Dict global de executors ativos por job_id
- `apps/web/src/components/chat/checkpoint-timeline.tsx` â€” Timeline visual de checkpoints
- `tests/test_orchestration_router.py` â€” 17 testes (routing, execute, context)
- `tests/test_claude_agent_executor.py` â€” 17 testes (init, run, tools, iterations, errors)
- `tests/test_context_manager.py` â€” 29 testes (tokens, window, compact, limits)
- `tests/test_permission_manager.py` â€” 25 testes (policy, overrides, rate limit, audit)
- `tests/test_parallel_executor.py` â€” 28 testes (similarity, merge, execution, timeout, cancel)

### Arquivos Modificados

- `app/services/ai/model_registry.py` â€” 3 agent entries (claude-agent, openai-agent, google-agent) + `is_agent_model()` + `AGENT_MODEL_IDS`
- `app/api/endpoints/jobs.py` â€” `_detect_agent_models()` + branch condicional (agent â†’ router, normal â†’ LangGraph intacto)
- `app/services/ai/langgraph/workflow.py` â€” ImplementaÃ§Ã£o real com astream(), SSEEvents, context compaction, checkpoints
- `app/api/endpoints/chats.py` â€” Endpoints POST `/{chat_id}/tool-approval` e `/{chat_id}/restore-checkpoint`
- `app/services/ai/langgraph/improvements/__init__.py` â€” Exports de CheckpointManager e run_nodes_parallel
- `apps/web/src/components/chat/chat-interface.tsx` â€” ToolApprovalModal, ContextIndicatorCompact, CheckpointTimeline plugados

### DecisÃµes TÃ©cnicas

- **jobs.py**: Branch agent termina com `return`, LangGraph permanece 100% intacto (zero regressÃ£o)
- **workflow.py**: Lazy import do `legal_workflow_app`, streaming SSE completo (NODE_START, TOKEN, OUTLINE, HIL_REQUIRED, AUDIT_DONE, NODE_COMPLETE, DONE)
- **Endpoints**: Imports lazy dentro das funÃ§Ãµes para evitar dependÃªncias circulares
- **Frontend**: `ContextIndicatorCompact` substitui indicador bÃ¡sico de token percent

### VerificaÃ§Ãµes
- `python3 -c "import ast; ..."` â€” Syntax OK para todos os arquivos Python
- `tsc --noEmit` â€” Frontend sem erros de tipo
- `eslint` â€” Frontend sem erros de lint

---

## 2026-01-27 â€” MCP Tool Gateway Implementation (UnificaÃ§Ã£o de Tools)

### Contexto
- ImplementaÃ§Ã£o de arquitetura de Tool Gateway usando MCP (Model Context Protocol)
- Unifica todas as tools jurÃ­dicas em um Ãºnico hub consumÃ­vel por Claude, OpenAI e Gemini
- Cada provider tem seu adapter: Claude usa MCP nativo, OpenAI via function adapter, Gemini via ADK

### Arquitetura

```
Tool Gateway (MCP Server)
â”œâ”€â”€ Tool Registry      â†’ Registro unificado de todas as tools
â”œâ”€â”€ Policy Engine      â†’ allow/ask/deny + rate limit + audit
â”œâ”€â”€ MCP Server         â†’ JSON-RPC 2.0 sobre HTTP/SSE
â””â”€â”€ Adapters/
    â”œâ”€â”€ ClaudeMCPAdapter   â†’ MCP nativo
    â”œâ”€â”€ OpenAIMCPAdapter   â†’ Converte MCP â†’ function_calling
    â””â”€â”€ GeminiMCPAdapter   â†’ Converte MCP â†’ FunctionDeclaration + ADK
```

### Arquivos Criados

**app/services/ai/tool_gateway/**
- `__init__.py` â€” Exports do mÃ³dulo
- `tool_registry.py` â€” Registro singleton de tools com metadata (policy, category)
- `policy_engine.py` â€” Enforces policies (ALLOW/ASK/DENY), rate limits, audit log
- `mcp_server.py` â€” Servidor MCP JSON-RPC com tools/list e tools/call
- `adapters/__init__.py` â€” Exports dos adapters
- `adapters/base_adapter.py` â€” Interface abstrata
- `adapters/claude_adapter.py` â€” Thin wrapper (Claude Ã© MCP-native)
- `adapters/openai_adapter.py` â€” Converte MCP â†’ OpenAI functions
- `adapters/gemini_adapter.py` â€” Converte MCP â†’ Gemini + ADK MCPToolset

### Tools Registradas

| Categoria | Tools | Policy |
|-----------|-------|--------|
| **RAG** | search_rag, search_templates, search_jurisprudencia, search_legislacao | ALLOW |
| **DataJud** | consultar_processo_datajud, buscar_publicacoes_djen | ALLOW |
| **Tribunais** | consultar_processo_pje, consultar_processo_eproc | ALLOW |
| **Document** | read_document, edit_document, create_section | ALLOW/ASK |
| **Sensitive** | protocolar_documento | DENY (requer override) |

### Endpoints FastAPI

```
POST /api/mcp/gateway/rpc          â†’ JSON-RPC para tools/list e tools/call
GET  /api/mcp/gateway/sse          â†’ SSE para eventos (approval requests)
GET  /api/mcp/gateway/tools        â†’ Lista tools com filtro por categoria
POST /api/mcp/gateway/approve/{id} â†’ Aprova/rejeita execuÃ§Ã£o pendente
GET  /api/mcp/gateway/audit        â†’ Log de auditoria por tenant
```

### Uso nos Executors

```python
# Claude Agent
adapter = ClaudeMCPAdapter(context={"user_id": user_id, "tenant_id": tenant_id})
tools = await adapter.get_tools()
result = await adapter.handle_tool_use(tool_use_block)

# OpenAI Agent
adapter = OpenAIMCPAdapter(context={...})
tools = await adapter.get_tools()  # Formato function calling
results = await adapter.handle_tool_calls(tool_calls)

# Google Agent
adapter = GeminiMCPAdapter(context={...})
genai_tools = adapter.get_genai_tools()  # google.genai.types.Tool
results = await adapter.handle_function_calls(function_calls)
```

### BenefÃ­cios
1. **Single Source of Truth**: Uma definiÃ§Ã£o de tool para todos os providers
2. **Policies Centralizadas**: allow/ask/deny aplicadas uniformemente
3. **Audit Trail**: Log de todas as execuÃ§Ãµes por tenant
4. **Rate Limiting**: Controle de uso por tool/tenant
5. **Extensibilidade**: Adicionar nova tool = registrar no registry

---

## 2026-01-27 â€” IntegraÃ§Ã£o Tool Gateway nos Executors

### Contexto
- AtualizaÃ§Ã£o dos 3 executores de agentes para usar o Tool Gateway
- CentralizaÃ§Ã£o do carregamento e execuÃ§Ã£o de tools via MCP adapters
- MantÃ©m compatibilidade com mÃ©todos anteriores de carregamento de tools

### Arquivos Modificados

**app/services/ai/claude_agent/executor.py**:
- Import de `ClaudeMCPAdapter` do Tool Gateway
- Novos atributos: `_mcp_adapter`, `_execution_context`
- Novos mÃ©todos:
  - `_get_context()` â€” Retorna contexto atual para Tool Gateway
  - `_init_mcp_adapter()` â€” Inicializa adapter com contexto
  - `load_tools_from_gateway()` â€” Carrega tools via MCP adapter (recomendado)
  - `execute_tool_via_gateway()` â€” Executa tool_use block via Gateway

**app/services/ai/executors/openai_agent.py**:
- Import de `OpenAIMCPAdapter` do Tool Gateway
- Novos atributos: `_mcp_adapter`, `_execution_context`
- Novos mÃ©todos:
  - `_get_context()` â€” Retorna contexto atual
  - `_init_mcp_adapter()` â€” Inicializa adapter
  - `load_tools_from_gateway()` â€” Carrega tools no formato OpenAI via Gateway
  - `execute_tool_calls_via_gateway()` â€” Executa tool_calls via Gateway

**app/services/ai/executors/google_agent.py**:
- Import de `GeminiMCPAdapter` do Tool Gateway
- Novos atributos: `_mcp_adapter`, `_execution_context`
- Novos mÃ©todos:
  - `_get_context()` â€” Retorna contexto atual
  - `_init_mcp_adapter()` â€” Inicializa adapter
  - `load_tools_from_gateway()` â€” Carrega tools no formato Gemini via Gateway
  - `get_genai_tools_from_gateway()` â€” Retorna google.genai.types.Tool via Gateway
  - `execute_function_calls_via_gateway()` â€” Executa function_calls via Gateway

### PadrÃ£o de Uso

```python
# Claude
executor = ClaudeAgentExecutor(config=config)
await executor.load_tools_from_gateway(context={
    "user_id": user_id,
    "tenant_id": tenant_id,
    "case_id": case_id,
})
# Durante execuÃ§Ã£o, tools sÃ£o roteadas pelo MCP server automaticamente

# OpenAI
executor = OpenAIAgentExecutor(config=config)
await executor.load_tools_from_gateway(context={...})
# Tool calls podem ser executados via: execute_tool_calls_via_gateway()

# Google
executor = GoogleAgentExecutor(config=config)
await executor.load_tools_from_gateway(context={...})
# ou: executor.get_genai_tools_from_gateway() para uso direto
```

### DecisÃµes Tomadas
- Manter compatibilidade: mÃ©todos antigos (`load_unified_tools`, `register_tool`) continuam funcionando
- Novos mÃ©todos `*_from_gateway` sÃ£o recomendados pois passam pelo Tool Gateway com policy enforcement
- Context Ã© propagado para o MCP server em cada chamada de tool

---

## 2026-01-27 â€” VerificaÃ§Ã£o de Estado vs Arquitetura Recomendada

### Contexto
- VerificaÃ§Ã£o completa do estado atual do Iudex contra arquitetura recomendada
- AnÃ¡lise de 5 trilhas: Sources, RAG, Generation, Automation, Governance
- VerificaÃ§Ã£o de templates e MCP tribunais

### Resultados da AnÃ¡lise

| Trilha | Status | Detalhes |
|--------|--------|----------|
| **RAG Global + Local** | âœ… 100% | 6 Ã­ndices, hybrid search, CRAG gate |
| **DataJud/DJEN** | âœ… 100% | Sync automÃ¡tico, auto-discovery |
| **Pipeline GeraÃ§Ã£o** | âœ… 100% | 7 fases, 30+ templates, debate multi-agente |
| **Tools/PermissÃµes** | âœ… 100% | 14 tools jurÃ­dicas, hierarquia de permissÃµes |
| **Governance** | âœ… 100% | JSONL audit, multi-tenant, billing |

### Templates JurÃ­dicos
- 30+ templates com checklists, variÃ¡veis, estilos
- Tipos: petiÃ§Ãµes, contratos, recursos, pareceres
- Sistema de versÃµes e customizaÃ§Ã£o por cliente

### Tribunais Service
- **Tipo**: REST API (nÃ£o MCP protocol)
- **Integrados**: PJe, e-Proc
- **TODO**: e-SAJ

### MCP no Frontend
- `chat-store.ts`: estados `mcpToolCalling`, `mcpUseAllServers`, `mcpServerLabels`
- `chat-input.tsx`: toggle para habilitar MCP + seletor de servidores
- `IUDEX_MCP_SERVERS`: variÃ¡vel de ambiente para configuraÃ§Ã£o

### PendÃªncias
- [ ] Implementar integraÃ§Ã£o e-SAJ

---

## 2026-01-27 â€” Multi-Provider Agent Executors (OpenAI + Google)

### Contexto
- ContinuaÃ§Ã£o da sessÃ£o anterior (apÃ³s compactaÃ§Ã£o)
- ImplementaÃ§Ã£o de executores para OpenAI Agents SDK e Google ADK
- Todos os executores compartilham: tools unificadas, permissÃµes, checkpoints, SSE

### Arquivos Criados/Modificados

**executors/base.py** â€” Interface base:
- `AgentProvider` enum (ANTHROPIC, OPENAI, GOOGLE)
- `ExecutorStatus` enum (IDLE, RUNNING, WAITING_APPROVAL, etc.)
- `ExecutorConfig` dataclass (model, max_tokens, permissions, etc.)
- `ExecutorState` dataclass (job_id, tokens, tools, checkpoints)
- `BaseAgentExecutor` ABC (run, resume, register_tool, load_unified_tools)

**executors/openai_agent.py** â€” OpenAI Agents SDK:
- `OpenAIAgentConfig` â€” Config especÃ­fica (model, assistants_api, etc.)
- `OpenAIAgentExecutor` â€” ImplementaÃ§Ã£o completa:
  - `run()` â€” ExecuÃ§Ã£o com agentic loop
  - `_run_with_chat_completions()` â€” Loop com tool calling
  - `_convert_tool_for_openai()` â€” Converte tools para formato OpenAI
  - Suporte a permissÃµes, checkpoints, streaming SSE

**executors/google_agent.py** â€” Google ADK/Gemini:
- `GoogleAgentConfig` â€” Config especÃ­fica (use_vertex, use_adk)
- `GoogleAgentExecutor` â€” ImplementaÃ§Ã£o completa:
  - `_run_with_adk()` â€” ExecuÃ§Ã£o via ADK (AdkApp)
  - `_run_agent_loop()` â€” Loop manual para Gemini direto
  - `_create_adk_tools()` â€” Converte tools para formato ADK
  - Suporte a Vertex AI, checkpoints, streaming

**executors/__init__.py** â€” Factory e exports:
- `get_executor_for_provider()` â€” Factory por nome
- `get_available_providers()` â€” Lista providers disponÃ­veis
- Exports de todas as classes e configs

**orchestration/router.py** â€” Atualizado:
- `ExecutorType` enum com OPENAI_AGENT, GOOGLE_AGENT
- `AGENT_MODELS` set com todos agentes
- `AGENT_TO_EXECUTOR` mapping
- `_is_agent_enabled()` helper
- `determine_executor()` atualizado para todos providers
- `execute()` com routing para todos executors
- `_execute_openai_agent()` â€” ExecuÃ§Ã£o OpenAI
- `_execute_openai_fallback()` â€” Fallback sem SDK
- `_execute_google_agent()` â€” ExecuÃ§Ã£o Google
- `_execute_google_fallback()` â€” Fallback sem ADK

**apps/web/src/config/models.ts** â€” Frontend:
- `AgentId` type expandido: "claude-agent" | "openai-agent" | "google-agent"
- `AGENT_REGISTRY` com configs dos 3 agentes:
  - claude-agent: Claude Agent SDK, tools juridicas
  - openai-agent: OpenAI Agents SDK, checkpoints
  - google-agent: Google ADK, Vertex AI

### Arquitetura Final

```
OrchestrationRouter
â”œâ”€â”€ ExecutorType.CLAUDE_AGENT â†’ ClaudeAgentExecutor
â”œâ”€â”€ ExecutorType.OPENAI_AGENT â†’ OpenAIAgentExecutor
â”œâ”€â”€ ExecutorType.GOOGLE_AGENT â†’ GoogleAgentExecutor
â”œâ”€â”€ ExecutorType.PARALLEL â†’ ParallelExecutor (agent + debate)
â””â”€â”€ ExecutorType.LANGGRAPH â†’ LangGraph workflow
```

Todos os executores:
- Usam `load_unified_tools()` para carregar as 15 tools
- Compartilham `ToolExecutionContext` (user_id, case_id, etc.)
- Emitem eventos SSE padronizados
- Suportam checkpoints/rewind
- Respeitam hierarquia de permissÃµes

### VariÃ¡veis de Ambiente
```env
CLAUDE_AGENT_ENABLED=true
OPENAI_AGENT_ENABLED=true
GOOGLE_AGENT_ENABLED=true
PARALLEL_EXECUTION_ENABLED=true
PARALLEL_EXECUTION_TIMEOUT=300
```

### PrÃ³ximos Passos
- [ ] Testar integraÃ§Ã£o completa com todos os providers
- [ ] Rodar Alembic migration para as 3 novas tabelas
- [ ] Verificar lint/type-check no frontend e backend

---

## 2026-01-27 â€” IntegraÃ§Ã£o Unificada de Tools (SDK + Legal + MCP)

### Contexto
- UnificaÃ§Ã£o de todas as tools para uso por Claude Agent E LangGraph
- AdaptaÃ§Ã£o das tools do Claude SDK para contexto jurÃ­dico
- IntegraÃ§Ã£o com MCP tools existentes

### Arquivos Criados

**shared/unified_tools.py** (15 tools):
| Tool | Categoria | Risco | DescriÃ§Ã£o |
|------|-----------|-------|-----------|
| `read_document` | document | low | LÃª documentos do caso |
| `write_document` | document | medium | Cria/sobrescreve documentos |
| `edit_document` | document | medium | Edita seÃ§Ãµes especÃ­ficas |
| `find_documents` | search | low | Busca por padrÃ£o (glob) |
| `search_in_documents` | search | low | Busca texto (grep) |
| `web_search` | search | low | Pesquisa web |
| `web_fetch` | search | low | Busca URL especÃ­fica |
| `delegate_research` | analysis | medium | Subagentes paralelos |
| `search_jurisprudencia` | search | low | Busca tribunais |
| `search_legislacao` | search | low | Busca leis |
| `verify_citation` | citation | low | Verifica citaÃ§Ãµes |
| `search_rag` | search | low | Busca RAG |
| `create_section` | document | medium | Cria seÃ§Ã£o em documento |
| `mcp_tool_search` | system | low | Descobre MCP tools |
| `mcp_tool_call` | system | medium | Executa MCP tool |

**shared/tool_handlers.py**:
- `ToolExecutionContext` â€” Contexto para execuÃ§Ã£o (user_id, case_id, etc.)
- `ToolHandlers` â€” Classe com handlers para cada tool
- `execute_tool()` â€” FunÃ§Ã£o de conveniÃªncia

**shared/langgraph_integration.py**:
- `LangGraphToolBridge` â€” Bridge entre tools e LangGraph
- `create_tool_node()` â€” Cria node para workflow
- `get_tools_for_langgraph_agent()` â€” Tools + executor para create_react_agent

**shared/startup.py**:
- `init_ai_services()` â€” Inicializa no startup
- `shutdown_ai_services()` â€” Cleanup no shutdown

### Arquivos Modificados
- `shared/__init__.py` â€” Exports de tudo
- `claude_agent/executor.py` â€” MÃ©todo `load_unified_tools()`
- `main.py` â€” Chamadas de init/shutdown no lifespan

### Uso

**No Claude Agent:**
```python
executor = ClaudeAgentExecutor()
executor.load_unified_tools(context=ToolExecutionContext(user_id="..."))
```

**No LangGraph:**
```python
from app.services.ai.shared import create_tool_node, get_tools_for_langgraph_agent

# OpÃ§Ã£o 1: Node para grafo
tool_node = create_tool_node(context)
builder.add_node("tools", tool_node)

# OpÃ§Ã£o 2: Tools + executor para react agent
tools, executor = get_tools_for_langgraph_agent(context)
agent = create_react_agent(model, tools)
```

### PermissÃµes por Risco
- **LOW** â†’ ALLOW (leitura, busca)
- **MEDIUM** â†’ ASK (criaÃ§Ã£o, ediÃ§Ã£o)
- **HIGH** â†’ DENY (delete, bash)

---

## 2026-01-27 â€” VerificaÃ§Ã£o e ConclusÃ£o: Claude Agent SDK + LangGraph Improvements

### Contexto
- VerificaÃ§Ã£o final da implementaÃ§Ã£o completa do plano Claude Agent SDK
- Todas as 5 fases foram concluÃ­das com sucesso

### Arquivos Verificados (Backend)

**Estrutura claude_agent/**
- `__init__.py` â€” Exports principais
- `executor.py` (39KB) â€” ClaudeAgentExecutor com run(), resume(), SSE streaming
- `permissions.py` (25KB) â€” PermissionManager com hierarquia session > project > global
- `tools/legal_research.py` (21KB) â€” Tool de pesquisa jurÃ­dica
- `tools/document_editor.py` (24KB) â€” Tool de ediÃ§Ã£o de documentos
- `tools/citation_verifier.py` (26KB) â€” Tool de verificaÃ§Ã£o de citaÃ§Ãµes
- `tools/rag_search.py` (21KB) â€” Tool de busca RAG

**Estrutura orchestration/**
- `router.py` (34KB) â€” OrchestrationRouter com determine_executor()
- `parallel_executor.py` (33KB) â€” ParallelExecutor com merge via LLM
- `event_merger.py` (5KB) â€” Merge de eventos SSE

**Estrutura langgraph/**
- `workflow.py` (3.5KB) â€” Workflow base
- `improvements/context_manager.py` (25KB) â€” CompactaÃ§Ã£o com tiktoken
- `subgraphs/parallel_research.py` (28KB) â€” Fan-out/fan-in research

**Estrutura shared/**
- `sse_protocol.py` (11KB) â€” SSEEvent com 24+ tipos de eventos
- `context_protocol.py` (10KB) â€” Protocolo de contexto
- `tool_registry.py` (6KB) â€” Registry de tools

**Models/**
- `tool_permission.py` â€” ToolPermission, PermissionMode, PermissionScope
- `conversation_summary.py` â€” ConversationSummary para compactaÃ§Ã£o
- `checkpoint.py` â€” Checkpoint, SnapshotType para rewind

**Migration/**
- `f6c7d8e9a0b1_add_claude_agent_tables.py` â€” Cria 3 tabelas com Ã­ndices

### Arquivos Verificados (Frontend)

- `components/chat/tool-approval-modal.tsx` â€” Modal de aprovaÃ§Ã£o Ask/Allow/Deny
- `components/chat/context-indicator.tsx` â€” Indicador visual de contexto
- `components/chat/model-selector.tsx` â€” SeÃ§Ã£o "Agentes" adicionada
- `config/models.ts` â€” AgentConfig, AGENT_REGISTRY com "claude-agent"
- `stores/chat-store.ts` â€” isAgentMode e estados relacionados

### Testes de Import Realizados
```bash
# Todos OK âœ…
from app.models import ToolPermission, ConversationSummary, Checkpoint
from app.services.ai.shared import SSEEvent, SSEEventType
from app.services.ai.claude_agent import ClaudeAgentExecutor, PermissionManager
from app.services.ai.orchestration import OrchestrationRouter, ParallelExecutor
from app.services.ai.langgraph.improvements import ContextManager
from app.services.ai.langgraph.subgraphs import parallel_research_subgraph
```

### CorreÃ§Ãµes Aplicadas
- Adicionado ConversationSummary e Checkpoint ao models/__init__.py

### Status Final
- **FASE 1**: Estrutura e models âœ…
- **FASE 2**: Claude Agent SDK âœ…
- **FASE 3**: LangGraph Improvements âœ…
- **FASE 4**: OrquestraÃ§Ã£o paralela âœ…
- **FASE 5**: Frontend âœ…

### PrÃ³ximos Passos (Opcional)
1. Rodar migration: `alembic upgrade head`
2. Integrar OrchestrationRouter no job_manager.py
3. Criar checkpoint-timeline.tsx (componente visual de timeline)
4. Testes de integraÃ§Ã£o end-to-end

---

## 2026-01-26 â€” FASE 4: ImplementaÃ§Ã£o do OrchestrationRouter (Task 4.1)

### Contexto
- ImplementaÃ§Ã£o da Fase 4 (Task 4.1) do plano Claude Agent SDK
- Objetivo: implementar o OrchestrationRouter em `apps/api/app/services/ai/orchestration/router.py`

### Arquivos Alterados
- `apps/api/app/services/ai/orchestration/router.py` â€” ImplementaÃ§Ã£o completa do OrchestrationRouter
- `apps/api/app/services/ai/orchestration/__init__.py` â€” AtualizaÃ§Ã£o dos exports

### Classes Implementadas

**ExecutorType (Enum):**
- `LANGGRAPH` â€” Workflow LangGraph existente
- `CLAUDE_AGENT` â€” Claude Agent SDK autÃ´nomo
- `PARALLEL` â€” ExecuÃ§Ã£o paralela (Agent + validaÃ§Ã£o)

**RoutingDecision (dataclass):**
- `executor_type`, `primary_models`, `secondary_models`, `reason`

**OrchestrationContext (dataclass):**
- Contexto completo para execuÃ§Ã£o de prompts
- Campos: prompt, job_id, user_id, chat_id, case_bundle, rag_context, template_structure, extra_instructions, conversation_history, chat_personality, reasoning_level, temperature, web_search, max_tokens

**OrchestrationRouter (classe principal):**
- Ponto de entrada para execuÃ§Ã£o de prompts
- Drop-in replacement no job_manager

### MÃ©todos Implementados

| MÃ©todo | DescriÃ§Ã£o |
|--------|-----------|
| `determine_executor()` | Decide qual executor usar baseado nos modelos e modo |
| `validate_model_selection()` | Valida seleÃ§Ã£o de modelos |
| `execute()` | MÃ©todo principal - executa prompt e retorna stream SSE |
| `_execute_claude_agent()` | Executa usando Claude Agent SDK |
| `_execute_claude_fallback()` | Fallback quando SDK nÃ£o disponÃ­vel |
| `_execute_langgraph()` | Executa usando workflow LangGraph existente |
| `_execute_langgraph_fallback()` | Fallback quando LangGraph nÃ£o disponÃ­vel |
| `_execute_parallel()` | Executa Agent + modelos de validaÃ§Ã£o |
| `_build_legal_system_prompt()` | ConstrÃ³i system prompt jurÃ­dico |
| `_build_full_prompt()` | ConstrÃ³i prompt completo com contexto |

### Regras de DecisÃ£o Implementadas
1. Se mode == "minuta" â†’ sempre LANGGRAPH
2. Se sÃ³ "claude-agent" selecionado â†’ CLAUDE_AGENT
3. Se "claude-agent" + outros modelos â†’ PARALLEL
4. Se sÃ³ modelos normais â†’ LANGGRAPH

### Funcionalidades
- Imports dinÃ¢micos para evitar circular imports
- Fallbacks robustos quando componentes nÃ£o disponÃ­veis
- Singleton via `get_orchestration_router()`
- ConfiguraÃ§Ã£o via variÃ¡veis de ambiente:
  - `CLAUDE_AGENT_ENABLED` (default: true)
  - `PARALLEL_EXECUTION_ENABLED` (default: true)
  - `PARALLEL_EXECUTION_TIMEOUT` (default: 300s)

### Comandos Executados
- `python3 -m py_compile router.py` â€” OK (sintaxe vÃ¡lida)
- `python3 -m py_compile __init__.py` â€” OK (sintaxe vÃ¡lida)

### DecisÃµes Tomadas
- Usar imports dinÃ¢micos para evitar problemas de circular imports
- Implementar fallbacks completos para cada executor
- Manter compatibilidade com job_manager existente via yield de SSEEvent
- Usar OrchestrationContext como abstraÃ§Ã£o unificada de contexto

---

## 2026-01-26 â€” FASE 3: Parallel Research Subgraph (LangGraph)

### Contexto
- ImplementaÃ§Ã£o da Fase 3.2 do plano Claude Agent SDK
- Objetivo: criar subgraph de pesquisa paralela para o workflow LangGraph

### Arquivos Criados
- `apps/api/app/services/ai/langgraph/subgraphs/parallel_research.py` â€” Subgraph completo
- `apps/api/app/services/ai/langgraph/subgraphs/__init__.py` â€” Exports do mÃ³dulo
- `apps/api/tests/test_parallel_research_subgraph.py` â€” Testes unitÃ¡rios (22 testes)

### Arquivos Modificados
- `apps/api/app/services/ai/langgraph/__init__.py` â€” Adicionados exports do subgraph

### Funcionalidades Implementadas

**ResearchState (TypedDict):**
- Campos de input: query, section_title, thesis, input_text
- ConfiguraÃ§Ã£o: job_id, tenant_id, processo_id, top_k, max_context_chars
- Queries customizÃ¡veis por fonte
- Resultados intermediÃ¡rios por fonte
- Output: merged_context, citations_map, sources_used, metrics

**Nodes do Subgraph:**
- `distribute_query` â€” Distribui query principal em queries especÃ­ficas por fonte
- `search_rag_local` â€” Busca em documentos locais (SEI, caso)
- `search_rag_global` â€” Busca em biblioteca global (lei, juris, templates)
- `search_web` â€” Busca web via Perplexity
- `search_jurisprudencia` â€” Busca em base de jurisprudÃªncia
- `parallel_search_node` â€” Executa todas buscas em paralelo via asyncio.gather
- `merge_research_results` â€” Consolida, deduplica, reranqueia e formata contexto

**FunÃ§Ãµes Helper:**
- `_get_rag_manager()` â€” ObtÃ©m RAGManager singleton
- `_get_web_search_service()` â€” ObtÃ©m WebSearchService
- `_get_jurisprudence_service()` â€” ObtÃ©m JurisprudenceService
- `_hash_content()` â€” Hash MD5 para deduplicaÃ§Ã£o
- `_normalize_text()` â€” NormalizaÃ§Ã£o para comparaÃ§Ã£o
- `_is_duplicate()` â€” DetecÃ§Ã£o de duplicados
- `_score_result()` â€” Scoring de relevÃ¢ncia com boosts

**FunÃ§Ã£o de ConveniÃªncia:**
- `run_parallel_research()` â€” Executa subgraph com parÃ¢metros simplificados

### Estrutura do Flow
```
distribute â†’ parallel_search â†’ merge_results â†’ END
                  â†³ asyncio.gather(rag_local, rag_global, web, juris)
```

### DecisÃµes Tomadas
- Fan-out/fan-in via asyncio.gather dentro de um Ãºnico node (compatibilidade LangGraph)
- Resultados organizados por source_type no contexto final
- DeduplicaÃ§Ã£o por hash MD5 + normalizaÃ§Ã£o de texto
- Reranking por score base + term matches + source boost + recency
- Limite de 5 resultados por tipo de fonte
- Max chars configurÃ¡vel (default: 12000)

### Comandos Executados
- `python3 -c "import ast; ast.parse(...)"` â€” Syntax check OK
- `python3 -m pytest tests/test_parallel_research_subgraph.py` â€” 22 passed

### VerificaÃ§Ãµes
- Syntax: OK
- Imports: OK
- Testes: 22/22 passed

---

## 2026-01-26 â€” FASE 2: ImplementaÃ§Ã£o do ClaudeAgentExecutor (Task 2.1)

### Contexto
- ImplementaÃ§Ã£o da Fase 2 (Task 2.1) do plano Claude Agent SDK
- Objetivo: criar o executor principal do agente Claude

### Arquivos Criados

**SSE Protocol (shared/sse_protocol.py):**
- `SSEEventType` - Enum com todos os tipos de eventos SSE
- `SSEEvent` - Dataclass para envelope de eventos
- `ToolApprovalMode` - Enum para modos de permissÃ£o
- Factory functions para criar eventos especÃ­ficos:
  - `agent_iteration_event`, `tool_call_event`, `tool_result_event`
  - `tool_approval_required_event`, `context_warning_event`
  - `checkpoint_created_event`, `token_event`, `thinking_event`
  - `done_event`, `error_event`

**Claude Agent Executor (claude_agent/executor.py):**
- `AgentConfig` - ConfiguraÃ§Ã£o do executor com:
  - model, max_iterations, max_tokens, temperature
  - context_window, compaction_threshold
  - tool_permissions, enable_thinking, enable_checkpoints
- `AgentState` - Estado runtime do agente com:
  - messages, tokens, tools_called, pending_approvals
  - checkpoints, final_output, error, timestamps
- `AgentStatus` - Enum de status (idle, running, waiting_approval, etc.)
- `ClaudeAgentExecutor` - Classe principal com:
  - `run()` - Loop principal do agente (AsyncGenerator[SSEEvent])
  - `resume()` - Continua apÃ³s aprovaÃ§Ã£o de tool
  - `register_tool()` - Registra tools com permissÃµes
  - `cancel()` - Cancela execuÃ§Ã£o
- `create_claude_agent()` - Factory function

### Arquivos Alterados
- `apps/api/app/services/ai/shared/__init__.py` â€” Exports do sse_protocol
- `apps/api/app/services/ai/claude_agent/__init__.py` â€” Adicionados exports do executor

### Funcionalidades Implementadas

**Agent Loop:**
1. Recebe prompt do usuÃ¡rio e contexto
2. Chama Claude com tools habilitados
3. Processa tool_use blocks da resposta
4. Verifica permissÃµes antes de executar (Allow/Deny/Ask)
5. Pausa para aprovaÃ§Ã£o quando permission_mode = "ask"
6. Emite eventos SSE para cada aÃ§Ã£o
7. Cria checkpoints automÃ¡ticos a cada N iteraÃ§Ãµes
8. Monitora uso de contexto e emite warnings

**Permission System:**
- ALLOW: executa automaticamente
- DENY: retorna erro sem executar
- ASK: pausa e aguarda resume()

**Event Flow:**
```
AGENT_START â†’ [AGENT_ITERATION â†’ TOOL_CALL â†’ TOOL_RESULT]* â†’ DONE
           â†³ TOOL_APPROVAL_REQUIRED â†’ (pause) â†’ resume() â†’ ...
```

### Comandos Executados
- `python3 -m py_compile executor.py` â€” OK
- `python3 -m py_compile sse_protocol.py` â€” OK
- `python3 -m py_compile __init__.py` â€” OK (ambos)

### DecisÃµes Tomadas
- Uso de AsyncGenerator para streaming de eventos SSE
- Compatibilidade com formato de eventos do JobManager (v1 envelope)
- SeparaÃ§Ã£o clara entre config (AgentConfig) e state (AgentState)
- Tool executors sÃ£o registrados externamente (dependency injection)
- Checkpoints sÃ£o IDs (persistÃªncia serÃ¡ implementada depois)

### PrÃ³ximos Passos
- [ ] Task 2.2: Criar tools jurÃ­dicos (legal_research.py completo)
- [ ] Task 2.4: Adicionar claude-agent no model_registry.py
- [ ] Task 2.5: Integrar com job_manager.py e jobs.py

---

## 2026-01-26 â€” FASE 2: PermissionManager para Claude Agent SDK

### Contexto
- ImplementaÃ§Ã£o da Fase 2.3 do plano Claude Agent SDK
- Objetivo: criar sistema de permissÃµes granular para tools do agente

### Arquivos Criados
- `apps/api/app/models/tool_permission.py` â€” Modelo SQLAlchemy para permissÃµes
- `apps/api/app/services/ai/claude_agent/permissions.py` â€” PermissionManager completo

### Arquivos Modificados
- `apps/api/app/models/__init__.py` â€” Adicionado exports do ToolPermission
- `apps/api/app/core/database.py` â€” Adicionado import para auto-create da tabela
- `apps/api/app/services/ai/claude_agent/__init__.py` â€” Exporta classes do permissions

### Funcionalidades Implementadas

**ToolPermission (model SQLAlchemy):**
- `id`, `user_id`, `tool_name` â€” identificacao
- `pattern` â€” padrao glob para matching de input
- `mode` â€” PermissionMode enum (allow/deny/ask)
- `scope` â€” PermissionScope enum (session/project/global)

**PermissionManager (classe principal):**
- `check(tool_name, tool_input)` â†’ PermissionCheckResult
- `add_rule(tool_name, mode, scope, pattern)` â†’ PermissionRule
- `allow_once()`, `allow_always()`, `deny_always()` â€” shortcuts

**FunÃ§Ãµes UtilitÃ¡rias:**
- `get_default_permission(tool_name)` â€” retorna default do sistema
- `is_high_risk_tool(tool_name)` â€” detecta tools de alto risco
- `is_read_only_tool(tool_name)` â€” detecta tools apenas leitura

### DecisÃµes Tomadas
- Hierarquia de precedÃªncia: session > project > global > system
- Cache de regras com TTL de 60s (configurÃ¡vel)
- Matching de padrÃµes glob via fnmatch

### VerificaÃ§Ãµes
- Imports: OK
- Testes de unidade inline: OK

---

## 2026-01-26 â€” FASE 5: AtualizaÃ§Ã£o do model-selector.tsx para incluir seÃ§Ã£o Agentes

### Contexto
- ContinuaÃ§Ã£o da implementaÃ§Ã£o da Fase 5 do plano Claude Agent SDK
- Objetivo: atualizar o model-selector.tsx para incluir seÃ§Ã£o de Agentes na UI

### Arquivos Alterados
- `apps/web/src/config/models.ts` â€” Adicionada configuraÃ§Ã£o de Agentes (AgentConfig, AGENT_REGISTRY)
- `apps/web/src/components/chat/model-selector.tsx` â€” Nova seÃ§Ã£o "Agentes" no dropdown de seleÃ§Ã£o

### Novas AdiÃ§Ãµes em models.ts

**Tipos:**
- `AgentId = "claude-agent"` â€” Tipo union para IDs de agentes
- `AgentConfig` â€” Interface de configuraÃ§Ã£o de agentes com campos: id, label, provider, baseModel, isAgent, capabilities, description, icon, tooltip

**Registry:**
- `AGENT_REGISTRY` â€” Registro de agentes disponÃ­veis
- ConfiguraÃ§Ã£o do Claude Agent com capabilities: tools, autonomous, permissions, juridico

**FunÃ§Ãµes Helper:**
- `getAgentConfig(agentId)` â€” ObtÃ©m config de um agente pelo ID
- `listAgents()` â€” Lista todos os agentes disponÃ­veis
- `isAgentId(id)` â€” Type guard para verificar se um ID Ã© de agente

### AlteraÃ§Ãµes no model-selector.tsx

**Imports adicionados:**
- `listAgents, AgentId, getAgentConfig, isAgentId` de `@/config/models`
- Ãcone `Bot` de `lucide-react`
- Componente `Badge` de `@/components/ui/badge`

**Nova UI:**
- SeÃ§Ã£o "Agentes" separada dos "Modelos" no dropdown
- Ãcone Bot com gradiente amber/orange para diferenciaÃ§Ã£o visual
- Badge "Agent" em cada item de agente
- Tooltip rico com descriÃ§Ã£o e lista de capabilities do agente
- AtualizaÃ§Ã£o do botÃ£o trigger para mostrar corretamente quando um agente estÃ¡ selecionado

### Comandos Executados
- `npm run build` â€” OK (compilaÃ§Ã£o bem-sucedida)
- `npx eslint` â€” OK (sem erros de lint)

### DecisÃµes Tomadas
- SeparaÃ§Ã£o visual clara entre Modelos e Agentes usando labels e Ã­cones diferentes
- Uso de Badge com cor amber para indicar itens do tipo Agent
- Tooltip detalhado mostrando capabilities do agente para ajudar usuÃ¡rio a entender funcionalidades
- Mantida compatibilidade com sistema existente de toggleModel

---

## 2026-01-26 â€” FASE 5: AtualizaÃ§Ã£o do chat-store.ts para novos eventos SSE

### Contexto
- ImplementaÃ§Ã£o da Fase 5 do plano Claude Agent SDK
- Objetivo: atualizar o chat-store.ts para suportar os novos eventos SSE do Claude Agent

### Arquivos Alterados
- `apps/web/src/stores/chat-store.ts` â€” Adicionados novos estados e handlers para Claude Agent SDK

### Novos Estados Adicionados (Interface ChatState)

**Claude Agent SDK State:**
- `isAgentMode: boolean` â€” Indica se estÃ¡ em modo agente
- `agentIterationCount: number` â€” Contador de iteraÃ§Ãµes do agente
- `contextUsagePercent: number` â€” Porcentagem de uso do contexto
- `lastSummaryId: string | null` â€” ID do Ãºltimo resumo de compactaÃ§Ã£o
- `pendingToolApproval` â€” Dados da tool aguardando aprovaÃ§Ã£o
- `toolPermissions: Record<string, 'allow' | 'deny' | 'ask'>` â€” PermissÃµes de tools
- `checkpoints: Array<{id, description, createdAt}>` â€” Lista de checkpoints
- `parallelExecution` â€” Estado de execuÃ§Ã£o paralela de tools
- `lastToolCall` â€” Ãšltima chamada de tool e seu status

### Novos Handlers de Eventos SSE

| Evento | AÃ§Ã£o |
|--------|------|
| `agent_iteration` | Incrementa contador de iteraÃ§Ãµes |
| `tool_call` | Atualiza lastToolCall com status pending |
| `tool_result` | Atualiza lastToolCall com resultado |
| `tool_approval_required` | Configura pendingToolApproval |
| `context_warning` | Atualiza contextUsagePercent |
| `compaction_done` | Atualiza lastSummaryId e contextUsagePercent |
| `checkpoint_created` | Adiciona checkpoint Ã  lista |
| `parallel_start` | Inicia estado de execuÃ§Ã£o paralela |
| `parallel_progress` | Atualiza progresso da execuÃ§Ã£o paralela |
| `parallel_complete` | Finaliza execuÃ§Ã£o paralela |

### Novas Actions Implementadas

1. **setIsAgentMode(enabled)** â€” Ativa/desativa modo agente
2. **compactConversation()** â€” Solicita compactaÃ§Ã£o da conversa ao backend
3. **approveToolCall(approved, remember?)** â€” Aprova/nega execuÃ§Ã£o de tool
4. **restoreCheckpoint(checkpointId)** â€” Restaura um checkpoint anterior
5. **setToolPermission(tool, permission)** â€” Define permissÃ£o para uma tool
6. **clearPendingToolApproval()** â€” Limpa aprovaÃ§Ã£o pendente

### Comandos Executados
- `npm run lint --workspace=apps/web` â€” Erros prÃ©-existentes (nÃ£o relacionados)
- `npm run type-check --workspace=apps/web` â€” OK (sem erros)

### Status
- [x] Interface ChatState atualizada com novos tipos
- [x] Valores iniciais adicionados na store
- [x] Handlers de eventos SSE implementados
- [x] Actions implementadas
- [x] Type-check passou

---

## 2026-01-26 â€” FASE 3: ContextManager para LangGraph Improvements

### Contexto
- ImplementaÃ§Ã£o da Fase 3 do plano Claude Agent SDK
- Objetivo: criar gerenciador de contexto no estilo Claude Code

### Arquivos Criados
- `apps/api/app/services/ai/langgraph/__init__.py` â€” MÃ³dulo principal
- `apps/api/app/services/ai/langgraph/improvements/__init__.py` â€” SubmÃ³dulo de melhorias
- `apps/api/app/services/ai/langgraph/improvements/context_manager.py` â€” ContextManager completo
- `apps/api/app/services/ai/langgraph/nodes/__init__.py` â€” Placeholder para nodes

### Funcionalidades Implementadas

**ContextWindow (dataclass):**
- `total_tokens`: Total de tokens no contexto
- `limit`: Limite do modelo
- `threshold`: Threshold de compactaÃ§Ã£o (default 70%)
- `usage_percent`: Porcentagem de uso atual
- `needs_compaction`: Flag calculada automaticamente
- `messages_count` / `tool_results_count`: Contadores

**ContextManager (classe principal):**

1. **count_tokens(messages)** â†’ int
   - Usa tiktoken (cl100k_base encoding) se disponÃ­vel
   - Fallback para estimativa ~3.5 chars/token
   - Suporta formato OpenAI e Anthropic (multimodal)

2. **should_compact(messages)** â†’ bool
   - Verifica se uso >= threshold (70%)
   - Loga informaÃ§Ãµes quando precisa compactar

3. **compact(messages, preserve_recent, preserve_instructions)** â†’ tuple
   - EstratÃ©gia em 2 passos:
     - Passo 1: `_clear_old_tool_results()` - limpa tool_results antigos
     - Passo 2: `_summarize_old_messages()` - resume mensagens antigas
   - Retorna (mensagens compactadas, resumo gerado)

4. **_clear_old_tool_results(messages, keep_recent)** â†’ List
   - Remove conteÃºdo de tool_results antigos
   - MantÃ©m identificadores (tool_call_id, tool_use_id)
   - Preserva mensagens recentes intactas

5. **_generate_summary(messages)** â†’ str
   - Gera resumo usando Claude Haiku (modelo rÃ¡pido)
   - Preserva: decisÃµes, informaÃ§Ãµes crÃ­ticas, contexto necessÃ¡rio
   - Fallback: extraÃ§Ã£o heurÃ­stica de pontos principais

6. **estimate_compaction_savings(messages)** â†’ Dict
   - Estima economia de tokens antes de compactar
   - Ãštil para UI mostrar preview

### Limites por Modelo
```python
MODEL_CONTEXT_LIMITS = {
    "claude-4.5-opus": 200_000,
    "gpt-5.2": 400_000,
    "gemini-2.0-flash": 1_000_000,
    # ... outros modelos
}
```

### DecisÃµes Tomadas
- Usar tiktoken para contagem precisa (fallback para estimativa)
- Threshold padrÃ£o 70% (configurÃ¡vel via env CONTEXT_COMPACTION_THRESHOLD)
- Modelo de resumo: claude-3-haiku-20240307 (rÃ¡pido e barato)
- Singleton via `get_context_manager()` para uso global
- Suporte a injeÃ§Ã£o de cliente Anthropic para testes

### VerificaÃ§Ãµes
- Python syntax: OK (`python3 -m py_compile`)

---

## 2026-01-26 â€” FASE 5: Componente ToolApprovalModal para Claude Agent SDK

### Contexto
- ImplementaÃ§Ã£o da Fase 5.2 do plano Claude Agent SDK
- Objetivo: criar modal de aprovaÃ§Ã£o de tools do agente

### Arquivos Criados
- `apps/web/src/components/chat/tool-approval-modal.tsx` â€” Modal de aprovaÃ§Ã£o de tools

### Funcionalidades Implementadas

**ToolApprovalModal:**
- Exibe nome da tool com label amigÃ¡vel
- Mostra nÃ­vel de risco com cores (low/medium/high):
  - Verde: baixo risco (operaÃ§Ãµes de leitura)
  - Amarelo: mÃ©dio risco (ediÃ§Ãµes)
  - Vermelho: alto risco (bash, file operations)
- Preview do que a tool vai fazer
- ParÃ¢metros de entrada expandÃ­veis/colapsÃ¡veis
- BotÃµes de aÃ§Ã£o:
  - [Aprovar] / [Negar]
  - [Sempre Permitir] / [Sempre Negar]
- Sistema de "lembrar escolha" (session/always)
- Warning especial para tools de alto risco

### Props do Componente
```typescript
interface ToolApprovalModalProps {
  isOpen: boolean;
  onClose: () => void;
  tool: {
    name: string;
    input: Record<string, any>;
    riskLevel: 'low' | 'medium' | 'high';
    description?: string;
  };
  onApprove: (rememberChoice?: 'session' | 'always') => void;
  onDeny: (rememberChoice?: 'session' | 'always') => void;
}
```

### DecisÃµes Tomadas
- Seguir padrÃ£o visual do human-review-modal existente
- Mapeamento de nomes de tools para labels em portuguÃªs
- Cores consistentes com sistema de risco do plano
- Preview automÃ¡tico baseado no tipo de tool
- OpÃ§Ã£o de "lembrar" sÃ³ aparece para aÃ§Ãµes de deny ou para approve em high-risk

### VerificaÃ§Ãµes
- ESLint: passou sem erros
- TypeScript: componente sem erros (erro existente no chat-store.ts de outra feature)

---

## 2026-01-26 â€” FASE 5: Componente ContextIndicator para Claude Agent SDK

### Contexto
- ImplementaÃ§Ã£o da Fase 5 do plano Claude Agent SDK
- Objetivo: criar componente visual para indicar uso da janela de contexto

### Arquivos Criados
- `apps/web/src/components/chat/context-indicator.tsx` â€” Componente principal

### Funcionalidades Implementadas

**ContextIndicator (versÃ£o completa):**
- Barra de progresso com cores dinÃ¢micas:
  - Verde (< 50%): contexto saudÃ¡vel
  - Amarelo (50-70%): uso moderado
  - Vermelho (> 70%): contexto quase cheio
- Tooltip com detalhes (tokens usados / limite)
- BotÃ£o "Compactar" aparece quando > 60%
- Loading state durante compactaÃ§Ã£o
- AnimaÃ§Ã£o suave na barra (transition-all duration-500)

**ContextIndicatorCompact (versÃ£o inline):**
- Badge circular compacto para uso em headers
- Mesmo sistema de cores
- Tooltip com informaÃ§Ãµes detalhadas

### Props do Componente
```typescript
interface ContextIndicatorProps {
  usagePercent: number;
  tokensUsed: number;
  tokenLimit: number;
  onCompact?: () => void;
  isCompacting?: boolean;
}
```

### DecisÃµes Tomadas
- Barra de progresso customizada em vez de usar Progress do shadcn (mais controle sobre cores)
- NÃºmeros formatados com separador de milhar (pt-BR)
- BotÃ£o compactar sÃ³ aparece se handler fornecido E uso > 60%
- VersÃ£o compacta exportada separadamente para flexibilidade

### DependÃªncias Utilizadas
- `@/components/ui/button` â€” BotÃ£o shadcn
- `@/components/ui/tooltip` â€” Tooltip shadcn
- `lucide-react` â€” Ãcones (Loader2, Minimize2)
- `@/lib/utils` â€” FunÃ§Ã£o cn() para classes condicionais

### Testes Executados
- `npm run lint` â€” Componente sem erros (erros existentes sÃ£o de outros arquivos)
- `npx tsc --noEmit` â€” Tipos corretos

---

## 2026-01-26 â€” Fix: DiarizaÃ§Ã£o pyannote nÃ£o funcionava (HF_TOKEN timing bug)

### Contexto
- UsuÃ¡rio perguntou se `mlx_vomo.py` captura diferentes professores em uma mesma aula
- VerificaÃ§Ã£o revelou que diarizaÃ§Ã£o estava desabilitada por bug de timing

### Problema
- `HF_TOKEN` era lido na linha 195 (nÃ­vel de mÃ³dulo) antes do `load_dotenv()` ser chamado
- `load_dotenv()` sÃ³ era executado na linha 4137, dentro do `__init__` da classe
- Resultado: `HF_TOKEN` sempre era `None`, desabilitando diarizaÃ§Ã£o

### Arquivos Alterados
- `mlx_vomo.py` â€” Adicionado `load_dotenv()` no inÃ­cio do mÃ³dulo (linhas 37-41)

### Comandos Executados
- `pip show pyannote.audio` â€” v4.0.3 instalado âœ…
- `python3 -c "from pyannote.audio import Pipeline..."` â€” Pipeline funciona âœ…
- Teste de carregamento completo â€” Pipeline no device MPS âœ…

### Resultado
- DiarizaÃ§Ã£o agora **totalmente funcional**
- Identifica automaticamente diferentes falantes (SPEAKER 1, SPEAKER 2, etc.)
- Tenta mapear speakers para nomes reais de professores via LLM

---

## 2026-01-25 â€” Fase 1: Observabilidade no Pipeline RAG

### Contexto
- ImplementaÃ§Ã£o da Fase 1 do roadmap: Observabilidade
- Objetivo: melhorar mÃ©tricas de tempo por stage e logging estruturado

### Arquivos Alterados

**`apps/api/app/services/rag/pipeline/rag_pipeline.py`**:

1. **MÃ©todo `to_metrics()` na classe `PipelineTrace`** (linhas 448-507):
   - Novo mÃ©todo que retorna dict com mÃ©tricas de latÃªncia por stage
   - Calcula percentis p50/p95/p99 das latÃªncias dos stages
   - Inclui: `trace_id`, `total_duration_ms`, `stage_latencies`, `percentiles`, `stage_count`, `error_count`, `stages_with_errors`, `search_mode`, `final_results_count`
   - Nota: percentis sÃ£o calculados a partir dos stages da trace atual; para p50/p95/p99 acurados entre mÃºltiplas requisiÃ§Ãµes, agregar `stage_latencies` externamente

2. **Logging estruturado no RRF Merge** (linhas 1706-1717):
   - `logger.error()` agora inclui `extra={}` com: stage, lexical_count, vector_count, error_type, trace_id
   - Adicionado `exc_info=True` para stack trace

3. **Logging estruturado no Visual Search** (linhas 1648-1660):
   - `logger.warning()` agora inclui `extra={}` com: stage, query, tenant_id, error_type, trace_id
   - Adicionado `exc_info=True` para stack trace

4. **Logging estruturado no Pipeline principal** (linhas 3120-3135):
   - `logger.error()` agora inclui `extra={}` com: trace_id, query, indices, collections, stages_completed, stages_failed, error_type, total_duration_ms
   - Permite rastreamento completo do estado do pipeline no momento da falha

### DecisÃµes Tomadas
- Percentis calculados inline para evitar dependÃªncia de estatÃ­sticas externas
- Logging estruturado usa formato `extra={}` do Python logging (compatÃ­vel com formatadores JSON)
- Mantida compatibilidade com cÃ³digo existente (sem breaking changes)

### Testes Executados
- `python3 -m py_compile rag_pipeline.py` â€” OK
- Teste manual do mÃ©todo `to_metrics()` â€” OK
- VerificaÃ§Ã£o de imports e estrutura bÃ¡sica â€” OK

---

## 2026-01-25 â€” Fase 2: Error Handling no Pipeline RAG

### Contexto
- ImplementaÃ§Ã£o da Fase 2 do roadmap de otimizaÃ§Ã£o do pipeline RAG
- Objetivo: substituir `except Exception` genÃ©ricos por exceÃ§Ãµes especÃ­ficas
- Manter comportamento fail-soft para componentes opcionais
- Propagar erros para componentes obrigatÃ³rios quando `fail_open=False`

### Arquivos Criados

**`apps/api/app/services/rag/pipeline/exceptions.py`**:
- Hierarquia completa de exceÃ§Ãµes customizadas
- Classes: `RAGPipelineError` (base), `SearchError`, `LexicalSearchError`, `VectorSearchError`, `EmbeddingError`, `RerankerError`, `CRAGError`, `GraphEnrichError`, `CompressionError`, `ExpansionError`, `QueryExpansionError`, `ComponentInitError`
- Cada exceÃ§Ã£o inclui:
  - `message`: descriÃ§Ã£o do erro
  - `component`: nome do componente que falhou
  - `context`: dict com informaÃ§Ãµes adicionais
  - `recoverable`: indica se o pipeline pode continuar
  - `cause`: exceÃ§Ã£o original encadeada
  - `to_dict()`: serializaÃ§Ã£o para logging/tracing

### Arquivos Alterados

**`apps/api/app/services/rag/pipeline/__init__.py`**:
- Adicionado import e export de todas as exceÃ§Ãµes customizadas

**`apps/api/app/services/rag/pipeline/rag_pipeline.py`**:

1. **Import de exceÃ§Ãµes** (linha ~129): Importadas todas as exceÃ§Ãµes de `exceptions.py`

2. **Query Enhancement** (linha ~1096): `except Exception` agora:
   - Re-raises `QueryExpansionError` se jÃ¡ for nossa exceÃ§Ã£o
   - Loga com contexto extra (query, hyde, multiquery)
   - Raises `QueryExpansionError` com causa encadeada quando `fail_open=False`

3. **Lexical Search - per query** (linha ~1332): Logging melhorado com contexto

4. **Lexical Search - stage** (linha ~1355): `except Exception` agora:
   - Re-raises `LexicalSearchError` se jÃ¡ for nossa exceÃ§Ã£o
   - Loga com contexto (indices, queries_count)
   - Raises `LexicalSearchError` com causa encadeada

5. **Vector Search - per query** (linha ~1528):
   - Re-raises `EmbeddingError` (indica problemas de modelo)
   - Logging melhorado com contexto

6. **Vector Search - stage** (linha ~1551): `except Exception` agora:
   - Re-raises `VectorSearchError` se jÃ¡ for nossa exceÃ§Ã£o
   - Loga com contexto (collections, queries_count)
   - Raises `VectorSearchError` com causa encadeada

7. **CRAG Gate** (linha ~2075): `except Exception` agora:
   - Re-raises `CRAGError` se jÃ¡ for nossa exceÃ§Ã£o
   - Loga com contexto (results_count, decision, retry_count)
   - Raises `CRAGError` com causa encadeada

8. **Reranker** (linha ~2158): `except Exception` agora:
   - Re-raises `RerankerError` se jÃ¡ for nossa exceÃ§Ã£o
   - Loga com contexto (candidates_count, model)
   - Raises `RerankerError` com causa encadeada

9. **Chunk Expansion** (linha ~2239): `except Exception` agora:
   - Re-raises `ExpansionError` se jÃ¡ for nossa exceÃ§Ã£o
   - Loga com contexto (chunks_count, window, max_extra)
   - Raises `ExpansionError` com causa encadeada

10. **Compression** (linha ~2324): `except Exception` agora:
    - Re-raises `CompressionError` se jÃ¡ for nossa exceÃ§Ã£o
    - Loga com contexto (results_count, token_budget)
    - Raises `CompressionError` com causa encadeada

11. **Graph Enrich** (linha ~2700): `except Exception` agora:
    - Re-raises `GraphEnrichError` para casos crÃ­ticos
    - Loga com contexto detalhado
    - MantÃ©m fail-soft (retorna contexto parcial)

### DecisÃµes TÃ©cnicas
- **Re-raise pattern**: Cada handler verifica se jÃ¡ Ã© nossa exceÃ§Ã£o antes de wrapping
- **Fail-soft preservado**: Componentes opcionais (graph, visual) continuam nÃ£o propagando
- **Contexto rico**: Cada exceÃ§Ã£o carrega informaÃ§Ãµes Ãºteis para debugging
- **Causa encadeada**: ExceÃ§Ã£o original preservada via `cause` parameter
- **Logging estruturado**: Uso de `extra={}` para contexto adicional no logger

### VerificaÃ§Ãµes
- âœ… Sintaxe Python verificada para `exceptions.py`
- âœ… Sintaxe Python verificada para `rag_pipeline.py`
- âœ… Sintaxe Python verificada para `__init__.py`
- âœ… Teste manual de hierarquia de exceÃ§Ãµes funcionando

### PrÃ³ximos Passos (Fase 3+)
- Adicionar mÃ©tricas de erro por tipo de exceÃ§Ã£o
- Integrar com observabilidade (traces, spans)
- Considerar circuit breaker para falhas recorrentes

---

## 2026-01-25 â€” Fase 4: Async para Chamadas SÃ­ncronas no Pipeline RAG

### Contexto
- ImplementaÃ§Ã£o da Fase 4 do roadmap de otimizaÃ§Ã£o do pipeline RAG
- Objetivo: envolver chamadas sÃ­ncronas que bloqueiam o event loop com `asyncio.to_thread()`
- OperaÃ§Ãµes que demoram >10ms (embedding, reranking, extraÃ§Ã£o de entidades, compressÃ£o)

### Arquivos Alterados

**`apps/api/app/services/rag/pipeline/rag_pipeline.py`**:

1. **`_stage_vector_search` (linha ~1374)**: `self._embeddings.embed_query(query)` agora usa `asyncio.to_thread`

2. **`_add_graph_chunks_to_results` (linha ~1670)**: `Neo4jEntityExtractor.extract(query)` agora usa `asyncio.to_thread`

3. **`_stage_crag_gate` (linha ~1901)**: Embedding de queries no retry CRAG agora usa `asyncio.to_thread`

4. **`_stage_rerank` (linhas ~2027-2032)**: `self._reranker.rerank()` agora usa `asyncio.to_thread`

5. **`_stage_compress` (linhas ~2158-2162)**: `self._compressor.compress_results()` agora usa `asyncio.to_thread`

6. **`_stage_graph_enrich` (linhas ~2410, 2416)**: `Neo4jEntityExtractor.extract()` para query e resultados agora usa `asyncio.to_thread`

### DecisÃµes TÃ©cnicas
- **asyncio.to_thread**: Escolhido para mover operaÃ§Ãµes CPU-bound ou sÃ­ncronas de I/O para threads do pool padrÃ£o
- **Keyword args**: Para `rerank` e `compress_results`, parÃ¢metros foram convertidos de keyword para positional pois `to_thread` nÃ£o suporta kwargs diretamente
- **Import asyncio**: JÃ¡ estava presente no arquivo (linha 34)

### VerificaÃ§Ãµes
- âœ… Sintaxe Python verificada
- âœ… 5 testes RAG passando:
  - `test_corrective_flags_do_not_force_legacy`
  - `test_agentic_routing_applies_to_new_pipeline`
  - `test_history_rewrite_applies_to_new_pipeline`
  - `test_dense_research_increases_top_k_in_new_pipeline`
  - `test_new_pipeline_uses_legacy_env_defaults_when_callers_do_not_override`

---

## 2026-01-25 â€” Fase 3: ParalelizaÃ§Ã£o no Pipeline RAG

### Contexto
- ImplementaÃ§Ã£o da Fase 3 do roadmap de otimizaÃ§Ã£o do pipeline RAG
- Objetivo: executar busca lexical e vetorial em paralelo usando `asyncio.gather`
- Controle de concorrÃªncia com semÃ¡foro para limitar operaÃ§Ãµes simultÃ¢neas

### Arquivos Alterados

**`apps/api/app/services/rag/pipeline/rag_pipeline.py`**:

1. **`__init__` (linha ~637)**: Adicionado `self._search_semaphore = asyncio.Semaphore(5)` para controle de concorrÃªncia

2. **`search()` (linhas ~2701-2758)**: Refatorado Stages 2 e 3 para execuÃ§Ã£o paralela:
   - Queries de citaÃ§Ã£o (`is_citation_query`) continuam executando apenas busca lexical
   - Para queries normais, `_stage_lexical_search` e `_stage_vector_search` agora executam em paralelo via `asyncio.gather`
   - Tratamento de exceÃ§Ãµes com `return_exceptions=True` - se uma busca falhar, a outra continua funcionando
   - Erros sÃ£o logados e adicionados ao trace, mas nÃ£o quebram o pipeline
   - SemÃ¡foro limita a 5 operaÃ§Ãµes de busca concorrentes para evitar sobrecarga

### DecisÃµes TÃ©cnicas
- **SemÃ¡foro**: Limite de 5 operaÃ§Ãµes foi escolhido como balanÃ§o entre performance e uso de recursos
- **Tratamento de erros**: Falha graceful - se lexical falha retorna `[]`, se vector falha retorna `[]`
- **Compatibilidade**: LÃ³gica de `skip_vector` e `is_citation_query` preservada

### VerificaÃ§Ãµes
- âœ… Sintaxe Python verificada (`py_compile`)
- âœ… Testes RAG passando (`test_rag_corrective_new_pipeline.py`)

---

## 2026-01-25 â€” MigraÃ§Ã£o para Neo4j Visualization Library (NVL)

### Contexto
- UsuÃ¡rio perguntou qual Ã© a biblioteca de visualizaÃ§Ã£o mais avanÃ§ada recomendada pela Neo4j
- Pesquisa identificou NVL como a biblioteca oficial que alimenta Bloom e Neo4j Browser
- MigraÃ§Ã£o completa de react-force-graph-2d para @neo4j-nvl/react

### Pacotes Instalados
```bash
npm install @neo4j-nvl/react @neo4j-nvl/interaction-handlers @neo4j-nvl/base
```

### Arquivos Alterados

**`apps/web/src/app/(dashboard)/graph/page.tsx`**:
- MigraÃ§Ã£o completa para NVL (Neo4j Visualization Library)
- `InteractiveNvlWrapper` como componente principal
- FunÃ§Ãµes de transformaÃ§Ã£o: `transformToNvlNodes`, `transformToNvlRelationships`
- Handlers atualizados para API NVL:
  - `onNodeClick(node: Node, hitTargets: HitTargets, evt: MouseEvent)`
  - `onHover(element, hitTargets, evt)` com acesso via `hitTargets.nodes[0].data.id`
- Zoom via `nvlRef.current.setZoom()` e `nvlRef.current.fit()`
- Layout force-directed nativo

### CaracterÃ­sticas NVL
- **Renderer**: WebGL (fallback canvas)
- **Layout**: Force-directed nativo otimizado
- **InteraÃ§Ã£o**: Clique, hover, drag, zoom, pan
- **Estilos**: Cores por grupo, tamanho por relevÃ¢ncia, highlight de seleÃ§Ã£o/path

### Tipos Importantes
```typescript
// Node da NVL
interface Node {
  id: string;
  color?: string;
  size?: number;
  caption?: string;
  captionAlign?: 'top' | 'bottom' | 'center';
  selected?: boolean;
  pinned?: boolean;
}

// HitTargetNode (retornado em eventos de hover)
interface HitTargetNode {
  data: Node;           // <- ID estÃ¡ aqui: data.id
  targetCoordinates: Point;
  pointerCoordinates: Point;
}
```

### VerificaÃ§Ãµes
- âœ… Type check passou (web app)
- âœ… Lint passou (graph files)

---

## 2026-01-25 â€” Melhorias na PÃ¡gina de Grafo + AutenticaÃ§Ã£o

### Contexto
- AnÃ¡lise de diferenÃ§as entre frontend e backend da pÃ¡gina de grafo
- ImplementaÃ§Ã£o de autenticaÃ§Ã£o nos endpoints do grafo
- Melhorias de performance e UX com React Query

### Arquivos Alterados

**`apps/api/app/api/endpoints/graph.py`**:
- Adicionada autenticaÃ§Ã£o via `get_current_user` em todos os endpoints
- `tenant_id` agora Ã© extraÃ­do automaticamente do usuÃ¡rio logado
- Removido parÃ¢metro `tenant_id` dos query params (seguranÃ§a)

**`apps/web/src/lib/use-graph.ts`** (NOVO):
- React Query hooks para cache das chamadas de API
- `useGraphData`, `useGraphEntity`, `useGraphRemissoes`
- `useSemanticNeighbors` (lazy loading)
- `useGraphPath`, `useGraphStats`
- Prefetch functions para hover preview
- Stale-while-revalidate caching

**`apps/web/src/lib/api-client.ts`**:
- Tipos enriquecidos para `/path` (nodes/edges detalhados)

**`apps/web/src/app/(dashboard)/graph/page.tsx`**:
- Migrado para React Query hooks
- Novo "Modo Caminho" para encontrar path entre 2 nÃ³s
- VisualizaÃ§Ã£o enriquecida do caminho com detalhes dos nÃ³s
- Tabs para Info/RemissÃµes/Vizinhos SemÃ¢nticos
- Lazy loading de vizinhos semÃ¢nticos (sÃ³ carrega na aba)
- Prefetch on hover para UX mais rÃ¡pida
- Skeletons para loading states

**`apps/web/src/components/ui/skeleton.tsx`** (NOVO):
- Componente shadcn/ui para loading states

### Melhorias Implementadas

1. **SeguranÃ§a**: Endpoints agora requerem autenticaÃ§Ã£o
2. **Cache**: React Query com stale-while-revalidate (2-5 min)
3. **VisualizaÃ§Ã£o de Path**: Mostra nÃ³s intermediÃ¡rios e chunks
4. **Lazy Loading**: Vizinhos carregam sob demanda
5. **Prefetch**: Dados prÃ©-carregados ao passar o mouse

### Testes
- 18 testes passando (test_hybrid_reranker.py)
- Type check OK

---

## 2026-01-25 â€” Reranker HÃ­brido: Local + Cohere com Boost JurÃ­dico

### Contexto
- ImplementaÃ§Ã£o de reranker hÃ­brido para SaaS em produÃ§Ã£o
- Local cross-encoder para desenvolvimento (grÃ¡tis)
- Cohere Rerank v3 para produÃ§Ã£o (escala sem GPU)
- Ambos aplicam boost para termos jurÃ­dicos brasileiros

### Arquivos Criados/Alterados

**`apps/api/app/services/rag/core/cohere_reranker.py`** (NOVO):
- `CohereReranker`: integraÃ§Ã£o com Cohere Rerank API
- `CohereRerankerConfig`: configuraÃ§Ã£o (modelo, API key, etc)
- Boost jurÃ­dico aplicado **pÃ³s-Cohere** (Cohere score + legal boost)
- Retry automÃ¡tico com backoff exponencial

**`apps/api/app/services/rag/core/hybrid_reranker.py`** (NOVO):
- `HybridReranker`: seleÃ§Ã£o automÃ¡tica entre Local e Cohere
- `RerankerProvider`: enum (auto, local, cohere)
- Auto: dev=local, prod=cohere (se disponÃ­vel)
- Fallback para local se Cohere falhar

**`apps/api/app/services/rag/config.py`**:
- Novas configuraÃ§Ãµes:
  - `rerank_provider`: "auto" | "local" | "cohere"
  - `cohere_rerank_model`: "rerank-multilingual-v3.0"
  - `cohere_fallback_to_local`: true
  - `rerank_legal_boost`: 0.1

**`apps/api/app/services/rag/core/reranker.py`**:
- Corrigido padrÃ£o de Lei (Lei nÂº 14.133)

**`apps/api/tests/rag/test_hybrid_reranker.py`** (NOVO):
- 18 testes para providers, config, legal boost

### ConfiguraÃ§Ã£o

```env
# Desenvolvimento (padrÃ£o)
RERANK_PROVIDER=auto
ENVIRONMENT=development
# Usa cross-encoder local (grÃ¡tis)

# ProduÃ§Ã£o
RERANK_PROVIDER=auto
ENVIRONMENT=production
COHERE_API_KEY=sua-chave
# Usa Cohere (se API key presente)
```

### Uso

```python
from app.services.rag.core.hybrid_reranker import get_hybrid_reranker

reranker = get_hybrid_reranker()
result = reranker.rerank(query, results)

print(f"Provider: {result.provider_used}")
print(f"Fallback usado: {result.used_fallback}")
```

### Fluxo do Boost JurÃ­dico

```
Query + Docs â†’ Cohere Rerank â†’ cohere_score
                                    â†“
                           + legal_boost (se match padrÃµes)
                                    â†“
                              final_score
```

### PadrÃµes JurÃ­dicos Detectados
- `art. 5`, `Â§ 1Âº`, `inciso I`
- `Lei nÂº 14.133`, `Lei 8.666`
- `SÃºmula 331`, `STF`, `STJ`, `TST`
- CNJ: `0000000-00.0000.0.00.0000`
- `CÃ³digo Civil`, `habeas corpus`, etc.

### Testes
```
pytest tests/rag/test_hybrid_reranker.py -v
======================= 18 passed =======================
```

---

## 2026-01-25 â€” OCR HÃ­brido com Fallback para Cloud

### Contexto
- ImplementaÃ§Ã£o de estratÃ©gia hÃ­brida de OCR para produÃ§Ã£o
- Tesseract gratuito para volume baixo, cloud OCR para escala
- Suporte a Azure Document Intelligence, Google Vision e Gemini Vision

### Arquivos Criados/Alterados

**`apps/api/app/services/ocr_service.py`** (NOVO):
- `OCRProvider` enum: pdfplumber, tesseract, azure, google, gemini
- `OCRResult` dataclass: resultado com texto, provider, pÃ¡ginas, erro
- `OCRUsageTracker`: rastreia volume diÃ¡rio para decisÃ£o de fallback
- `HybridOCRService`: serviÃ§o principal com estratÃ©gia inteligente
  - PDF com texto selecionÃ¡vel â†’ pdfplumber (gratuito, rÃ¡pido)
  - Volume baixo â†’ Tesseract local
  - Volume alto ou fallback â†’ Cloud OCR

**`apps/api/app/core/config.py`**:
- Novas configuraÃ§Ãµes de OCR:
  - `OCR_PROVIDER`: provider padrÃ£o (tesseract)
  - `OCR_CLOUD_THRESHOLD_DAILY`: threshold para cloud (1000 pÃ¡ginas)
  - `AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT/KEY`
  - `GOOGLE_VISION_ENABLED`, `GEMINI_OCR_ENABLED`
  - `GEMINI_OCR_MODEL`: modelo para OCR (gemini-2.0-flash)

**`apps/api/app/services/document_processor.py`**:
- `extract_text_from_image`: usa HybridOCRService com fallback
- `extract_text_from_pdf_with_ocr`: usa HybridOCRService com fallback
- `_extract_text_from_pdf_tesseract`: implementaÃ§Ã£o original preservada

**`apps/api/tests/test_ocr_service.py`** (NOVO):
- 17 testes para OCRProvider, OCRResult, OCRUsageTracker, HybridOCRService
- Testes de isolamento com reset de singleton

### EstratÃ©gia de OCR

```
Upload â†’ Ã‰ PDF com texto? â†’ Sim â†’ pdfplumber (grÃ¡tis)
                         â†’ NÃ£o â†’ Volume < 1000/dia? â†’ Sim â†’ Tesseract (grÃ¡tis)
                                                    â†’ NÃ£o â†’ Cloud OCR (Azure/Gemini)
```

### ComparaÃ§Ã£o de Custos
| Provider | Custo/1K pÃ¡ginas | Quando usar |
|----------|------------------|-------------|
| pdfplumber | $0 | PDFs com texto selecionÃ¡vel |
| Tesseract | $0 | Volume < 1000 pÃ¡ginas/dia |
| Azure | ~$1.50 | Alta precisÃ£o, formulÃ¡rios |
| Gemini | ~$0.04/img | Melhor custo-benefÃ­cio cloud |

### Testes
```
pytest tests/test_ocr_service.py -v
======================= 17 passed in 0.17s =======================
```

---

## 2026-01-25 â€” Semantic Extractor: Neo4j Vector Index Native

### Contexto
- RefatoraÃ§Ã£o do SemanticEntityExtractor para usar Ã­ndice vetorial nativo do Neo4j
- Alinhamento com documentaÃ§Ã£o oficial Neo4j 5.x para vector search
- Sistema de fallback robusto quando Neo4j nÃ£o estÃ¡ disponÃ­vel

### Arquivos Alterados

**`apps/api/app/services/rag/core/semantic_extractor.py`:**
- Corrigido `CHECK_VECTOR_INDEX` query (SHOW INDEXES nÃ£o suporta RETURN)
- Corrigido `_create_vector_index()` para usar DDL com valores hardcoded (parÃ¢metros nÃ£o funcionam em DDL)
- Prioridade de index creation: CALL syntax â†’ DDL syntax
- Adicionado `LocalEmbeddingsService` (sentence-transformers, sem API key)
- Adicionado `GeminiEmbeddingsService` (fallback quando OpenAI indisponÃ­vel)
- Prioridade de embeddings: OpenAI â†’ Gemini â†’ Local sentence-transformers

### ConfiguraÃ§Ã£o Neo4j Aura
```
NEO4J_URI=neo4j+s://24df7574.databases.neo4j.io
NEO4J_PASSWORD=***
RAG_GRAPH_BACKEND=neo4j
```

### Resultado dos Testes
```
Mode: NEO4J (Ã­ndice vetorial nativo)
Entidades encontradas:
- PrincÃ­pio da Boa-FÃ© Objetiva: 0.789
- Boa-FÃ© Objetiva: 0.779
- Enriquecimento Sem Causa: 0.772
- PrescriÃ§Ã£o: 0.746
```

### Performance
- Neo4j native: ~50ms per query (vector similarity via `db.index.vector.queryNodes`)
- Fallback numpy: ~100ms per query (local cosine similarity)

---

## 2026-01-25 â€” ExtraÃ§Ã£o de RemissÃµes entre Dispositivos Legais

### Contexto
- Adicionado extrator de remissÃµes (cross-references) entre dispositivos legais
- Complementa o LegalEntityExtractor existente com detecÃ§Ã£o de relaÃ§Ãµes

### Arquivo Alterado

**`apps/api/app/services/rag/core/neo4j_mvp.py`:**
- Adicionado `REMISSION_PATTERNS` - regex para padrÃµes de remissÃ£o
- Adicionado `extract_remissions()` - extrai relaÃ§Ãµes entre dispositivos
- Adicionado `extract_with_remissions()` - retorna entidades + remissÃµes

### Tipos de RemissÃµes Detectadas
| Tipo | PadrÃ£o |
|------|--------|
| `combinado_com` | c/c, em conjunto com |
| `nos_termos_de` | nos termos do, conforme |
| `aplica_se` | aplica-se o |
| `remete_a` | remete ao |
| `por_forca_de` | por forÃ§a do |
| `sequencia` | arts. X e Y |

### Uso
```python
from app.services.rag.core.neo4j_mvp import LegalEntityExtractor

result = LegalEntityExtractor.extract_with_remissions(text)
# result['entities'] = dispositivos legais
# result['remissions'] = relaÃ§Ãµes entre dispositivos
```

---

## 2026-01-25 â€” IntegraÃ§Ã£o: ColPali no RAG Pipeline + IngestÃ£o Visual

### Contexto
- IntegraÃ§Ã£o do ColPali Visual Retrieval como stage opcional no RAG Pipeline
- Visual search roda em paralelo com lexical/vector search quando habilitado
- Task Celery para indexaÃ§Ã£o visual assÃ­ncrona de PDFs
- IntegraÃ§Ã£o com endpoint de upload de documentos

### Arquivos Alterados

**`apps/api/app/services/rag/pipeline/rag_pipeline.py`:**
- `PipelineStage` enum: Adicionado `VISUAL_SEARCH = "visual_search"`
- `RAGPipeline.__init__`: Adicionado parÃ¢metro `colpali`
- `_ensure_components`: InicializaÃ§Ã£o lazy do ColPali quando `COLPALI_ENABLED=true`
- `_stage_visual_search`: Novo mÃ©todo que executa busca visual via ColPali
- `_merge_visual_results`: Merge de resultados visuais com weight reduzido (0.3)
- `_stage_merge_rrf`: Atualizado para aceitar `visual_results` opcional
- `search` e `search_sync`: Adicionado parÃ¢metro `visual_search_enabled`

**`apps/api/app/workers/tasks/document_tasks.py`:**
- Nova task `visual_index_task`: Indexa PDF visualmente usando ColPali

**`apps/api/app/workers/tasks/__init__.py`:**
- Export de `visual_index_task`

**`apps/api/app/api/endpoints/documents.py`:**
- Import de `visual_index_task`
- Flag `visual_index` no metadata do upload enfileira indexaÃ§Ã£o visual

### DependÃªncias Instaladas
```bash
pip install colpali-engine torch pillow pymupdf
```

### Fluxo do Pipeline (Atualizado)
```
Query -> Query Enhancement -> Lexical Search -> Vector Search (condicional)
     -> Visual Search (quando habilitado) -> Merge RRF (inclui visuais)
     -> CRAG Gate -> Rerank -> Expand -> Compress -> Graph Enrich -> Trace
```

### Uso - Busca
```python
# Via parÃ¢metro (override config)
result = await pipeline.search("tabela de honorÃ¡rios", visual_search_enabled=True)

# Via env var (default)
# COLPALI_ENABLED=true
result = await pipeline.search("grÃ¡fico de custos")
```

### Uso - IngestÃ£o Visual (Upload)
```bash
# Upload com indexaÃ§Ã£o visual
curl -X POST /api/documents/upload \
  -F "file=@documento.pdf" \
  -F 'metadata={"visual_index": true, "tenant_id": "tenant1"}'
```

O documento serÃ¡:
1. Processado normalmente (extraÃ§Ã£o de texto, OCR se necessÃ¡rio)
2. Enfileirado para indexaÃ§Ã£o visual via task Celery `visual_index`
3. PÃ¡ginas indexadas no Qdrant collection `visual_docs`

### Resultado dos Testes
- ColPali tests: **18 passed**
- Pipeline imports: **OK**
- Syntax check: **OK**
- Task import: **OK**

### PrÃ³ximos Passos
- Criar testes de integraÃ§Ã£o ColPali + Pipeline
- Testar com PDFs reais (tabelas, grÃ¡ficos, infogrÃ¡ficos)
- Adicionar endpoint dedicado `/api/rag/visual/index` para reindexar documentos existentes

---

## 2026-01-25 â€” ImplementaÃ§Ã£o: ColPali Visual Document Retrieval Service

### Contexto
- ImplementaÃ§Ã£o do serviÃ§o ColPali para retrieval visual de documentos
- PDFs com tabelas, figuras, infogrÃ¡ficos - sem depender de OCR

### Arquivos Criados
- `apps/api/app/services/rag/core/colpali_service.py` â€” ServiÃ§o completo:
  - ColPaliConfig com 15+ parÃ¢metros configurÃ¡veis
  - ColPaliService com lazy loading de modelo
  - Suporte a ColPali, ColQwen2.5, ColSmol
  - Late interaction (MaxSim) para scoring
  - IntegraÃ§Ã£o com Qdrant para armazenamento
  - Patch highlights para explainability
- `apps/api/tests/test_colpali_service.py` â€” 18 testes unitÃ¡rios

### Arquivos Alterados
- `apps/api/app/services/rag/core/__init__.py` â€” ExportaÃ§Ãµes adicionadas

### Resultado dos Testes
**18 passed, 0 failed**

### ConfiguraÃ§Ã£o (Environment Variables)
```bash
COLPALI_ENABLED=true
COLPALI_MODEL=vidore/colqwen2.5-v1
COLPALI_DEVICE=auto
COLPALI_BATCH_SIZE=4
COLPALI_QDRANT_COLLECTION=visual_docs
```

### Uso
```python
from app.services.rag.core import get_colpali_service

service = get_colpali_service()
await service.index_pdf("/path/to/doc.pdf", "doc1", "tenant1")
results = await service.search("tabela de custos", "tenant1")
```

### PrÃ³ximos Passos
- Integrar com RAG pipeline (stage adicional)
- Criar endpoint de API para ingestÃ£o visual
- Testar com PDFs reais

---

## 2026-01-25 â€” VerificaÃ§Ã£o: Retrieval HÃ­brido Neo4j (Fase 1 Completa)

### Contexto
- VerificaÃ§Ã£o das alteraÃ§Ãµes implementadas seguindo guia de arquitetura hÃ­brida
- ValidaÃ§Ã£o de consistÃªncia entre neo4j_mvp.py, rag_pipeline.py, graph.py, rag.py

### Resultado: **27 testes passaram, 0 falhas**

### Componentes Verificados

| Arquivo | Status | Detalhes |
|---------|--------|----------|
| `neo4j_mvp.py` | âœ… | FIND_PATHS com path_nodes/edges, security trimming, fulltext/vector indexes |
| `rag_pipeline.py` | âœ… | GraphContext.paths, RAG_LEXICAL_BACKEND, RAG_VECTOR_BACKEND |
| `graph.py` | âœ… | Security em 7+ endpoints (tenant_id, scope, sigilo) |
| `rag.py` | âœ… | RAG_GRAPH_INGEST_ENGINE com mvp/graph_rag/both |

### Fase 1 Implementada
- âœ… Neo4jMVP como camada de grafo (multi-hop 1-2 hops)
- âœ… Paths explicÃ¡veis (path_nodes, path_edges)
- âœ… Security: allowed_scopes, group_ids, case_id, user_id, sigilo
- âœ… Flags: NEO4J_FULLTEXT_ENABLED, NEO4J_VECTOR_INDEX_ENABLED
- âœ… Routing: RAG_LEXICAL_BACKEND, RAG_VECTOR_BACKEND
- âœ… IngestÃ£o: RAG_GRAPH_INGEST_ENGINE (mvp/graph_rag/both)

### Pendente (PrÃ³ximos Passos)
- âŒ ColPali Service (retrieval visual)
- âŒ Neo4j Vector Search wiring
- âŒ MÃ©tricas comparaÃ§Ã£o Qdrant vs Neo4j

### DocumentaÃ§Ã£o Atualizada
- `docs/PLANO_RETRIEVAL_HIBRIDO.md` â€” Status atualizado

---

## 2026-01-25 â€” CorreÃ§Ã£o: Semantic Extractor alinhado com Neo4j Vector Index

### Contexto
- UsuÃ¡rio questionou se implementaÃ§Ã£o do `semantic_extractor.py` estava alinhada com documentaÃ§Ã£o Neo4j
- Descoberto que a implementaÃ§Ã£o original armazenava embeddings em memÃ³ria Python e fazia similaridade em Python
- Neo4j 5.15+ tem suporte nativo a Ã­ndices vetoriais que nÃ£o estava sendo usado

### Problema Identificado
- `semantic_extractor.py` armazenava seed embeddings em `Dict[str, List[float]]` Python
- CÃ¡lculo de `cosine_similarity()` feito em numpy, nÃ£o Neo4j
- `graph_neo4j.py` jÃ¡ tinha queries para `db.index.vector.queryNodes` nÃ£o utilizadas

### Arquivos Alterados
- `apps/api/app/services/rag/core/semantic_extractor.py` â€” Refatorado completamente:
  - Seed entities agora armazenados no Neo4j como nÃ³s `SEMANTIC_ENTITY`
  - Embeddings armazenados na propriedade `embedding` do nÃ³
  - Ãndice vetorial criado com `CREATE VECTOR INDEX` (Neo4j 5.x syntax)
  - Busca via `db.index.vector.queryNodes` em vez de numpy
  - RelaÃ§Ãµes `SEMANTICALLY_RELATED` persistidas no grafo

### DecisÃµes Tomadas
- Usar label dedicado `SEMANTIC_ENTITY` para seeds semÃ¢nticos
- Suportar ambas sintaxes de criaÃ§Ã£o de Ã­ndice (5.11+ e 5.15+)
- DimensÃ£o 3072 para text-embedding-3-large da OpenAI
- Threshold de similaridade 0.75 para matches semÃ¢nticos

### Alinhamento com Neo4j Docs
```cypher
-- CriaÃ§Ã£o de Ã­ndice vetorial (Neo4j 5.x)
CREATE VECTOR INDEX semantic_entity_embedding IF NOT EXISTS
FOR (n:SEMANTIC_ENTITY)
ON n.embedding
OPTIONS {indexConfig: {
    `vector.dimensions`: 3072,
    `vector.similarity_function`: 'cosine'
}}

-- Query de similaridade
CALL db.index.vector.queryNodes(
    'semantic_entity_embedding',
    $top_k,
    $embedding
) YIELD node, score
```

### PrÃ³ximos Passos
- Testar criaÃ§Ã£o de Ã­ndice em ambiente com Neo4j
- Verificar se SEMANTIC_ENTITY aparece na visualizaÃ§Ã£o do grafo
- Considerar adicionar mais seeds conforme feedback

---

## Template de Entrada

```markdown
## [DATA] â€” Objetivo da SessÃ£o

### Contexto
- Motivo/problema que levou Ã  sessÃ£o

### Arquivos Alterados
- `caminho/arquivo.ts` â€” descriÃ§Ã£o da mudanÃ§a

### Comandos Executados
- `pnpm test` â€” resultado
- `pnpm lint` â€” resultado

### DecisÃµes Tomadas
- Por que escolheu X em vez de Y

### PrÃ³ximos Passos
- O que ficou pendente

### Feedback do UsuÃ¡rio
- ComentÃ¡rios/correÃ§Ãµes recebidas
```

---

## 2026-01-25 â€” Plano de ImplementaÃ§Ã£o: Retrieval HÃ­brido com Neo4j + ColPali

### Contexto
- UsuÃ¡rio solicitou plano de implementaÃ§Ã£o para arquitetura de retrieval hÃ­brida
- Objetivo: manter Qdrant + OpenSearch como candidate generators, adicionar Neo4j como camada de grafo
- Incluir ColPali para retrieval visual de documentos (tabelas, figuras)
- Seguir abordagem em fases para nÃ£o ficar refÃ©m de uma Ãºnica tecnologia

### Arquivos Criados
- `docs/PLANO_RETRIEVAL_HIBRIDO.md` â€” Plano completo de implementaÃ§Ã£o com:
  - Arquitetura em 2 fases (MVP + migraÃ§Ã£o gradual)
  - CÃ³digo de implementaÃ§Ã£o para 4 novos serviÃ§os
  - ConfiguraÃ§Ã£o de environment variables
  - Cronograma e mÃ©tricas de sucesso

### Pesquisa Realizada
- ColPali: Visual document retrieval usando Vision Language Models
  - Paper: https://arxiv.org/abs/2407.01449
  - Modelos: vidore/colpali, vidore/colqwen2.5-v1, vidore/colsmol
  - Ideal para PDFs com tabelas/figuras sem depender de OCR
- Neo4j Hybrid: Vector Index + Fulltext Index nativos
  - HybridRetriever do neo4j-graphrag-python
  - Vector: HNSW com cosine similarity
  - Fulltext: Lucene com analyzer brasileiro

### Arquitetura Proposta

**Fase 1 (Prioridade - 2-3 semanas):**
- Manter Qdrant + OpenSearch (sem risco)
- Adicionar Neo4j Graph Expansion (1-2 hops)
- Adicionar ColPali para documentos visuais
- Retrieval Router com feature flags

**Fase 2 (ApÃ³s mÃ©tricas - 2-3 semanas):**
- Neo4j FULLTEXT para UI/lexical
- Neo4j VECTOR INDEX para seeds
- Comparar mÃ©tricas (latÃªncia/recall/custo)
- Desligar backends redundantes sÃ³ apÃ³s paridade

### DecisÃµes Tomadas
- ColQwen2.5 como modelo ColPali default (mais eficiente que original)
- Multi-hop limitado a 2 hops (performance vs completude)
- RRF como mÃ©todo de fusÃ£o (jÃ¡ usado no pipeline)
- Feature flags para tudo (reversibilidade)

### PrÃ³ximos Passos
1. Implementar `neo4j_graph_expansion.py`
2. Implementar `colpali_service.py`
3. Implementar `retrieval_router.py`
4. Integrar com RAG Pipeline existente
5. Criar endpoints de API
6. Criar componente de visualizaÃ§Ã£o de grafo

### ReferÃªncias
- https://github.com/illuin-tech/colpali
- https://huggingface.co/blog/manu/colpali
- https://neo4j.com/docs/neo4j-graphrag-python/current/
- https://neo4j.com/docs/cypher-manual/current/indexes/semantic-indexes/vector-indexes/

---

## 2026-01-25 â€” Pagina de Visualizacao de Grafo de Conhecimento Juridico

### Contexto
- Usuario solicitou pagina para descobrir relacoes entre dispositivos legais
- Relacoes semanticas (co-ocorrencia, contexto) alem de relacoes explicitas (cita, revoga)
- Checkboxes para filtrar por legislacao, jurisprudencia e doutrina
- Visualizacao interativa do grafo Neo4j

### Arquivos Criados
- `apps/api/app/api/endpoints/graph.py` â€” Endpoints para visualizacao do grafo
  - GET /graph/entities â€” Busca entidades por tipo
  - GET /graph/entity/{id} â€” Detalhes com vizinhos e chunks
  - GET /graph/export â€” Exporta grafo para visualizacao D3/force-graph
  - GET /graph/path â€” Encontra caminhos entre entidades
  - GET /graph/stats â€” Estatisticas do grafo
  - GET /graph/remissoes/{id} â€” Remissoes (referencias cruzadas)
  - GET /graph/semantic-neighbors/{id} â€” Vizinhos semanticos
  - GET /graph/relation-types â€” Tipos de relacoes disponiveis
- `apps/web/src/app/(dashboard)/graph/page.tsx` â€” Pagina de visualizacao do grafo
- `apps/web/src/stores/graph-store.ts` â€” Store Zustand para estado do grafo
- `apps/web/src/types/react-force-graph.d.ts` â€” Tipos TypeScript para react-force-graph

### Arquivos Alterados
- `apps/api/app/api/routes.py` â€” Adicionado router do grafo
- `apps/web/src/lib/api-client.ts` â€” Adicionados metodos para API do grafo

### Dependencias Adicionadas
- `react-force-graph-2d` â€” Visualizacao interativa de grafos

### Funcionalidades
- Visualizacao interativa com zoom, pan e drag
- Filtros por grupo: Legislacao, Jurisprudencia, Doutrina
- Cores por tipo de entidade
- Painel de detalhes ao clicar em no
- Remissoes semanticas (co-ocorrencia em documentos)
- Legenda explicativa
- Estatisticas do grafo

### Tipos de Relacoes Semanticas
- co_occurrence: Entidades mencionadas no mesmo trecho
- related: Conexao semantica inferida pelo contexto
- complementa: Complementa ou detalha outro dispositivo
- interpreta: Oferece interpretacao do dispositivo

### Verificacao
- `npm run type-check` â€” OK
- `npm run lint` â€” Warning menor (useEffect deps)

### Proximos Passos
- Integrar com navegacao do sidebar
- Adicionar busca com autocomplete
- Implementar tooltips nas arestas mostrando tipo de relacao

---

## 2026-01-25 â€” ExtensÃ£o MCP para Tribunais

### Contexto
- UsuÃ¡rio solicitou extensÃ£o MCP similar ao sei-mcp
- MCP (Model Context Protocol) permite Claude Code interagir com tribunais brasileiros

### Arquivos Criados
**packages/tribunais-mcp/**
- `package.json` â€” ConfiguraÃ§Ã£o do pacote
- `tsconfig.json` â€” ConfiguraÃ§Ã£o TypeScript
- `src/index.ts` â€” Entry point
- `src/server.ts` â€” Servidor MCP
- `src/websocket/server.ts` â€” WebSocket server para comunicaÃ§Ã£o com extensÃ£o Chrome
- `src/tools/all-tools.ts` â€” 35+ ferramentas MCP definidas
- `src/tools/index.ts` â€” Handler de ferramentas
- `src/types/index.ts` â€” Tipos TypeScript
- `src/utils/logger.ts` â€” Logger (usa stderr para nÃ£o interferir com stdio)

### Ferramentas MCP Implementadas

| Categoria | Ferramentas |
|-----------|-------------|
| AutenticaÃ§Ã£o | login, logout, get_session |
| Consulta | buscar_processo, consultar_processo, listar_movimentacoes, listar_documentos, consultar_partes |
| Peticionamento | listar_tipos_peticao, peticionar, iniciar_processo, consultar_protocolo |
| Downloads | download_documento, download_processo, download_certidao |
| Prazos | listar_intimacoes, ciencia_intimacao, listar_prazos |
| SessÃµes | list_sessions, get_session_info, close_session, switch_session |
| Janela | minimize_window, restore_window, focus_window, get_window_state |
| Debug | screenshot, snapshot, navigate, click, type, wait |
| Credenciais | listar_credenciais, testar_credencial |

### Arquivos Alterados
- `apps/tribunais-extension/background.js`:
  - Porta padrÃ£o alterada para 19998 (MCP)
  - Adicionado campo `serverType` ('mcp' | 'legacy')
  - Handlers MCP: login, logout, screenshot, snapshot, navigate, click, type, wait
  - Handlers de janela: minimize_window, restore_window, focus_window
  - FunÃ§Ã£o `delegateToContentScript` para comandos delegados

### Arquitetura
```
Claude Code â†” MCP Server (stdio) â†” WebSocket â†” ExtensÃ£o Chrome â†” DOM Tribunal
```

### Uso
```bash
# Iniciar servidor MCP
cd packages/tribunais-mcp
npm run build
node dist/index.js

# Conectar extensÃ£o Chrome na porta 19998
```

### VariÃ¡veis de Ambiente
- `TRIBUNAIS_MCP_WS_PORT` â€” Porta WebSocket (default: 19998)
- `TRIBUNAIS_MCP_LOG_LEVEL` â€” NÃ­vel de log (debug, info, warn, error)

---

## 2026-01-25 â€” Servico Hibrido de CAPTCHA (2Captcha, Anti-Captcha, CapMonster + HIL)

### Contexto
- UsuÃ¡rio solicitou suporte a CAPTCHAs difÃ­ceis (reCAPTCHA, hCaptcha)
- Escolheu estratÃ©gia hÃ­brida: serviÃ§o primeiro, fallback para resoluÃ§Ã£o manual

### Arquivos Criados
- `apps/tribunais/src/services/captcha-solver.ts` â€” Novo serviÃ§o de resoluÃ§Ã£o de CAPTCHA
- `apps/tribunais/tests/captcha-solver.test.ts` â€” Testes unitÃ¡rios (11 testes)
- `apps/tribunais/vitest.config.ts` â€” ConfiguraÃ§Ã£o do Vitest

### Arquivos Alterados
- `apps/tribunais/src/queue/worker.ts` â€” Integrado com CaptchaSolverService, removida funÃ§Ã£o obsoleta `requestCaptchaSolution`, cleanup de imports
- `apps/tribunais/package.json` â€” Adicionado vitest e scripts de teste

### Funcionalidades do CaptchaSolverService
- **Providers suportados**: 2Captcha, Anti-Captcha, CapMonster, Manual (HIL)
- **Tipos de CAPTCHA**: image, recaptcha_v2, recaptcha_v3, hcaptcha
- **EstratÃ©gia hÃ­brida**:
  1. Tenta resolver via serviÃ§o configurado (API)
  2. Se falhar, fallback para resoluÃ§Ã£o manual (HIL via Redis pub/sub)
- **ConfiguraÃ§Ã£o via env vars**:
  - `CAPTCHA_PROVIDER`: '2captcha' | 'anticaptcha' | 'capmonster' | 'manual'
  - `CAPTCHA_API_KEY`: chave da API do serviÃ§o
  - `CAPTCHA_SERVICE_TIMEOUT`: timeout do serviÃ§o em ms (default: 120000)
  - `CAPTCHA_FALLBACK_MANUAL`: fallback para HIL se serviÃ§o falhar (default: true)

### Testes Implementados
- ConfiguraÃ§Ã£o do solver (valores default, todos os providers)
- Tratamento de erros (API key missing, API failure)
- Fallback para manual (com/sem Redis)
- Tipos de CAPTCHA nÃ£o suportados

### DecisÃµes Tomadas
- Singleton para reutilizar conexÃµes Redis
- Polling a cada 5s para 2Captcha/Anti-Captcha, 3s para CapMonster (mais rÃ¡pido)
- Mesmo formato de task do Anti-Captcha para CapMonster (APIs compatÃ­veis)
- Callback resolve(null) para cancelamento pelo usuÃ¡rio
- Testes focam em error handling (polling requer mock de timers complexo)

---

## 2026-01-25 â€” UI de CAPTCHA na ExtensÃ£o Chrome e Desktop App

### Contexto
- Implementar interface de usuÃ¡rio para resolver CAPTCHAs na extensÃ£o Chrome e no app desktop
- Permite que o usuÃ¡rio veja e resolva CAPTCHAs durante operaÃ§Ãµes em tribunais

### Arquivos Alterados

**ExtensÃ£o Chrome:**
- `apps/tribunais-extension/background.js` â€” Adicionado handler `handleRequestCaptchaSolution`, funÃ§Ã£o `sendCaptchaSolution`, case no switch de comandos, handler de mensagem `captcha_solution`
- `apps/tribunais-extension/popup.html` â€” Adicionados estilos CSS para UI de CAPTCHA (imagem, input, timer, botÃµes), seÃ§Ã£o HTML `captchaPending`
- `apps/tribunais-extension/popup.js` â€” Adicionados elementos DOM, estado `currentCaptcha`/`captchaTimerInterval`, funÃ§Ãµes `showCaptcha`, `hideCaptcha`, `startCaptchaTimer`, `submitCaptcha`, `cancelCaptcha`, `openTribunalPage`, event listeners

**Desktop App:**
- `apps/tribunais-desktop/src/main/websocket-client.ts` â€” Adicionado case `request_captcha_solution`, mÃ©todo `sendCaptchaSolution`
- `apps/tribunais-desktop/src/main/index.ts` â€” Import de `shell`, handler `captcha-required`, handlers IPC `solve-captcha` e `open-external`
- `apps/tribunais-desktop/src/preload/index.ts` â€” Adicionados `solveCaptcha`, `openExternal`, canal `captcha-request`
- `apps/tribunais-desktop/src/renderer/index.html` â€” Estilos CSS para CAPTCHA, seÃ§Ã£o HTML `captchaCard`, elementos DOM, funÃ§Ãµes JavaScript (showCaptcha, hideCaptcha, etc.), event listeners

### Funcionalidades
- Exibe CAPTCHA de imagem com campo de texto
- Timer visual mostrando tempo restante
- Suporte a reCAPTCHA/hCaptcha com botÃ£o para abrir pÃ¡gina do tribunal
- Envio de soluÃ§Ã£o ou cancelamento
- Auto-cancel quando expira

### Fluxo de UI
1. Servidor envia `request_captcha_solution` via WebSocket
2. Extension/Desktop armazena dados e mostra notificaÃ§Ã£o
3. UI mostra card de CAPTCHA com imagem e input
4. UsuÃ¡rio digita soluÃ§Ã£o e clica Enviar
5. SoluÃ§Ã£o Ã© enviada via WebSocket (`captcha_solved`)
6. UI fecha o card

---

## 2026-01-25 â€” Suporte CAPTCHA HIL no ServiÃ§o de Tribunais

### Contexto
- Adicionar Human-in-the-Loop para resoluÃ§Ã£o de CAPTCHAs durante operaÃ§Ãµes em tribunais
- CAPTCHAs sÃ£o comuns em tribunais brasileiros e precisam de intervenÃ§Ã£o humana

### Arquivos Alterados
- `apps/tribunais/src/types/index.ts` â€” Adicionados tipos para CAPTCHA: CaptchaType, CaptchaInfo, CaptchaSolution, CaptchaRequiredEvent, CaptchaSolutionResponse
- `apps/tribunais/src/extension/websocket-server.ts` â€” Subscriber para canal `tribunais:captcha_required`, handlers para enviar CAPTCHA ao cliente e receber soluÃ§Ãµes
- `apps/tribunais/src/queue/worker.ts` â€” Subscriber para `tribunais:captcha_solution`, funÃ§Ã£o `requestCaptchaSolution` com Promise/timeout, `captchaHandler` para integrar com TribunalService
- `apps/tribunais/src/services/tribunal.ts` â€” Interface `ExecuteOperationOptions` com callback `onCaptchaRequired`, integraÃ§Ã£o com config de CAPTCHA do tribunais-playwright

### Fluxo Implementado
1. Worker executa operaÃ§Ã£o no tribunal
2. tribunais-playwright detecta CAPTCHA
3. Callback `onCaptchaRequired` Ã© chamado
4. Worker publica evento no Redis (`tribunais:captcha_required`)
5. WebSocket server recebe e envia para extensÃ£o/desktop do usuÃ¡rio
6. UsuÃ¡rio resolve o CAPTCHA
7. ExtensÃ£o/desktop envia soluÃ§Ã£o via WebSocket
8. WebSocket server publica no Redis (`tribunais:captcha_solution`)
9. Worker recebe via subscriber e continua operaÃ§Ã£o

### Decisoes Tomadas
- Timeout de 2 minutos para resolver CAPTCHA
- Se nenhuma extensÃ£o conectada, publica falha imediatamente
- Cleanup de CAPTCHAs pendentes no graceful shutdown

---

## 2026-01-25 â€” Extensao Chrome para Certificados A3 (tribunais-extension)

### Contexto
- Criar extensao Chrome para automacao de tribunais com certificado digital A3
- Conectar ao servidor Iudex via WebSocket para receber comandos
- Detectar paginas de tribunais e estado de login

### Arquivos Criados
- `apps/tribunais-extension/manifest.json` â€” Manifest V3 com permissoes para dominios de tribunais
- `apps/tribunais-extension/background.js` â€” Service Worker com conexao WebSocket, reconexao automatica, processamento de comandos
- `apps/tribunais-extension/popup.html` â€” Interface do usuario para configuracao e status
- `apps/tribunais-extension/popup.js` â€” Logica do popup (conexao, config, operacoes)
- `apps/tribunais-extension/content.js` â€” Script injetado em paginas de tribunais (deteccao de login, execucao de acoes)
- `apps/tribunais-extension/types.d.ts` â€” Tipos TypeScript para documentacao do protocolo
- `apps/tribunais-extension/README.md` â€” Documentacao da extensao
- `apps/tribunais-extension/icons/` â€” Icones PNG em 16, 32, 48 e 128px

### Funcionalidades Implementadas
- Conexao WebSocket persistente com reconexao automatica
- Autenticacao com userId configurado
- Comandos: authenticate, request_interaction, execute_browser_action, request_signature
- Deteccao de tribunais: TJSP (ESAJ), TRF3 (PJe), PJe generico
- Notificacoes do Chrome para interacao do usuario
- Content script para deteccao de tela de login e certificado

### Decisoes Tomadas
- Manifest V3 para compatibilidade futura
- JavaScript puro (sem build) para simplicidade
- Keepalive com chrome.alarms para manter service worker ativo
- Tipos TypeScript apenas como documentacao (extensao roda JS)

### Proximos Passos
- Testar integracao com servidor WebSocket
- Implementar assinatura digital com certificado A3
- Adicionar mais tribunais na configuracao

---

## 2026-01-25 â€” IntegraÃ§Ã£o Backend FastAPI com ServiÃ§o de Tribunais

### Contexto
- Criar integraÃ§Ã£o do serviÃ§o de tribunais Node.js com o backend FastAPI do Iudex
- Permitir gerenciamento de credenciais, consultas de processos e peticionamento

### Arquivos Criados
- `apps/api/app/schemas/tribunais.py` â€” Schemas Pydantic para request/response (enums, credenciais, operaÃ§Ãµes, processo, webhooks)
- `apps/api/app/services/tribunais_client.py` â€” Cliente HTTP assÃ­ncrono usando httpx para comunicaÃ§Ã£o com serviÃ§o Node.js
- `apps/api/app/api/endpoints/tribunais.py` â€” Endpoints FastAPI (credenciais, consultas, peticionamento)
- `apps/api/app/api/endpoints/webhooks.py` â€” Handler de webhooks do serviÃ§o de tribunais

### Arquivos Alterados
- `apps/api/app/api/routes.py` â€” Adicionados routers de tribunais e webhooks
- `apps/api/app/core/config.py` â€” Adicionadas configuraÃ§Ãµes TRIBUNAIS_SERVICE_URL e TRIBUNAIS_WEBHOOK_SECRET

### Endpoints Implementados
- `POST /api/tribunais/credentials/password` â€” Criar credencial com senha
- `POST /api/tribunais/credentials/certificate-a1` â€” Upload de certificado A1
- `POST /api/tribunais/credentials/certificate-a3-cloud` â€” Registrar A3 na nuvem
- `POST /api/tribunais/credentials/certificate-a3-physical` â€” Registrar A3 fÃ­sico
- `GET /api/tribunais/credentials/{user_id}` â€” Listar credenciais
- `DELETE /api/tribunais/credentials/{credential_id}` â€” Remover credencial
- `GET /api/tribunais/processo/{credential_id}/{numero}` â€” Consultar processo
- `GET /api/tribunais/processo/{credential_id}/{numero}/documentos` â€” Listar documentos
- `GET /api/tribunais/processo/{credential_id}/{numero}/movimentacoes` â€” Listar movimentaÃ§Ãµes
- `POST /api/tribunais/operations/sync` â€” OperaÃ§Ã£o sÃ­ncrona
- `POST /api/tribunais/operations/async` â€” OperaÃ§Ã£o assÃ­ncrona (fila)
- `GET /api/tribunais/operations/{job_id}` â€” Status de operaÃ§Ã£o
- `POST /api/tribunais/peticionar` â€” Protocolar petiÃ§Ã£o
- `POST /api/webhooks/tribunais` â€” Webhook de notificaÃ§Ãµes

### DecisÃµes Tomadas
- Usar httpx (async) para comunicaÃ§Ã£o com serviÃ§o Node.js
- ValidaÃ§Ã£o de ownership nas operaÃ§Ãµes (userId deve corresponder ao usuÃ¡rio autenticado)
- Webhooks processados em background para nÃ£o bloquear resposta
- Schemas com suporte a aliases (camelCase/snake_case) para compatibilidade

### PrÃ³ximos Passos
- Implementar notificaÃ§Ã£o WebSocket ao receber webhooks
- Adicionar testes de integraÃ§Ã£o
- Configurar webhook secret em produÃ§Ã£o

---

## 2026-01-24 â€” Streaming SSE de Ãšltima GeraÃ§Ã£o (step.* events)

### Contexto
- Implementar eventos SSE granulares (`step.*`) para criar UI de atividade consistente
- Padronizar todos os provedores (OpenAI, Gemini, Claude, Perplexity, Deep Research)
- Melhorar UX com chips de queries/fontes em tempo real durante streaming

### Arquivos Alterados

#### Backend
- `apps/api/app/services/ai/deep_research_service.py`:
  - Adicionado `_generate_step_id()` helper para IDs Ãºnicos
  - Google non-Agent: `step.start`, extraÃ§Ã£o de `grounding_metadata`, `step.done`
  - Google Agent (Interactions API): `step.start`, regex para queries/URLs, `step.done`
  - Perplexity Deep Research: `step.start`, `step.add_source` incremental, `step.done`

- `apps/api/app/services/ai/agent_clients.py`:
  - Adicionado `_extract_grounding_metadata()` helper para Gemini
  - Streaming loop emite `grounding_query` e `grounding_source`
  - Tracking de duplicatas com sets

- `apps/api/app/services/chat_service.py`:
  - Deep Research: propaga eventos `step.*` diretamente ao SSE
  - Gemini Chat: processa `grounding_query` â†’ `step.add_query`, `grounding_source` â†’ `step.add_source`
  - OpenAI Responses: handlers para `web_search_call.*` e `file_search_call.*`
  - Perplexity Chat: citaÃ§Ãµes incrementais com `step.add_source`

#### Frontend
- `apps/web/src/stores/chat-store.ts`:
  - Handlers para `step.start`, `step.add_query`, `step.add_source`, `step.done`
  - IntegraÃ§Ã£o com `upsertActivityStep` existente
  - AcumulaÃ§Ã£o de citations no metadata

### Formato dos Eventos SSE
```json
{"type": "step.start", "step_name": "Pesquisando", "step_id": "a1b2c3d4"}
{"type": "step.add_query", "step_id": "a1b2c3d4", "query": "jurisprudÃªncia STF..."}
{"type": "step.add_source", "step_id": "a1b2c3d4", "source": {"title": "STF", "url": "https://..."}}
{"type": "step.done", "step_id": "a1b2c3d4"}
```

### Scores Atualizados
| Provider | Score Anterior | Score Atual |
|----------|----------------|-------------|
| Claude Extended Thinking | 9/10 | 9/10 (jÃ¡ excelente) |
| Perplexity Chat | 7/10 | 10/10 |
| Perplexity Deep Research | 7/10 | 10/10 |
| OpenAI Responses API | 7/10 | 10/10 |
| Gemini Chat | 6/10 | 10/10 |
| Gemini Deep Research | 8/10 | 10/10 |

### DecisÃµes Tomadas
- Usamos `step_id` Ãºnico (uuid[:8]) para permitir mÃºltiplos steps simultÃ¢neos
- Grounding metadata extraÃ­do tanto de snake_case quanto camelCase (compatibilidade SDK)
- `step.done` emitido mesmo em caso de erro para UI consistente
- Tracking de duplicatas com sets para evitar eventos repetidos

### PrÃ³ximos Passos
- Testar manualmente cada provider
- Verificar que ActivityPanel exibe chips corretamente
- Opcional: adicionar `step.start/done` para Claude thinking (baixa prioridade)

---

## 2026-01-24 â€” Melhorias v2.28 no mlx_vomo.py (ValidaÃ§Ã£o e SanitizaÃ§Ã£o)

### Contexto
- AnÃ¡lise de documentos de transcriÃ§Ã£o (`transcricao-1769147720947.docx` e `Bloco 01 - UrbanÃ­stico_UNIFICADO_FIDELIDADE.md`)
- Identificados problemas de truncamento em tabelas e texto durante chunking
- Headings duplicados (`#### ####`) e separadores inconsistentes

### Arquivos Alterados
- `mlx_vomo.py`:
  - **Novas funÃ§Ãµes de validaÃ§Ã£o** (linhas 480-850):
    - `corrigir_headings_duplicados()`: Corrige `#### #### TÃ­tulo` â†’ `#### TÃ­tulo`
    - `padronizar_separadores()`: Remove ou padroniza `---`, `***`, `___`
    - `detectar_tabelas_em_par()`: Detecta pares ğŸ“‹ Quadro-sÃ­ntese + ğŸ¯ Pegadinhas
    - `validar_celulas_tabela()`: Detecta truncamentos conhecidos (ex: "Comcobra", "onto")
    - `chunk_texto_seguro()`: Chunking inteligente que evita cortar tabelas
    - `validar_integridade_pos_merge()`: ValidaÃ§Ã£o completa pÃ³s-merge
    - `sanitizar_markdown_final()`: Pipeline de sanitizaÃ§Ã£o completo
  - **Melhorias em `_smart_chunk_with_overlap()`**:
    - Overlap 30% maior quando chunk contÃ©m tabela
    - Prioriza corte apÃ³s pares de tabelas (ğŸ“‹ + ğŸ¯)
    - Evita cortar no meio de tabelas
  - **Melhorias em `_add_table_to_doc()`**:
    - Novo parÃ¢metro `table_type` (quadro_sintese, pegadinhas, default)
    - Cores diferenciadas: azul para sÃ­ntese, laranja para pegadinhas
    - Zebra striping (linhas alternadas)
    - Largura de colunas otimizada por tipo
  - **IntegraÃ§Ã£o em `save_as_word()`**:
    - Chama `sanitizar_markdown_final()` antes de converter
    - Chama `corrigir_tabelas_prematuras()` para reposicionar tabelas no lugar errado
    - Detecta tipo de tabela pelo heading anterior
  - **Nova funÃ§Ã£o `corrigir_tabelas_prematuras()`**:
    - Detecta quando tabela (ğŸ“‹ ou ğŸ¯) aparece antes do conteÃºdo terminar
    - Move automaticamente a tabela para DEPOIS do conteÃºdo explicativo
    - ParÃ¢metros configurÃ¡veis: `min_chars_apos_tabela=100`, `min_linhas_apos=2`
  - **Melhoria no prompt PROMPT_TABLE_APOSTILA**:
    - Adicionada seÃ§Ã£o "ORDEM OBRIGATÃ“RIA: CONTEÃšDO PRIMEIRO, TABELA DEPOIS"
    - Exemplos visuais de ERRADO vs CORRETO para guiar o LLM

### Comandos Executados
- `python3 -m py_compile mlx_vomo.py` â€” âœ… Sintaxe OK
- Testes unitÃ¡rios das novas funÃ§Ãµes â€” âœ… Todos passaram

### DecisÃµes Tomadas
- Usar overlap de 30% em vez de 15% para chunks com tabelas (mais seguro)
- Remover separadores horizontais por padrÃ£o (nÃ£o agregam valor no DOCX)
- Diferenciar visualmente tabelas de sÃ­ntese (azul) e pegadinhas (laranja)
- ValidaÃ§Ã£o nÃ£o-bloqueante (log de warnings, nÃ£o raise)

### PrÃ³ximos Passos
- Testar com arquivos reais de transcriÃ§Ã£o maiores
- Considerar adicionar Ã­ndice remissivo de termos jurÃ­dicos
- Avaliar necessidade de exportaÃ§Ã£o PDF simultÃ¢nea

---

## 2026-01-24 â€” CorreÃ§Ãµes P1/P2 Neo4j Hybrid Mode (AnÃ¡lise Paralela)

### Contexto
- AnÃ¡lise paralela com 3 agentes identificou 5 issues no Neo4j hybrid mode
- P1 (CrÃ­tico): Falta validaÃ§Ã£o contra colisÃ£o de labels estruturais (Entity, Document, Chunk)
- P2 (Moderado): Parsing de env vars inconsistente entre `config.py` e `neo4j_mvp.py`

### Arquivos Alterados
- `apps/api/app/services/rag/core/graph_hybrid.py`:
  - Adicionado `FORBIDDEN_LABELS = frozenset({"Entity", "Document", "Chunk", "Relationship"})`
  - `label_for_entity_type()` agora valida contra labels proibidos
  - Docstring expandida explicando as 4 validaÃ§Ãµes aplicadas
- `apps/api/app/services/rag/core/neo4j_mvp.py`:
  - Adicionada funÃ§Ã£o `_env_bool()` local (consistente com `config.py`)
  - `from_env()` agora usa `_env_bool()` ao invÃ©s de parsing inline
  - Defaults agora consistentes: `graph_hybrid_auto_schema=True`, outros `False`
- `apps/api/tests/test_graph_hybrid.py`:
  - Novo teste `test_label_for_entity_type_forbidden_labels()`
  - Valida que nenhum tipo mapeado colide com labels estruturais

### Comandos Executados
- `python tests/test_graph_hybrid.py` â€” 4/4 testes passaram

### Resultados da AnÃ¡lise Paralela
1. **Agent 1 (argument_pack)**: VersÃ£o produÃ§Ã£o (`argument_pack.py`) mais completa que patch GPT
2. **Agent 2 (usage patterns)**: 0 mÃ©todos quebrados no codebase
3. **Agent 3 (Neo4j integration)**: Score 8/10, 5 issues identificados (2 agora corrigidos)

### CorreÃ§Ãµes Adicionais (P3)
- `graph_hybrid.py`: `migrate_hybrid_labels()` agora usa transaÃ§Ã£o explÃ­cita
  - `session.begin_transaction()` para atomicidade
  - Rollback automÃ¡tico em caso de falha
  - Logging de resultado
- Removido `argument_pack_patched.py` (arquivo legado, versÃ£o produÃ§Ã£o jÃ¡ completa)

### PrÃ³ximos Passos
- Testar ingestÃ£o real para validar Neo4j population

---

## 2026-01-24 â€” AutomaÃ§Ã£o GraphRAG (Neo4j) na IngestÃ£o + Modo HÃ­brido

### Contexto
- Neo4j Aura configurado e conectado com schema correto (:Document, :Chunk, :Entity)
- GraphRAG nÃ£o estava sendo populado automaticamente durante ingestÃ£o de documentos
- UsuÃ¡rio solicitou: "quero tudo automatizado"
- RevisÃ£o da implementaÃ§Ã£o do modo hÃ­brido (GPT) identificou whitelist incompleta

### Arquivos Alterados
- `apps/api/app/api/endpoints/rag.py` â€” Adicionado integraÃ§Ã£o automÃ¡tica com GraphRAG:
  - Import `os` para env vars
  - Helper `_should_ingest_to_graph()` â€” verifica flag explÃ­cito ou `RAG_GRAPH_AUTO_INGEST`
  - Helper `_ingest_document_to_graph()` â€” extrai entidades legais e ingere no Neo4j/NetworkX
  - Modificado `ingest_local()` â€” chama graph ingest apÃ³s RAG ingest
  - Modificado `ingest_global()` â€” chama graph ingest apÃ³s RAG ingest (se nÃ£o foi duplicado)
- `apps/api/app/services/rag/core/graph_hybrid.py` â€” Expandida whitelist de tipos:
  - Adicionados: jurisprudencia, tese, documento, recurso, acordao, ministro, relator
  - Agora cobre todos os tipos do `EntityType` enum em `graph_rag.py`
- `apps/api/tests/test_graph_hybrid.py` â€” Atualizado testes para novos tipos
- `apps/api/.env` â€” Adicionado:
  - `RAG_GRAPH_AUTO_INGEST=true`
  - `RAG_GRAPH_HYBRID_MODE=true`
  - `RAG_GRAPH_HYBRID_AUTO_SCHEMA=true`

### DecisÃµes Tomadas
- **Fail-safe**: Erros de graph ingest nÃ£o falham a ingestÃ£o RAG principal
- **Factory pattern**: Usa `get_knowledge_graph()` que seleciona Neo4j ou NetworkX baseado em `RAG_GRAPH_BACKEND`
- **ExtraÃ§Ã£o automÃ¡tica**: Usa `LegalEntityExtractor` para extrair leis, sÃºmulas, jurisprudÃªncia do texto
- **Modo hÃ­brido completo**: Labels por tipo (:Entity:Lei, :Entity:Sumula, etc.) para todos os tipos jurÃ­dicos
- **Argumentos opcionais**: Flag `extract_arguments` para extrair teses/fundamentos/conclusÃµes

### Comandos Executados
- `python -m py_compile app/api/endpoints/rag.py` â€” OK
- Import test â€” OK
- Label test â€” 9/9 testes passaram

### PrÃ³ximos Passos
- Testar ingestÃ£o real de documento e verificar populaÃ§Ã£o no Neo4j
- Considerar criar endpoint de sincronizaÃ§Ã£o retroativa (documentos jÃ¡ ingeridos â†’ graph)

---

## 2026-01-24 â€” Commit Consolidado: RAG Quality 9.5/10

### Contexto
- Avaliacao inicial do sistema RAG: 8.5/10
- Implementacao de melhorias para atingir 9.5/10 usando 10 subagentes em paralelo

### Commit
- **Hash**: `ee66fb4`
- **Arquivos**: 42 alterados, 11.371 inserÃ§Ãµes, 116 remoÃ§Ãµes, 19 novos arquivos

### EntregÃ¡veis por Categoria

**Testes (414 novos):**
- `tests/rag/test_crag_gate.py` â€” 66 testes CRAG gate
- `tests/rag/test_query_expansion.py` â€” 65 testes query expansion
- `tests/rag/test_reranker.py` â€” 53 testes reranker
- `tests/rag/test_qdrant_service.py` â€” 58 testes Qdrant multi-tenant
- `tests/rag/test_opensearch_service.py` â€” 57 testes OpenSearch BM25
- `tests/rag/fixtures.py` â€” Mocks compartilhados com docs jurÃ­dicos BR

**DocumentaÃ§Ã£o:**
- `docs/rag/ARCHITECTURE.md` â€” Pipeline 10 estÃ¡gios com Mermaid
- `docs/rag/CONFIG.md` â€” 60+ variÃ¡veis de ambiente documentadas
- `docs/rag/API.md` â€” 5 endpoints com exemplos Python/JS/cURL

**ResiliÃªncia:**
- `services/rag/core/resilience.py` â€” CircuitBreaker (CLOSED/OPEN/HALF_OPEN)
- `api/endpoints/health.py` â€” Endpoint `/api/health/rag`

**Evals:**
- `evals/benchmarks/v1.0_legal_domain.jsonl` â€” 87 queries jurÃ­dicas
- `services/ai/rag_evaluator.py` â€” MÃ©tricas legais (citation_coverage, temporal_validity)
- `.github/workflows/rag-eval.yml` â€” CI/CD semanal + PR

**Performance:**
- `services/rag/core/budget_tracker.py` â€” 50k tokens / 5 LLM calls por request
- `services/rag/core/reranker.py` â€” preload() para eliminar cold start
- `services/rag/core/embeddings.py` â€” 31 queries jurÃ­dicas comuns prÃ©-carregadas

**CÃ³digo:**
- `services/rag/utils/env_helpers.py` â€” ConsolidaÃ§Ã£o de utilitÃ¡rios duplicados
- `services/rag_context.py`, `rag_module.py` â€” Marcados DEPRECATED

### PrÃ³ximos Passos Opcionais
- Configurar secrets GitHub (OPENAI_API_KEY, GOOGLE_API_KEY) para CI/CD
- Rodar `pytest tests/rag/ -v` para verificar todos os 414 testes
- Habilitar preload em staging: `RAG_PRELOAD_RERANKER=true`

---

## 2026-01-24 â€” Budget Cap para RAG Request

### Contexto
- Implementar controle de custos para operacoes HyDE + multi-query no pipeline RAG
- Evitar gastos excessivos com chamadas LLM durante query expansion

### Arquivos Criados
- `apps/api/app/services/rag/core/budget_tracker.py` â€” novo modulo para tracking de orcamento por request

### Arquivos Alterados
- `apps/api/app/services/rag/config.py` â€” adicionadas configuracoes de budget (max_tokens_per_request, max_llm_calls_per_request, warn_at_budget_percent)
- `apps/api/app/services/rag/core/__init__.py` â€” exporta novos componentes do BudgetTracker
- `apps/api/app/services/rag/core/query_expansion.py` â€” integrado BudgetTracker nas funcoes expand_async, generate_hypothetical_document, generate_query_variants, rewrite_query e _call_gemini
- `apps/api/app/services/rag/pipeline/rag_pipeline.py` â€” integrado BudgetTracker no search(), _stage_query_enhancement(), e PipelineTrace

### Comandos Executados
- `python -m py_compile` em todos arquivos alterados â€” OK
- Testes de import e funcionalidade basica â€” OK

### Decisoes Tomadas
- Usar estimativa baseada em caracteres para tokens (evitar dependencias pesadas de tokenizers)
- BudgetTracker como dataclass para facilitar serializacao e uso
- Integrar budget tracking opcional (graceful degradation se modulo nao disponivel)
- Adicionar budget_usage ao PipelineTrace para observabilidade completa

### Funcionalidades Implementadas
1. **BudgetTracker class**: Track tokens e LLM calls por request
2. **Budget config**: max_tokens=50000, max_llm_calls=5, warn_at=80%
3. **Integration points**: query expansion, HyDE, multi-query
4. **Observability**: Usage reports no trace output

### Proximos Passos
- Integrar com embedding tracking no vector search
- Adicionar metricas de budget ao dashboard
- Configurar alertas quando budget excedido

---

## 2026-01-23 â€” ConfiguraÃ§Ã£o do Sistema de MemÃ³ria

### Contexto
- Implementar sistema de memÃ³ria persistente para Claude Code registrar trabalho e melhorar com feedback

### Arquivos Criados
- `CLAUDE.md` â€” memÃ³ria principal do projeto
- `.claude/rules/testing.md` â€” regras de testes
- `.claude/rules/code-style.md` â€” estilo de cÃ³digo
- `.claude/rules/security.md` â€” regras de seguranÃ§a
- `.claude/rules/api.md` â€” regras da API
- `docs/AI_LOG.md` â€” este arquivo
- `docs/LESSONS_LEARNED.md` â€” liÃ§Ãµes aprendidas

### Comandos Executados
- Nenhum comando de verificaÃ§Ã£o necessÃ¡rio (apenas criaÃ§Ã£o de docs)

### DecisÃµes Tomadas
- Estrutura modular com rules separadas por Ã¡rea
- YAML frontmatter em api.md para aplicar sÃ³ em apps/api/
- Log e lessons em docs/ para fÃ¡cil acesso

### PrÃ³ximos Passos
- Aplicar estrutura nos demais projetos do Cursor
- Criar script de automaÃ§Ã£o

---

## 2026-01-24 â€” PR2 & PR3: Consolidate Tracing & Unify Pipeline

### Contexto
- Checklist RAG identificou duplicaÃ§Ã£o de tracing e mÃºltiplos pipelines RAG

### PR2: Consolidate Tracing

**Arquivos Alterados:**
- `apps/api/app/services/rag/utils/trace.py` â€” Adicionados 10 novos event types para compatibilidade
  - QUERY_REWRITE, HYDE_GENERATE, GRAPH_EXPAND, ARGUMENT_CONTEXT, CONTEXT_COMPRESS
  - FALLBACK, RAG_ROUTER_DECISION, PROMPT_FINAL, PARENT_CHILD_EXPAND, GENERIC
- `apps/api/app/services/rag/utils/trace.py` â€” Adicionado suporte a conversation_id e message_id
- `apps/api/app/services/rag/utils/trace.py` â€” Adicionada funÃ§Ã£o trace_event_legacy() para compatibilidade
- `apps/api/app/services/rag_trace.py` â€” Convertido para wrapper que delega ao novo trace.py

**Resultado:**
- CÃ³digo legado continua funcionando sem mudanÃ§as (rag_trace.py Ã© wrapper)
- Novo cÃ³digo pode usar trace.py diretamente com tipos estruturados
- Um Ãºnico sistema de tracing com mÃºltiplos canais (JSONL, OTel, LangSmith, DB)

### PR3: Unify RAG Pipeline

**Arquivos Criados:**
- `apps/api/app/services/rag/pipeline_adapter.py` â€” Adapter unificado

**EstratÃ©gia:**
- Flag `RAG_USE_NEW_PIPELINE` controla qual pipeline usar (default: legacy)
- Quando features especÃ­ficas sÃ£o necessÃ¡rias (query rewrite com histÃ³rico, adaptive routing, argument graph), usa legacy automaticamente
- Quando possÃ­vel, delega para RAGPipeline novo

**Resultado:**
- API mantÃ©m compatibilidade total com build_rag_context()
- Novo cÃ³digo pode usar build_rag_context_unified() com mesmo interface
- MigraÃ§Ã£o gradual: teste com RAG_USE_NEW_PIPELINE=true quando pronto

### Comandos Executados
- `python -c "from app.services.rag.utils.trace import ..."` â€” OK
- `python -c "from app.services.rag.pipeline_adapter import ..."` â€” OK

### PrÃ³ximos Passos
- Testar com RAG_USE_NEW_PIPELINE=true em ambiente de staging
- Gradualmente migrar callers para usar build_rag_context_unified
- Quando validado, tornar novo pipeline o default

---

## 2026-01-24 â€” Fix TTL Cleanup Field Mismatch (PR1 do checklist RAG)

### Contexto
- Checklist de qualidade RAG identificou que o TTL cleanup nÃ£o funcionava
- `ttl_cleanup.py` buscava campos inexistentes (`ingested_at`, `created_at`, `timestamp`)
- OpenSearch e Qdrant usam `uploaded_at` como campo de timestamp

### Arquivos Alterados
- `apps/api/app/services/rag/utils/ttl_cleanup.py` â€” Corrigido para usar `uploaded_at`
  - OpenSearch: mudou query de `should` com 3 campos para `must` com `uploaded_at`
  - Qdrant: mudou `timestamp_fields` de 4 campos incorretos para `["uploaded_at"]`
- `apps/api/tests/test_ttl_cleanup.py` â€” Criado novo arquivo com 8 testes unitÃ¡rios

### Comandos Executados
- `python -m py_compile app/services/rag/utils/ttl_cleanup.py` â€” OK
- `pytest tests/test_ttl_cleanup.py -v` â€” 8 passed

### DecisÃµes Tomadas
- Usar `must` em vez de `should` no OpenSearch (campo Ã© obrigatÃ³rio, nÃ£o opcional)
- Teste de cÃ³digo-fonte para validar que o campo correto estÃ¡ sendo usado (evita mocks complexos)

### Impacto
- **Antes**: TTL cleanup nunca deletava dados (buscava campos que nÃ£o existiam)
- **Depois**: Dados locais mais antigos que TTL (7 dias) serÃ£o corretamente removidos

### PrÃ³ximos Passos (do checklist RAG)
- PR2: Consolidar tracing (`rag_trace.py` â†’ `trace.py`)
- PR3: Unificar pipeline (`build_rag_context()` â†’ `RAGPipeline`)

---

## 2026-01-24 â€” SimplificaÃ§Ã£o Painel Auditoria + DebateAuditPanel

### Contexto
- Painel de auditoria do Canvas tinha componentes redundantes
- Faltava visibilidade completa dos debates entre agentes no LangGraph

### Arquivos Alterados

**SimplificaÃ§Ã£o do QualityPanel (transcriÃ§Ã£o):**
- `apps/web/src/components/dashboard/quality-panel.tsx`
  - Removidos botÃµes "Validar Fidelidade", "SÃ³ Estrutural", "Gerar SugestÃµes (IA)"
  - Mantido apenas "ValidaÃ§Ã£o Completa" (HIL Unificado)
  - Removidas funÃ§Ãµes nÃ£o utilizadas (handleValidate, handleAnalyzeStructure, handleSemanticSuggestions)
  - Removidos states nÃ£o utilizados (isValidating, isAnalyzing)

**Ajustes nos painÃ©is de Quality Gate e HIL:**
- `apps/web/src/components/dashboard/quality-gate-panel.tsx`
  - Removido defaultValue do accordion (fechado por padrÃ£o)
  - Adicionado card "Cobertura refs" com percentual
  - Grid agora tem 4 colunas: CompressÃ£o, Cobertura refs, Refs omitidas, Checks

- `apps/api/app/services/ai/quality_gate.py`
  - Adicionado campo `reference_coverage: float` ao dataclass QualityGateResult
  - Retorna coverage no resultado e no gate_results do nÃ³

**Novo componente DebateAuditPanel:**
- `apps/web/src/components/dashboard/debate-audit-panel.tsx` (novo)
  - Mostra drafts completos de cada modelo
  - Exibe divergÃªncias detalhadas por seÃ§Ã£o
  - Lista issues da crÃ­tica do comitÃª
  - Mostra decisÃµes do merge (Judge)
  - Exibe risk flags e claims pendentes
  - Accordion com seÃ§Ãµes divergentes abertas por padrÃ£o

- `apps/web/src/components/dashboard/canvas-container.tsx`
  - Adicionado import e uso do DebateAuditPanel na aba Auditoria

### Comandos Executados
- `npm -w apps/web run type-check` â€” OK
- `python -c "from app.services.ai.quality_gate import ..."` â€” OK

### DecisÃµes Tomadas
- HIL Unificado Ã© o mais completo (diff + correÃ§Ã£o determinÃ­stica + semÃ¢ntica)
- PreventiveAuditPanel e QualityPanel removidos do Canvas (especÃ­ficos para transcriÃ§Ã£o)
- DebateAuditPanel permite auditoria completa dos debates multi-agente

### Estrutura Final Aba Auditoria (Canvas)
```
1. CabeÃ§alho Compliance + Risk Badge
2. QualityGatePanel (compressÃ£o, cobertura, refs omitidas)
3. HilChecklistPanel (10 fatores de risco)
4. RelatÃ³rio de Conformidade (Markdown)
5. Tabela de CitaÃ§Ãµes
6. DebateAuditPanel (drafts, divergÃªncias, crÃ­ticas, merge)
7. HilHistoryPanel (histÃ³rico de interaÃ§Ãµes humanas)
8. AuditIssuesPanel (se houver issues)
```

---

## 2026-01-24 â€” HistÃ³rico de InteraÃ§Ãµes HIL

### Contexto
- InteraÃ§Ãµes HIL (Human-in-the-Loop) nÃ£o estavam sendo registradas para auditoria
- Faltava histÃ³rico de aprovaÃ§Ãµes, ediÃ§Ãµes e instruÃ§Ãµes dadas ao agente

### Arquivos Alterados

**Backend:**
- `apps/api/app/services/ai/langgraph_legal_workflow.py`
  - Adicionado campo `hil_history: List[Dict[str, Any]]` ao DocumentState

- `apps/api/app/api/endpoints/jobs.py`
  - Endpoint `/resume` agora captura conteÃºdo original antes de resumir
  - Cria entrada de histÃ³rico com: id, timestamp, checkpoint, user, decisÃ£o, conteÃºdo antes/depois, instruÃ§Ãµes, proposta
  - Inclui `hil_history` no resume_payload para persistir no state
  - Evento `hil_response` agora inclui `hil_entry` completo
  - Evento `done` agora inclui `hil_history`, `processed_sections`, `has_any_divergence`, `divergence_summary`

**Frontend:**
- `apps/web/src/components/dashboard/hil-history-panel.tsx` (novo)
  - Exibe histÃ³rico de todas as interaÃ§Ãµes HIL
  - Cards com: checkpoint, timestamp, usuÃ¡rio, decisÃ£o
  - Mostra instruÃ§Ãµes dadas ao agente
  - Mostra proposta do usuÃ¡rio (quando rejeita)
  - Diff visual entre conteÃºdo original e editado
  - Ordenado por timestamp (mais recente primeiro)

- `apps/web/src/components/dashboard/canvas-container.tsx`
  - Adicionado import e uso do HilHistoryPanel na aba Auditoria

### Estrutura de uma entrada HIL
```json
{
  "id": "uuid",
  "timestamp": "2026-01-24T10:30:00Z",
  "checkpoint": "section",
  "section_title": "Dos Fatos",
  "user_id": "user_123",
  "user_email": "user@example.com",
  "decision": "edited",
  "approved": true,
  "original_content": "...",
  "edited_content": "...",
  "instructions": "...",
  "proposal": "...",
  "iteration": 1
}
```

### Comandos Executados
- `npm -w apps/web run type-check` â€” OK
- `python -m py_compile app/api/endpoints/jobs.py` â€” OK

---

## 2026-01-24 â€” CaseState Enxuto e AuditÃ¡vel

### Contexto
- Codebase precisava de um estado mÃ­nimo (CaseState) auditÃ¡vel
- LangGraph DocumentState tinha 90% dos campos necessÃ¡rios mas nÃ£o era persistido
- Faltavam: tasks[], partes, cnj_number normalizado

### Arquivos Criados
- `apps/api/app/models/workflow_state.py` â€” Persiste DocumentState do LangGraph
  - sources[], citations_map (retrieval)
  - drafts_history, hil_history (versÃµes)
  - routing_decisions, alert_decisions, citation_decisions, audit_decisions, quality_decisions (decisions_log)
  - MÃ©todo `from_document_state()` para converter do LangGraph

- `apps/api/app/models/case_task.py` â€” Tarefas derivadas com prazos
  - Campos: deadline, priority, status, task_type
  - Sources: manual, djen, workflow, ai_suggested
  - MÃ©todos: `from_djen_intimation()`, `from_workflow_suggestion()`

- `apps/api/alembic/versions/d3a4f8c9e2b1_add_workflow_state_case_tasks.py` â€” MigraÃ§Ã£o

### Arquivos Alterados
- `apps/api/app/models/case.py`
  - Adicionado `cnj_number` (normalizado no padrÃ£o CNJ)
  - Adicionado `classe` (classe processual)
  - Adicionado `assunto` (assunto principal)
  - Adicionado `partes` (JSONB com autor, rÃ©u, terceiros, advogados)
  - MÃ©todos: `normalize_cnj()`, `add_parte()`, `get_partes_resumo()`

- `apps/api/app/models/__init__.py`
  - Adicionados exports dos novos modelos

- `apps/api/app/api/endpoints/jobs.py`
  - Import de `WorkflowState` e `AsyncSessionLocal`
  - FunÃ§Ã£o `persist_workflow_state()` para persistÃªncia em background
  - Chamada via `asyncio.create_task()` no evento "done"

### Estrutura Final do CaseState

```
Case (DB)
â”œâ”€â”€ cnj_number (normalizado)
â”œâ”€â”€ partes (JSONB: autor, rÃ©u, terceiros)
â”œâ”€â”€ classe, assunto, tribunal
â””â”€â”€ tasks[] â†’ CaseTask

WorkflowState (DB) â€” Persistido apÃ³s workflow
â”œâ”€â”€ sources[] (documentos recuperados)
â”œâ”€â”€ retrieval_queries[]
â”œâ”€â”€ citations_map
â”œâ”€â”€ drafts_history[]
â”œâ”€â”€ hil_history[]
â”œâ”€â”€ processed_sections[]
â””â”€â”€ decisions (routing, alerts, citations, audit, quality)
```

### Comandos Executados
- `python -m py_compile ...` â€” OK para todos os arquivos

### PrÃ³ximos Passos
- ~~Rodar migraÃ§Ã£o: `alembic upgrade head`~~ âœ…
- ~~Criar endpoints REST para consultar WorkflowState e CaseTasks~~ âœ…
- Integrar criaÃ§Ã£o automÃ¡tica de tasks a partir do DJEN

### Endpoints REST Criados (v5.7)

**WorkflowState:**
- `GET /audit/workflow-states` â€” Lista estados de workflow do usuÃ¡rio
- `GET /audit/workflow-states/{id}` â€” Detalhes completos (auditoria)
- `GET /audit/workflow-states/by-job/{job_id}` â€” Busca por job
- `GET /audit/workflow-states/{id}/sources` â€” Fontes recuperadas
- `GET /audit/workflow-states/{id}/decisions` â€” DecisÃµes do workflow
- `GET /audit/workflow-states/{id}/hil-history` â€” HistÃ³rico HIL

**CaseTasks:**
- `GET /audit/tasks` â€” Lista tarefas (filtros: case, status, priority, overdue)
- `GET /audit/tasks/{id}` â€” Detalhes da tarefa
- `POST /audit/tasks` â€” Criar tarefa manual
- `PATCH /audit/tasks/{id}` â€” Atualizar tarefa
- `DELETE /audit/tasks/{id}` â€” Deletar tarefa

**Summary:**
- `GET /audit/summary` â€” Resumo para dashboard

---

## 2026-01-24 â€” Auditoria Detalhada no GeneratorWizard

### Contexto
- A pÃ¡gina de geraÃ§Ã£o de peÃ§as (`/cases/[id]` aba Generation) usava `GeneratorWizard`
- Este componente nÃ£o tinha os novos painÃ©is de auditoria criados para o CanvasContainer
- UsuÃ¡rio pediu para preservar a UI existente e incorporar o painel completo de auditoria

### Arquivos Alterados
- `apps/web/src/components/dashboard/generator-wizard.tsx`
  - Adicionados imports: QualityGatePanel, HilChecklistPanel, DebateAuditPanel, HilHistoryPanel
  - Adicionada seÃ§Ã£o expandÃ­vel "Auditoria Detalhada" apÃ³s os painÃ©is existentes (JobQualityPanel, etc.)
  - Accordion colapsÃ¡vel com todos os 4 painÃ©is de auditoria

### Estrutura Adicionada
```tsx
<Accordion type="single" collapsible>
    <AccordionItem value="audit-details">
        <AccordionTrigger>
            Auditoria Detalhada [Badge: Compliance & HIL]
        </AccordionTrigger>
        <AccordionContent>
            1. QualityGatePanel (compressÃ£o, cobertura, refs omitidas)
            2. HilChecklistPanel (10 fatores de risco)
            3. DebateAuditPanel (drafts, divergÃªncias, crÃ­ticas, merge)
            4. HilHistoryPanel (histÃ³rico de interaÃ§Ãµes humanas)
        </AccordionContent>
    </AccordionItem>
</Accordion>
```

### Comandos Executados
- `npm -w apps/web run type-check` â€” OK

### DecisÃµes Tomadas
- SeÃ§Ã£o expandÃ­vel preserva UI limpa por padrÃ£o
- Accordion colapsÃ¡vel nÃ£o atrapalha fluxo de geraÃ§Ã£o
- Mesmos painÃ©is do CanvasContainer para consistÃªncia

---

## 2026-01-24 â€” B2 Citer/Verifier Node (Gate PrÃ©-Debate)

### Contexto
- AnÃ¡lise comparativa entre arquitetura proposta (Times A/B) e fluxo LangGraph atual
- Identificado gap: verificaÃ§Ã£o de rastreabilidade afirmaÃ§Ã£oâ†’fonte era parcial (policy [n], retry need_juris)
- Implementado B2 Citer/Verifier como gate obrigatÃ³rio entre pesquisa e debate

### Arquivos Criados
- `apps/api/app/services/ai/citer_verifier.py` â€” NÃ³ B2 completo com:
  - ExtraÃ§Ã£o de afirmaÃ§Ãµes jurÃ­dicas via LLM
  - Mapeamento para fontes RAG e citations_map
  - Tags [VERIFICAR] em claims sem fonte
  - DecisÃ£o de force_hil (coverage < 60%) e block_debate (coverage < 30%)

### Arquivos Alterados
- `apps/api/app/services/ai/langgraph_legal_workflow.py`:
  - Adicionado import do citer_verifier_node
  - Adicionados campos ao DocumentState: citer_verifier_result, verified_context, citer_verifier_force_hil, citer_verifier_coverage, citer_verifier_critical_gaps, citer_min_coverage
  - Registrado nÃ³ no workflow
  - Alterada edge: fact_check â†’ citer_verifier â†’ debate (com router condicional)
  - Atualizado docstring do mÃ³dulo

### Fluxo Atualizado
```
fact_check â†’ citer_verifier â†’ [coverage >= 0.3] â†’ debate
                            â†’ [coverage < 0.3] â†’ divergence_hil (skip debate)
```

### Comandos Executados
- `python -m py_compile apps/api/app/services/ai/citer_verifier.py` â€” OK
- `python -c "from app.services.ai.langgraph_legal_workflow import legal_workflow_app"` â€” OK

### DecisÃµes Tomadas
- Arquivo separado (citer_verifier.py) para modularidade
- Coverage mÃ­nimo padrÃ£o de 60% (configurÃ¡vel via citer_min_coverage)
- Block debate se coverage < 30% (muito baixo para gerar conteÃºdo confiÃ¡vel)
- Router condicional permite skip do debate em casos crÃ­ticos

### PrÃ³ximos Passos
- Testes unitÃ¡rios para citer_verifier_node
- UI para exibir resultado da verificaÃ§Ã£o (coverage, claims verificados/nÃ£o verificados)
- Considerar Time A (Monitoramento) como prÃ³ximo gap a implementar

---

## 2026-01-24 â€” Documentacao Completa do RAG Pipeline

### Contexto
- Solicitacao de criar pacote de documentacao abrangente para o sistema RAG
- Consolidar informacoes dispersas em codigo e arquivos existentes

### Arquivos Criados
- `docs/rag/ARCHITECTURE.md` â€” Arquitetura do pipeline de 10 estagios
  - Diagrama Mermaid do fluxo completo
  - Descricao detalhada de cada estagio (Query Enhancement, Lexical, Vector, Merge, CRAG, Rerank, Expand, Compress, Graph, Trace)
  - Modelo de seguranca multi-tenant
  - Feature flags e otimizacoes

- `docs/rag/CONFIG.md` â€” Referencia completa de configuracao
  - Todas as 60+ variaveis de ambiente documentadas
  - Agrupadas por categoria (Feature Flags, CRAG, Query Expansion, Reranking, Compression, Storage, Tracing)
  - Valores padrao, ranges validos e exemplos

- `docs/rag/API.md` â€” Documentacao da API REST
  - 5 endpoints: search, ingest/local, ingest/global, delete, stats
  - Request/response schemas com exemplos
  - Codigos de erro e rate limiting
  - Exemplos em Python, JavaScript e cURL

### Arquivos Lidos para Extracao de Informacao
- `apps/api/app/services/rag/config.py` â€” Todas as configuracoes
- `apps/api/app/services/rag/pipeline/rag_pipeline.py` â€” Logica do pipeline
- `apps/api/app/api/endpoints/rag.py` â€” Endpoints da API
- `rag.md` â€” Material de referencia (livro RAG)

### Comandos Executados
- `mkdir -p docs/rag` â€” Criar diretorio

### Decisoes Tomadas
- Documentacao em Portugues (idioma do projeto)
- Mermaid para diagramas (suportado pelo GitHub)
- Organizacao em 3 arquivos separados por publico (arquitetura, ops/config, devs/API)
- Incluir referencias a papers originais (RAG, CRAG, HyDE, RRF)

### Proximos Passos
- Criar testes de validacao da documentacao (links, exemplos)
- Adicionar documentacao de GraphRAG quando Neo4j for expandido
- Criar guia de troubleshooting

---

## 2026-01-24 â€” Consolidacao RAG: Remocao de Shims e Extracao de Utilitarios

### Contexto
- Codigo RAG tinha duplicacao de funcoes utilitarias (env_bool, env_int, env_float)
- Shims `rag_context.py` e `rag_module.py` delegavam para implementacoes reais
- Arquivos importavam dos shims em vez de importar diretamente

### Arquivos Criados
- `apps/api/app/services/rag/utils/env_helpers.py` â€” Funcoes utilitarias extraidas
  - `env_bool()` â€” Parse de boolean de variavel de ambiente
  - `env_int()` â€” Parse de int de variavel de ambiente
  - `env_float()` â€” Parse de float de variavel de ambiente

### Arquivos Alterados

**Fase 1: Atualizacao de imports para usar implementacoes reais:**
- `apps/api/app/api/endpoints/chats.py`
  - `from app.services.rag.pipeline_adapter import build_rag_context_unified as build_rag_context`
- `apps/api/app/services/chat_service.py`
  - `from app.services.rag.pipeline_adapter import build_rag_context_unified as build_rag_context`
- `apps/api/app/services/ai/langgraph_legal_workflow.py`
  - `from app.services.rag_module_old import create_rag_manager, get_scoped_knowledge_graph`
- `apps/api/app/services/document_generator.py`
  - `from app.services.rag_module_old import RAGManager, create_rag_manager`
- `apps/api/app/api/endpoints/admin_rag.py`
  - `from app.services.rag_module_old import create_rag_manager`
- `apps/api/app/api/endpoints/advanced.py`
  - `from app.services.rag_module_old import RAGManager`
- `apps/api/app/services/ai/orchestrator.py`
  - `from app.services.rag_module_old import create_rag_manager`
- `apps/api/app/services/rag/pipeline/rag_pipeline.py`
  - `from app.services.rag_module_old import get_scoped_knowledge_graph`

**Fase 2: Extracao de utilitarios duplicados:**
- `apps/api/app/services/rag_context_legacy.py`
  - Removidas funcoes locais `_env_bool`, `_env_int`, `_env_float`
  - Importa de `app.services.rag.utils.env_helpers`
- `apps/api/app/services/rag/pipeline_adapter.py`
  - Removidas funcoes locais `_env_bool`, `_env_int`, `_env_float`
  - Importa de `app.services.rag.utils.env_helpers`
- `apps/api/app/services/rag/pipeline/rag_pipeline.py`
  - Removidas funcoes locais `_env_bool`, `_env_int`
  - Importa de `app.services.rag.utils.env_helpers`
- `apps/api/app/services/rag/utils/__init__.py`
  - Adicionados exports de `env_bool`, `env_int`, `env_float`

**Atualizacao de documentacao dos shims:**
- `apps/api/app/services/rag_context.py` â€” Marcado como DEPRECATED com imports preferidos
- `apps/api/app/services/rag_module.py` â€” Marcado como DEPRECATED com imports preferidos

### Comandos Executados
- `python -c "from app.services.rag.utils.env_helpers import ..."` â€” OK
- `python -c "from app.services.rag.pipeline_adapter import ..."` â€” OK
- `python -c "from app.services.rag_context import ..."` â€” OK (shim ainda funciona)
- `python -c "from app.services.rag_module import ..."` â€” OK (shim ainda funciona)
- `python -c "import app.api.endpoints.chats; ..."` â€” OK (todos modulos modificados)

### Decisoes Tomadas
- Shims mantidos para compatibilidade (marcados como deprecated)
- Imports diretos usam `rag_module_old` e `rag.pipeline_adapter`
- Funcoes utilitarias centralizadas em `rag/utils/env_helpers.py`
- Alias `_env_bool` mantido nos arquivos para minimizar mudancas internas

### Resultado
- **Antes**: 3 copias de `_env_bool`, `_env_int`, `_env_float`
- **Depois**: 1 implementacao em `env_helpers.py`, importada por 3 arquivos
- Shims continuam funcionando para codigo legado
- Novo codigo deve importar diretamente das implementacoes reais

---

## 2026-01-24 â€” Preload Strategy para Reranker e Embeddings

### Contexto
- Cold start latency no reranker model impactava primeira requisicao RAG
- Necessidade de eliminar latencia inicial carregando modelos no startup

### Arquivos Alterados
- `apps/api/app/services/rag/core/reranker.py`
  - Adicionado metodo `preload()` que carrega modelo e executa warmup inference
  - Adicionado metodo `is_preloaded()` para verificar status
  - Warmup usa query e documento juridico real em portugues

- `apps/api/app/services/rag/core/embeddings.py`
  - Adicionada lista `COMMON_LEGAL_QUERIES` com 31 queries juridicas comuns
  - Adicionada funcao `preload_embeddings_cache()` para pre-carregar embeddings
  - Adicionada funcao `is_embeddings_service_ready()` para verificar status

- `apps/api/app/main.py`
  - Adicionada funcao async `_preload_rag_models()` no lifespan
  - Preload executado em thread pool para nao bloquear event loop
  - Configuravel via `RAG_PRELOAD_RERANKER=true` e `RAG_PRELOAD_EMBEDDINGS=true`

### Variaveis de Ambiente
```bash
# Habilitar preload do reranker (cross-encoder model)
RAG_PRELOAD_RERANKER=true

# Habilitar preload de embeddings de queries juridicas comuns
RAG_PRELOAD_EMBEDDINGS=true
```

### Comandos Executados
- `python -m py_compile app/main.py app/services/rag/core/reranker.py app/services/rag/core/embeddings.py` â€” OK

### Decisoes Tomadas
- Preload via run_in_executor para nao bloquear startup
- Configuracao opt-in via env vars (padrao false)
- Queries de warmup em portugues juridico para otimizar cache hit rate
- Log de tempo de carga para monitoramento

### Impacto
- **Antes**: Primeira query RAG tinha latencia adicional de 2-5s para carregar modelo
- **Depois**: Modelos carregados no startup, primeira query sem cold start

---

## 2026-01-24 â€” CI/CD Integration para RAG Evaluation Automatizada

### Contexto
- Necessidade de automatizar avaliacao de qualidade do sistema RAG
- Workflow CI/CD para validar thresholds de metricas em PRs e pushes
- Execucao semanal completa com metricas LLM

### Arquivos Criados
- `.github/workflows/rag-eval.yml` â€” Workflow principal com:
  - Triggers: push/PR em paths RAG, schedule semanal (Monday 6am UTC), workflow_dispatch manual
  - Job `evaluate`: metricas basicas (context_precision, context_recall)
  - Job `weekly-full-eval`: metricas completas incluindo LLM (faithfulness, answer_relevancy)
  - Thresholds: context_precision >= 0.70, context_recall >= 0.65
  - Comentario automatico em PRs com resultados
  - Upload de artefatos (30 dias para PRs, 90 dias para weekly)

- `evals/benchmarks/v1.0_legal_domain.jsonl` â€” Dataset de benchmark juridico
  - 12 queries cobrindo Lei, Jurisprudencia, Doutrina
  - Topicos: licitacao, sumulas STJ, prisao preventiva, contratos admin, prescricao, dano moral coletivo, habeas corpus, desconsideracao PJ, dolo/culpa, modulacao STF, principios admin, reserva do possivel

- `evals/scripts/run_eval.sh` â€” Script para execucao local
  - Opcoes: --dataset, --top-k, --with-llm, --persist-db, --min-precision, --min-recall
  - Timestamp automatico no output
  - Geracao de report se eval_report.py existir

- `evals/results/.gitkeep` â€” Placeholder para diretorio de resultados

### Arquivos Alterados
- `eval_rag.py` â€” Adicionado alias `--output` para `--out` (compatibilidade CI)
- `.gitignore` â€” Adicionadas regras para ignorar resultados de avaliacao (exceto .gitkeep)

### Arquivos Removidos
- `.github/workflows/rag_eval.yml` â€” Removido (substituido pelo novo rag-eval.yml mais completo)

### Comandos Executados
- `mkdir -p evals/benchmarks evals/scripts evals/results` â€” OK
- `chmod +x evals/scripts/run_eval.sh` â€” OK

### Decisoes Tomadas
- Workflow dispatch manual para flexibilidade em testes
- Schedule semanal com metricas LLM (mais caro, mas completo)
- Thresholds conservadores inicialmente (70%/65%) para permitir baseline
- Comentario em PR usa GitHub Script para melhor formatacao
- Artefatos de weekly com 90 dias para analise de tendencias

### Proximos Passos
- Adicionar mais queries ao benchmark conforme casos de uso reais
- Configurar secrets no GitHub (OPENAI_API_KEY, GOOGLE_API_KEY)
- Ajustar thresholds apos baseline estabelecido
- Integrar com dashboard de observabilidade

---

## 2026-01-24 â€” Legal Domain RAG Evaluation Metrics

### Contexto
- Necessidade de metricas de avaliacao especificas para dominio juridico brasileiro
- Metricas RAGAS padrao nao capturam nuances legais (citacoes, vigencia temporal, jurisdicao)
- Implementacao de avaliador complementar ao RAGAS existente

### Arquivos Criados
- `apps/api/app/services/ai/rag_evaluator.py` â€” Modulo completo com:
  - `LegalEvalResult` dataclass para resultados de avaliacao
  - `extract_legal_claims()` â€” Extrai afirmacoes juridicas do texto
  - `count_cited_claims()` â€” Conta claims com citacoes
  - `evaluate_citation_coverage()` â€” % de claims com fonte atribuida
  - `extract_cited_laws()` â€” Extrai referencias legais (Lei, Decreto, MP, LC, etc.)
  - `is_law_current()` â€” Verifica se lei ainda esta em vigor (database de leis revogadas)
  - `evaluate_temporal_validity()` â€” % de leis citadas ainda vigentes
  - `evaluate_jurisdiction_match()` â€” Verifica se jurisdicao esta correta
  - `extract_legal_entities()` â€” Extrai entidades por tipo (laws, articles, sumulas, decisions)
  - `evaluate_entity_accuracy()` â€” Precision/recall de entidades extraidas
  - `evaluate_legal_answer()` â€” Executa todas as avaliacoes em uma resposta
  - `add_legal_metrics_to_ragas()` â€” Integra metricas legais aos resultados RAGAS
  - `evaluate_legal_batch()` â€” Avalia batch de amostras

### Padroes Regex Implementados
- Leis: Lei, LC, Decreto, Decreto-Lei, MP, Resolucao, IN, Portaria
- Codigos: CF, CPC, CPP, CTN, CDC, CLT, ECA
- Artigos: Art. X, Art. X, caput, Art. X, I, Art. X, Â§ 1Âº
- Sumulas: Sumula X TST/STF/STJ, Sumula Vinculante X, OJ X SDI
- Decisoes: RE, REsp, ADI, HC, MS + numeros CNJ

### Database de Leis Revogadas
- Lei 8.666/93 â€” parcialmente revogada (Lei 14.133/2021)
- Lei 10.520/2002 â€” revogada (Lei 14.133/2021)
- MP 927/2020 â€” perdeu eficacia (nao convertida)
- MP 936/2020 â€” convertida (Lei 14.020/2020)
- Decreto-Lei 200/67 â€” parcialmente vigente

### Metricas Implementadas
1. **Citation Coverage** (0-1): % de claims juridicos com citacao
2. **Temporal Validity** (0-1): % de leis citadas em vigor
3. **Jurisdiction Match** (bool): Jurisdicao correta (federal, estadual, municipal, trabalhista)
4. **Entity Precision** (0-1): Entidades corretas / entidades encontradas
5. **Entity Recall** (0-1): Entidades encontradas / entidades esperadas
6. **Legal Score** (0-1): Media ponderada (25% cit + 20% temp + 15% jur + 20% prec + 20% rec)

### Comandos Executados
- `python -m py_compile apps/api/app/services/ai/rag_evaluator.py` â€” OK
- Testes unitarios inline â€” 10/10 passaram

### Integracao com eval_rag.py
- Funcao `add_legal_metrics_to_ragas()` adiciona metricas legais ao payload existente
- Pode ser chamada apos `ragas.evaluate()` para enriquecer resultados
- Adiciona campos `legal_*` ao summary e `legal_metrics` a cada sample

### Proximos Passos
- Integrar chamada ao rag_evaluator no eval_rag.py principal
- Adicionar queries com expected_entities ao benchmark
- Criar dashboard de metricas legais
- Expandir database de leis revogadas

---

## 2026-01-24 â€” Testes Unitarios RAG Pipeline Core

### Contexto
- Componentes core do RAG pipeline (CRAG gate, query expansion, reranker) sem cobertura de testes
- Necessidade de testes que nao dependam de conexoes reais (OpenSearch, Qdrant)
- Uso de mocks para simular comportamentos

### Arquivos Criados

**Estrutura de testes:**
- `apps/api/tests/rag/__init__.py` â€” Pacote de testes RAG
- `apps/api/tests/rag/fixtures.py` â€” Fixtures e mocks compartilhados
  - Mock OpenSearch client responses
  - Mock Qdrant client responses
  - Mock embedding responses
  - Sample legal documents (legislacao, jurisprudencia)
  - Sample queries with expected results
  - Helper functions para assertions

**Testes CRAG Gate (66 testes):**
- `apps/api/tests/rag/test_crag_gate.py`
  - TestCRAGConfig: default values, overrides, from_rag_config
  - TestEvidenceLevel: classification properties, confidence scores
  - TestCRAGEvaluation: serialization, reason property
  - TestCRAGGateClassification: STRONG/MODERATE/LOW/INSUFFICIENT evidence
  - TestCRAGGateDecisions: pass/fail thresholds
  - TestCRAGGateRecommendedActions: strategies por evidence level
  - TestRetryStrategyBuilder: strategies for each evidence level
  - TestCRAGOrchestrator: evaluate, should_retry, get_retry_parameters
  - TestCRAGAuditTrail: create, add_action, finalize, serialization
  - TestCRAGIntegration: search_with_correction, dedupe
  - TestConvenienceFunctions: evaluate_crag_gate, get_retry_strategy
  - TestEdgeCases: single result, negative scores, missing fields

**Testes Query Expansion (65 testes):**
- `apps/api/tests/rag/test_query_expansion.py`
  - TestQueryExpansionConfig: default values, from_rag_config
  - TestTTLCache: get/set, expiration, eviction, stats
  - TestRRFScore: score calculation, rank ordering
  - TestMergeResultsRRF: dedup, fusion boost, top_k
  - TestMergeLexicalVectorRRF: hybrid results, weighted fusion
  - TestLegalAbbreviationExpansion: STF, STJ, CPC, CLT, CF expansion
  - TestQueryExpansionService: cache, heuristic variants
  - TestQueryExpansionServiceWithMockedLLM: HyDE, multi-query, advanced search
  - TestSingletonFactory: get_instance, reset
  - TestEdgeCases: unicode, special characters, LLM failure

**Testes Reranker (53 testes):**
- `apps/api/tests/rag/test_reranker.py`
  - TestRerankerConfig: default values, from_rag_config
  - TestRerankerResult: creation, bool, len, iter
  - TestPortugueseLegalDomainBoost: art, sumula, tribunals, CNJ, lei patterns
  - TestCrossEncoderRerankerCore: empty results, score preservation
  - TestBatchProcessing: multiple queries, top_k
  - TestTextTruncation: short, long, word boundary, empty
  - TestLazyLoading: model not loaded on init, loaded on use
  - TestFallbackBehavior: fallback model, original order
  - TestScoreNormalization: negative scores, min_score filter
  - TestConvenienceFunctions: rerank, rerank_with_metadata
  - TestSingletonPattern: get_instance, reset, cache
  - TestEdgeCases: missing text, empty text, different field names
  - TestLegalDomainIntegration: boost affects ranking

### Comandos Executados
- `pytest tests/rag/test_crag_gate.py -v -o "addopts="` â€” 66 passed
- `pytest tests/rag/test_query_expansion.py -v -o "addopts="` â€” 65 passed
- `pytest tests/rag/test_reranker.py -v -o "addopts="` â€” 53 passed
- `pytest tests/rag/ -v -o "addopts="` â€” 299 passed total

### Decisoes Tomadas
- Fixtures em arquivo separado para reutilizacao
- Mocks de CrossEncoder, OpenSearch, Qdrant para evitar dependencias externas
- Testes de edge cases para robustez
- Documentacao brasileira nos samples (legislacao, jurisprudencia)
- Patterns de domain boost para portugues juridico

### Cobertura de Testes
- **CRAG Gate**: evidence classification, gate decisions, retry strategies, audit trail
- **Query Expansion**: TTL cache, RRF fusion, legal abbreviations, HyDE, multi-query
- **Reranker**: legal domain boost, batch processing, lazy loading, fallback behavior

### Proximos Passos
- Integrar testes ao CI/CD pipeline
- Adicionar testes de integracao com mocks de storage services
- Expandir cobertura para graph enrichment e compression modules

---

## 2026-01-25 â€” ServiÃ§o de AutomaÃ§Ã£o de Tribunais

### Contexto
- Criar serviÃ§o para integrar o Iudex com tribunais brasileiros (PJe, eproc, e-SAJ)
- Suportar consultas e peticionamento
- Suportar 3 mÃ©todos de autenticaÃ§Ã£o: senha, certificado A1, certificado A3

### Arquivos Criados
- `apps/tribunais/package.json` â€” ConfiguraÃ§Ã£o do pacote
- `apps/tribunais/tsconfig.json` â€” ConfiguraÃ§Ã£o TypeScript
- `apps/tribunais/README.md` â€” DocumentaÃ§Ã£o completa da API
- `apps/tribunais/src/index.ts` â€” Entry point do serviÃ§o
- `apps/tribunais/src/types/index.ts` â€” Tipos (AuthType, OperationType, etc.)
- `apps/tribunais/src/services/crypto.ts` â€” Criptografia AES-256-GCM para credenciais
- `apps/tribunais/src/services/credentials.ts` â€” Gerenciamento de credenciais
- `apps/tribunais/src/services/tribunal.ts` â€” OperaÃ§Ãµes nos tribunais
- `apps/tribunais/src/api/server.ts` â€” Servidor Express
- `apps/tribunais/src/api/routes.ts` â€” Rotas da API REST
- `apps/tribunais/src/queue/worker.ts` â€” Worker BullMQ para operaÃ§Ãµes assÃ­ncronas
- `apps/tribunais/src/extension/websocket-server.ts` â€” WebSocket para extensÃµes Chrome
- `apps/tribunais/src/utils/logger.ts` â€” Logger Winston

### DecisÃµes Tomadas
- **Express v5**: Usar helper `getParam()` para lidar com params que podem ser array
- **Certificado A1**: Salvar buffer em arquivo temporÃ¡rio (tribunais-playwright espera path)
- **BullMQ/Redis**: Fila para operaÃ§Ãµes longas e que requerem interaÃ§Ã£o humana
- **WebSocket**: ComunicaÃ§Ã£o bidirecional com extensÃ£o Chrome para certificados A3
- **Mapeamento de tipos**: Converter entre tipos tribunais-playwright â†” Iudex

### Comandos Executados
- `pnpm build` (tribunais-playwright) â€” OK
- `npx tsc --noEmit` (Iudex/apps/tribunais) â€” OK apÃ³s correÃ§Ãµes

### Arquitetura
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frontend (Next.js) â†’ Backend (FastAPI) â†’ Tribunais  â”‚
â”‚                                         â”‚           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ API HTTP â”‚  â”‚ WebSocketâ”‚  â”‚ Worker (BullMQ)   â”‚ â”‚
â”‚  â”‚ :3100    â”‚  â”‚ :3101    â”‚  â”‚ (assÃ­ncrono)      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚               â”‚
    Cert A1/Senha    Cert A3 (extensÃ£o Chrome)
    (automÃ¡tico)     (interaÃ§Ã£o humana)
```

### PrÃ³ximos Passos
- Criar extensÃ£o Chrome para certificados A3
- Integrar com backend FastAPI do Iudex
- Adicionar testes de integraÃ§Ã£o
- Deploy em produÃ§Ã£o

---

## 2026-01-25 â€” Anexar Documentos a Casos com IntegraÃ§Ã£o RAG/Graph

### Contexto
- UsuÃ¡rio solicitou integraÃ§Ã£o completa de documentos com casos
- Documentos anexados devem ser automaticamente indexados no RAG local e no Grafo de Conhecimento
- Respeitar controle de acesso/escopo existente (multi-tenant)

### Arquivos Alterados (Backend)
- `apps/api/app/models/document.py` â€” Adicionados campos:
  - `case_id` â€” FK para casos
  - `rag_ingested`, `rag_ingested_at`, `rag_scope` â€” Tracking de indexaÃ§Ã£o RAG
  - `graph_ingested`, `graph_ingested_at` â€” Tracking de indexaÃ§Ã£o Graph

- `apps/api/app/api/endpoints/cases.py` â€” Novos endpoints:
  - POST `/{case_id}/documents/upload` â€” Upload direto para caso com auto-ingestÃ£o
  - GET `/{case_id}/documents` â€” Listar documentos do caso
  - POST `/{case_id}/documents/{doc_id}/attach` â€” Anexar documento existente
  - DELETE `/{case_id}/documents/{doc_id}/detach` â€” Desanexar documento

### Arquivos Criados (Backend)
- `apps/api/alembic/versions/e5b6c7d8f9a0_add_document_case_rag_fields.py` â€” Migration Alembic

### Arquivos Alterados (Frontend)
- `apps/web/src/lib/api-client.ts` â€” Novos mÃ©todos:
  - `getCaseDocuments()` â€” Buscar documentos do caso
  - `uploadDocumentToCase()` â€” Upload direto com FormData
  - `attachDocumentToCase()` â€” Anexar doc existente
  - `detachDocumentFromCase()` â€” Desanexar documento

- `apps/web/src/app/(dashboard)/cases/[id]/page.tsx` â€” Atualizada tab "Arquivos":
  - Lista documentos com status de indexaÃ§Ã£o RAG/Graph
  - Upload via drag-and-drop ou seleÃ§Ã£o de arquivo
  - Indicadores visuais de status (Ã­cones verde/amarelo)
  - BotÃ£o para desanexar documento do caso
  - Feedback automÃ¡tico de progresso

### Funcionalidades Implementadas
- **Upload direto para caso**: Arquivo â†’ Caso â†’ Auto-ingestÃ£o RAG local + Graph
- **Background tasks**: Processamento assÃ­ncrono de documentos
- **Status tracking**: Campos booleanos + timestamp para cada etapa de ingestÃ£o
- **UI responsiva**: Drag-and-drop, loading states, status icons
- **Fallback gracioso**: Se novo endpoint falhar, usa busca por tags (legado)

### Fluxo de IngestÃ£o
```
Upload â†’ Salvar documento â†’ Atualizar case_id â†’
  â”œâ”€â”€ Background: Extrair texto (PDF/DOCX/TXT/HTML)
  â”œâ”€â”€ Background: Ingerir RAG local (rag_ingested=true)
  â””â”€â”€ Background: Ingerir Graph Neo4j (graph_ingested=true)
```

### VerificaÃ§Ã£o
- `npx tsc --noEmit` â€” OK (sem erros nos arquivos modificados)
- `npm run lint` â€” Erros prÃ©-existentes em outros arquivos, nÃ£o nos modificados

### PrÃ³ximos Passos
- Implementar polling para atualizar status de ingestÃ£o em tempo real
- Adicionar opÃ§Ã£o para anexar documentos existentes da biblioteca
- Criar visualizaÃ§Ã£o de progresso de ingestÃ£o

---

## 2026-01-25 â€” ExtraÃ§Ã£o SemÃ¢ntica de Entidades via Embeddings + RAG

### Contexto
- Grafo Neo4j jÃ¡ tinha estrutura para teses e conceitos, mas extraÃ§Ã£o era apenas regex
- UsuÃ¡rio pediu para usar RAG e embeddings (nÃ£o LLM) para extraÃ§Ã£o semÃ¢ntica
- Implementada extraÃ§Ã£o baseada em embedding similarity:
  - Usa EmbeddingsService existente (OpenAI text-embedding-3-large)
  - Conceitos jurÃ­dicos prÃ©-definidos como "Ã¢ncoras" (seeds)
  - Similaridade coseno para encontrar conceitos no texto
  - RelaÃ§Ãµes baseadas em proximidade de embedding

### Arquivos Criados/Alterados
- `apps/api/app/services/rag/core/semantic_extractor.py` â€” Extrator baseado em embeddings
  - **33 conceitos seed**: princÃ­pios, institutos, conceitos doutrinÃ¡rios, teses
  - Usa `EmbeddingsService` (text-embedding-3-large, 3072 dims)
  - Similaridade coseno para matching (threshold: 0.75)
  - RelaÃ§Ãµes entre entidades semÃ¢nticas e regex (threshold: 0.6)

- `apps/api/app/services/rag/core/neo4j_mvp.py`:
  - ParÃ¢metro `semantic_extraction: bool` em `ingest_document()`
  - IntegraÃ§Ã£o com extrator de embeddings

- `apps/api/app/api/endpoints/graph.py`:
  - `ENTITY_GROUPS` expandido com tipos semÃ¢nticos
  - `SEMANTIC_RELATIONS` expandido

### Conceitos Seed (Ã‚ncoras)
| Categoria | Exemplos |
|-----------|----------|
| PrincÃ­pios | Legalidade, ContraditÃ³rio, Ampla Defesa, Dignidade |
| Institutos | PrescriÃ§Ã£o, DecadÃªncia, Dano Moral, Tutela Antecipada |
| Conceitos | Boa-FÃ© Objetiva, Abuso de Direito, Venire Contra Factum |
| Teses | Responsabilidade Objetiva do Estado, Teoria da Perda de Uma Chance |

### Fluxo de ExtraÃ§Ã£o
```
Documento â†’ Chunks â†’ Embedding (text-embedding-3-large)
                          â”‚
                          â–¼
              Cosine Similarity com Seeds
                          â”‚
                          â–¼
              Match (sim >= 0.75) â†’ Entidade SemÃ¢ntica
                          â”‚
                          â–¼
              Similarity com Entidades Regex â†’ RelaÃ§Ãµes
```

### VerificaÃ§Ã£o
- `python -c "from app.services.rag.core.semantic_extractor import get_semantic_extractor, LEGAL_CONCEPT_SEEDS; print(len(LEGAL_CONCEPT_SEEDS))"` â€” OK (33 seeds)

---

## 2026-01-26 â€” Melhorias na PÃ¡gina de Grafos: SeleÃ§Ã£o de Materiais e Pesquisa Lexical

### Contexto
- UsuÃ¡rio solicitou funcionalidades tÃ­picas de grafos Neo4j na pÃ¡gina `/graph`
- Objetivo: permitir filtrar o grafo por materiais da biblioteca/casos e pesquisa lexical

### DecisÃµes de Design
- **Layout**: Painel lateral esquerdo colapsÃ¡vel (confirmado pelo usuÃ¡rio)
- **Pesquisa lexical**: Sistema de tags simples - digitar e pressionar Enter (confirmado pelo usuÃ¡rio)

### Arquivos Criados

**`apps/web/src/components/graph/GraphMaterialSelector.tsx`**:
- Componente de seleÃ§Ã£o de materiais com 3 abas: Documentos, Casos, Biblioteca
- Checkbox para seleÃ§Ã£o mÃºltipla
- Busca integrada em cada aba
- Exibe badges com itens selecionados
- Toggle para ativar/desativar filtro por materiais

**`apps/web/src/components/graph/GraphLexicalSearch.tsx`**:
- Componente de pesquisa lexical com sistema de tags
- 3 categorias: Termos/Frases, Dispositivos Legais, Autores/Tribunais
- Badges coloridos por categoria (azul, verde, violeta)
- Seletor de modo de correspondÃªncia: "Qualquer (OU)" vs "Todos (E)"
- BotÃ£o para limpar todos os filtros

**`apps/web/src/components/graph/index.ts`**:
- Barrel export para os novos componentes

### Arquivos Alterados

**`apps/web/src/stores/graph-store.ts`**:
- Adicionados campos em `GraphFilters`:
  - `selectedDocuments: string[]`
  - `selectedCases: string[]`
  - `filterByMaterials: boolean`
  - `lexicalTerms: string[]`
  - `lexicalAuthors: string[]`
  - `lexicalDevices: string[]`
  - `lexicalMatchMode: 'all' | 'any'`
- Adicionadas 15+ actions para gerenciar os novos filtros
- Atualizado `selectFilteredNodes` para filtrar por termos lexicais no cliente

**`apps/web/src/app/(dashboard)/graph/GraphPageClient.tsx`**:
- Adicionado painel lateral esquerdo colapsÃ¡vel (w-80)
- Abas "Materiais" e "Lexical" com os novos componentes
- BotÃ£o de toggle no header para mostrar/ocultar painel de filtros
- Imports de novos Ã­cones (PanelLeftClose, PanelLeft, Filter)

**`apps/web/src/components/layout/sidebar-pro.tsx`**:
- Adicionado link para pÃ¡gina de Grafos (`/graph`) no menu lateral
- Ãcone: Network

### Estrutura do Painel de Filtros

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [Materiais] [Lexical]                   â”‚ â† Abas
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚ Aba Materiais:                          â”‚
â”‚ - Toggle "Filtrar por materiais"        â”‚
â”‚ - Busca                                 â”‚
â”‚ - [Docs] [Casos] [Biblioteca]           â”‚
â”‚ - Lista com checkboxes                  â”‚
â”‚ - Badges selecionados                   â”‚
â”‚                                         â”‚
â”‚ Aba Lexical:                            â”‚
â”‚ - Termos/Frases [tags + input]          â”‚
â”‚ - Dispositivos Legais [tags + input]    â”‚
â”‚ - Autores/Tribunais [tags + input]      â”‚
â”‚ - Modo: [Qualquer OU] [Todos E]         â”‚
â”‚ - [Limpar filtros]                      â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### VerificaÃ§Ã£o
- `npx tsc --noEmit` â€” OK (sem erros de tipo)
- Lint: erros prÃ©-existentes em outros arquivos (nÃ£o relacionados Ã s mudanÃ§as)

---

## 2026-01-26 â€” IntegraÃ§Ã£o Lexical Search com Neo4j Fulltext Index

### Contexto
- UsuÃ¡rio solicitou que a busca lexical fosse ancorada no RAG existente
- A implementaÃ§Ã£o original usava `CONTAINS` (ineficiente)
- TambÃ©m solicitou funcionalidade de inserir fatos do RAG local

### Pesquisa Neo4j
Consultada [documentaÃ§Ã£o oficial do Neo4j](https://neo4j.com/docs/cypher-manual/current/indexes/semantic-indexes/full-text-indexes/):
- Ãndices fulltext usam Apache Lucene
- Consulta via `db.index.fulltext.queryNodes(indexName, queryString)`
- Suporta operadores Lucene: AND, OR, aspas para match exato
- Retorna `node` e `score` (relevÃ¢ncia)

### Ãndices Fulltext Existentes no Projeto
O projeto jÃ¡ tinha Ã­ndices fulltext configurados em `neo4j_mvp.py`:
- `rag_entity_fulltext` â†’ Entity (name, entity_id, normalized)
- `rag_chunk_fulltext` â†’ Chunk (text_preview)
- `rag_doc_fulltext` â†’ Document (title)

### AlteraÃ§Ãµes no Backend

**`apps/api/app/api/endpoints/graph.py`**:

1. **Endpoint `/graph/lexical-search`** - Reescrito para usar fulltext index:
   ```python
   CALL db.index.fulltext.queryNodes('rag_entity_fulltext', $lucene_query) YIELD node AS e, score
   WHERE e.entity_type IN $types
   ```
   - ConstrÃ³i query Lucene com AND/OR baseado no match_mode
   - Escapa caracteres especiais do Lucene
   - Retorna `relevance_score` alÃ©m de `mention_count`
   - Fallback para CONTAINS se Ã­ndice fulltext nÃ£o disponÃ­vel

2. **Endpoint `/graph/add-from-rag`** - JÃ¡ existia com implementaÃ§Ã£o correta:
   - Busca chunks de documentos especificados
   - Extrai entidades com `LegalEntityExtractor.extract()`
   - Usa MERGE para entidades (evita duplicatas)
   - Cria relacionamentos MENTIONS

### IntegraÃ§Ã£o Frontend (jÃ¡ implementada)

**`apps/web/src/lib/api-client.ts`**:
- `graphLexicalSearch()` - chama `/graph/lexical-search`
- `graphAddFromRAG()` - chama `/graph/add-from-rag`

**`apps/web/src/lib/use-graph.ts`**:
- `useLexicalSearch()` - hook com React Query
- `useAddFromRAG()` - mutation hook

**`apps/web/src/components/graph/GraphLexicalSearch.tsx`**:
- Usa `useLexicalSearch` para buscar entidades
- Exibe resultados com score de relevÃ¢ncia

### VerificaÃ§Ã£o
- `python3 -m py_compile` â€” OK
- `npx tsc --noEmit` â€” OK

### Fluxo Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frontend: GraphLexicalSearch                                    â”‚
â”‚ - UsuÃ¡rio digita termos/dispositivos/autores                    â”‚
â”‚ - useLexicalSearch() faz chamada Ã  API                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Backend: /graph/lexical-search                                  â”‚
â”‚ - ConstrÃ³i Lucene query string (AND/OR)                         â”‚
â”‚ - CALL db.index.fulltext.queryNodes('rag_entity_fulltext', ...) â”‚
â”‚ - Retorna entidades rankeadas por score                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Neo4j: rag_entity_fulltext index                                â”‚
â”‚ - Indexa: Entity.name, Entity.entity_id, Entity.normalized      â”‚
â”‚ - Apache Lucene engine                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2026-02-03 â€” Implementacao dos Gaps 7 e 8 do Office Add-in

### Objetivo
Implementar Gap 7 (UI/UX Feedback de Aplicacao) e Gap 8 (Exportacao de Audit Log) para o Word Add-in.

### Arquivos Criados

**Frontend (apps/office-addin)**:
- `src/components/ui/Toast.tsx` â€” Sistema de notificacoes toast com suporte a success/error/warning/info
  - Componente `Toast` com auto-dismiss
  - `ToastContainer` para renderizar multiplos toasts
  - `useToast` hook para gerenciamento local
  - `toast` object global para uso fora de componentes React
  - `useGlobalToast` hook para conectar ao estado global

- `src/components/ui/Spinner.tsx` â€” Componente de loading spinner com tamanhos xs/sm/md/lg

- `src/api/audit-export.ts` â€” Utilitarios de exportacao de relatorios de auditoria
  - `exportAuditReport()` â€” Funcao principal que gera e baixa o relatorio
  - Suporte a formatos: JSON, CSV (com UTF-8 BOM para Excel), PDF (via HTML/print)
  - Inclui resumo com estatisticas e detalhes de cada redline

### Arquivos Modificados

**Frontend**:
- `src/components/playbook/ClauseCard.tsx`:
  - Adicionado estado de loading por acao (apply/comment/highlight/reject)
  - Feedback visual com spinner durante operacoes
  - Mensagem de erro detalhada com botao "Tentar novamente"
  - Callbacks agora retornam Promise para suportar async

- `src/components/playbook/PlaybookPanel.tsx`:
  - Integrado ToastContainer para feedback global
  - Adicionado dropdown de exportacao (JSON/CSV/PDF)
  - Spinners nos botoes de batch actions
  - Toast notifications para sucesso/erro de operacoes

**Backend (apps/api)**:
- `app/schemas/word_addin.py`:
  - Adicionado `AuditReportSummary` â€” Resumo do relatorio
  - Adicionado `AuditReportRedline` â€” Detalhes de cada redline no relatorio
  - Adicionado `AuditReportResponse` â€” Response completo do audit report

- `app/api/endpoints/word_addin.py`:
  - Adicionado import dos novos schemas
  - Novo endpoint `GET /playbook/run/{playbook_run_id}/audit-report`
  - Retorna relatorio completo com estados de redlines (applied/rejected/pending)

### Verificacao
- `python3 -m py_compile` â€” OK para schemas e endpoints
- `npx tsc --noEmit` â€” OK (sem erros de tipo)

### Funcionalidades Implementadas

**Gap 7 â€” UI/UX Feedback**:
- Spinner durante aplicacao de redlines (individual e batch)
- Toast de sucesso/erro apos cada acao
- Mensagem de erro detalhada no card do redline
- Botao "Tentar novamente" em caso de falha
- Feedback visual nos botoes de batch (Apply All, Comentar tudo, etc)

**Gap 8 â€” Exportacao de Audit Log**:
- Dropdown "Exportar" no header da tela de resultados
- Export JSON com estrutura completa do relatorio
- Export CSV com UTF-8 BOM para compatibilidade com Excel
- Export PDF via HTML que abre dialogo de impressao
- Relatorio inclui: resumo, risk score, status de cada redline, timestamps

---

<!-- Novas entradas acima desta linha -->

## 2026-02-05 â€” SessÃ£o 125: CriaÃ§Ã£o do AskModeToggle

### Objetivo
Criar componente de toggle para alternar entre 3 modos de consulta na pÃ¡gina /ask: auto, edit e answer.

### Arquivos Criados
- apps/web/src/components/ask/ask-mode-toggle.tsx â€” Componente principal (2.6KB)
- apps/web/src/components/ask/ask-mode-toggle.example.tsx â€” Exemplo de uso interativo (2.1KB)
- apps/web/src/components/ask/README.md â€” DocumentaÃ§Ã£o completa (1.5KB)

### Arquivos Alterados
- apps/web/src/components/ask/index.ts â€” Adicionadas exportaÃ§Ãµes do componente e tipo QueryMode

### DecisÃµes TÃ©cnicas
- **PadrÃ£o Segmented Control**: Seguiu padrÃ£o Tabs do shadcn/ui para consistÃªncia
- **Ãcones**: Sparkles (Auto), Edit3 (Editar), MessageSquare (Responder) do lucide-react
- **Tooltips**: TooltipProvider com delay 300ms
- **Responsividade**: Labels ocultas < 640px (sm), apenas Ã­cones
- **Acessibilidade**: Roles ARIA (tablist/tab), aria-selected, aria-label
- **Estilo**: Aspas simples conforme padrÃ£o do projeto

### Funcionalidades
- Toggle entre 3 modos: 'auto' | 'edit' | 'answer'
- Tooltips descritivos em portuguÃªs
- Interface adaptativa (mobile = Ã­cones, desktop = Ã­cones + labels)
- IntegraÃ§Ã£o com theme system (dark/light mode)

### VerificaÃ§Ã£o
- âœ… ESLint passou sem erros
- âœ… PadrÃµes do projeto seguidos
- âœ… DocumentaÃ§Ã£o e exemplo criados

---
