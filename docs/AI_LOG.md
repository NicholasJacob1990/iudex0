# AI_LOG.md ‚Äî Hist√≥rico de Sess√µes Claude Code

> Este arquivo registra as sess√µes do Claude Code neste projeto.
> Atualize ao final de cada sess√£o significativa.

---

## 2026-02-13 ‚Äî Uniformiza√ß√£o custom_prompt + ASR Hints Multi-Provider + Telemetria

### Resumo
Implementa√ß√£o de 6 fases para uniformizar hints ASR em todos os providers de transcri√ß√£o (AssemblyAI, RunPod, Whisper local, ElevenLabs), corrigir cache hashing, uniformizar custom_prompt `tables_only` em FIDELIDADE, e adicionar suporte a custom_spelling + telemetria no AssemblyAI.

### Arquivos Alterados
- `apps/api/app/services/transcription_service.py` ‚Äî `_normalize_hints()` centralizado, `_hash_list()`/`_hash_spelling()` helpers, cache hashes enriched (hints_fingerprint, speaker_id, custom_spelling, prompt_mode), AAI modo exclusivo prompt/keyterms, `speech_model_used` logging, RunPod hints via initial_prompt, Whisper hints via `_transcribe_whisper_with_optional_external_diarization()`, ElevenLabs scribe_v2 feature-flagged
- `mlx_vomo.py` ‚Äî `extra_terms` param em `_get_whisper_initial_prompt_for_asr()`, `transcribe_with_segments()`, `transcribe_beam_with_segments()`, `transcribe()`, `_transcribe_with_segments_chunked()`, `transcribe_file_full()`, `_build_system_prompt()` com `custom_prompt_scope`
- `apps/api/app/schemas/transcription.py` ‚Äî `CustomPromptScopeType`, `SpellingCorrection` model, `custom_prompt_scope` + `custom_spelling` fields
- `apps/api/app/api/endpoints/transcription.py` ‚Äî `custom_prompt_scope` Form em 6 endpoints, `area`/`custom_keyterms` em hearing endpoints

### Arquivos Criados (testes)
- `apps/api/tests/test_normalize_hints.py` ‚Äî 35 testes
- `apps/api/tests/test_custom_prompt_scope.py` ‚Äî 7 testes
- `apps/api/tests/test_assemblyai_improvements.py` ‚Äî 14 testes
- `apps/api/tests/test_runpod_hints.py` ‚Äî 8 testes
- `apps/api/tests/test_whisper_hints.py` ‚Äî 14 testes
- `apps/api/tests/test_elevenlabs_v2.py` ‚Äî 12 testes

### Decis√µes Tomadas
- Provider limits: AAI=1000, RunPod=200, ElevenLabs=100, Whisper=50
- AAI modo exclusivo: >50 keyterms ‚Üí keyterms_only; ‚â§50 ‚Üí both; sem ‚Üí prompt_only
- Whisper hints via `extra_terms` param expl√≠cito (sem estado global mut√°vel)
- ElevenLabs scribe_v2 feature-flagged via `ELEVENLABS_USE_SCRIBE_V2=true`
- FIDELIDADE agora usa `tables_only` por padr√£o (opt-in `style_and_tables` para legacy)

### Testes
- 90/90 testes passando em todas as 6 fases

### Env Vars Novas
- `ELEVENLABS_USE_SCRIBE_V2=true` ‚Äî ativa scribe_v2 com keyterms

---

## 2026-02-13 ‚Äî Embedding Provider Standardization: voyage-4-large 1024d

### Resumo
Padroniza√ß√£o dos providers de embedding no Iudex para usar voyage-4-large (1024d) como modelo padr√£o para direito BR, substituindo JurisBERT (768d). Implementa√ß√£o de 8 melhorias ordenadas por impacto/esfor√ßo + corre√ß√£o de 6 findings de code review (2 HIGH, 4 MEDIUM).

### Arquivos Alterados (8 melhorias)
- `apps/api/app/services/rag/embedding_router.py` ‚Äî Adicionado VOYAGE_V4 ao enum, nova collection legal_br_v4 (1024d), BR roteia para voyage-4-large, usage tracking, deprecation warning para legacy collections
- `apps/api/app/services/rag/voyage_embeddings.py` ‚Äî Default model mudado para voyage-4-large, OpenAI fallback com Matryoshka dimension reduction compat√≠vel com target
- `apps/api/app/services/rag/kanon_embeddings.py` ‚Äî OpenAI fallback usa self._dimensions (Matryoshka) em vez de 3072d hardcoded
- `apps/api/app/services/rag/jurisbert_embeddings.py` ‚Äî OpenAI fallback usa JURISBERT_DIMENSIONS (768) em vez de 3072d hardcoded
- `apps/api/app/services/rag/core/neo4j_mvp.py` ‚Äî vector_dimensions default 768‚Üí1024, NEO4J_VECTOR_DIM separado de NEO4J_EMBEDDING_DIM
- `apps/api/app/services/rag/core/graph_neo4j.py` ‚Äî Env var separada NEO4J_KG_EMBEDDING_DIM para KG embeddings (128d)
- `apps/api/app/services/rag/core/embeddings.py` ‚Äî VOYAGE_DEFAULT_MODEL default atualizado
- `apps/api/app/services/rag/legal_embeddings.py` ‚Äî VOYAGE_DEFAULT_MODEL default atualizado
- `apps/api/app/services/rag/config.py` ‚Äî Coment√°rios clarificando dimens√µes por provider
- `apps/api/app/services/rag/.env.example` ‚Äî Documenta√ß√£o de routing overrides e voyage-context-3

### Arquivos Alterados (6 findings de code review)
- `apps/api/app/services/rag/core/contextual_embeddings.py` ‚Äî `_RE_ART_WITH_LEI` regex agora com `re.IGNORECASE` e `[A-Za-z]` (era `[A-Z]`)
- `apps/api/app/services/rag/core/kg_builder/legal_postprocessor.py` ‚Äî `_apply_normalization()` paginado com SKIP/LIMIT (era `list()` de todos os n√≥s)
- `apps/neo4j-rag/neo4j_rag/pipeline.py` ‚Äî `ensure_indexes()` separa critical vs optional; critical falha com RuntimeError
- `apps/neo4j-rag/neo4j_rag/ingest/graph_builder.py` ‚Äî `ingest_document()` usa `session.execute_write()` para atomicidade transacional
- `apps/neo4j-rag/neo4j_rag/cli.py` ‚Äî `ingest` command retorna exit code 1 quando h√° erros

### Arquivos Criados
- `apps/api/scripts/bench_embedding_providers.py` ‚Äî Script de benchmark JurisBERT vs voyage-4-large

### Decis√µes Tomadas
- voyage-4-large (1024d, $0.12/1M tok) como padr√£o BR em vez de JurisBERT (768d)
- Dimens√µes hardcodadas por provider nos fallback paths (elimina ambiguidade EMBEDDING_DIMENSIONS)
- NEO4J_VECTOR_DIM separado de NEO4J_EMBEDDING_DIM para evitar conflito chunk vs KG embeddings
- Legacy collections (lei, juris, etc.) mantidas com warning de depreca√ß√£o
- OpenAI fallback usa Matryoshka dimension reduction para gerar vetores na dimens√£o do provider original (1024d para Voyage/Kanon, 768d para JurisBERT)
- ensure_indexes distingue critical (vector, fulltext, constraints) de optional (lookup indexes)
- graph_builder.py usa managed transactions (session.execute_write) para rollback at√¥mico por documento

---

## 2026-02-13 ‚Äî RunPod Worker v3: Worker Unificado + Client Completo

### Resumo
Implementa√ß√£o completa do plano de evolu√ß√£o do RunPod Custom Worker v3, abrangendo todas as fases (0-3) aprovadas.

### Fases Implementadas

**Fase 0 ‚Äî Quick Wins:**
- Idle timeout atualizado para 300s via RunPod GraphQL API
- FlashBoot: requer ativa√ß√£o manual via console RunPod

**Fase 1 ‚Äî Handler v3 (rp_handler.py reescrito):**
- BatchedInferencePipeline (2-4x speedup)
- Multi-model (large-v3 + large-v3-turbo) com hot-swap e GC
- Hotwords jur√≠dicos (STJ, STF, agravo, mandado, etc.)
- Anti-hallucination (repetition_penalty=1.1, no_repeat_ngram_size=3)
- Todos os params do worker oficial suportados
- Generator handler (streaming via /stream/{job_id})
- int8_float16 compute type (35% menos VRAM)
- FFmpeg audio preprocessing (opcional)
- SRT/VTT output formats
- Metadata passthrough

**Fase 2 ‚Äî Worker Unificado:**
- Diariza√ß√£o pyannote 3.1 integrada no mesmo container
- WhisperX word alignment (opcional)
- Speaker assignment por overlap (segmento + palavra)
- Elimina necessidade do endpoint separado de diariza√ß√£o

**Fase 3 ‚Äî Client (runpod_transcription.py):**
- `submit_unified_job()` para worker v3 (transcri√ß√£o + diariza√ß√£o unificada)
- `stream_results()` para consumir generator handler via /stream/{job_id}
- Webhook URL no payload (env RUNPOD_WEBHOOK_URL)
- Hallucination filter (BoH) em `extract_transcription()`
- Suporte ao novo output format v3 (speakers, SRT/VTT, metadata, model info)
- Fallback strategy: primary ‚Üí v3 unified ‚Üí legacy diarization endpoint

### Arquivos Alterados
- `apps/runpod-worker/rp_handler.py` ‚Äî reescrito completo (v3)
- `apps/runpod-worker/Dockerfile` ‚Äî base atualizada, multi-model, pyannote, int8_float16
- `apps/runpod-worker/requirements.txt` ‚Äî faster-whisper 1.2+, pyannote, whisperx
- `apps/api/app/services/runpod_transcription.py` ‚Äî stream, webhook, hallucination filter, v3 output
- `apps/api/tests/test_runpod_client.py` ‚Äî 24 testes (novos: hallucination, v3 output, unified diarization)
- `.github/workflows/deploy-runpod-worker.yml` ‚Äî v3 tags, HF_TOKEN build arg, int8_float16 env

### Testes
- 24/24 testes RunPod client passando
- 7/7 testes base URL resolution passando
- 12/12 testes transcription queue passando

### Pr√≥ximos Passos
- Ativar FlashBoot via console RunPod
- Build e push Docker image v3 (trigger GitHub Actions)
- Adicionar `HF_TOKEN` secret ao GitHub repo (para build Docker com pyannote)

---

## 2026-02-13 ‚Äî Fase 4: P√≥s-processamento de Transcri√ß√£o + Webhook

### Resumo
Implementa√ß√£o completa da Fase 4 do plano RunPod v3: p√≥s-processamento de qualidade para transcri√ß√µes jur√≠dicas e endpoint webhook para callbacks do RunPod.

### Funcionalidades Implementadas

**Endpoint Webhook (`POST /transcription/webhook`):**
- Recebe callbacks do RunPod ao completar job
- Busca job correspondente pelo `runpod_run_id`
- Aplica pipeline de p√≥s-processamento automaticamente
- Salva resultado processado no disco

**Dicion√°rio Jur√≠dico (`apply_legal_dictionary`):**
- 30+ padr√µes regex para corre√ß√µes de termos legais comuns do Whisper
- Palavras partidas: "a gravo" ‚Üí "agravo", "em bargos" ‚Üí "embargos", "man dado" ‚Üí "mandado"
- Confus√µes fon√©ticas: "havias corpus" ‚Üí "habeas corpus", "est √© efe" ‚Üí "STF"
- Abrevia√ß√µes de tribunais: "t√™ jota esse" ‚Üí "TJS"

**Restaura√ß√£o de Pontua√ß√£o (`restore_punctuation`):**
- Ponto antes de "Artigo", "Par√°grafo", "Inciso", etc.
- V√≠rgula antes de conjun√ß√µes adversativas (por√©m, contudo, todavia)
- Dois-pontos ap√≥s verbos decis√≥rios (decide, determina, resolve)
- Normaliza√ß√£o de espa√ßos m√∫ltiplos

**Normaliza√ß√£o de Siglas (`normalize_acronyms`):**
- ~30 siglas jur√≠dicas (STF, STJ, CPC, OAB, TJSP, etc.)
- Uppercasing word-boundary-safe

**Detec√ß√£o de Alucina√ß√£o via LLM (`detect_hallucinations_llm`):**
- Score 0-1 por segmento usando Gemini 2.0 Flash
- Detec√ß√£o heur√≠stica de segmentos suspeitos (curtos, repetidos, final de √°udio)
- Async para n√£o bloquear pipeline

**Integra√ß√£o no Pipeline:**
- `postprocess_transcription()` chamado em `_transcribe_via_runpod()` ap√≥s `extract_transcription()`
- Non-fatal: falha no postprocessing n√£o bloqueia transcri√ß√£o

### Arquivos Criados
- `apps/api/app/services/transcription_postprocessing.py` ‚Äî m√≥dulo completo de p√≥s-processamento
- `apps/api/tests/test_transcription_postprocessing.py` ‚Äî 28 testes

### Arquivos Alterados
- `apps/api/app/api/endpoints/transcription.py` ‚Äî endpoint webhook
- `apps/api/app/services/transcription_service.py` ‚Äî integra√ß√£o do postprocessing

### Testes
- 71/71 testes passando (24 RunPod + 7 base URL + 12 queue + 28 postprocessing)

---

## 2026-02-12 ‚Äî Fix: Diffs n√£o apareciam para corre√ß√£o de itens diagn√≥sticos

### Resumo
Corrigido bug onde clicar "Corrigir com IA" em itens de diagn√≥stico (Auditoria preventiva, Valida√ß√£o, An√°lise estrutural, etc.) n√£o gerava diffs vis√≠veis no DiffConfirmDialog.

### Causa Raiz
3 problemas combinados:
1. **`fix_type` errado**: Issues classificados como `structural` iam para `apply_structural_fixes_from_issues`, que s√≥ trata `duplicate_paragraph/duplicate_section/heading_numbering` e ignora qualquer outra categoria ‚Üí zero mudan√ßas.
2. **Sem `suggested_section`**: Backend n√£o conseguia inferir em qual se√ß√£o H2 aplicar a corre√ß√£o (4 estrat√©gias de fallback todas falhavam).
3. **Batch sem `formatted_context`**: `handleFixDiagnosticModule` enviava issues sem contexto da se√ß√£o ‚Üí backend ca√≠a no fallback de documento inteiro ‚Üí LLM retornava conte√∫do inalterado.

### Corre√ß√µes Aplicadas
- `diagnosticToActionable`: For√ßar `fix_type: 'content'` para TODOS os issues diagn√≥sticos (structural fix engine n√£o os suporta)
- Extrair `suggested_section` do `raw_item` (`localizacao_formatado`, `localizacao`, `heading_line`) e de `evidence_formatted`
- Extrair `reference` do `raw_item` (`trecho_formatado`, `correcao_sugerida`)
- `handleFixDiagnosticModule`: Enriquecer cada issue com `formatted_context` via `extractSectionFromMarkdown` antes de enviar ao backend

### Arquivos Alterados
- `apps/web/src/app/(dashboard)/transcription/page.tsx` ‚Äî `diagnosticToActionable`, `handleFixDiagnosticModule`

### Verifica√ß√£o
- `npx tsc --noEmit` ‚Äî OK
- `npx eslint` ‚Äî OK

---

## 2026-02-12 ‚Äî APOSTILA: Passada Final com Contexto Total

### Resumo
Aplicada a mesma estrat√©gia de contexto total da revis√£o leve de FIDELIDADE na passada final do modo APOSTILA (`ai_structure_review`), reduzindo truncamento em documentos longos durante a revis√£o sem√¢ntica.

### Arquivos Modificados
- `mlx_vomo.py` ‚Äî `ai_structure_review` agora usa contexto completo por padr√£o (`use_full_context=True` via `IUDEX_APOSTILA_FULL_CONTEXT`), com fallback legado opcional para truncamento.

### Decis√µes
- Padr√£o: **janela total** para APOSTILA na passada final.
- Compatibilidade: env `IUDEX_APOSTILA_FULL_CONTEXT` pode desligar e voltar ao comportamento antigo (truncar para 800k chars e estrutura para 50k).
- Revis√£o de FIDELIDADE j√° permanecia em contexto total.

### Verifica√ß√£o
- `python3 -m py_compile mlx_vomo.py` sem erros.

---

## 2026-02-12 ‚Äî Paralelizar HIL Fix Pipeline (asyncio.gather)

### Resumo
Otimizado `fix_content_issues_with_llm` em `quality_service.py` para processar se√ß√µes em paralelo
ao inv√©s de sequencialmente. Chamadas LLM por se√ß√£o s√£o independentes ‚Äî a depend√™ncia de ordem
(bottom-up) existe apenas na aplica√ß√£o dos patches ao documento.

### Arquivos Modificados
- `apps/api/app/services/quality_service.py` ‚Äî Substitu√≠do loop sequencial (linhas 1456-1492) por `asyncio.gather()` + `Semaphore(5)`. Issues legal + other s√£o mescladas numa √∫nica passada por se√ß√£o. Patches aplicados bottom-up ap√≥s todas as chamadas LLM completarem.

### Decis√µes
- `asyncio.Semaphore(max_concurrent=5)` via `IUDEX_HIL_MAX_CONCURRENT_SECTIONS` ‚Äî limita press√£o na API
- `original_content_snapshot` capturado uma vez ‚Äî todos os prompts leem do mesmo snapshot
- Retry logic permanece dentro de `_patch_section` (sob o sem√°foro, n√£o bloqueia outras se√ß√µes)
- Fallback para documento inteiro continua sequencial (1 √∫nica chamada LLM)

### Performance Esperada
- 5 se√ß√µes: ~50s ‚Üí ~10s (5x)
- 10 se√ß√µes: ~100s ‚Üí ~20s (5x)

---

## 2026-02-12 ‚Äî UnifiedAuditPanel: MetricsGrid, StatusBar, ModuleBreakdown

### Resumo
Reescrito `UnifiedAuditPanel` para restaurar funcionalidades que existiam no antigo `QualityPanel`:
grid de m√©tricas (Fidelidade/Alertas/Corre√ß√µes HIL), barra de status (aprova√ß√£o, timestamp, HIL, taxa compress√£o),
badges de omiss√µes/distor√ß√µes no m√≥dulo de valida√ß√£o, e renderiza√ß√£o de coverage como prosa (n√£o issues individuais).

### Arquivos Modificados
- `apps/web/src/components/dashboard/unified-audit-panel.tsx` ‚Äî Reescrito com novos sub-componentes: `MetricsGrid`, `StatusBar`, `formatTimestamp`; props `validationReport` e `analysisResult` adicionadas; `ModuleBreakdown` enriquecido (badges omiss√µes/distor√ß√µes, coverage como prosa)
- `apps/web/src/app/(dashboard)/transcription/page.tsx` ‚Äî Passado `validationReport={jobQuality?.validation_report}` e `analysisResult={jobQuality?.analysis_result}` ao `<UnifiedAuditPanel>`

### Decis√µes
- Dados j√° vinham do backend (`quality.validation_report`, `quality.analysis_result`) ‚Äî mudan√ßa puramente de frontend
- Coverage check renderiza como bloco monospace (prosa) ao inv√©s de lista de issues, evitando bug visual
- Score de fidelidade (valida√ß√£o) exibido separadamente do score consolidado (min(preventive, validation))
- StatusBar mostra taxa de compress√£o com alerta visual quando < 70%

---

## 2026-02-12 ‚Äî Melhorias UI Transcri√ß√£o + Desabilitar Fallback + Registry Updates

### Resumo
Desabilitado fallback autom√°tico de engine (AAI‚ÜíWhisper), melhorado polling de progresso na UI, corrigido SSE streams cruzando entre jobs, e adicionado atualiza√ß√£o do registry no emit para progresso em tempo real.

### Arquivos Modificados
- `apps/api/app/services/transcription_service.py` ‚Äî `_is_provider_fallback_allowed()` retorna `False` quando usu√°rio escolheu engine espec√≠fica; `emit()` atualiza registry a cada 3s via `job_id`
- `apps/api/app/api/endpoints/transcription.py` ‚Äî Adicionado `job_id=` em 4 call sites de `process_file_with_progress`
- `apps/web/src/app/(dashboard)/transcription/page.tsx` ‚Äî Polling 5s para jobs ativos; AbortController para cancelar SSE streams stale
- `apps/web/scripts/check-node-version.cjs` ‚Äî Relaxado check de vers√£o Node (permite v25+)

### Decis√µes
- Fallback off por padr√£o quando engine √© escolhida pelo usu√°rio (respeitar escolha)
- Registry update a cada 3s (n√£o a cada emit) para evitar overhead de I/O
- AbortController ref para evitar state corruption quando usu√°rio troca de job

---

## 2026-02-12 ‚Äî RunPod Custom Endpoint + Fix output=None + Importa√ß√£o AssemblyAI

### Resumo
Recria√ß√£o de endpoint RunPod com imagem Docker custom (`nicholasjacob1990/faster-whisper-diarize:v1`), corre√ß√£o do bug cr√≠tico `output=None` no RunPod, e importa√ß√£o de 2 jobs AssemblyAI para o sistema de cache do Iudex.

### Problemas Resolvidos
1. **RunPod `output=None`**: Worker recebia payload com 7 aliases de URL + campo `"transcription": "plain_text"` que confundiam o handler. Simplificado para `{"audio": url}` apenas.
2. **GraphQL API mudou**: RunPod migrou de `api.runpod.ai/graphql` ‚Üí `api.runpod.io/graphql`.
3. **Endpoint throttled**: Primeiro endpoint criado com GPUs limitadas (AMPERE_24,16). Recriado com sele√ß√£o ampla.
4. **HMAC token mismatch**: Testes manuais usavam `hashlib.sha256()` mas c√≥digo usa `hmac.new()` com `settings.SECRET_KEY`.
5. **Cache AAI miss para PGM_RJ**: SHA-256 dos arquivos PGM_RJ difere dos temp_cloud. Criados cache entries para hashes reais.

### Arquivos Modificados
- `apps/api/app/services/runpod_transcription.py` ‚Äî Simplifica√ß√£o do `submit_job()`: removido `_with_audio_aliases()` e `"transcription": "plain_text"`
- `apps/api/.env` ‚Äî `RUNPOD_ENDPOINT_ID=e7apudo9b603of` (custom, 2x mais r√°pido que official)

### Arquivos Criados
- `apps/api/storage/aai_transcripts/9df6d990*.json` ‚Äî Cache AAI para `15_Administrativo_Tributario.mp3`
- `apps/api/storage/aai_transcripts/7e42a07a*.json` ‚Äî Cache AAI para `17_Tributario_Eduardo_Sobral.mp3`
- `apps/api/storage/aai_transcripts/d0032d38*.json` ‚Äî Cache AAI para `15_Administrativo_Tributario.mp4`
- `apps/api/storage/aai_transcripts/f029905f*.json` ‚Äî Cache AAI para `17_Tributario_Eduardo_Sobral.mp4`
- `storage/assemblyai_cache/*.json` ‚Äî Respostas completas AAI (raw + iudex format)

### RunPod Endpoints (estado atual)
| Endpoint | ID | Imagem | Uso |
|---|---|---|---|
| Custom (ativo) | `e7apudo9b603of` | `nicholasjacob1990/faster-whisper-diarize:v1` | Transcri√ß√£o principal |
| Official (backup) | `ey0lpri25p5y7g` | `runpod/ai-api-faster-whisper:1.0.10` | Backup |
| Diariza√ß√£o | `m4rtd819crtvmw` | Custom pyannote | Diariza√ß√£o separada |

### Testes Manuais
- Custom endpoint: 13.6s, 50 segments, 5582 chars, 1007 word timestamps
- Official endpoint: 26.1s, mesma output
- **Custom 2x mais r√°pido**

### Jobs AssemblyAI Importados
- `3061c7ac` ‚Üí `15_Administrativo_Tributario` (235min, 187772 chars)
- `d50683b9` ‚Üí `17_Tributario_Eduardo_Sobral` (266min, 201898 chars, 4 speakers)

### Pend√™ncias
- Re-testar transcri√ß√£o RunPod via UI ap√≥s fix do payload
- Testar cache AAI para arquivos PGM_RJ via UI (modo APOSTILA)

---

## 2026-02-11 ‚Äî Unifica√ß√£o do Sistema de Auditoria (3 abas ‚Üí 1)

### Resumo
Unifica√ß√£o completa do sistema de auditoria na p√°gina de transcri√ß√£o. Antes: 3 abas divergentes (Qualidade, Auditoria Preventiva, Corre√ß√µes HIL) lendo de fontes diferentes para o mesmo job. Agora: 1 aba "Auditoria" com fonte can√¥nica √∫nica (`audit_summary.json` para vis√£o, `audit_issues` para a√ß√µes HIL).

### Arquivos Criados
- `apps/web/src/lib/audit-types.ts` ‚Äî Tipos TS: AuditSummary, AuditModule, AuditActionableIssue
- `apps/web/src/components/dashboard/unified-audit-panel.tsx` ‚Äî Painel unificado: ScoreCard, ModuleBreakdown (Accordion), ActionableIssuesList

### Arquivos Modificados
- `apps/api/app/api/endpoints/transcription.py` ‚Äî Helpers `_build_audit_context_from_job()` e `_regenerate_audit_for_job()`, endpoint `POST /jobs/{id}/regenerate-audit`, regenera√ß√£o autom√°tica no `POST /jobs/{id}/quality`
- `apps/web/src/lib/api-client.ts` ‚Äî `regenerateTranscriptionAudit()`, payload expandido em `updateTranscriptionJobQuality`
- `apps/web/src/app/(dashboard)/transcription/page.tsx` ‚Äî Substitui√ß√£o de 3 tabs por 1 "Auditoria" (non-hearing), hearing mode inalterado

### Arquivos Deprecados (mantidos por 1 ciclo)
- `apps/web/src/components/dashboard/quality-panel.tsx`
- `apps/web/src/components/dashboard/audit-issues-panel.tsx`
- `apps/web/src/components/dashboard/preventive-audit-panel.tsx`

### Decis√µes Tomadas
- Regenera√ß√£o full pipeline (5 plugins) no `POST /quality`, n√£o no `/apply-revisions`
- Score policy: `min(preventive_score, validation_score)` quando ambos existem
- `audit_issues` (IDs est√°veis MD5) como fonte can√¥nica de a√ß√µes HIL
- Hearing mode completamente inalterado (mant√©m aba qualidade separada)
- Troca imediata de UI (sem feature flag)

### Testes
- 18 testes de auditoria: PASSED
- 56 testes transcription/quality/hearing: PASSED
- TypeScript: compila sem erros
- Next.js: compila sem erros (9606 m√≥dulos)

### Nota
- Teste pr√©-existente `test_unified_audit_endpoint.py` j√° estava quebrado (importa `app.schemas.audit_unified` que nunca existiu) ‚Äî n√£o √© das nossas mudan√ßas

---

## 2026-02-11 ‚Äî Transcri√ß√£o Paralela: RunPod WhisperX + Fila Inteligente + Diariza√ß√£o

### Resumo
Implementa√ß√£o completa de transcri√ß√£o paralela com RunPod Serverless (WhisperX worker) incluindo:
- Provider registry com sem√°foro per-provider (Whisper sequencial, AssemblyAI/RunPod paralelo)
- RunPod async HTTP client adaptado para WhisperX (diariza√ß√£o com pyannote)
- Audio serve endpoint com HMAC tokens para RunPod workers
- Multi-upload frontend com jobs independentes e seletor de engine
- Configura√ß√£o da conta RunPod via Playwright ($10 cr√©ditos, WhisperX endpoint)

### Arquivos Criados
- `apps/api/app/services/transcription_providers.py` ‚Äî Provider registry (Whisper, AssemblyAI, ElevenLabs, RunPod)
- `apps/api/app/services/runpod_transcription.py` ‚Äî RunPod async client (WhisperX format, diariza√ß√£o)
- `apps/api/tests/test_runpod_client.py` ‚Äî 14 testes (submit, poll, cancel, extract com/sem diariza√ß√£o)
- `apps/api/tests/test_transcription_queue.py` ‚Äî 12 testes (sem√°foros per-provider, concurrency)

### Arquivos Modificados
- `apps/api/app/api/endpoints/transcription.py` ‚Äî Sem√°foros per-provider + audio serve endpoint
- `apps/api/app/services/transcription_service.py` ‚Äî Integra√ß√£o RunPod no fluxo SSE
- `apps/web/src/app/(dashboard)/transcription/page.tsx` ‚Äî Multi-upload + engine selector
- `apps/web/src/lib/api-client.ts` ‚Äî Tipo `runpod` no union de engines
- `apps/api/.env` ‚Äî RUNPOD_API_KEY, RUNPOD_ENDPOINT_ID, HUGGINGFACE_ACCESS_TOKEN
- `apps/web/.env.local` ‚Äî NEXT_PUBLIC_RUNPOD_ENABLED=true

### Decis√µes Tomadas
- **WhisperX** em vez de Faster Whisper: inclui diariza√ß√£o (pyannote) e word alignment
- Input field `audio_file` (WhisperX) vs `audio` (Faster Whisper)
- Endpoint WhisperX (`x9kudgpn8mjsva`): GPU 80GB/48GB Pro, max 2 workers, US-TX-3
- Diariza√ß√£o ativada por padr√£o quando `HUGGINGFACE_ACCESS_TOKEN` dispon√≠vel
- `extract_transcription()` retorna `speakers` e `has_diarization` fields

### RunPod Config
- API Key: `rpa_44P...` (em .env)
- WhisperX Endpoint: `x9kudgpn8mjsva`
- Faster Whisper Endpoint: `yt0im4t61ncmbr` (pode ser deletado ‚Äî n√£o tem diariza√ß√£o)

### Testes
- 26 testes passando (pytest) ‚Äî `test_runpod_client.py` + `test_transcription_queue.py`

---

## 2026-02-11 ‚Äî Pesquisa e Plano: Iudex como Claude Cowork

### Resumo
Pesquisa extensiva com 6+ subagentes em paralelo para mapear toda a arquitetura do Claude Cowork, plugin system, MCP servers, e SDKs de agentes (Claude, OpenAI, Gemini). Plano documentado para transformar o Iudex numa plataforma Cowork-like multi-provider.

### Arquivos Criados
- `docs/PLANO_IUDEX_COWORK.md` ‚Äî Plano completo de 16 se√ß√µes com arquitetura, fases, arquivos, riscos

### Pesquisa Realizada (6 agentes paralelos)
1. **Iudex Backend** ‚Äî 43 models, 30+ routers, skills/workflows/MCP/RAG/playbooks
2. **Iudex Frontend** ‚Äî React Flow workflow builder, 17 node types, Zustand stores, SSE streaming
3. **Claude Cowork** ‚Äî 11 plugins oficiais, sistema de conectores `~~category`, hooks, .plugin format
4. **OpenAI Agents SDK** ‚Äî Agent, Runner, Handoffs, Guardrails, MCP, Sessions, Tracing
5. **Gemini ADK** ‚Äî Sequential/Parallel/LoopAgent, MCPToolset, A2A Protocol, Callbacks
6. **MCP Ecosystem** ‚Äî 25+ servers catalogados (PJe, BRLaw, DataJud, Office, Notion, Slack, etc.)

### Decis√µes Tomadas
- Abordagem h√≠brida multi-provider: Claude para racioc√≠nio jur√≠dico, OpenAI para orquestra√ß√£o, Gemini para pesquisa paralela
- Plugin system inspirado no Cowork mas integrado ao backend existente do Iudex
- v1: 6 fases (~10-14 sem) ‚Äî revisado ap√≥s descoberta que SDKs j√° estavam integrados
- v2: 3 fases (~4-6 sem) ‚Äî Commands + Hooks -> MCP + Connectors -> Plugin System + UI
- Connector abstraction (`~~category`) simplificado (config por tenant, n√£o registry completo)

### Auto-Cr√≠tica do Plano v1
- Fase 2 (Multi-Provider) era 100% redundante ‚Äî executors e adapters j√° existiam
- Skills UI j√° existe com wizard, editor, validation ‚Äî n√£o precisa criar
- Plano reduziu de ~25 para ~12 novos arquivos

### Cotejo com 10 Subagentes (v2 ‚Üí v2.1)
- Descoberto que `slash-command-menu.tsx` j√° tem 15 SystemCommands (v2 dizia "n√£o existe")
- Descoberto que `marketplace/page.tsx` j√° tem search/filter/install (v2 dizia "UI n√£o existe")
- Observabilidade in-memory identificada como gap real ‚Üí adicionada persistence em DB
- SubAgent definitions (agents/*.md do Cowork) adicionadas ao plugin manifest
- Fases reordenadas: Plugin Foundation primeiro (pr√©-requisito para commands/hooks)

### Incorpora√ß√£o INVENTARIO + BACKEND_DOMAIN_MAP (v2.1 ‚Üí v2.2)
Leitura dos invent√°rios revelou 7+ redund√¢ncias adicionais no plano:
- `command_service.py` J√Å EXISTE (234 linhas, 9 commands hardcoded) ‚Äî plano propunha criar
- DataJud COMPLETO: `djen_service.py` (734 linhas) + SDK tools + watchlist + sync ‚Äî plano propunha criar MCP wrapper
- `mcp-legal-server/main.py` j√° existe com RPC, ACL, rate limiting
- `AgentPool` (spawn/cancel/list) + `ParallelAgentsNode` (LangGraph) j√° existem ‚Äî SubAgentDefinition redundante
- Knowledge API (5 endpoints: legisla√ß√£o, jurisprud√™ncia, web, citations, shepardize) j√° existe
- Tribunais API (13 endpoints: credenciais, processos, peticionamento) j√° existe
- Marketplace API (6 endpoints: categories, install, review) j√° existe

**Resultado**: Plano v2.2 reduzido a ~8 novos arquivos, 2 fases, 3-4 semanas. Fase MCP Legal ELIMINADA.

### Arquivos Criados/Atualizados
- `docs/PLANO_IUDEX_COWORK.md` ‚Äî Plano v1 (6 fases, refer√™ncia)
- `docs/PLANO_IUDEX_COWORK_v2.md` ‚Äî **Atualizado para v2.2** (2 fases, invent√°rio completo)

### Pr√≥ximos Passos
- In√≠cio da Fase 1 (Plugin Foundation + Commands extend + Hooks, ~2 semanas)

---

## 2026-02-11 ‚Äî Corre√ß√£o de 15+ falhas de testes + Infraestrutura Docker RAG

### Resumo
Identificadas e corrigidas 15+ falhas de teste na suite completa (1909 testes). Infraestrutura Docker (Qdrant, OpenSearch, Neo4j) instalada e configurada.

### Resultados
| M√©trica | Antes | Depois |
|---------|-------|--------|
| Passed | 1822 | **1858** |
| Failed | 13 | **0** (1 intermitente) |
| Skipped | 74 | **50** |

### Arquivos Alterados
- `app/api/endpoints/chats.py` ‚Äî Fix `show_thinking_step` ‚Üí `thinking_enabled` (NameError)
- `app/services/ai/skills/skill_builder.py` ‚Äî `validate_skill_markdown` n√£o retorna cedo quando frontmatter tem keys v√°lidas; permite detec√ß√£o de conflitos
- `app/services/quality_service.py` ‚Äî Removido `import os` duplicado no finally; adicionado processamento de `heading_semantic_issues` com refinamento AI
- `tests/test_chat_skill_resolution.py` ‚Äî Atualizado para desempacotar 3 valores de `_resolve_matched_skill_prompt`
- `tests/test_skill_builder.py` ‚Äî Adicionados 3 triggers ao markdown de teste
- `tests/test_kg_builder.py` ‚Äî `hasattr()` em vez de `in` para `GraphSchema` do neo4j-graphrag
- `tests/test_quality_structural_fixes.py` ‚Äî Removido kwarg `mode` obsoleto
- `tests/test_hearing_format_source.py` ‚Äî Lambda `*args, **kwargs` + monkeypatch `_infer_speaker_roles_with_llm`
- `tests/rag/test_qdrant_service.py` ‚Äî Bridge `query_points` ‚Üí `search` para mocks
- `tests/rag/test_qdrant_integration.py` ‚Äî Helper `_search()` compat√≠vel com query_points API
- `docker-compose.rag.yml` ‚Äî Qdrant v1.7.4 ‚Üí v1.12.6

### Infraestrutura Docker
- **Qdrant** v1.12.6 em localhost:6333
- **OpenSearch** 2.11.0 em localhost:9200 (security disabled para testes)
- **Neo4j** 5.21.0-enterprise em localhost:8687 (Bolt)
- Pacotes instalados: `neo4j-graphrag`, `opensearch-py`, `qdrant-client`, `msal`, `botbuilder-core`

---

## 2026-02-11 ‚Äî Hierarquia: 5 melhorias anti-fragmenta√ß√£o (v2.41)

### Problema
`mlx_vomo.py` gerava muitos t√≥picos ## planos (flat) sem hierarquia. Aspectos de um mesmo tema viravam H2 separados ao inv√©s de subt√≥picos (###).

### 5 Melhorias Implementadas

**1. Pr√©-filtro da estrutura antes dos chunks**
- Portadas `filtrar_niveis_excessivos()` e `simplificar_estrutura_se_necessario()` de `format_transcription_gemini.py`
- Remove itens com n√≠vel > 3, simplifica para n√≠veis 1-2 se estrutura > 60 linhas

**2. Separa√ß√£o estrutura de corte vs hierarquia**
- `global_structure` (com ABRE/FECHA) ‚Üí usado em `dividir_sequencial` para cortes
- `hierarchy_structure` (limpa via `limpar_estrutura_para_review`) ‚Üí usada para guiar H2/H3 nos chunks
- Evita que √¢ncoras verbatim poluam o guia hier√°rquico

**3. Merge sem√¢ntico de t√≠tulos repetidos**
- `renumber_headings` agora usa `SequenceMatcher` (ratio > 0.85) para fundir t√≠tulos quase-duplicados entre fronteiras de chunks
- Impede infla√ß√£o de t√≥picos por repeti√ß√£o

**4. Auditoria final l√™ formato numerado**
- `final_structure_audit` agora reconhece tanto `##`/`###` quanto `1.`/`1.1.` no mapeamento
- Remove ABRE/FECHA das compara√ß√µes
- Antes, a auditoria ignorava o mapeamento inteiro porque s√≥ procurava markdown headers

**5. Regra de granularidade H2 no PROMPT_MAPEAMENTO**
- Regra 6: "Abra novo t√≥pico n√≠vel 1 SOMENTE quando macroassunto mudar"
- Regra 7: Anti-fragmenta√ß√£o expl√≠cita com exemplos correto/errado

### Prompts Tamb√©m Editados (sess√£o anterior)
- `PROMPT_STRUCTURE_APOSTILA`: Tabela de 3 n√≠veis, exemplos, anti-fragmenta√ß√£o
- `PROMPT_STRUCTURE_REVIEW`: Anti-fragmenta√ß√£o + marcos legais como ###
- `PROMPT_STRUCTURE_REVIEW_LITE`: Mesmas regras

### Arquivos Alterados
- `mlx_vomo.py` ‚Äî 7 edi√ß√µes (2 fun√ß√µes novas, pipeline, renumber_headings, audit, mapeamento, 3 prompts)

---

## 2026-02-11 ‚Äî Fix: Tabelas ausentes em transcri√ß√µes + Melhorias de granularidade

### Problema
Tabelas n√£o apareciam nas transcri√ß√µes pela UI/API, embora no CLI sa√≠ssem corretamente.

### Causa Raiz
1. `max_output_tokens=16384` no `mlx_vomo.py` era insuficiente ‚Äî tabelas s√£o geradas no final de cada chunk e eram truncadas
2. Detec√ß√£o de tabela ausente (`_has_incomplete_table`) s√≥ detectava tabelas parciais, n√£o completamente ausentes
3. Post-processing n√£o reposicionava tabelas para fim de se√ß√£o
4. `_auto_apply_structural_fixes` e `_auto_apply_content_fixes` no pipeline da API podiam remover tabelas sem prote√ß√£o

### Altera√ß√µes em `mlx_vomo.py`
- `max_output_tokens`: 16384 ‚Üí 32000 (alinhado com `format_transcription_gemini.py`)
- Threshold de par√°grafos APOSTILA: 900 ‚Üí 500 chars (mais granular)
- Adicionada instru√ß√£o de isolar Quest√µes/Exerc√≠cios em blockquotes no `PROMPT_STYLE_APOSTILA`
- `mover_tabelas_para_fim_de_secao` adicionado ao pipeline p√≥s-processamento (passada 2.8)
- Nova fun√ß√£o `_has_missing_table()`: detecta t√≠tulos üìã sem tabela correspondente
- `_retry_incomplete_table` agora detecta tabelas incompletas E ausentes

### Altera√ß√µes em `transcription_service.py`
- Guarda em `_auto_apply_structural_fixes`: se auto-fix remove todas as tabelas, reverte para original
- Guarda em `_auto_apply_content_fixes`: mesma prote√ß√£o contra perda de tabelas pelo LLM

### Arquivos Alterados
- `mlx_vomo.py` ‚Äî 5 edi√ß√µes (tokens, threshold, prompt, pipeline, retry)
- `apps/api/app/services/transcription_service.py` ‚Äî 2 guardas de prote√ß√£o de tabelas

---

## 2026-02-11 ‚Äî Verifica√ß√£o: Marked com `breaks: true` e GFM Pipe Tables

### Pergunta Original
Investigar se `parseMarkdownToHtmlSync()` em `markdown-parser.ts` tem problemas com `breaks: true` e tabelas GFM pipe:
1. O `breaks: true` interfere com a detec√ß√£o de blocos de tabela?
2. Se o LLM gerar `<table>` HTML bruto, ser√° escapado pelo renderer?

### Testes Realizados
Usando `marked@17.0.1` (vers√£o atual no projeto):

**Teste 1: Impacto de `breaks: true` nas tabelas**
- COM `breaks: true`: Tabelas pipe markdown parseiam corretamente ‚úì
- SEM `breaks: true` (controle): Mesmo resultado ‚úì
- Conclus√£o: **`breaks: true` N√ÉO interfere com tabelas GFM** ‚Äî o parser trata tabelas como blocos antes de aplicar `breaks`

**Teste 2: Tabelas com newlines singulares**
- Input: `| Col1 | Col2 |\n|------|------|\n| A | B |\nParagraph here`
- Resultado: Primeira tabela parseada corretamente, depois a linha "Paragraph here" foi colocada em uma nova linha de tabela (n√£o √© exatamente markdown-correto, mas marked faz assim)
- COM double newline: Funciona corretamente (tabela separada do par√°grafo)

**Teste 3: HTML Tables (raw HTML gerado por LLM)**
- Input: `<table><tr><td>A</td><td>B</td></tr></table>`
- Output COM renderer `html()` que escapa: `&lt;table&gt;...&lt;/table&gt;` ‚úì
- Conclus√£o: **HTML tables geradas pelo LLM SER√ÉO escapadas** e renderizadas como texto, n√£o como tabelas visuais

**Teste 4: CRLF line endings**
- Windows-style CRLF: Sem problemas, marked normaliza internamente ‚úì

### Conclus√£o Final
1. **`breaks: true` √© seguro para tabelas** ‚Äî n√£o h√° interfer√™ncia
2. **Pipe markdown tables funcionam normalmente** ‚úì
3. **Potencial problema real: Se LLM gerar HTML `<table>`**
   - Ser√° escapado para `&lt;table&gt;` (seguran√ßa boa)
   - Mas usu√°rio v√™ texto bruto, n√£o tabela visual
   - Solu√ß√£o: Antecipar e treinar LLM para gerar pipe tables, n√£o HTML tables

### Arquivos Criados/Verificados
- `/apps/web/src/lib/markdown-parser.ts` (v17.0.1) ‚Äî verificado ‚úì
- `/apps/web/package.json` (marked@17.0.1)
- `/apps/web/src/lib/__tests__/markdown-parser-tables.test.ts` ‚Äî suite de testes (Jest)
- `/scripts/test-markdown-tables.js` ‚Äî script de verifica√ß√£o manual (5/5 testes passam ‚úì)
- `/docs/MARKDOWN_PARSER_ANALYSIS.md` ‚Äî an√°lise completa
- `/docs/MARKDOWN_PARSER_ENHANCEMENTS.md` ‚Äî op√ß√µes de melhoria (opcional)

### Status Final
‚úì `breaks: true` N√ÉO interfere com tabelas GFM
‚úì Pipe markdown tables parseiam corretamente
‚úì HTML tables s√£o escapadas (seguran√ßa)
‚úì C√≥digo est√° funcional e seguro ‚Äî MANTER ATUAL
‚ö† Se LLM usar HTML tables, aparecem como texto (por design)
‚Üí Solu√ß√£o: Treinar LLM para usar pipe tables

---

## 2026-02-10 ‚Äî Fix HIL/Audit Tab Navigation + Diff Formatado

### Contexto
Ap√≥s a unifica√ß√£o do sistema de auditoria, os diffs e aprova√ß√µes no painel HIL pararam de funcionar. Al√©m disso, os diffs eram exibidos em texto bruto (tags HTML/markdown vis√≠veis).

### Bugs Corrigidos
1. **Tab navigation quebrada**: `setActiveTab('hil')` apontava para tab inexistente ‚Äî a tab 'hil' foi substitu√≠da por 'audit' mas 4 refer√™ncias n√£o foram atualizadas
2. **Diff confirmation ausente**: AuditDashboard aplicava corre√ß√µes diretamente sem mostrar DiffConfirmDialog ‚Äî alterado para passar pelo fluxo de `pendingRevision` + `showDiffConfirm`

### Feature: Diff Formatado no DiffConfirmDialog
- Nova tab "Diff Formatado" como default (3 tabs: Formatado, Bruto, Final)
- Diff inline por palavra usando `diffWords()` em texto limpo (plain text extra√≠do de HTML/markdown)
- Destaque visual: verde para adi√ß√µes, vermelho+strikethrough para remo√ß√µes
- Compara√ß√£o lado a lado "Original/Corrigido" com conte√∫do renderizado (DOMPurify para HTML, react-markdown para markdown)
- Detec√ß√£o autom√°tica de tipo de conte√∫do (HTML vs markdown)
- Tab Preview tamb√©m melhorada para renderizar HTML com DOMPurify

### Arquivos Modificados
- `apps/web/src/app/(dashboard)/transcription/page.tsx` ‚Äî 4x `setActiveTab('hil')` ‚Üí `setActiveTab('audit')` + wiring do DiffConfirmDialog via `setPendingRevision`
- `apps/web/src/components/dashboard/diff-confirm-dialog.tsx` ‚Äî Rewrite completo com tab formatada, utilities de plain text, detec√ß√£o HTML/markdown

### Verifica√ß√£o
- `npx tsc --noEmit` ‚Äî OK (zero erros)

---

## 2026-02-10 ‚Äî Unifica√ß√£o do Sistema de Auditoria

### Contexto
Sistema de auditoria fragmentado em 3 pain√©is (Quality, Preventive, HIL) com terminologia inconsistente, detec√ß√£o duplicada e fluxo manual. Unificado em uma aba "Auditoria" √∫nica para documentos.

### Arquivos Criados
- `apps/api/app/schemas/audit_unified.py` ‚Äî Schemas Pydantic unificados (tipos, severidades, dedup, mapeamento)
- `apps/api/app/api/endpoints/audit_unified.py` ‚Äî Endpoints `/quality/unified-audit` e `/quality/unified-apply`
- `apps/web/src/lib/unified-audit.ts` ‚Äî Tipos TS, parseUnifiedResponse, mergeFromLegacy, computeHealth
- `apps/web/src/components/dashboard/audit-dashboard.tsx` ‚Äî Componente principal com sub-tabs (Issues, Resumo, Detalhes)
- `apps/web/src/components/dashboard/audit-health-bar.tsx` ‚Äî Barra compacta vis√≠vel em todas as tabs

### Arquivos Modificados
- `apps/api/app/api/routes.py` ‚Äî Registro do router audit_unified
- `apps/web/src/lib/api-client.ts` ‚Äî fetchUnifiedAudit + applyUnifiedAuditFixes
- `apps/web/src/app/(dashboard)/transcription/page.tsx` ‚Äî Substitui√ß√£o de 3 tabs por 1 aba "Auditoria" unificada + health bar

### Decis√µes
- Preservado o QualityPanel (variant='dashboard') na sub-tab "Resumo"
- Diffs mostrados em formato rich (antes/depois estilizado), n√£o git-style
- Hearing mant√©m QualityPanel full separado sem altera√ß√µes
- Auto-convers√£o de issues preventivas (sem bot√£o manual)
- Backend reutiliza quality_service existente (n√£o duplica)
- Endpoints registrados em `/quality/unified-*` (prefix `/audit` j√° ocupado por auditoria jur√≠dica)

### Verifica√ß√£o
- `npx tsc --noEmit` ‚Äî OK (zero erros)
- Python syntax check ‚Äî OK

### Revis√£o 1 ‚Äî Corre√ß√µes de C√≥digo
1. **CR√çTICO**: `quality_service.analyze_document()` n√£o existia ‚Üí `analyze_structural_issues()`
2. **Dedup**: `parseUnifiedResponse()` sem dedup ‚Üí adicionado `deduplicateByFingerprint()`
3. **Confian√ßa preventiva**: Hardcoded 0.6 ‚Üí extrai do campo `confianca`
4. **Severidade**: Falhava com `confianca` float ‚Üí caminhos separados
5. **Contagem m√≥dulos**: Antes do dedup ‚Üí movida para depois
6. **computeHealth**: Warning para qualquer issue ‚Üí s√≥ `high+`
7. **contentType hardcoded**: `"apostila"` ‚Üí din√¢mico baseado em documentMode
8. **setTimeout**: Em `handleAutoApply` ‚Üí aplica direto
9. **Imports √≥rf√£os**: Removidos do page.tsx
10. **Toast fallback**: Adicionado ao usar legacy merge

### Revis√£o 2 ‚Äî Corre√ß√µes de L√≥gica
11. **Imports n√£o usados**: `Copy`, `Eye`, `Card*`, `buildQualityHilIssues`, `AlertTriangle` ‚Üí removidos
12. **Health stale ap√≥s apply**: N√£o recomputava ‚Üí agora recomputa inline
13. **Apply duplicado**: `handleAutoApply` copy-paste ‚Üí extra√≠do `applyIssues()` compartilhado
14. **`normalizeType()` no-op**: Fun√ß√£o morta ‚Üí removida
15. **Backend status inconsistente**: `warning if all_issues` ‚Üí alinhado: `warning if high+`

### Revis√£o 3 ‚Äî Bug Cr√≠tico: Corre√ß√µes Silenciosamente Ignoradas
**Causa raiz**: `apply_unified_hil_fixes` filtra por `type in structural_types` e `type in semantic_types`, mas a normaliza√ß√£o convertia tipos espec√≠ficos (`"duplicate_paragraph"`) para gen√©ricos (`"structural"`), que N√ÉO est√£o nos sets. Resultado: 100% das issues eram ignoradas.

**Corre√ß√µes aplicadas:**
16. **`original_type` adicionado ao schema**: Preserva tipo raw para o backend apply
17. **Endpoint restaura `original_type`**: No `/unified-apply`, `fix["type"] = fix["original_type"]`
18. **`semantic_types` expandido**: Inclu√≠dos `hallucination`, `context`, `source_error`, `missing_reference` + aliases preventivos
19. **Fallback por `fix_type`**: Se `type` n√£o est√° em nenhum set, usa `fix_type == "content"` como crit√©rio
20. **Feedback de zero mudan√ßas**: Toast warning quando `applied === 0` ou conte√∫do n√£o mudou
21. **`original_type` no frontend**: Preservado em `hilToUnified()` e `qualityFixToUnified()`

### Revis√£o 4 ‚Äî Fixes N√£o Aplicam: Campos Estruturais Perdidos
**Causa raiz**: `UnifiedAuditIssue` (Pydantic) **n√£o tinha `extra="allow"`**, ent√£o campos estruturais essenciais (`heading_line`, `old_title`, `new_title`, `title`, `line_index`, `table_heading`, `strategy`, etc.) eram silenciosamente descartados na serializa√ß√£o. Quando o frontend reenvia os issues para o apply, esses campos n√£o existiam mais.

**Corre√ß√µes aplicadas:**
22. **`model_config = ConfigDict(extra="allow")`** em `UnifiedAuditIssue` ‚Äî preserva campos extras na serializa√ß√£o
23. **`normalize_quality_issues()` repassa campos originais**: `**extra_fields` spread no construtor para manter `heading_line`, `title`, `line_index`, etc.
24. **`action` corrigido no `/unified-apply`**: Determina `INSERT/REPLACE` a partir do patch ao inv√©s de copiar `action_summary` (texto descritivo), que n√£o matchava no legacy fallback
25. **Error reporting**: `skipped_fixes` agora inclu√≠dos no response como `content_error` + diagnostics
26. **Toast order fix**: Warnings de `structural_error`/`content_error` movidos para ANTES do `return` no apply (eram unreachable quando applied===0)

### Arquivos Adicionalmente Modificados (revis√µes)
- `apps/api/app/services/quality_service.py` ‚Äî Expandido `semantic_types` + fallback por `fix_type`
- `apps/api/app/schemas/audit_unified.py` ‚Äî `ConfigDict(extra="allow")` em `UnifiedAuditIssue`
- `apps/api/app/api/endpoints/audit_unified.py` ‚Äî Extra fields passthrough, action verb fix, logging, skipped_fixes relay
- `apps/web/src/components/dashboard/audit-dashboard.tsx` ‚Äî Toast order fix

---

## 2026-02-10 ‚Äî Sincroniza√ß√£o de PROMPT_FIDELIDADE entre CLI e UI

### Contexto
A transcri√ß√£o gerada pela UI (web) no modo FIDELIDADE apresentava qualidade inferior √† gerada pela CLI (mlx_vomo.py): 13% menos conte√∫do, tabelas mais simples (4 colunas vs 5), sem tabela de pegadinhas, menos listas e negritos.

### Causas Raiz Identificadas
1. **3 c√≥pias desincronizadas do prompt FIDELIDADE**: `mlx_vomo.py` (atualizado), `legal_prompts.py` (desatualizado), `lib/prompts.ts` (desatualizado)
2. **legal_prompts.py** proibia bullet points (`N√ÉO USE BULLET POINTS`) enquanto mlx_vomo.py permitia com modera√ß√£o
3. **Tabela gen√©rica 4 colunas** nas c√≥pias da UI vs 5 colunas + tabela de pegadinhas no CLI
4. **Sem instru√ß√£o de speakers, encerramento, quebra sem√¢ntica** nas c√≥pias da UI
5. O preset `data/prompts.ts` (TRANSCRIPTION_PRESETS) j√° estava atualizado com tabelas ricas

### Arquivos Alterados
- `apps/api/app/services/legal_prompts.py` ‚Äî PROMPT_FIDELIDADE alinhado com mlx_vomo.py
- `apps/web/src/lib/prompts.ts` ‚Äî PROMPT_FIDELIDADE alinhado com mlx_vomo.py

### Melhorias Implementadas
- Bullet points permitidos com modera√ß√£o (era PROIBIDO)
- Tabela 5 colunas com "Dica de prova" + segunda tabela "Pegadinhas"
- Instru√ß√£o de completude (7 tipos de conte√∫do obrigat√≥rio)
- Regras de legibilidade detalhadas (quebra sem√¢ntica, pontos de quebra, anti-telegr√°fico)
- Identifica√ß√£o de speakers (`## [Disciplina] ‚Äî Prof. [Nome]`)
- Preserva√ß√£o de encerramentos de aula
- Tratamento nuan√ßado de g√≠rias (parentesco factual vs g√≠ria)
- Regra anti-duplica√ß√£o com tratamento de repeti√ß√£o de contexto

---

## 2026-02-10 ‚Äî Validadores de Alucina√ß√£o e Contexto no false_positive_prevention.py

### Contexto
Os validadores de `false_positive_prevention.py` n√£o tinham tratamento espec√≠fico para alucina√ß√µes e problemas de contexto ‚Äî ambos recebiam confidence 0.70 autom√°tica sem verifica√ß√£o contra RAW.

### Arquivos Alterados
- `apps/api/app/services/false_positive_prevention.py` ‚Äî Adicionados 2 validadores + 1 helper:
  - `_validate_hallucination()`: Extrai fragmentos factuais (nomes, leis, datas, n√∫meros) e verifica se existem no RAW. Se existem ‚Üí falso positivo. Se n√£o ‚Üí alucina√ß√£o confirmada. Tamb√©m faz fuzzy search do trecho completo e verifica presen√ßa no formatado.
  - `_validate_context_issue()`: Verifica se a ambiguidade existe tamb√©m no RAW (ent√£o n√£o √© erro de formata√ß√£o), detecta marcadores de ambiguidade (pronomes, demonstrativos, "referido", "citado"), e valida corre√ß√£o sugerida contra RAW.
  - `_extract_factual_fragments()`: Extrai nomes pr√≥prios, refer√™ncias legais, datas, n√∫meros e frases citadas para verifica√ß√£o determin√≠stica.
- `apps/api/app/api/endpoints/quality_control.py` ‚Äî `ConvertToHilRequest` com `hallucinations` e `context_issues`
- `apps/api/app/services/quality_service.py` ‚Äî `convert_to_hil_issues` processa alucina√ß√µes e contexto

### Resultados dos Testes
- Alucina√ß√£o real (conte√∫do fabricado) ‚Üí 1.00 very_high
- Alucina√ß√£o falso positivo (conte√∫do no RAW) ‚Üí 0.20 very_low (filtrada)
- Contexto real (ambiguidade da formata√ß√£o) ‚Üí 1.00 very_high
- Contexto falso positivo (mesmo texto no RAW) ‚Üí 0.40 very_low (filtrada)

---

## 2026-02-10 ‚Äî Fix: Convers√£o completa Quality ‚Üí HIL + Race condition + UI did√°tica

### Contexto
Usu√°rio n√£o conseguia converter problemas da aba Qualidade em issues para corre√ß√£o, nem regenerar a auditoria preventiva. Tamb√©m pediu melhor nomenclatura de bot√µes e que TODOS os tipos de problemas (alucina√ß√µes, contexto, omiss√µes, distor√ß√µes, estruturais) fossem convertidos em issues HIL.

### Arquivos Alterados
- `apps/web/src/components/dashboard/quality-panel.tsx` ‚Äî Bot√£o "Detectar Problemas" (`handleConvertToUnifiedHil`) na toolbar do dashboard; renomea√ß√£o de bot√µes ("Recalcular Nota", "Checklist Legal"); em dashboard mode envia issues para aba HIL via `onConvertContentAlerts`; passa `hallucinations` e `context_issues` para API
- `apps/web/src/app/(dashboard)/transcription/page.tsx` ‚Äî Reescrito `handleRecomputePreventiveAudit`: fetch direto via `downloadTranscriptionReport` + `finally`
- `apps/web/src/lib/api-client.ts` ‚Äî `convertToHilIssues` aceita `hallucinations` e `context_issues`
- `apps/api/app/api/endpoints/quality_control.py` ‚Äî `ConvertToHilRequest` com `hallucinations` e `context_issues`
- `apps/api/app/services/quality_service.py` ‚Äî `convert_to_hil_issues` processa alucina√ß√µes (type="alucinacao", action=REPLACE) e problemas de contexto (type=ctx_type, action=REPLACE)

### Bugs Corrigidos
1. **Bot√£o oculto**: "Valida√ß√£o Completa" estava escondido em modo dashboard ‚Üí agora vis√≠vel como "Detectar Problemas"
2. **Convers√£o incompleta**: S√≥ omiss√µes/distor√ß√µes/estruturais eram convertidas ‚Üí agora alucina√ß√µes e contexto tamb√©m
3. **Fluxo HIL**: Em dashboard mode, issues v√£o direto para aba Corre√ß√µes via `onConvertContentAlerts`
4. **Race condition**: stale closure em `fetchPreventiveAudit` ‚Üí bypass com download direto
5. **Loading congelado**: faltava `finally { setPreventiveAuditLoading(false) }`

---

## 2026-02-10 ‚Äî HIL Audit: Clareza de UI, Performance e Bug de Score

### Contexto
O sistema HIL de transcri√ß√µes tinha problemas de clareza (issues descritivos demais, sem a√ß√£o concreta) e performance (LLM calls sequenciais). Al√©m disso, ap√≥s aplicar corre√ß√µes num job, a nota de fidelidade caiu sem explica√ß√£o vis√≠vel.

### Arquivos Alterados

**Fase 1 ‚Äî UI Clareza**
- `apps/web/src/lib/preventive-hil.ts` ‚Äî TYPE_LABELS cobrindo todas origens, `getTypeLabel()`, `action_summary` em `buildPreventiveHilIssues` e `buildQualityHilIssues`
- `apps/web/src/components/dashboard/audit-issues-panel.tsx` ‚Äî Agrupamento por prioridade (cr√≠ticos/sugest√µes), evidence inline, banner de revalida√ß√£o
- `apps/web/src/app/(dashboard)/transcription/page.tsx` ‚Äî Wired `onRevalidate` prop

**Fase 2 ‚Äî Performance + SSE**
- `apps/api/app/services/quality_service.py` ‚Äî Paraleliza√ß√£o de LLM calls com `asyncio.gather` + `Semaphore(3)`, guardrails de headings, `on_progress` callback
- `apps/api/app/api/endpoints/transcription.py` ‚Äî Novo endpoint `POST /apply-revisions-stream` com SSE
- `apps/web/src/lib/api-client.ts` ‚Äî `applyRevisionsStream()` com fallback
- `apps/web/src/app/(dashboard)/transcription/page.tsx` ‚Äî Consumo de SSE com progresso real no toast

**Fase 3 ‚Äî Evidence Backend**
- `apps/api/app/services/preventive_hil.py` ‚Äî `evidence_formatted` para omiss√µes e contexto
- `audit_fidelity_preventive.py` ‚Äî `trecho_formatado` obrigat√≥rio no prompt JSON

**Bug: Score caindo sem explica√ß√£o**
- `audit_fidelity_preventive.py` ‚Äî `_build_compat_report` agora inclui `alucinacoes`, `problemas_contexto`, `pausar_para_revisao`
- `apps/api/app/services/quality_service.py` ‚Äî `validate_document` retorna `hallucinations`, `context_issues`, `pause_reason`
- `apps/api/app/api/endpoints/quality_control.py` ‚Äî `ValidateResponse` com novos campos
- `apps/web/src/components/dashboard/quality-panel.tsx` ‚Äî Interface, normalizeReport e UI para alucina√ß√µes, problemas de contexto e motivo de pausa

### Decis√µes Tomadas
- Paraleliza√ß√£o com sem√°foro de 3 (configur√°vel via `IUDEX_HIL_CONCURRENCY`)
- Patches aplicados bottom-to-top para estabilidade de √≠ndices
- Guardrail: rejeita patches que alteram headings markdown
- SSE mant√©m fallback para endpoint s√≠ncrono

---

## 2026-02-10 ‚Äî Backend: Outlook Add-in Workflows + Email Trigger Aut√¥nomo

### Contexto
O Outlook Add-in tinha frontend completo com 3 abas (Resumo, Pesquisa, Workflows), mas a aba de Workflows n√£o funcionava porque os endpoints de backend nunca foram implementados. Al√©m disso, o sistema de email trigger precisava de renova√ß√£o de subscriptions e configura√ß√£o por usu√°rio.

### Arquivos Alterados

**Feature 1: Backend dos Workflows do Add-in**
- `apps/api/app/schemas/outlook_addin_schemas.py` ‚Äî Adicionados `OutlookWorkflowTriggerRequest` e `OutlookWorkflowRunResponse`
- `apps/api/app/models/workflow.py` ‚Äî Removida FK de `workflow_runs.workflow_id`, ajustados relationships para `viewonly=True`
- `apps/api/app/services/builtin_workflows.py` ‚Äî **NOVO** ‚Äî Registry com 4 workflows builtin (extract-deadlines, draft-reply, create-calendar-events, classify-archive)
- `apps/api/app/workers/tasks/workflow_tasks.py` ‚Äî Adicionadas tasks `run_builtin_workflow` e `renew_graph_subscriptions`
- `apps/api/app/api/endpoints/outlook_addin.py` ‚Äî Adicionados `POST /workflow/trigger` e `GET /workflow/status/{run_id}`
- `alembic/versions/a1b2c3d4e5f6_drop_workflow_runs_fk.py` ‚Äî **NOVO** ‚Äî Migration para drop FK

**Corre√ß√µes adicionais (runtime/integra√ß√£o)**
- `apps/api/app/workers/tasks/workflow_tasks.py` ‚Äî `run_triggered_workflow` agora aceita `run_id` opcional e atualiza o `WorkflowRun` existente (evita ‚Äúruns zumbis‚Äù no status polling)
- `apps/api/app/api/endpoints/outlook_addin.py` ‚Äî Disparo de workflow UUID via Celery usando `send_task(...)` + valida√ß√£o de membership em org
- `apps/api/app/services/workflow_triggers.py` ‚Äî Dispatch de eventos via `send_task(...)` para evitar depend√™ncia de registro local de tasks no processo da API
- `apps/api/app/workers/celery_app.py` e `apps/api/app/workers/tasks/__init__.py` ‚Äî Ajuste de autodiscovery/imports para garantir que tasks de workflow sejam registradas no worker
- `apps/api/app/api/endpoints/graph_webhooks.py` e `apps/api/app/api/endpoints/email_triggers.py` ‚Äî `expirationDateTime` em RFC3339 UTC (`Z`) + require `GRAPH_WEBHOOK_SECRET`
- `alembic/versions/a1b2c3d4e5f6_drop_workflow_runs_fk.py` ‚Äî Drop FK agora inspeciona o nome real da constraint (robusto entre ambientes)
- `apps/api/app/core/database.py` ‚Äî `EmailTriggerConfig` importado no `init_db()` (suporta `create_all` sem Alembic)

**Feature 2: Email Command Trigger**
- `apps/api/app/models/email_trigger_config.py` ‚Äî **NOVO** ‚Äî Modelo de configura√ß√£o de triggers por usu√°rio
- `apps/api/app/api/endpoints/email_triggers.py` ‚Äî **NOVO** ‚Äî CRUD completo + POST /subscribe
- `apps/api/app/api/endpoints/graph_webhooks.py` ‚Äî Completados lifecycle handlers + valida√ß√£o de sender
- `apps/api/app/workers/celery_app.py` ‚Äî Adicionado `graph-subscription-renewal` ao beat schedule
- `apps/api/app/api/routes.py` ‚Äî Registrada rota `/email-triggers`
- `apps/api/app/models/__init__.py` ‚Äî Adicionado import de `EmailTriggerConfig`
- `alembic/versions/b2c3d4e5f6a7_create_email_trigger_configs.py` ‚Äî **NOVO** ‚Äî Migration para tabela

### Decis√µes Tomadas
- Removida FK em `workflow_runs.workflow_id` para permitir slugs builtin (ex: "extract-deadlines") sem violar constraints
- Builtin workflows executam via chamadas diretas de IA (sem LangGraph) para simplicidade
- Valida√ß√£o de sender: se o usu√°rio tem configs com `authorized_senders`, apenas esses remetentes disparam workflows

---

## 2026-02-10 ‚Äî Workflows: Hard Deep Research (Paridade com Ask) + UI

### Contexto
O modo ‚ÄúHard Deep Research‚Äù (multi-provedor + loop agentico) existia no Ask chat, mas n√£o estava dispon√≠vel como n√≥ no builder de Workflows nem como template com streaming de tokens/cita√ß√µes.

### Arquivos Alterados
- `apps/api/app/services/ai/deep_research_hard_service.py` ‚Äî `study_done` agora inclui `sources` (deduplicadas) + `provider_summaries`
- `apps/api/app/services/ai/workflow_compiler.py` ‚Äî Novo node type `deep_research` (mode `hard|normal`), inclui `citations` em `step_outputs`
- `apps/api/app/services/ai/workflow_runner.py` ‚Äî Poller de `JobManager` para ‚Äútoken streaming‚Äù de nodes (ex: hard deep research) no SSE do run
- `apps/api/app/scripts/seed_workflow_templates.py` ‚Äî Template ‚ÄúPesquisa Aprofundada‚Äù migrou para o node `deep_research` em hard mode
- `apps/api/tests/test_workflow_deep_research_hard_streaming.py` ‚Äî Teste garantindo streaming de tokens via workflow SSE
- `apps/web/src/components/workflows/node-types/deep-research-node.tsx` ‚Äî **NOVO** ‚Äî Node UI
- `apps/web/src/components/workflows/node-types/index.ts` ‚Äî Registro do node `deep_research`
- `apps/web/src/components/workflows/workflow-builder.tsx` ‚Äî Node palette + defaults para `deep_research`
- `apps/web/src/components/workflows/properties-panel.tsx` ‚Äî UI de configura√ß√£o do node (mode/effort/providers/timeouts/query/include_sources)

### Verifica√ß√£o
- `apps/api`: `pytest` para templates + streaming (`tests/test_workflow_templates_seed.py`, `tests/test_workflow_deep_research_hard_streaming.py`)
- `apps/web`: `npm run type-check` e `npm run lint` (sem erros)

### Verifica√ß√£o
- Verifica√ß√£o de sintaxe em todos os 11 arquivos ‚Äî OK
- Migrations precisam ser executadas: `alembic upgrade head`

---

## 2026-02-10 ‚Äî Workflows: Templates (Catalogo) + Seed via UI

### Contexto
Templates de workflow foram adicionados no seed (`seed_workflow_templates.py`), mas a UI podia n√£o exibir nada quando o seed n√£o foi executado no banco.

### Mudan√ßas
- `apps/api/app/scripts/seed_workflow_templates.py`
  - Docstring n√£o fixa mais contagem (usa `len(TEMPLATES)`).
  - Exposto `seed(seed_user_id=...) -> {inserted, skipped, total}` para reuso por endpoint/admin UI.
- `apps/api/app/api/endpoints/workflows.py`
  - `GET /workflows/catalog` agora filtra `is_template=True` (cat√°logo de templates).
  - `POST /workflows/templates/seed` (ADMIN) para executar o seed via API.
- `apps/web/src/lib/api-client.ts`
  - `seedWorkflowTemplates()` para chamar o endpoint acima.
- `apps/web/src/app/(dashboard)/workflows/catalog/page.tsx`
  - Bot√£o "Carregar templates" (e fallback no estado vazio) para executar seed e recarregar o cat√°logo.

### Verifica√ß√£o
- `npx tsc --noEmit` ‚Äî OK
- `python3 -c "ast.parse(...)"` ‚Äî OK


## 2026-02-10 ‚Äî Sess√£o 164: Melhorar Clareza e Performance do HIL de Transcri√ß√µes

### Objetivo
Melhorar a clareza da UI de auditoria HIL na p√°gina de transcri√ß√µes e a performance na aplica√ß√£o de corre√ß√µes.

### Arquivos Editados

**Frontend**
- `apps/web/src/lib/preventive-hil.ts` ‚Äî TYPE_LABELS (todas origens), getTypeLabel(), action_summary em buildPreventiveHilIssues e buildQualityHilIssues, remo√ß√£o do fallback "Em an√°lise" no verdict
- `apps/web/src/components/dashboard/audit-issues-panel.tsx` ‚Äî Reescrito: agrupamento por prioridade (cr√≠ticos vs sugest√µes), labels leg√≠veis via getTypeLabel(), evidence inline nos cards colapsados, action_summary, bot√£o Revalidar Qualidade, severity warning com bg-red
- `apps/web/src/app/(dashboard)/transcription/page.tsx` ‚Äî onRevalidate wired (muda para aba quality), applyHilIssues migrado para SSE streaming com progress em tempo real (removido slowTimer)
- `apps/web/src/lib/api-client.ts` ‚Äî Novo m√©todo applyRevisionsStream() com SSE parsing + fallback autom√°tico para endpoint n√£o-streaming

**Backend**
- `apps/api/app/services/quality_service.py` ‚Äî fix_content_issues_with_llm paralelizado com asyncio.gather + Semaphore(3), heading guardrail (_validate_headings_preserved), on_progress callback, prompt instru√ß√£o "NAO modifique headings"
- `apps/api/app/api/endpoints/transcription.py` ‚Äî Novo endpoint POST /apply-revisions-stream (SSE com progress events)
- `apps/api/app/services/preventive_hil.py` ‚Äî evidence_formatted preenchido para omiss√µes e contexto (LLM snippet + section anchor fallback)
- `audit_fidelity_preventive.py` ‚Äî trecho_formatado adicionado ao schema JSON de omissoes_criticas e problemas_contexto

### Decis√µes Tomadas
- Paraleliza√ß√£o usa Semaphore(3) configur√°vel via IUDEX_HIL_CONCURRENCY; patches aplicados bottom-to-top ap√≥s gather
- Heading guardrail rejeita patches que alteram headings markdown (seguran√ßa para patches paralelos)
- onRevalidate no HIL panel navega para aba "quality" em vez de duplicar l√≥gica de revalida√ß√£o
- SSE fallback: se streaming falhar, applyRevisionsStream chama automaticamente o endpoint sync

### Verifica√ß√µes
- TypeScript tsc --noEmit: OK
- Python ast.parse: OK (quality_service.py, transcription.py, preventive_hil.py, audit_fidelity_preventive.py)

---

## 2026-02-10 ‚Äî Sess√£o 163: Template #27 (Minuta por Email) + Suporte a Anexos no Pipeline

### Objetivo
Criar Template #27 para gera√ß√£o autom√°tica de minuta via email do Outlook (sem HIL) e implementar suporte completo a encaminhamento de anexos em todo o pipeline de workflows ass√≠ncronos.

### Arquivos Editados
- `apps/api/app/services/graph_email.py` ‚Äî Adicionado `get_attachments()`, par√¢metro `attachments` em `send_email()` e `reply_email()` com pattern createReply‚Üípatch‚Üíadd attachments‚Üísend
- `apps/api/app/services/workflow_delivery.py` ‚Äî Adicionado `_resolve_attachments()`, `_build_output_attachment()`, `_escape_html()`, embedding de cita√ß√£o original no path createReply
- `apps/api/app/api/endpoints/graph_webhooks.py` ‚Äî `_handle_mail_notification()` agora busca anexos via `get_attachments()` e inclui no event_data
- `apps/api/app/scripts/seed_workflow_templates.py` ‚Äî Template #27: Minuta Autom√°tica por Email (Outlook), docstring atualizada para 27 templates
- `apps/web/src/components/workflows/properties-panel.tsx` ‚Äî Checkbox "Encaminhar anexos do email original" nos panels email e outlook_reply

### Decis√µes Tomadas
- Graph API `/reply` n√£o suporta anexos ‚Üí usa createReply ‚Üí draft ‚Üí add attachments ‚Üí send
- Quando createReply √© usado, cita√ß√£o original √© perdida ‚Üí delivery service embeda HTML original manualmente
- `forward_attachments` (bool) e `attachment_filter` (lista de extens√µes) como config keys
- `include_output_attachment` (bool) gera arquivo HTML do output como anexo Graph-compatible
- `RAG_PRELOAD_EMBEDDINGS=false` necess√°rio para startup quando quota OpenAI esgotada

### Verifica√ß√µes
- Python py_compile: OK em todos os arquivos modificados
- TypeScript tsc --noEmit: OK
- Servidor rodando em localhost:8000, health check OK

---

## 2026-02-10 ‚Äî Sess√£o 162: Agendamento Configur√°vel DJEN/DataJud + Verifica√ß√µes

### Objetivo
Permitir que o usu√°rio configure frequ√™ncia e hor√°rio do rastreamento de movimenta√ß√µes DJEN/DataJud na UI. Verificar e corrigir implementa√ß√µes anteriores (proactive.py faltante, typo Calendario).

### Arquivos Criados
- `apps/api/app/services/djen_scheduler.py` ‚Äî Helper `compute_next_sync()` para daily, twice_daily, weekly, custom (croniter)
- `apps/api/app/services/teams_bot/proactive.py` ‚Äî M√≥dulo de mensagens proativas Teams (faltava na implementa√ß√£o anterior)
- `apps/api/alembic/versions/a866b468b088_add_sync_schedule_columns_to_watchlists.py` ‚Äî Migra√ß√£o: 5 colunas em process_watchlist + djen_oab_watchlist

### Arquivos Editados
- `apps/api/app/models/djen.py` ‚Äî +5 colunas em ProcessWatchlist e DjenOabWatchlist (sync_frequency, sync_time, sync_cron, sync_timezone, next_sync_at)
- `apps/api/app/schemas/djen.py` ‚Äî Campos de agendamento em Create/Response schemas, novo ProcessWatchlistUpdate
- `apps/api/app/api/endpoints/djen.py` ‚Äî POST salva schedule + compute next_sync, +2 PATCH endpoints para atualizar agendamento
- `apps/api/app/workers/tasks/djen_tasks.py` ‚Äî Nova task `djen_scheduled_sync` (5min via Beat), verifica next_sync_at por watchlist
- `apps/api/app/workers/celery_app.py` ‚Äî Adicionado `djen-scheduled-sync` ao beat_schedule
- `apps/web/src/app/(dashboard)/cnj/page.tsx` ‚Äî Formul√°rios com select de frequ√™ncia + input de hor√°rio, cards exibem frequ√™ncia/hor√°rio/pr√≥ximo sync
- `apps/web/src/components/workflows/node-types/delivery-node.tsx` ‚Äî Fix typo "Calendario" ‚Üí "Calend√°rio"
- `apps/api/app/core/microsoft_auth.py` ‚Äî Rejeita usu√°rios Microsoft sem conta Iudex (ValueError ‚Üí 403)
- `apps/api/app/api/endpoints/microsoft_sso.py` ‚Äî Catch ValueError, retorna HTTP 403

### Decis√µes Tomadas
- Celery Beat a cada 5 min verifica `next_sync_at <= now` por watchlist individual (mais eficiente que APScheduler)
- `compute_next_sync()` retorna datetime UTC; suporta croniter como depend√™ncia opcional
- Legacy `djen_daily_sync` mantida como fallback para watchlists sem next_sync_at

### Verifica√ß√µes
- Python py_compile: OK em 6 arquivos
- TypeScript tsc --noEmit: OK
- Alembic upgrade head: OK (migra√ß√£o aplicada)

---

## 2026-02-10 ‚Äî Sess√£o 161: Microsoft SSO no Word Add-in

### Objetivo
Adicionar autentica√ß√£o Microsoft SSO (NAA + fallback popup) ao Word Add-in existente, mantendo email/senha como fallback.

### Arquivos Criados
- `apps/office-addin/src/auth/msal-config.ts` ‚Äî Configura√ß√£o MSAL com NAA + fallback PCA (mesmo padr√£o do Outlook add-in, porta 3100)
- `apps/office-addin/.env` ‚Äî Vari√°veis VITE_AZURE_CLIENT_ID e VITE_API_URL

### Arquivos Editados
- `apps/office-addin/package.json` ‚Äî Adicionado `@azure/msal-browser: ^3.27.0`
- `apps/office-addin/src/api/client.ts` ‚Äî Nova fun√ß√£o `microsoftSSOLogin()` que envia token Microsoft ao backend via `POST /auth/microsoft-sso`
- `apps/office-addin/src/stores/auth-store.ts` ‚Äî Novo m√©todo `loginWithMicrosoft()` usando acquireToken + microsoftSSOLogin, logout agora tamb√©m faz msalLogout
- `apps/office-addin/src/components/auth/LoginForm.tsx` ‚Äî Bot√£o "Entrar com Microsoft" como prim√°rio, email/senha colapsado como fallback
- `apps/office-addin/manifest.xml` ‚Äî Adicionado `<WebApplicationInfo>` com client ID e scope User.Read

### Configura√ß√£o Azure AD
- Adicionados SPA redirect URIs: `https://localhost:3100`, `http://localhost:3100` ao App Registration existente
- Reusado mesmo App Registration `c256c4ab-8325-442b-bd9c-36c112e14eb7`

### Verifica√ß√µes
- `tsc --noEmit` ‚Äî OK (sem erros)
- `npm install` ‚Äî OK (@azure/msal-browser 3.30.0 instalado)

---

## 2026-02-10 ‚Äî Sess√£o 160: Workflows Ass√≠ncronos Event-Driven com Triggers e Entregas

### Objetivo
Criar workflows que executam independente do app estar aberto, disparados por eventos externos (Teams, Outlook, DJEN, agendamentos) com entrega autom√°tica de resultados (email, Teams, calend√°rio, webhook).

### Arquivos Criados
- `apps/api/app/services/graph_email.py` ‚Äî Email via Microsoft Graph (send, reply, get details)
- `apps/api/app/services/graph_calendar.py` ‚Äî Calendar via Microsoft Graph (create, list events)
- `apps/api/app/services/workflow_delivery.py` ‚Äî DeliveryService: despacha resultados para 5 destinos (email, teams_message, calendar_event, webhook_out, outlook_reply)
- `apps/api/app/services/workflow_triggers.py` ‚Äî TriggerRegistry: encontra workflows matching por tipo de trigger e despacha via Celery
- `apps/web/src/components/workflows/node-types/trigger-node.tsx` ‚Äî N√≥ visual trigger (amber/Zap)
- `apps/web/src/components/workflows/node-types/delivery-node.tsx` ‚Äî N√≥ visual delivery (green/Send)

### Arquivos Editados
- `apps/api/app/workers/tasks/workflow_tasks.py` ‚Äî Nova task `run_triggered_workflow` + `_run_triggered()` com dispatch de deliveries
- `apps/api/app/services/ai/workflow_compiler.py` ‚Äî 2 novos node factories (`trigger`, `delivery`), campos `trigger_event` e `delivery_results` no WorkflowState
- `apps/api/app/services/teams_bot/handlers.py` ‚Äî `handle_workflow_command()` agora despacha via TriggerRegistry
- `apps/api/app/api/endpoints/graph_webhooks.py` ‚Äî `_handle_mail_notification()` fetch email + dispatch trigger
- `apps/api/app/services/djen_sync.py` ‚Äî Dispatch trigger ap√≥s novas intima√ß√µes DJEN
- `apps/web/src/components/workflows/node-types/index.ts` ‚Äî Registro de TriggerNode e DeliveryNode
- `apps/web/src/components/workflows/workflow-builder.tsx` ‚Äî NODE_PALETTE com trigger e delivery, defaults no addNode
- `apps/web/src/components/workflows/properties-panel.tsx` ‚Äî Pain√©is completos para trigger (5 tipos) e delivery (5 tipos)
- `apps/api/app/scripts/seed_workflow_templates.py` ‚Äî 5 templates ass√≠ncronos (#22-26): Auto-An√°lise Email, Monitor DJEN, Minuta Teams, Relat√≥rio Matinal, Webhook API

### Decis√µes Tomadas
- Email/Calendar via Microsoft Graph API (tokens OBO j√° existentes no Redis)
- 5 tipos de trigger: teams_command, outlook_email, djen_movement, schedule, webhook
- 5 tipos de delivery: email, teams_message, calendar_event, webhook_out, outlook_reply
- Delivery dispatch acontece ap√≥s workflow completar no Celery (n√£o dentro do StateGraph)
- TriggerRegistry busca workflows ativos com n√≥s trigger matching o evento

### Verifica√ß√µes
- Python ast.parse: OK em todos os 9 arquivos backend
- TypeScript tsc --noEmit: exit code 0

---

## 2026-02-10 ‚Äî Sess√£o 159: Workflows ‚Äî Tools/Modelos/Templates Completos

### Objetivo
Expor todas as tools, modelos e instrumentos nos campos de configura√ß√£o dos workflows via dropdowns/multi-selects. Adicionar templates especializados inspirados no Harvey AI e funcionalidades de risco/fraude, transcri√ß√£o e deep research.

### Arquivos Criados
- `apps/web/src/hooks/use-workflow-options.ts` ‚Äî Hook para buscar tools (API + 17 builtins) e modelos
- `apps/web/src/components/workflows/node-types/claude-agent-node.tsx` ‚Äî N√≥ visual para agente IA
- `apps/web/src/components/workflows/node-types/parallel-agents-node.tsx` ‚Äî N√≥ visual para agentes paralelos

### Arquivos Editados
- `apps/web/src/components/workflows/node-types/index.ts` ‚Äî Registro de claude_agent e parallel_agents
- `apps/web/src/components/workflows/workflow-builder.tsx` ‚Äî NODE_PALETTE + defaults para novos n√≥s
- `apps/web/src/components/workflows/properties-panel.tsx` ‚Äî Pain√©is completos para claude_agent (seletor de agente, modelo, tools multi-select, toggles de capacidades) e parallel_agents; melhorias em tool_call (dropdown) e legal_workflow (multi-select de modelos)
- `apps/api/app/scripts/seed_workflow_templates.py` ‚Äî 8 novos templates (5 Harvey AI + 3 especializados: Risco/Fraude, Transcri√ß√£o, Deep Research). Total: 20 templates.

### Decis√µes Tomadas
- Hook `useWorkflowOptions` faz merge de tools da API com builtins SDK para garantir disponibilidade offline
- Seletor de agente usa AGENT_REGISTRY (Claude/OpenAI/Google) com capabilities distintas
- Toggles de Web Search, Deep Research e Code Execution mapeiam para configura√ß√µes dos executors
- Templates de risco usam parallel_agents com 3 dimens√µes (fidelidade, financeiro, compliance)
- Template de deep research usa claude_agent com web_search e deep_research habilitados

### Verifica√ß√£o
- `tsc --noEmit` ‚Äî OK
- `python ast.parse()` ‚Äî OK

---

## 2026-02-10 ‚Äî Sessao 158: Implementacao Phase 1 MVP Office Add-ins

### Objetivo
Implementar todas as funcionalidades Phase 1 do PRD/Design Doc Office Add-ins usando 6 subagentes em paralelo.

### Agentes Executados (6 em paralelo)

| # | Agente | Status | Arquivos |
|---|--------|--------|----------|
| 7 | Outlook Add-in Frontend | COMPLETADO | 36 arquivos em `apps/outlook-addin/` |
| 8 | Teams App Frontend | COMPLETADO | 20 arquivos em `apps/teams-app/` |
| 9 | Backend Auth + Models + Config | COMPLETADO | 6 novos + 4 editados |
| 10 | Backend Outlook Endpoints | COMPLETADO | 3 arquivos |
| 11 | Backend Teams Bot | COMPLETADO | 7 arquivos |
| 12 | Backend Graph + Webhooks | COMPLETADO | 3 arquivos |

### Arquivos Criados ‚Äî Frontend

**Outlook Add-in (`apps/outlook-addin/`)** ‚Äî 36 arquivos:
- Scaffold completo: package.json, vite.config.ts, tsconfig.json, tailwind.config.ts
- `manifest.json` ‚Äî JSON Unified Manifest (ADR-001) com Mailbox 1.5
- Auth MSAL: `msal-config.ts` (NAA com fallback), `auth-provider.tsx`
- Office bridge: `mail-bridge.ts` (getCurrentEmailData, onItemChanged)
- API: `client.ts` (JWT refresh queue), `sse-client.ts`, `outlook-api.ts`
- Stores Zustand: `auth-store.ts`, `email-store.ts`, `summary-store.ts`
- Componentes: SummaryPanel, SummaryCard, DeadlineList, ActionBar, CorpusSearch, ResultCard, WorkflowTrigger, WorkflowStatus
- Layout: TaskPane, Header, TabNavigation, ErrorBoundary
- Auth UI: LoginForm, AuthGuard
- Hooks: `useSSEStream.ts`
- Testes: `office-mock.ts` (mock completo do Office.js)

**Teams App (`apps/teams-app/`)** ‚Äî 20 arquivos:
- `manifest.json` ‚Äî Teams v1.19 com bot + static tabs + RSC
- Tab frontend: Vite + React + Fluent UI + Zustand (porta 3300)
- Auth: `teams-auth.ts` (Teams SDK v2 SSO)
- Componentes: Dashboard, WorkflowList, CorpusSearch

### Arquivos Criados ‚Äî Backend

**Auth + Models (Agente 9):**
- `app/models/microsoft_user.py` ‚Äî MicrosoftUser (oid, tid, email, UniqueConstraint)
- `app/models/graph_subscription.py` ‚Äî GraphSubscription (subscription_id, resource, expiration)
- `app/models/email_analysis_cache.py` ‚Äî EmailAnalysisCache (internet_message_id, result JSON)
- `app/schemas/microsoft_auth.py` ‚Äî MicrosoftSSORequest/Response, TeamsSSORequest
- `app/core/microsoft_auth.py` ‚Äî validate_microsoft_token (PyJWKClient RS256), OBO flow
- `app/api/endpoints/microsoft_sso.py` ‚Äî POST /auth/microsoft-sso, /auth/teams-sso

**Outlook Endpoints (Agente 10):**
- `app/schemas/outlook_addin_schemas.py` ‚Äî SummarizeEmailRequest, ClassifyRequest/Response
- `app/api/endpoints/outlook_addin.py` ‚Äî POST /summarize (SSE), /classify, /extract-deadlines
- `app/services/outlook_addin_service.py` ‚Äî OutlookAddinService com streaming via agent_clients

**Teams Bot (Agente 11):**
- `app/api/endpoints/teams_bot.py` ‚Äî POST /webhook, /notify/{user_id}
- `app/services/teams_bot/bot.py` ‚Äî IudexBot(ActivityHandler) com command routing
- `app/services/teams_bot/handlers.py` ‚Äî 7 handlers (search, analyze, workflow, etc.)
- `app/services/teams_bot/cards.py` ‚Äî 7 Adaptive Card builders
- `app/services/teams_bot/conversation_store.py` ‚Äî Redis ConversationReference (30d TTL)
- `app/workers/tasks/notification_tasks.py` ‚Äî Celery tasks proactive messaging

**Graph + Webhooks (Agente 12):**
- `app/services/graph_client.py` ‚Äî httpx + tenacity retry + throttling (429 + Retry-After)
- `app/core/webhook_validation.py` ‚Äî HMAC-SHA256 clientState validation
- `app/api/endpoints/graph_webhooks.py` ‚Äî Notification/lifecycle endpoints + subscription CRUD

### Arquivos Editados
- `app/core/config.py` ‚Äî AZURE_CLIENT_ID, AZURE_CLIENT_SECRET, AZURE_TENANT_ID, TEAMS_BOT_APP_ID/PASSWORD, GRAPH_WEBHOOK_SECRET, GRAPH_NOTIFICATION_URL, OUTLOOK_ADDIN_ENABLED, TEAMS_BOT_ENABLED, +4 CORS origins
- `app/api/routes.py` ‚Äî +4 routers (microsoft_sso, outlook_addin, teams_bot, graph_webhooks)
- `app/core/database.py` ‚Äî +3 model imports (MicrosoftUser, GraphSubscription, EmailAnalysisCache)
- `requirements.txt` ‚Äî +PyJWT[crypto], +msal, +botbuilder-core, +botbuilder-schema

### Adaptacoes ao Codebase Real
1. Redis: `from app.core.redis import redis_client` (nao `redis_client` module)
2. AI: `stream_vertex_gemini_async` / `call_vertex_gemini_async` de `agent_clients` (nao `orchestrator.stream_completion`)
3. Null guards em redis_client (Optional no projeto)

### Decisoes
- Outlook porta 3200, Teams tab porta 3300 (nao conflitam com Word add-in 3100)
- Outlook usa JSON Unified Manifest (ADR-001)
- Teams usa manifest v1.19 com bot + static tabs
- OutlookAddinService segue padrao singleton do word_addin_service

---

## 2026-02-10 ‚Äî Sessao 157b: Verificacao e Correcoes dos Docs Office Add-ins

### Objetivo
Verificar PRD e Design Doc contra pesquisa tecnica e aplicar todas as correcoes identificadas.

### Pipeline Executado
1. **3 agentes de verificacao em paralelo**:
   - PRD verifier ‚Äî confrontou RFs/RNFs com pesquisa
   - Design Doc verifier ‚Äî gap analysis de 23 itens (CRITICAL/IMPORTANT/IMPROVEMENT)
   - File reference/diagram verifier ‚Äî verificou refs a arquivos existentes e consistencia
2. **3 agentes de correcao em paralelo** ‚Äî aplicaram 19 fixes total

### Correcoes Aplicadas

#### PRD (`docs/PRD_OFFICE_ADDINS.md`) ‚Äî 5 fixes
- Fase 1: "Manifesto XML" ‚Üí "Manifesto JSON Unificado" (consistencia com ADR-001)
- Adicionado risco R12: Conditional Access deprecation marco 2026
- Adicionado risco R13: Adaptive Cards v1.2 no mobile
- Tabela de limites: +subscriptions por mailbox (1.000), +lifecycleNotificationUrl obrigatorio
- Nota mobile apos RF-TM-07: Teams mobile suporta apenas Adaptive Cards v1.2

#### Design Doc (`docs/DESIGN_DOC_OFFICE_ADDINS.md`) ‚Äî 14 fixes
- **Secao 5.1 (NAA)**: redirectUri com env-based switching (dev vs prod)
- **Secao 5.1**: cacheLocation de sessionStorage ‚Üí localStorage (docs oficiais Microsoft)
- **Apos Secao 5.1**: Alerta critico Conditional Access deprecation marco 2026
- **Apos alerta**: Tabela de metodos MSAL.js suportados/nao-suportados em NAA
- **ADR-004**: Clarificacao Adaptive Cards v1.5 desktop/web, v1.2 mobile
- **ADR-005**: Limite 1.000 subscriptions por mailbox
- **Secao 6.2**: Nota throttling reduzido pela metade desde 30/09/2025
- **Secao 6.3**: Requisito lifecycleNotificationUrl quando expiration > 1h
- **Secao 7.2**: Nota que ADR-001 escolheu JSON Unificado, XML mantido como referencia
- **Secao 7.3**: Nota convertToRestId para converter IDs EWS ‚Üí Graph
- **Secao 8.5**: Nota expiracao 30 dias para Adaptive Cards via Power Automate
- **Secao 15.2**: Path correto Mac sideloading
- **Fase 1**: "Manifesto XML" ‚Üí "Manifesto JSON Unificado" (consistencia)

### Gaps Criticos Identificados e Resolvidos
- **Conditional Access deprecation** (marco 2026) ‚Äî MSAL NAA incompativel
- **Adaptive Cards v1.2 no mobile** ‚Äî limitacao nao documentada inicialmente
- **Inconsistencia manifesto** ‚Äî ADR-001 dizia JSON mas fases diziam XML
- **redirectUri hardcoded** ‚Äî precisava ser env-based para producao
- **cacheLocation errado** ‚Äî docs Microsoft usam localStorage, nao sessionStorage

### Comandos/Agentes
- 6 agentes subprocesso executados (3 verificacao + 3 correcao)
- Todos completados com sucesso

---

## 2026-02-10 ‚Äî Sessao 157: PRD + Design Doc para Add-ins Outlook e Teams

### Objetivo
Criar documentacao completa (PRD e Design Doc) para construcao de add-ins Outlook e Teams integrados ao Iudex, combinando pesquisa tecnica dos agentes com estrutura do GPT.

### Arquivos Criados

| Arquivo | Tamanho | Descricao |
|---------|---------|-----------|
| `docs/PRD_OFFICE_ADDINS.md` | ~20KB | PRD com 14 secoes: visao, personas, casos de uso, RFs/RNFs, comandos, MoSCoW, metricas, riscos, fases |
| `docs/DESIGN_DOC_OFFICE_ADDINS.md` | ~55KB | Design Doc com 16 secoes: stack, arquitetura, ADRs, auth NAA, Graph, componentes, modelo dados, seguranca, deploy, testes, fases |

### Decisoes Tomadas
- **JSON Unificado para Outlook** (ADR-001), JSON para Teams (manifesto unificado v1.19)
- **NAA como auth primaria**: MSAL.js >= 3.27.0, com fallback SSO e popup
- **Bot Framework em Python**: Integrado ao FastAPI existente (nao Node.js)
- **ConversationReference em Redis**: TTL 30 dias, nao PostgreSQL
- **Graph Webhooks + Delta Query**: Padrao recomendado para sync

### Arquivos Existentes Referenciados
- `apps/office-addin/` ‚Äî Padroes reutilizados (Vite, React, Fluent UI, SSE, Zustand)
- `apps/api/app/api/endpoints/word_addin.py` ‚Äî Padrao de endpoints
- `apps/api/app/models/workflow.py` ‚Äî Modelo WorkflowRun com HIL
- `apps/api/app/services/dms_service.py` ‚Äî Graph integration existente

### Proximos Passos
- Iniciar Sprint 1-2 (Fundacao): scaffold apps, Azure AD, auth endpoints
- Revisar documentos com equipe

---

## 2026-02-10 ‚Äî Sess√£o 156: Chat /ask ‚Äî Performance, UX, Acessibilidade e Arquitetura

### Objetivo
An√°lise completa com React Grab da p√°gina /ask (chat) e implementa√ß√£o de todas as melhorias identificadas em performance, UX, acessibilidade e arquitetura.

### Arquivos Alterados

| Arquivo | A√ß√£o | Descri√ß√£o |
|---------|------|-----------|
| `components/chat/chat-message.tsx` | Modificado | Envolvido em React.memo para evitar re-renders |
| `components/chat/chat-interface.tsx` | Modificado | useCallback nos handlers, RAF throttle no onScroll, ARIA attrs, lazy DiffConfirmDialog |
| `components/ask/ask-sources-panel.tsx` | Modificado | React.memo no ContextItemCard |
| `app/(dashboard)/ask/page.tsx` | Modificado | Agrupou Share/Export em dropdown, placeholder din√¢mico por modo |
| `hooks/use-ask-page-state.ts` | Modificado | showSourcesPanel default false; reescrito para compor 3 hooks menores |
| `components/chat/model-params-popover.tsx` | **Novo** | Extra√≠do do ChatInput (~780 linhas) ‚Äî consome useChatStore diretamente |
| `components/chat/template-popover.tsx` | **Novo** | Extra√≠do do ChatInput (~230 linhas) ‚Äî estado local pr√≥prio |
| `components/chat/chat-input.tsx` | Modificado | De 2090‚Üí560 linhas (73% redu√ß√£o). Removeu MCP dead code, imports n√£o usados |
| `hooks/use-layout-resize.ts` | **Novo** | Split-panel resize, fullscreen, layout mode (~230 linhas) |
| `hooks/use-chat-citations.ts` | **Novo** | Extra√ß√£o de cita√ß√µes/streaming status das mensagens (~140 linhas) |
| `hooks/use-chat-actions.ts` | **Novo** | Send, share, export, generate, setChatMode (~230 linhas) |

### Decis√µes Tomadas
- **Componentes extra√≠dos consomem useChatStore diretamente** em vez de receber 40+ props ‚Äî interface mais limpa
- **useAskPageState** foi decomposto em 3 hooks focados + composi√ß√£o, mantendo interface de retorno id√™ntica (zero breaking changes na p√°gina)
- **ContextBanner n√£o foi extra√≠do** ‚Äî apenas ~87 linhas, tightly coupled com prefill function
- **MCP code block removido** do ChatInput ‚Äî dead code nunca referenciado no JSX

### M√©tricas
- ChatInput: 2090 ‚Üí 560 linhas (73% redu√ß√£o)
- useAskPageState: 1052 ‚Üí 529 linhas (50% redu√ß√£o) + 3 hooks focados
- 5 novos arquivos criados, todos auto-suficientes

### Testes Executados
- `npx tsc --noEmit` ‚Äî compila√ß√£o limpa, zero erros
- ESLint tem issue pr√©-existente (ESLint v9 breaking changes)

---

## 2026-02-09 ‚Äî Sess√£o 155: SPLADE + Dense Hybrid com Pesos Din√¢micos (LLM Query Classifier)

### Objetivo
Implementar classifica√ß√£o din√¢mica de queries jur√≠dicas para ajustar pesos sparse/dense no hybrid search SPLADE+Dense, cobrindo todo o universo jur√≠dico (teoria, doutrina, fatos, teses, jurisprud√™ncia, dispositivos legais, legisla√ß√£o, provas).

### Arquivos Alterados

| Arquivo | A√ß√£o | Descri√ß√£o |
|---------|------|-----------|
| `rag/core/query_classifier.py` | **Novo** | 9 categorias MECE (IDENTIFICADOR‚ÜíCONCEITUAL), LLM classifier (Gemini Flash) com cache, fast-path regex para CNJ e Art./¬ß |
| `rag/storage/qdrant_service.py` | Modificado | +`search_hybrid_weighted()` com Weighted RRF, +`_search_sparse_only()`, +`_weighted_rrf_merge()`, +`search_hybrid_weighted_multi_collection_async()` |
| `rag/pipeline/rag_pipeline.py` | Modificado | Integra√ß√£o do classifier no `_search_one()`, roteamento weighted/native, telemetria estruturada `hybrid_search_telemetry` |
| `rag/config.py` | Modificado | +4 campos: `hybrid_default_sparse/dense_weight`, `hybrid_query_classifier_llm/model` |
| `tests/test_query_classifier.py` | **Novo** | 38 testes: fast-path regex, LLM mock, pesos por categoria, fallback, cache, edge cases |

### Decis√µes Tomadas
- **LLM > regex** para classifica√ß√£o: Gemini Flash com cache LRU (1024 entries), regex apenas para CNJ (100% determin√≠stico)
- **9 categorias MECE** organizadas por comportamento de busca (sparse‚Üídense), n√£o por tipo jur√≠dico
- **Weighted RRF app-level**: Qdrant FusionQuery n√£o aceita pesos ‚Üí 2 queries separadas (dense + sparse) + merge client-side
- **Otimiza√ß√£o**: pesos iguais (¬±0.01) ‚Üí delega para FusionQuery nativo (mais eficiente)
- **Feature flags**: `RAG_HYBRID_QUERY_CLASSIFIER_LLM=true/false` para ligar/desligar, `RAG_QDRANT_SPARSE_ENABLED` como gate principal

### Testes Executados
- `test_query_classifier.py`: 38/38 passed
- `test_routed_ingest.py`: 9/9 passed
- `test_hybrid_reranker.py`: 18/18 passed
- `test_graph_enrichment.py`: 20/20 passed

### Env Vars Novos
- `RAG_HYBRID_SPARSE_WEIGHT` (default 0.50)
- `RAG_HYBRID_DENSE_WEIGHT` (default 0.50)
- `RAG_HYBRID_QUERY_CLASSIFIER_LLM` (default true)
- `RAG_HYBRID_CLASSIFIER_MODEL` (default gemini-2.0-flash)

---

## 2026-02-09 ‚Äî Sess√£o 155b: Chat Fast RAG + Vetoriza√ß√£o de Anexos Grandes

### Objetivo
Separar o pipeline RAG: pipeline completo (HyDE, Multi-Query, CRAG, Compression, Parent-Child) apenas para corpus; chat usa fast path (lexical + vector + RRF + graph/cograg apenas). Anexos grandes no chat s√£o vetorizados via `ingest_local()` e buscados via `search_fast()`.

### Arquivos Alterados

| Arquivo | A√ß√£o | Descri√ß√£o |
|---------|------|-----------|
| `rag/pipeline/rag_pipeline.py` | Modificado | +`search_fast()`: wrapper que desabilita HyDE/CRAG/Compress/Parent-Child/Corrective, mant√©m GraphRAG/ArgumentRAG/CogRAG |
| `rag/pipeline_adapter.py` | Modificado | +`build_rag_context_fast()`: entry point simplificado para chat, resolve sources/filtros/query rewrite e delega para `search_fast()` |
| `chat_service.py` | Modificado | Global RAG ‚Üí `build_rag_context_fast()` (gate: `CHAT_RAG_FAST_PATH`); Local RAG ‚Üí `_vectorize_and_search_local()` via ingest_local+search_fast (gate: `CHAT_LOCAL_RAG_VECTORIZED`); +`_format_local_results()` helper |
| `tests/test_chat_fast_rag.py` | **Novo** | 12 testes: search_fast kwargs, build_rag_context_fast, format_local_results, vectorize_and_search_local |

### Decis√µes Tomadas
- **GraphRAG, ArgumentRAG e CogRAG ativos** no fast path (a pedido do usu√°rio) ‚Äî s√≥ stages de query enhancement desabilitados
- **Fallback via env vars**: `CHAT_RAG_FAST_PATH=false` ‚Üí pipeline completo; `CHAT_LOCAL_RAG_VECTORIZED=false` ‚Üí LocalProcessIndex legado
- **Vetoriza√ß√£o de anexos**: usa `ingest_local()` (Qdrant local_chunks + OpenSearch rag-local) com `thread_id` como `case_id` para scoping

### Testes Executados
- `test_chat_fast_rag.py`: 12/12 passed
- `test_query_classifier.py`: 38/38 passed (regress√£o)
- `test_hybrid_reranker.py`: 18/18 passed (regress√£o)

### Env Vars Novos
- `CHAT_RAG_FAST_PATH` (default `true`) ‚Äî Chat usa fast RAG
- `CHAT_LOCAL_RAG_VECTORIZED` (default `true`) ‚Äî Anexos do chat vetorizados via Qdrant

---

## 2026-02-09 ‚Äî Sess√£o 154: EmbeddingRouter ‚Üî Ingest Pipeline (end-to-end) + Rerank v4

### Objetivo
Conectar o EmbeddingRouter (que roteia por jurisdi√ß√£o: BR‚ÜíJurisBERT 768d, US/UK/INT‚ÜíKanon2 1024d, EU‚ÜíVoyageLaw2 1024d, General‚ÜíOpenAI 3072d) ao pipeline de ingest, que antes usava sempre OpenAI 3072d para multi-chunk. Tamb√©m atualizar Cohere Rerank para v4.0-pro.

### Arquivos Alterados

| Arquivo | A√ß√£o | Descri√ß√£o |
|---------|------|-----------|
| `rag/pipeline/rag_pipeline.py` | Modificado | `ingest_to_collection()`: novo param `embedding_vectors` (plural), l√≥gica de prioridade vetores‚Üífallback, dimens√£o expl√≠cita no create_collection; `ingest_local`/`ingest_global` propagam `embedding_vectors` |
| `rag/storage/qdrant_service.py` | Modificado | `COLLECTION_TYPES` + `_collection_map` expandidos com routed collections; `create_collection()` usa `EMBEDDING_COLLECTIONS` lookup para dimens√µes |
| `api/endpoints/rag.py` | Modificado | Smart ingest refatorado: chunk-first ‚Üí batch embed via router ‚Üí passa `embedding_vectors` ao pipeline |
| `rag/core/cohere_reranker.py` | Modificado | Default `rerank-multilingual-v3.0` ‚Üí `rerank-v4.0-pro` |
| `rag/config.py` | Modificado | Default reranker ‚Üí `rerank-v4.0-pro` |
| `tests/test_routed_ingest.py` | **Novo** | 9 testes: vetores pr√©-computados, fallback, backward compat, dimens√µes, propaga√ß√£o |
| `tests/rag/test_hybrid_reranker.py` | Modificado | Refer√™ncia do modelo atualizada |

### Decis√µes Tomadas
- **Chunk-first embedding**: Smart ingest chunka ANTES de embedar (mesma `chunk_document()` + clamping) para garantir 1 vetor por chunk
- **Prioridade de vetores**: `embedding_vectors` (plural) > `embedding_vector` (singular, 1 chunk) > `embed_many()` fallback
- **Fallback com warning**: Se count de vetores ‚â† count de chunks, loga warning e re-embeda com provider default
- **Import local**: `EMBEDDING_COLLECTIONS` importado dentro de `create_collection()` para evitar circular
- **Rerank v4.0-pro**: 1627 ELO, ~614ms; Pro recomendado sobre Fast (1506 ELO) para caso jur√≠dico

### Testes
- `test_routed_ingest.py`: 9/9 ‚úÖ
- `tests/rag/`: 317 passed, 8 failed (pr√©-existentes em test_qdrant_service.py ‚Äî upsert/search, N√ÉO relacionados)
- `test_graph_enrichment.py`: 20/20 ‚úÖ

---

## 2026-02-09 ‚Äî Sess√£o 153: Pipeline de Enriquecimento L1‚ÜíL2‚ÜíL3‚ÜíL3b (Transparency-First)

### Objetivo
Implementar pipeline completo de enriquecimento do grafo com abordagem "transparency-first": L2/L3/L3b criam `:RELATED_TO` com `layer='candidate'`, nunca rela√ß√µes tipadas diretamente. Inclui anti-alucina√ß√£o, handoff L2‚ÜíL3, e modo explorat√≥rio para n√≥s isolados.

### Arquivos Alterados

| Arquivo | A√ß√£o | Descri√ß√£o |
|---------|------|-----------|
| `kg_builder/link_predictor.py` | Modificado | Gen√©rica `infer_links_by_embedding_generic()`, `EmbeddingCandidate`, RELATED_TO, Artigo√óArtigo, cross-type |
| `kg_builder/llm_link_suggester.py` | Modificado | Anti-alucina√ß√£o `_validate_evidence()`, handoff L2‚ÜíL3 `validate_l2_candidates_via_llm()`, RELATED_TO |
| `kg_builder/llm_explorer.py` | **Novo** | Modo explorat√≥rio L3b: isolated nodes + shortlist + LLM exploration |
| `kg_builder/legal_postprocessor.py` | Modificado | Fases 2/3/3b com handoff, novos campos stats, env vars |
| `schemas/graph_enrich.py` | **Novo** | EnrichRequest/Response/Layer schemas |
| `services/graph_enrich_service.py` | **Novo** | Orquestrador L1‚ÜíL2‚ÜíL3‚ÜíL3b |
| `endpoints/graph.py` | Modificado | `POST /graph/enrich` endpoint |
| `tests/test_graph_enrichment.py` | **Novo** | 20 testes cobrindo L2/L3/L3b/schemas |

### Decis√µes Tomadas
- **Transparency-first**: Todas as edges L2/L3/L3b s√£o `:RELATED_TO` com `layer='candidate'`, nunca rela√ß√µes tipadas
- **candidate_type convention**: L2=`semantic:embedding_similarity:*`, L3=`rel:cita`, L3b=`exploratory:llm:*`
- **Anti-alucina√ß√£o**: Evid√™ncia do LLM validada como substring dos snippets fornecidos; falha ‚Üí confian√ßa -50%
- **L3b min_confidence=0.80**: Mais alto que L3 (0.75) por ser modo proativo
- **Reusa infraestrutura existente**: `include_candidates=false` j√° filtrava candidatos em queries

### Testes
- `test_graph_enrichment.py`: 20/20 ‚úÖ
- `test_kg_builder.py`: 96/96 ‚úÖ (sem regress√£o)
- `test_neo4j_mvp.py`: 56/56 ‚úÖ (sem regress√£o)
- `test_orchestration_router.py`: 27/27 ‚úÖ (sem regress√£o)

### Env Vars Novas
```
KG_BUILDER_PASS_L2_TO_L3=true
KG_BUILDER_INFER_LINKS_EXPLORATORY=false
KG_BUILDER_INFER_LINKS_ARTIGO=true
KG_BUILDER_INFER_LINKS_CROSS_TYPE=true
KG_BUILDER_EXPLORATORY_MAX_DEGREE=1
KG_BUILDER_EXPLORATORY_MAX_NODES=50
KG_BUILDER_EXPLORATORY_MIN_CONFIDENCE=0.80
```

---

## 2026-02-09 ‚Äî Sess√£o 152: GDS Risk Detectors + Chain Audit UI + Bug Fix Fase 3

### Objetivo
Integrar 7 detectores GDS ao pipeline de scan de risco, expor auditoria de cadeia na UI `/graph/risk`, e corrigir bug pr√©-existente no dispatch da Fase 3 GDS.

### Principais Entregas

#### 1. **Chain Audit na UI** (`GraphRiskPageClient.tsx`)
- Adicionados bot√µes "Aresta" e "Cadeia" (split do antigo "Auditar")
- Painel tabulado (Aresta / Cadeia) com visualiza√ß√£o de caminhos
- Cadeia mostra: contagem de paths, tempo de execu√ß√£o, n√≥s encadeados com cores, evid√™ncias por hop
- Chama `POST /graph/risk/audit/chain` (endpoint j√° existia, mas n√£o tinha UI)

#### 2. **7 Detectores GDS no Risk Scan** (`graph_risk_service.py`)
Novos detectores baseados em algoritmos GDS (antes o scan usava s√≥ Cypher b√°sico):

| Detector | Algoritmo GDS | Cen√°rio |
|----------|--------------|---------|
| `connected_risk_clusters` | WCC | Ilhas isoladas (clusters desconectados) |
| `influence_propagation` | Eigenvector Centrality | Entidades com alta influ√™ncia propagada |
| `critical_intermediaries` | Betweenness | Intermedi√°rios cr√≠ticos (bridges) |
| `hidden_communities` | Leiden | Comunidades ocultas com alta modularidade |
| `behavioral_similarity` | Node Similarity | Pares com Jaccard ‚â• 0.5 (comportamento similar) |
| `collusion_triangles` | Triangle Count | Entidades em muitos tri√¢ngulos (colus√£o) |
| `structural_vulnerabilities` | Bridges + Artic. Points | Pontos estruturais fr√°geis |

Total de detectors agora: **12** (5 originais + 7 GDS). Todos com fallback gracioso se GDS indispon√≠vel.

#### 3. **Bug Fix: Dispatch Fase 3 GDS** (`graph_ask_service.py`)
- `gds_operations` list n√£o inclu√≠a opera√ß√µes da Fase 3 (adamic_adar, node2vec, all_pairs_shortest_path, harmonic_centrality)
- Resultado: esses handlers nunca eram chamados ‚Äî fluxo pulava para templates
- Corrigido adicionando as 4 opera√ß√µes √† lista

### Testes
- **71 passed** (risk + GDS), incluindo o antes-falhando `test_dispatcher_calls_adamic_adar`
- 1 falha pr√©-existente em `test_skill_builder` (sem rela√ß√£o)

### Arquivos Modificados
- `apps/web/src/app/(dashboard)/graph/risk/GraphRiskPageClient.tsx` ‚Äî Chain audit UI
- `apps/api/app/services/graph_risk_service.py` ‚Äî 7 GDS detectors
- `apps/api/app/services/graph_ask_service.py` ‚Äî Bug fix gds_operations list (Fase 3)

---

## 2026-02-09 ‚Äî Sess√£o 151: Implementa√ß√£o GDS ‚Äî 8 Algoritmos Avan√ßados para Grafo

### Objetivo
Adicionar **TODOS** os algoritmos avan√ßados do Neo4j Graph Data Science (GDS) recomendados para an√°lise de grafos jur√≠dicos, expondo-os tanto para o chat (Ask/Minuta) quanto para a p√°gina Graph.

### Contexto
Usu√°rio perguntou se o grafo suporta pesquisas gen√©ricas (como o MCP Neo4j oficial com `get-schema`, `read-cypher`, `write-cypher`). Confirmei que j√° existe `text2cypher` (NL‚ÜíCypher com 3 camadas de seguran√ßa). Ap√≥s explica√ß√£o do GDS, usu√°rio pediu **"sim adicione todas"** as opera√ß√µes avan√ßadas.

### Principais Entregas

#### 1. **8 Opera√ß√µes GDS Implementadas**
Todas com handlers completos em `graph_ask_service.py`:

- **betweenness_centrality** ‚Äî Identifica n√≥s-ponte (conectam √°reas distintas)
  - Algoritmo: `gds.betweenness.stream`
  - Uso: "Artigos que conectam direito civil e tribut√°rio"

- **community_detection** ‚Äî Detecta comunidades tem√°ticas (Louvain)
  - Algoritmo: `gds.louvain.stream`
  - Uso: "Agrupar artigos por tema sem rotular manualmente"

- **node_similarity** ‚Äî Encontra entidades similares (vizinhos compartilhados)
  - Algoritmo: `gds.nodeSimilarity.stream`
  - Uso: "Decis√µes parecidas com X", "Artigos relacionados a Y"

- **pagerank_personalized** ‚Äî Ranking de import√¢ncia com vi√©s (sementes)
  - Algoritmo: `gds.pageRank.stream` + `sourceNodes`
  - Uso: "Artigos mais importantes conectados √† CF/88 Art. 5"

- **weakly_connected_components** ‚Äî Componentes desconectados (ilhas)
  - Algoritmo: `gds.wcc.stream`
  - Uso: "Existem artigos √≥rf√£os?", "Quais ilhas no grafo?"

- **shortest_path_weighted** ‚Äî Caminho mais curto ponderado (Dijkstra)
  - Algoritmo: `gds.shortestPath.dijkstra.stream` + `relationshipWeightProperty`
  - Uso: "Caminho mais forte entre Art. X e S√∫mula Y"

- **triangle_count** ‚Äî Contagem de tri√¢ngulos (clustering)
  - Algoritmo: `gds.triangleCount.stream`
  - Uso: "Artigos mais interligados em grupos", "N√∫cleos densos"

- **degree_centrality** ‚Äî Centralidade por grau (conex√µes diretas)
  - Algoritmo: `gds.degree.stream` + `orientation`
  - Uso: "Artigos mais citados", "Artigos que mais citam"

#### 2. **Seguran√ßa e Multi-tenancy**
- Todas as opera√ß√µes filtram por `tenant_id` nas proje√ß√µes de grafo
- Verifica√ß√£o GDS: `_check_gds_available()` verifica `gds.version()` antes de executar
- Requer `NEO4J_GDS_ENABLED=true` + plugin GDS instalado
- Cada opera√ß√£o usa proje√ß√µes ef√™meras com `randomUUID()` + cleanup autom√°tico via `gds.graph.drop()`

#### 3. **Exposi√ß√£o no Chat (Ask/Minuta)**
- Todas as 20 opera√ß√µes (7 existentes + 5 novas factual + 8 GDS) expostas em `unified_tools.py`
- Documenta√ß√£o completa para cada algoritmo com exemplos de uso
- Novos par√¢metros: `source_ids` (array), `weight_property`, `direction` ("OUTGOING"/"INCOMING"/"BOTH"), `top_k`
- Propaga√ß√£o de par√¢metros em `tool_handlers.py`

#### 4. **Testes**
- **24/24 testes passando** em `test_graph_gds.py`:
  - 8 testes de enum (verificam presen√ßa no GraphOperation)
  - 4 testes de disponibilidade GDS (env var, instala√ß√£o, cache)
  - 10 testes de handlers (smoke tests com mocks)
  - 2 testes de dispatcher (bloqueio quando GDS indispon√≠vel, roteamento correto)

### Arquivos Modificados

- **`apps/api/app/services/graph_ask_service.py`** (~350 linhas adicionadas)
  - +8 enum values em `GraphOperation`
  - +`_check_gds_available()` m√©todo de verifica√ß√£o
  - +8 handler methods: `_handle_betweenness_centrality()` at√© `_handle_degree_centrality()`
  - +Dispatcher atualizado com check GDS para as 8 opera√ß√µes

- **`apps/api/app/services/ai/shared/unified_tools.py`** (~60 linhas adicionadas)
  - +Enum atualizado com 8 novas opera√ß√µes GDS
  - +Documenta√ß√£o completa (ops 13-20) com exemplos de uso
  - +4 novos par√¢metros no schema: `source_ids`, `weight_property`, `direction`, `top_k`
  - +Footer atualizado: "Opera√ß√µes GDS (13-20) requerem NEO4J_GDS_ENABLED=true"

- **`apps/api/app/services/ai/shared/tool_handlers.py`** (~12 linhas adicionadas)
  - +Propaga√ß√£o de 4 novos par√¢metros: `source_ids`, `weight_property`, `direction`, `top_k`

- **`apps/api/tests/test_graph_gds.py`** (~400 linhas, arquivo novo)
  - 24 testes de smoke (enum, disponibilidade, handlers, dispatcher)

### Testes
```bash
pytest apps/api/tests/test_graph_gds.py -v -o "addopts="
# ======================== 24 passed in 10.44s ========================
```

### Env Vars Necess√°rias
```bash
NEO4J_GDS_ENABLED=true  # Habilita verifica√ß√£o GDS
# Plugin GDS deve estar instalado no Neo4j (detecta via gds.version())
```

### Padr√£o de Implementa√ß√£o
Todas as opera√ß√µes GDS seguem padr√£o unificado:
1. **Valida√ß√£o de par√¢metros** (source_id, target_id, source_ids conforme necess√°rio)
2. **Proje√ß√£o ef√™mera** de grafo com `randomUUID()` e filtro `tenant_id`
3. **Algoritmo GDS** via `gds.<algorithm>.stream()`
4. **Cleanup autom√°tico** via `gds.graph.drop()`
5. **Metadata rica** retornada (algoritmo, params, tempo de execu√ß√£o)

---

## 2026-02-09 ‚Äî Sess√£o 150: Graph Risk (Fraude/Auditoria) + Confirma√ß√£o Server-Side para link_entities + Tools no Chat

### Objetivo
1. Adicionar uma camada **determin√≠stica** para descoberta de fraudes e auditorias no grafo (multi-cen√°rio), com **p√°gina dedicada** `/graph/risk`.
2. Tornar `link_entities` seguro por padr√£o com **preflight server-side** e confirma√ß√£o expl√≠cita (`confirm=true`) antes de gravar.
3. Expor scan/auditoria tamb√©m para o **chat (Ask/Minuta)** via tools unificadas.

### Principais Entregas
- **link_entities 2-fases (preflight + confirm)**:
  - `apps/api/app/services/graph_ask_service.py`: `LINK_ENTITIES_REQUIRE_CONFIRM` (default `true`).
  - `confirm=false` retorna preview (`metadata.requires_confirmation=true`); `confirm=true` grava e retorna `metadata.write_operation=true`.
  - `apps/api/app/services/ai/shared/tool_handlers.py`: passa `metadata` para os modelos e propaga `confirm`.
  - `apps/api/app/services/ai/shared/unified_tools.py`: adiciona param `confirm` e regra ‚Äúnunca enviar confirm=true sem confirma√ß√£o expl√≠cita do usu√°rio‚Äù.
  - `apps/web/src/components/graph/GraphAuraAgentChat.tsx`: bot√£o ‚ÄúConfirmar‚Äù envia `confirm: true`.

- **Graph Risk backend**:
  - `apps/api/app/api/endpoints/graph_risk.py`: endpoints `/graph/risk/scan`, `/graph/risk/reports`, `/graph/risk/audit/*`.
  - `apps/api/app/services/graph_risk_service.py`: scan determin√≠stico + auditoria de arestas/cadeias + persist√™ncia.
  - `apps/api/app/models/graph_risk_report.py` + migration `apps/api/alembic/versions/y7z8a9b0c1d2_add_graph_risk_reports.py`.
  - Reten√ß√£o: `apps/api/app/tasks/graph_risk_cleanup.py` + Celery task `apps/api/app/workers/tasks/graph_risk_tasks.py` + schedule em `apps/api/app/workers/celery_app.py`.

- **P√°gina dedicada**:
  - `apps/web/src/app/(dashboard)/graph/risk/page.tsx`
  - `apps/web/src/app/(dashboard)/graph/risk/GraphRiskPageClient.tsx` (tabela de sinais + auditoria via API).
  - `apps/web/src/components/graph/GraphAuraAgentChat.tsx`: comando `/risk` abre a p√°gina.

- **Tools para chat (Ask/Minuta)**:
  - `scan_graph_risk`, `audit_graph_edge`, `audit_graph_chain` adicionadas em:
    - `apps/api/app/services/ai/shared/unified_tools.py`
    - `apps/api/app/services/ai/shared/tool_handlers.py`

### Testes
- `apps/api/tests/test_graph_write.py`: atualizado para preflight/confirm.
- `apps/api/tests/test_graph_risk_smoke.py`: smoke tests de import (schemas/service).

## 2026-02-08 ‚Äî Sess√£o 149: Otimiza√ß√£o DoclingAdapter (3-tier Adaptativo) + Verifica√ß√£o group_ids

### Objetivo
1. Verificar se `group_ids` est√° configurado nos 3 backends (OpenSearch, Qdrant, Neo4j)
2. Portar extra√ß√£o adaptativa 3-tier do `ingest_v2.py` para o `DoclingAdapter` da API

### Verifica√ß√£o group_ids
Confirmado em todos os 3 backends:
- **OpenSearch**: campo `group_ids` (keyword), filtro `{"terms": {"group_ids": group_ids}}`
- **Qdrant**: `group_ids` em PayloadSchemaType.KEYWORD, filtro `MatchAny(any=group_ids)`
- **Neo4j**: `d.group_ids` nos n√≥s Document, filtro Cypher `any(g IN $group_ids WHERE g IN coalesce(d.group_ids, []))`

### Otimiza√ß√£o DoclingAdapter ‚Äî 3-tier Adaptativo
**Problema**: `DoclingAdapter` usava `DocumentConverter()` com defaults (OCR+TableFormer sempre ligados), enquanto `ingest_v2.py` j√° tinha extra√ß√£o adaptativa 3-tier otimizada.

**Solu√ß√£o inicial**: Portado o padr√£o 3-tier:
1. **FAST** ‚Äî sem OCR, sem TableFormer (maioria dos PDFs texto-nativos)
2. **TABLES** ‚Äî com TableFormer (quando tabelas detectadas pelo DocLayNet)
3. **OCR** ‚Äî OCR + TableFormer (quando texto esparso: <100 chars/p√°gina)

### Refinamento de Crit√©rios (itera√ß√£o 2)
**Identificado**: Crit√©rios simplistas poderiam ativar tiers desnecessariamente:
- Threshold de 100 chars/p√°gina muito baixo (PDFs com margens/imagens)
- Detec√ß√£o bin√°ria de tabelas (1 tabela em 50 p√°ginas ‚Üí TableFormer em tudo)
- Sem valida√ß√£o de qualidade do texto FAST (encoding corrompido, OCR artifacts)

**Melhorias implementadas**:
1. **Threshold mais alto**: `_MIN_CHARS_PER_PAGE = 150` (de 100 ‚Üí 150)
2. **Densidade de tabelas**: `_has_significant_tables()` usa threshold de 5% (tabelas/p√°ginas >= 0.05)
   - Documentos ‚â§2 p√°ginas: qualquer tabela √© significativa
   - Documentos >2 p√°ginas: densidade precisa ser >= 5%
3. **Valida√ß√£o de qualidade**: `_is_text_quality_good()` verifica:
   - Printable ratio >= 85% (detecta encoding corrompido)
   - Space ratio 8-35% (detecta falta de separa√ß√£o de palavras = OCR artifact)
   - Avg token length 2-25 chars (detecta gibberish ou tokens concatenados)
   - Se qualidade baixa ‚Üí dispara OCR mesmo com texto n√£o-esparso

### Arquivos Modificados
- `apps/api/app/services/docling_adapter.py`
  - +3 converters lazy-initialized (`_converter_fast`, `_converter_tables`, `_converter_ocr`)
  - +`_get_converter(mode)` com imports lazy dentro de null-checks
  - +`_get_generic_converter()` para formatos n√£o-PDF
  - +`_is_text_sparse()` detec√ß√£o de texto esparso
  - +`_has_significant_tables()` detec√ß√£o de densidade de tabelas (substitui `_has_tables`)
  - +`_is_text_quality_good()` valida√ß√£o de qualidade de texto
  - +`_extract_pdf_adaptive()` e `_docling_pdf_adaptive_sync()` l√≥gica 3-tier refinada
  - +5 env vars configur√°veis: `DOCLING_MIN_CHARS_PER_PAGE`, `DOCLING_MIN_TABLE_DENSITY`, `DOCLING_MIN_PRINTABLE_RATIO`, `DOCLING_MIN_SPACE_RATIO`, `DOCLING_MAX_SPACE_RATIO`
  - +`docling_tier` no metadata de ExtractionResult
- `apps/api/tests/test_docling_adapter.py`
  - +26 testes (7 sparse, 8 tables density, 9 quality validation, 7 tier selection, 1 routing)
  - Removidos 3 testes legacy de `_has_tables()` (substitu√≠do por `_has_significant_tables`)

### Testes
- 35/35 testes passando
- Cobertura: detec√ß√£o de texto esparso, densidade de tabelas, valida√ß√£o de qualidade, tier selection completo

---

## 2026-02-08 ‚Äî Sess√£o 147: Infer√™ncia Estrutural (SUBDISPOSITIVO_DE)

### Objetivo
Adicionar arestas **determin√≠sticas** de hierarquia interna em `Artigo` (par√°grafo/inciso) para o artigo-pai, sem depender de LLM e sem risco de alucina√ß√£o.

### O Que Foi Adicionado
- Novo relationship type: `SUBDISPOSITIVO_DE`
  - `Artigo(subdispositivo)` ‚Üí `Artigo(artigo-pai)`
  - Infer√™ncia baseada apenas no `entity_id` (ex.: `art_5_p2_iI` ‚Üí `art_5_p2` ‚Üí `art_5`)

### Arquivos Modificados
- `apps/api/app/services/rag/core/kg_builder/legal_schema.py`
  - +`SUBDISPOSITIVO_DE` em `LEGAL_RELATIONSHIP_TYPES`
  - +pattern `("Artigo","SUBDISPOSITIVO_DE","Artigo")`
- `apps/api/app/services/rag/core/kg_builder/legal_postprocessor.py`
  - +step `3f`: `_infer_subdispositivo_de()` (Cypher puro, sem APOC)
  - Env gate: `KG_BUILDER_INFER_SUBDISPOSITIVO_DE` (default `true`)
  - +stat `subdispositivo_de_inferred`
- `apps/api/app/services/rag/core/kg_builder/pipeline.py`
  - +propaga√ß√£o `post_process_subdispositivo_de_inferred` para `result_stats`
- `apps/api/tests/test_structural_inference.py` (novo)

### Testes
- `tests/test_structural_inference.py`: 3 testes
- Regress√£o (subset): OK

## 2026-02-08 ‚Äî Sess√£o 148: Co-ocorr√™ncia Materializada (CO_MENCIONA) + Comando na P√°gina de Grafos

### Objetivo
Materializar arestas leves de co-ocorr√™ncia **por chunk** (Artigo‚ÄìArtigo) como camada **candidate**, tenant-scoped, para descoberta no grafo sem ‚Äúinventar sem√¢ntica‚Äù.

### O Que Foi Adicionado
- Opera√ß√£o GraphAsk: `recompute_co_menciona`
  - Recalcula `(:Artigo)-[:CO_MENCIONA {layer:'candidate', tenant_id, co_occurrences, weight, samples}]->(:Artigo)`
  - Determin√≠stica: baseada em `Chunk-[:MENTIONS]->Artigo` (co-ocorr√™ncia real)
  - N√£o interfere em travessias padr√£o: `legal_chain`/`path` excluem candidate por default (`include_candidates=false`)

### Arquivos Modificados
- `apps/api/app/services/graph_ask_service.py`
  - +enum `RECOMPUTE_CO_MENCIONA`
  - +handler `_handle_recompute_co_menciona()` (chama `neo4j_mvp.recompute_candidate_comentions` via `asyncio.to_thread`)
  - +dispatch e valida√ß√£o
- `apps/api/app/api/endpoints/graph_ask.py`
  - +`"recompute_co_menciona"` no `Literal` de `GraphAskRequest.operation`
- `apps/web/src/components/graph/GraphAuraAgentChat.tsx`
  - +comando `/comenciona [min] [maxPairs]` (ex.: `/comenciona 2 20000`)
  - +formatter de resposta
- `apps/api/tests/test_recompute_comenciona.py` (novo)

### Testes
- `tests/test_recompute_comenciona.py`: 4 testes
- Web type-check: OK

## 2026-02-08 ‚Äî Sess√£o 149: Confirma√ß√£o Antes de Escrever (Graph Page)

### Objetivo
Evitar escrita acidental no grafo: resolver entidades e inferir rela√ß√£o primeiro, **exibir preview**, e s√≥ escrever ap√≥s confirma√ß√£o expl√≠cita.

### O Que Foi Adicionado
- Confirma√ß√£o UI no chat do grafo para `link_entities`:
  - Mostra `source`, `relation_type`, `target`, `dimension` (quando infer√≠vel) e `evidence` (opcional)
  - Bot√µes **Confirmar** / **Cancelar**
- Suporte opcional a evidence no texto:
  - `evidence:"..."`, `trecho:"..."`, `ev:"..."`
  - Em `/link`, tamb√©m aceita `ev "..."` no final

### Arquivo Modificado
- `apps/web/src/components/graph/GraphAuraAgentChat.tsx`

### Testes
- Web type-check: OK

## 2026-02-08 ‚Äî Sess√£o 146: QA Factual no Grafo ‚Äî Expor opera√ß√µes avan√ßadas ao chat

### Objetivo
Habilitar pesquisas factuais gen√©ricas no grafo jur√≠dico pelos agentes de IA (Claude/GPT/Gemini). O `GraphAskService` tinha 15 opera√ß√µes implementadas mas o `ASK_GRAPH_TOOL` s√≥ expunha 7.

### Arquivos Modificados
- `apps/api/app/services/graph_ask_service.py`
  - +2 enum: `RELATED_ENTITIES`, `ENTITY_STATS`
  - +template Cypher `related_entities` (travessia direta bidirecional, exclui infra rels)
  - +handler `_handle_entity_stats()` (4 queries: total entities, by type, total rels, rel types)
  - +dispatch entity_stats no `ask()`
  - +valida√ß√£o e defaults para ambos
- `apps/api/app/services/ai/shared/unified_tools.py`
  - Enum expandido: 7 ‚Üí 12 opera√ß√µes (text2cypher, legal_chain, precedent_network, related_entities, entity_stats)
  - +3 params: question, decision_id, relation_filter
  - Descri√ß√µes ops 8-12 com exemplos de uso
- `apps/api/app/services/ai/shared/tool_handlers.py`
  - +propaga√ß√£o question, decision_id, relation_filter
- `apps/api/app/api/endpoints/graph_ask.py`
  - +2 Literal values: related_entities, entity_stats
- `apps/api/tests/test_factual_qa.py` ‚Äî **Novo**: 28 testes

### Testes
- 28 novos (test_factual_qa.py): enum exposure, params, template, handler, validation, endpoint
- 114 regress√£o OK (1 skipped)

### Decis√µes
- `related_entities` usa template Cypher (n√£o handler) pois se encaixa no padr√£o existing
- `entity_stats` usa handler especial (multi-query como discover_hubs)
- text2cypher, legal_chain, precedent_network j√° existiam ‚Äî s√≥ expostos na tool definition

---

## 2026-02-08 ‚Äî Sess√£o 145: Normaliza√ß√£o Agressiva + Hub Detection (Gaps neo4j-ingestor)

### Objetivo
Integrar 8 gaps identificados entre o standalone `neo4j-ingestor/` e o Iudex `legal_postprocessor.py`:
normaliza√ß√£o agressiva Python-side, corre√ß√£o de g√™nero, formata√ß√£o de par√°grafo/inciso,
dots em Decis√£o, dedup de relacionamentos, garbage cleanup, Lei Complementar‚ÜíLC, e hub detection.

### Arquivos Modificados
- `apps/api/app/services/rag/core/kg_builder/legal_postprocessor.py`
  - **Gap 1-3**: Fun√ß√µes `_normalize_artigo_name()` (accents ¬ß‚Üípar., ¬∫‚Üío, ¬™‚Üía), gender prepositions (do Lei‚Üída Lei), paragraph/inciso formatting
  - **Gap 4**: `_normalize_decisao_name()` (dots em n√∫meros: "4.650"‚Üí"4650", 2 passes)
  - **Gap 5**: Step 3d ‚Äî dedup de relacionamentos paralelos p√≥s-merge (itera todos rel types exceto infra)
  - **Gap 6**: Step 3e ‚Äî garbage cleanup (Artigo < 5 chars ‚Üí DETACH DELETE)
  - **Gap 7**: `_normalize_lei_name()` (Lei Complementar‚ÜíLC), `_normalize_sumula_name()` (S√∫mula‚ÜíSumula), `_normalize_tese_name()` (trailing period)
  - Substitui√ß√£o do antigo step 0a Cypher-based por `_apply_normalization()` Python-side para 5 labels
  - Novos stats fields: `decisao_python_normalized`, `sumula_python_normalized`, `lei_python_normalized`, `tese_python_normalized`, `relationships_deduped`, `garbage_artigo_removed`
- `apps/api/app/services/graph_ask_service.py`
  - **Gap 8**: `DISCOVER_HUBS` enum + `_handle_discover_hubs()` handler (5 Cypher queries categorizadas: artigos referenciados, outgoing, total degree, decis√µes com teses, leis com artigos)
- `apps/api/app/services/ai/shared/unified_tools.py`
  - Opera√ß√£o 7 `discover_hubs` no ASK_GRAPH_TOOL + param `top_n`
- `apps/api/app/services/ai/shared/tool_handlers.py`
  - Propaga√ß√£o de `top_n` para operation_params
- `apps/api/app/api/endpoints/graph_ask.py`
  - `"discover_hubs"` no Literal do endpoint REST

### Testes
- `test_postprocessor_normalization.py` (NOVO): 50 testes ‚Äî accents, gender, paragraph/inciso, decisao dots, sumula, lei complementar, tese, expansions, full pipeline, constants, stats fields
- `test_discover_hubs.py` (NOVO): 8 testes ‚Äî enum, validation, handler success/default/cap/categories/partial failure, tool definition
- Regress√£o: 150 passed, 1 skipped, 0 failures

### Refer√™ncias
- `/Users/nicholasjacob/Documents/neo4j-ingestor/fix_normalization.py` ‚Äî source das fun√ß√µes de normaliza√ß√£o
- `/Users/nicholasjacob/Documents/neo4j-ingestor/fix_gender.py` ‚Äî source das corre√ß√µes de g√™nero
- `/Users/nicholasjacob/Documents/neo4j-ingestor/mcp_server.py` ‚Äî source do hub detection (hubs_do_grafo)

---

## 2026-02-08 ‚Äî Sess√£o 143: Guidance Para `link_entities` (Search-First + Properties)

### Objetivo
Garantir que os modelos do chat usem `ask_graph.link_entities` de forma consistente e segura: **sempre resolver `entity_id` via `ask_graph.search` antes de criar arestas**, e suportar propriedades opcionais na cria√ß√£o.

### Arquivos Modificados
- `apps/api/app/services/ai/shared/unified_tools.py`
  - Melhorias na descri√ß√£o do `ASK_GRAPH_TOOL` (workflow recomendado: `search` ‚Üí confirma√ß√£o se amb√≠guo ‚Üí `link_entities`)
  - Adicionado `params.properties` (object) para propriedades opcionais na rela√ß√£o (audit props continuam imut√°veis)
  - Ajustadas descri√ß√µes de `source_id`/`target_id` para indicar uso em `path/link_entities`
- `apps/api/app/services/ai/orchestration/router.py`
  - System prompt jur√≠dico agora inclui regras expl√≠citas para uso do grafo (`search` antes de `link_entities`, sem Cypher de escrita)
- `apps/api/app/services/ai/agent_clients.py`
  - Instru√ß√£o padr√£o jur√≠dica refor√ßa `search` antes de `link_entities` e pro√≠be inventar IDs
- `apps/api/tests/test_graph_write.py`
  - Testes atualizados para validar `params.properties` e men√ß√£o do workflow ‚Äúsearch-first‚Äù na descri√ß√£o

### Testes
- `test_graph_write.py`: 11 passed
- `test_orchestration_router.py`: 27 passed

---

## 2026-02-08 ‚Äî Sess√£o 144: Graph Page `/link` (Resolve via Search + link_entities)

### Objetivo
Habilitar cria√ß√£o de arestas tamb√©m na p√°gina de grafos (Graph UI) sem LLM, via comando expl√≠cito `/link` no widget `GraphAuraAgentChat`.

### Implementa√ß√£o
- `apps/web/src/components/graph/GraphAuraAgentChat.tsx`
  - Adicionado suporte √† opera√ß√£o `link_entities` no tipo `GraphAskOperation`
  - Novo comando `/link` com resolu√ß√£o `search`-first no client:
    - Aceita `entity_id` diretamente (ex: `art_5_cf`) ou texto (ex: `"Art. 5 CF"`)
    - Sintaxe: `/link origem -> destino via RELACAO` ou `/link origem destino via RELACAO`
    - Se `search` retornar m√∫ltiplos candidatos, o chat pede para o usu√°rio escolher `entity_id`
  - Formata√ß√£o de resposta para `link_entities`

### Verifica√ß√£o
- `apps/web`: `npm run type-check` (tsc --noEmit) OK

---

## 2026-02-08 ‚Äî Sess√£o 145: Graph Page Natural Language ‚Üí `link_entities`

### Objetivo
Permitir usar linguagem natural para cria√ß√£o de arestas na p√°gina de grafos (sem comando `/link`), ex:
`Conecte Art. 5 CF com S√∫mula 473 STF via INTERPRETA`.

### Implementa√ß√£o
- `apps/web/src/components/graph/GraphAuraAgentChat.tsx`
  - Parser determin√≠stico para inten√ß√£o de escrita (gate por verbos imperativos + `via` ou termos como "aresta/rela√ß√£o")
  - Extrai pares de entidades via aspas (`"..."`), `entre X e Y`, `X com Y` ou `X -> Y`
  - Reusa o mesmo fluxo `search`-first do `/link` (resolve refs antes de chamar `link_entities`)

### Verifica√ß√£o
- `apps/web`: `npm run type-check` OK

---

## 2026-02-08 ‚Äî Sess√£o 146: Graph Page LLM Mode (Consultas GraphRAG via /chats SSE)

### Objetivo
Habilitar respostas em linguagem natural na p√°gina de grafos usando LLM + GraphRAG, mantendo escrita (arestas) fora do modo LLM.

### Implementa√ß√£o
- `apps/web/src/components/graph/GraphAuraAgentChat.tsx`
  - Toggle `LLM: ON/OFF` no header
  - Quando `LLM: ON` e a mensagem n√£o for comando (`/path`, `/search`, etc.):
    - cria (lazy) um chat backend (`POST /chats/`, modo `CHAT`) e guarda `chat_id` no `localStorage`
    - envia mensagem via SSE (`POST /chats/{chat_id}/messages/stream`) com `graph_rag_enabled=true` e `graph_hops`
    - renderiza tokens em streaming no widget
  - Safety: injeta `thesis` instruindo o agente a **n√£o** usar `link_entities` no modo LLM (writes ficam via `/link` ou parser determin√≠stico)

### Verifica√ß√£o
- `apps/web`: `npm run type-check` OK

---

## 2026-02-08 ‚Äî Sess√£o 147: Graph Page Natural Edges (Verb ‚Üí Relation Type)

### Objetivo
Permitir que usu√°rios criem arestas com linguagem realmente natural, sem `via` e sem `/link`, por exemplo:
`"Sumula 473 STF interpreta Art. 5 CF"` e `"Art. 135 CTN remete a Art. 50 CC"`.

### Implementa√ß√£o
- `apps/web/src/components/graph/GraphAuraAgentChat.tsx`
  - Infer√™ncia determin√≠stica de `relation_type` por verbos:
    - interpreta ‚Üí `INTERPRETA`
    - remete a ‚Üí `REMETE_A`
    - pertence a ‚Üí `PERTENCE_A`
    - fundamenta ‚Üí `FUNDAMENTA`
    - cita ‚Üí `CITA`
    - aplica (+ heur√≠stica p/ sumula) ‚Üí `APLICA`/`APLICA_SUMULA`
    - fixa tese ‚Üí `FIXA_TESE`
    - julga tema ‚Üí `JULGA_TEMA`
    - proferida por ‚Üí `PROFERIDA_POR` (com flip de dire√ß√£o)
    - revoga/altera/regulamenta/especializa/substitui/cancela/complementa/excepciona
  - Gating anti-acidente: s√≥ escreve quando detecta 2 refs ‚Äúcom cara de entidade‚Äù (art/s√∫mula/lei/tema + d√≠gitos, etc.)
  - Mant√©m `search-first` e exige escolha manual quando `search` retorna amb√≠guo

### Verifica√ß√£o
- `apps/web`: `npm run type-check` OK

---

## 2026-02-08 ‚Äî Sess√£o 148: Graph Page `/t2c` (Text2Cypher)

### Objetivo
Expor o Text2Cypher na p√°gina de grafos via comando `/t2c`, chamando o endpoint `POST /graph/ask/text2cypher`.

### Implementa√ß√£o
- `apps/web/src/components/graph/GraphAuraAgentChat.tsx`
  - Novo helper `callGraphText2Cypher()`
  - Suporte ao comando `/t2c <pergunta>` (ou `/text2cypher <pergunta>`)
  - Atualiza help string inicial para mencionar `/t2c`

### Observa√ß√µes
- O backend exige `TEXT2CYPHER_ENABLED=true`; caso contr√°rio a resposta retorna erro informando que est√° desabilitado.

### Verifica√ß√£o
- `apps/web`: `npm run type-check` OK

---

## 2026-02-08 ‚Äî Sess√£o 142: Graph Write via Chat ‚Äî `link_entities` no ask_graph

### Objetivo
Permitir que os modelos de IA do chat (Claude/GPT/Gemini) criem rela√ß√µes (arestas) entre entidades no grafo Neo4j via linguagem natural, usando a tool `ask_graph` unificada.

### Contexto
O grafo jur√≠dico v3.1 est√° populado (170 Artigos, 17 Decis√µes, 7 S√∫mulas, 260 cadeias). A tool `ask_graph` permitia consultas READ-ONLY. Primitivas de escrita segura (`link_entities_async()`, `_sanitize_relation_type()`) j√° existiam no `neo4j_mvp.py` mas n√£o eram acess√≠veis via chat. Leitura do `ingest_v2.py` standalone confirmou paridade de relationship types.

### Arquivos Criados
- `apps/api/tests/test_graph_write.py` ‚Äî **Novo**: 11 testes (enum, valida√ß√£o, handler success/error/fallback/audit, tool definition)

### Arquivos Modificados
- `apps/api/app/services/graph_ask_service.py`:
  - `GraphOperation.LINK_ENTITIES` adicionado ao enum
  - `_handle_link_entities()` ‚Äî handler async com 3 camadas de seguran√ßa
  - Dispatch routing no `ask()` (interceptado antes do template lookup)
  - `_validate_params()` ‚Äî adicionado `LINK_ENTITIES: ["source_id", "target_id"]`
- `apps/api/app/services/ai/shared/unified_tools.py`:
  - `ASK_GRAPH_TOOL` ‚Äî opera√ß√£o 6 `link_entities` + param `relation_type` + description com tipos v√°lidos
- `apps/api/app/services/ai/shared/tool_handlers.py`:
  - Propaga√ß√£o de `relation_type` do n√≠vel superior para `operation_params`
- `apps/api/app/api/endpoints/graph_ask.py`:
  - `"link_entities"` adicionado ao `Literal` do `GraphAskRequest`

### Seguran√ßa (3 camadas)
1. `_sanitize_relation_type()` ‚Äî whitelist de 30+ tipos + regex `^[A-Z][A-Z0-9_]{0,40}$`
2. `link_entities_async()` ‚Äî MATCH nas duas entidades (devem existir), MERGE idempotente
3. Properties de auditoria imut√°veis: `source: "user_chat"`, `layer: "user_curated"`, `verified: True`, `created_by: tenant_id`, `created_via: "chat"` (n√£o sobrescrev√≠veis pelo usu√°rio)

### Fluxo de Uso
```
User: "Conecte Art. 5 CF com S√∫mula 473 STF via INTERPRETA"
LLM: ask_graph(operation="search", params={query: "Art. 5 CF"}) ‚Üí entity_id
LLM: ask_graph(operation="search", params={query: "S√∫mula 473 STF"}) ‚Üí entity_id
LLM: ask_graph(operation="link_entities", params={source_id, target_id, relation_type: "INTERPRETA"})
```

### Testes
- `test_graph_write.py`: 11 passed
- Regress√£o: 84 passed, 1 skipped, 0 failed

### Primitivas Reutilizadas (n√£o modificadas)
- `neo4j_mvp.py:link_entities_async()` ‚Äî escrita segura com whitelist
- `neo4j_mvp.py:_sanitize_relation_type()` ‚Äî valida√ß√£o de tipo
- `legal_schema.py:LEGAL_RELATIONSHIP_TYPES` ‚Äî whitelist de 30+ tipos

---

## 2026-02-08 ‚Äî Sess√£o 141: Op√ß√£o B ‚Äî Pattern-Based Factual Relationship Extraction

### Objetivo
Implementar extra√ß√£o determin√≠stica de rela√ß√µes f√°ticas (PARTICIPA_DE, REPRESENTA) via regex patterns no pipeline KG Builder ‚Äî complementando a REGRA 11 (LLM) com uma camada de custo zero e lat√™ncia <1ms.

### Contexto
O pipeline regex j√° extra√≠a entidades f√°ticas (CPF, CNPJ, OAB, Processo) mas n√£o criava arestas entre elas. A Op√ß√£o B adiciona Step 6 em `_run_regex_extraction()` com 4 sub-steps que criam rela√ß√µes quando entidades coexistem no mesmo chunk com triggers textuais.

### Arquivos Criados
- `apps/api/tests/test_factual_relationships.py` ‚Äî **Novo**: 27 testes (trigger lists, PESSOA_ROLE_RE regex, slugify, extract_evidence, stats fields, schema integration)

### Arquivos Modificados
- `apps/api/app/services/rag/core/kg_builder/pipeline.py`:
  - `_PARTICIPA_TRIGGERS` (22 roles processuais: autor/r√©u/reclamante/apelante/etc.)
  - `_REPRESENTA_TRIGGERS` (10 roles de representa√ß√£o: advogado/procurador/defensor/etc.)
  - `_PESSOA_ROLE_RE` ‚Äî regex para "Nome Completo, papel" com suporte a preposi√ß√µes (da/de/dos/e)
  - `_slugify_name()` ‚Äî normaliza nomes para entity IDs (remove acentos, lowercase, underscores)
  - `_extract_evidence()` ‚Äî extrai trecho de ~160 chars ao redor do match
  - **Step 6** com 4 sub-steps:
    - 6a: CPF/CNPJ ‚Üí Processo via PARTICIPA_DE (requer trigger de papel processual)
    - 6b: OAB ‚Üí CPF/CNPJ via REPRESENTA (requer trigger de representa√ß√£o)
    - 6c: OAB ‚Üí Processo via PARTICIPA_DE (impl√≠cito, confidence 0.25)
    - 6d: Pessoa por nome + papel ‚Üí cria entidade Pessoa + PARTICIPA_DE ao Processo
  - 4 novos campos de stats: `factual_participa_links`, `factual_representa_links`, `factual_oab_processo_links`, `factual_pessoa_by_name`

### Bugs Encontrados e Corrigidos
1. **`re.IGNORECASE` quebrando detec√ß√£o de nomes**: Com IGNORECASE, o padr√£o de nome `[A-Z√Ä-√ö]` casava com min√∫sculas, fazendo "Jo√£o, autor" ser match indevido. Solu√ß√£o: remover flag, listar roles em lowercase apenas.
2. **Espa√ßo faltando entre palavras do nome**: O grupo opcional de preposi√ß√£o continha o `\s+` interno. Sem preposi√ß√£o, n√£o havia espa√ßo entre 1¬™ e 2¬™ palavra. Solu√ß√£o: mover `\s+` para fora do grupo opcional.
3. **Match parcial de "r√©" em "reclamante"**: Alternativa `r[e√©]` casava "re" no in√≠cio de "reclamante". Solu√ß√£o: reordenar alternativas (mais longas primeiro) + `\b` word boundary.

### Design Decisions
- **Strict**: sem trigger = sem link (exceto OAB‚ÜíProcesso, impl√≠cito)
- **Candidate layer**: todos os links usam `layer: "candidate"`, `verified: False`, `dimension: "fatica"`
- **Deduplica com LLM**: se REGRA 11 criar o mesmo link, o `MERGE` do Neo4j deduplica automaticamente
- **Case-sensitive por design**: regex sem IGNORECASE ‚Äî nomes pr√≥prios exigem capitaliza√ß√£o

### Testes
- 27 novos testes: todos passaram
- Suite KG completa (149 testes): 149 passed, 1 skipped, 0 failed

---

## 2026-02-08 ‚Äî Sess√£o 140: Factual Strict Parity + Decis√µes Arquiteturais (GLiNER/RAG)

### Objetivo
Alinhar extra√ß√£o f√°tica (REGRA 10-12) com a filosofia strict das rela√ß√µes jur√≠dicas, e validar decis√µes sobre breadth de entidades e REMETE_A sem√¢ntico.

### Altera√ß√µes
- **`legal_graphrag_prompt.py`** ‚Äî REGRA 0.1: adicionada dimens√£o "fatica" como 4¬™ dimens√£o + mapeamento (PARTICIPA_DE, REPRESENTA, OCORRE_EM, PARTE_DE, RELATED_TO). REGRA 11: adicionado requisito de evidence + dimension + trigger phrases para PARTICIPA_DE e REPRESENTA
- **`test_factual_extraction.py`** ‚Äî 4 novos testes: `test_regra_11_requires_evidence`, `test_regra_11_dimension_fatica`, `test_regra_11_has_triggers`, `test_dimension_fatica_in_base_prompt`

### Decis√µes Arquiteturais
1. **GLiNER para breadth, LLM para depth**: GLiNER j√° lida com 19 tipos de entidade (configur√°vel via `GLINER_LABELS`); o prompt LLM foca em 6 tipos f√°ticos de alto valor onde o LLM agrega com properties e rela√ß√µes
2. **REMETE_A textual-only**: Conex√µes sem√¢nticas s√£o redundantes com o RAG (Qdrant+OpenSearch+RRF) que j√° descobre rela√ß√µes sem√¢nticas no query time. O grafo armazena apenas rela√ß√µes estruturais expl√≠citas
3. **Valida√ß√£o com resultados reais**: ingest_v2.py produziu 246 REMETE_A, 62 cross-law, 30 cadeias 3-hops, 181 Art‚ÜêDecisao‚ÜíTese, 20 Sumula‚ÜíArt‚ÜíArt ‚Äî confirmando que extra√ß√£o strict gera grafos ricos

### Testes
- 65 testes passaram (todos os testes KG)

---

## 2026-02-08 ‚Äî Sess√£o 139: Prompt Strict + Verifica√ß√£o de 5 Mudan√ßas do Usu√°rio

### Objetivo
Decidir filosofia de extra√ß√£o (strict vs agressiva) e verificar 5 altera√ß√µes feitas pelo usu√°rio no frontend e backend.

### Decis√£o Arquitetural: Extra√ß√£o Strict com Evidence Obrigat√≥ria
- Testamos abordagem agressiva (v2 original: "Prefira EXTRAIR", evidence opcional) ‚Äî revertida pelo usu√°rio
- **Decis√£o final: strict** ‚Äî evidence obrigat√≥ria, "Na d√∫vida, OMITA" ‚Äî prioriza auditabilidade/transpar√™ncia
- Ambos os prompts (Iudex e ingest_v2.py) sincronizados com mesma filosofia strict
- Iudex √© superset do v2 (tem AFASTA, anti-hub REGRA 6, factual layer REGRA 10-12, 14 triggers REMETE_A)

### Altera√ß√µes Verificadas (feitas pelo usu√°rio)
1. **Prompt strict** em `legal_graphrag_prompt.py` ‚Äî REGRA 0 anti-contamina√ß√£o, evidence obrigat√≥ria
2. **UI hops limitado a 5** ‚Äî `clampGraphHops(Math.max(1, Math.min(5, ...)))` em 3 componentes:
   - `GraphAuraAgentChat.tsx:46`, `GraphPageClient.tsx:142`, `minuta-settings-drawer.tsx:128`
3. **`/diagnostics` command** em `GraphAuraAgentChat.tsx:61` ‚Äî parseia `diagnostics|diag|relatorio|report`
4. **`relation_details`** em `graph_ask_service.py:283-286,322-325` ‚Äî retorna `{type, dimension, evidence}` por rela√ß√£o
5. **Evidence nos samples** de `legal_diagnostics` ‚Äî `test_graph_ask_diagnostics.py` atualizado com assertions

### Testes
- 6 arquivos de teste executados: 227 passed, 6 skipped, 0 failed

### Li√ß√£o
- Para RAG jur√≠dico com foco em transpar√™ncia, extra√ß√£o agressiva (mais rela√ß√µes, menos evidence) √© contra-produtiva
- Compensa√ß√£o para grafo esparso: regex layer (REMETE_A, PERTENCE_A, APLICA_SUMULA) + chunk overlap

---

## 2026-02-08 ‚Äî Sess√£o 138: Paridade com ingest_v2.py ‚Äî Prompt, Schema, Post-processing, Chain Analysis

### Objetivo
Fechar os 4 gaps identificados entre o Iudex KG Builder e o standalone `ingest_v2.py`:
1. **APLICA_SUMULA**: tipo dedicado para Decisao‚ÜíSumula (v2 usa dedicado, Iudex usava gen√©rico APLICA)
2. **Prompt enriquecido**: arquitetura 3-camadas, tabela de dimens√µes, 11 triggers REMETE_A, REGRA 7 (Cita√ß√£o entre Decis√µes), REGRA 8 (Regulamenta e Especializa)
3. **Post-processing completo**: normaliza√ß√£o de nomes de Artigo (C√≥digo Civil‚ÜíCC), remo√ß√£o de Decis√£o composta, relabel expandido, migra√ß√£o APLICA‚ÜíAPLICA_SUMULA
4. **Chain Analysis**: 6 queries Cypher para cadeias 4-5 hops medindo qualidade do grafo

### Arquivos Criados
- `apps/api/app/services/rag/core/kg_builder/chain_analyzer.py` ‚Äî **Novo**: 6 chain queries (4h/5h), 17 component count queries, `ChainAnalysisResult` dataclass, `analyze_chains()` function
- `apps/api/tests/test_chain_analysis.py` ‚Äî **Novo**: 26 testes (schema, prompt parity, post-processor, chain analyzer)

### Arquivos Modificados
- `apps/api/app/services/rag/core/kg_builder/legal_schema.py` ‚Äî +3 relationship types (APLICA_SUMULA, AFASTA, ESTABELECE_TESE) + 6 patterns
- `apps/api/app/services/rag/core/kg_builder/legal_graphrag_prompt.py` ‚Äî Reescrita completa do STRICT_LEGAL_EXTRACTION_PROMPT com arquitetura 3-camadas, dimens√µes, APLICA_SUMULA nas cadeias-alvo, 11 triggers REMETE_A, REGRA 7 (Cita√ß√£o entre Decis√µes), REGRA 8 (Regulamenta e Especializa). FACTUAL_EXTRACTION_LAYER renumerado para REGRA 10/11/12
- `apps/api/app/services/rag/core/kg_builder/legal_postprocessor.py` ‚Äî +3 stats fields + step 0a (normaliza√ß√£o nomes artigo, 14 pares), relabel expandido com patterns v2, step 3b (compound Decisao removal), step 3c (migra√ß√£o APLICA‚ÜíAPLICA_SUMULA)
- `apps/api/app/services/rag/core/kg_builder/pipeline.py` ‚Äî APLICA_SUMULA no regex extraction + chain analysis integration (env-gated)
- `apps/api/tests/test_factual_extraction.py` ‚Äî Atualiza√ß√£o de 4 testes para refletir nova numera√ß√£o de regras (REGRA 7‚Üí10, 8‚Üí11, 9‚Üí12)

### Env Vars
- `KG_BUILDER_CHAIN_ANALYSIS=true` ‚Äî Roda an√°lise de cadeias 4-5 hops ap√≥s ingest√£o (default: `false`)

### Testes
- Novos: 26 passed (test_chain_analysis.py)
- Suite KG (152 testes): 152 passed, 1 skipped, 0 failed
- Regress√£o corrigida: 2 testes em test_factual_extraction.py atualizados (renumera√ß√£o REGRA 7‚Üí10)

### Decis√µes
- APLICA_SUMULA coexiste com APLICA gen√©rico (backward compat) ‚Äî prompt prioriza APLICA_SUMULA
- Prompt completamente reescrito com 9+3 regras (legal + factual layer) ‚Äî id√™ntico ao v2 mas com adi√ß√µes Iudex
- Post-processing: normaliza√ß√£o aplica a Artigo E Sumula (v2 s√≥ Artigo)
- Chain analysis √© opt-in (KG_BUILDER_CHAIN_ANALYSIS=false) ‚Äî roda via asyncio.to_thread para n√£o bloquear
- Relabel expandido: 8 regex patterns v2 para Decisao‚ÜíTribunal (Jurisprud√™ncia, Informativo, Caso, etc.)

---

## 2026-02-08 ‚Äî Sess√£o 137: Expans√£o de Entidades F√°ticas no KG Builder

### Objetivo
Expandir o KG Builder para extrair entidades f√°ticas (Pessoa, Empresa, Evento, CPF, CNPJ, datas, valores monet√°rios) al√©m das entidades doutrin√°rio-legais existentes. Reconciliar com o LLM Knowledge Graph Builder usando ontologia predefinida como seed + descoberta autom√°tica.

### Arquivos Criados
- `apps/api/tests/test_factual_extraction.py` ‚Äî **Novo**: 35 testes (CPF/CNPJ validation, regex extraction, schema patterns, whitelist, cross-merger equivalences, prompt layer)

### Arquivos Modificados
- `apps/api/app/services/rag/core/kg_builder/legal_schema.py` ‚Äî +3 node types (Pessoa, Empresa, Evento) + 5 rel types (PARTICIPA_DE, IDENTIFICADO_POR, OCORRE_EM, REPRESENTA, PARTE_DE) + 18 patterns
- `apps/api/app/services/rag/core/kg_builder/legal_graphrag_prompt.py` ‚Äî +`FACTUAL_EXTRACTION_LAYER` (REGRA 7-9) + `include_factual` param em `StrictLegalExtractionTemplate`
- `apps/api/app/services/rag/core/neo4j_mvp.py` ‚Äî +4 EntityTypes (CPF, CNPJ, DATA_JURIDICA, VALOR_MONETARIO) + regex patterns + `_validate_cpf()` + `_validate_cnpj()` + `_extract_factual()` + `include_factual` param em `extract()`/`extract_all()`
- `apps/api/app/services/rag/core/kg_builder/gliner_extractor.py` ‚Äî +5 labels (pessoa, empresa, evento, cpf, cnpj) + 5 entries no `_LABEL_MAP`
- `apps/api/app/services/rag/core/graph_hybrid.py` ‚Äî +10 entries no whitelist (5 f√°ticas + 5 gap fix: orgao_publico, prazo, valor_monetario, data_juridica, local)
- `apps/api/app/services/rag/core/kg_builder/cross_merger.py` ‚Äî +15 equival√™ncias f√°ticas (reclamante‚Üípessoa, empregador‚Üíempresa, audiencia‚Üíevento, etc.)
- `apps/api/app/services/rag/core/kg_builder/pipeline.py` ‚Äî Integra√ß√£o do flag `KG_BUILDER_FACTUAL_EXTRACTION` em regex e GraphRAG pipelines + stats f√°ticos

### Env Vars
- `KG_BUILDER_FACTUAL_EXTRACTION=true` ‚Äî Ativa extra√ß√£o de entidades f√°ticas (regex + prompt LLM). Default: `false`

### Testes
- Novos: 35 passed (test_factual_extraction.py)
- Suite KG (181 testes): 181 passed, 1 skipped, 0 failed
- Suite completa: 1446 passed, 74 skipped, 17 failed (pr√©-existentes: qdrant/skills/hearing/gemini)

### Decis√µes
- Abordagem 4 camadas: Ontologia seed ‚Üí LLM auto-discovery ‚Üí GLiNER zero-shot ‚Üí Regex determin√≠stico
- CPF/CNPJ com valida√ß√£o algor√≠tmica de d√≠gitos verificadores (Receita Federal)
- Datas validadas: range DD(1-31)/MM(1-12)/YYYY(1900-2100)
- Extra√ß√£o f√°tica √© opt-in (`KG_BUILDER_FACTUAL_EXTRACTION=false` por default) para seguran√ßa em produ√ß√£o
- Prompt f√°tico √© camada aditiva (REGRA 7-9) inserida no STRICT_LEGAL_EXTRACTION_PROMPT, n√£o substitutiva
- Whitelist gap fix: 5 tipos (orgao_publico, prazo, valor_monetario, data_juridica, local) estavam no schema mas faltavam no whitelist

---

## 2026-02-08 ‚Äî Sess√£o 136: Schema Discovery + Cross-Extractor Entity Merger

### Objetivo
Implementar as duas lacunas identificadas na an√°lise do hybrid ontology approach:
1. **Schema Discovery** ‚Äî Tipos descobertos pelo LLM ficavam como `:Entity` gen√©rico sem valida√ß√£o/persist√™ncia
2. **Cross-Extractor Entity Merger** ‚Äî Regex/GLiNER/LLM produziam entity_ids diferentes para a mesma entidade real

### Arquivos Criados
- `apps/api/app/services/rag/core/kg_builder/schema_discovery.py` ‚Äî **Novo**: SchemaDiscoveryProcessor (query unknown types ‚Üí validate via heuristics ‚Üí register dynamically ‚Üí persist as `:DiscoveredSchema`)
- `apps/api/app/services/rag/core/kg_builder/cross_merger.py` ‚Äî **Novo**: CrossExtractorMerger (TYPE_EQUIVALENCE_MAP, rapidfuzz matching, APOC-based merge)
- `apps/api/tests/test_schema_discovery.py` ‚Äî **Novo**: 20 testes (PascalCase, validation heuristics, dynamic registration, get_all_node_types)
- `apps/api/tests/test_cross_merger.py` ‚Äî **Novo**: 11 testes (pick_keeper, types_are_mergeable, canonical_type, equivalence consistency)

### Arquivos Modificados
- `apps/api/app/services/rag/core/graph_hybrid.py` ‚Äî `register_dynamic_label()` helper + adicionado "decisao" ao whitelist
- `apps/api/app/services/rag/core/kg_builder/legal_schema.py` ‚Äî `get_all_node_types()` retorna tipos base + descobertos
- `apps/api/app/services/rag/core/kg_builder/pipeline.py` ‚Äî Integra√ß√£o em `run_kg_builder()` e `_run_graphrag_pipeline()` com novos stats keys

### Env Vars (todas default off)
- `KG_BUILDER_SCHEMA_DISCOVERY=true` ‚Äî Ativa discovery p√≥s-GraphRAG
- `KG_BUILDER_SCHEMA_DISCOVERY_AUTO_REGISTER=true` ‚Äî Auto-promove tipos ao whitelist
- `KG_BUILDER_SCHEMA_DISCOVERY_MIN_INSTANCES=2` ‚Äî M√≠nimo de entidades para validar tipo
- `KG_BUILDER_CROSS_MERGER=true` ‚Äî Ativa merge cross-extractor
- `KG_BUILDER_CROSS_MERGER_THRESHOLD=88.0` ‚Äî Threshold fuzzy (> 85 do resolver normal)

### Testes
- Novos: 31 passed (20 schema_discovery + 11 cross_merger)
- Suite relacionada: 157 passed, 1 skipped, 0 failed
- Bug encontrado: "decisao" faltava no `HYBRID_LABELS_BY_ENTITY_TYPE` apesar de ser node type definido ‚Üí corrigido

### Decis√µes
- Schema discovery valida com 6 heur√≠sticas: stopwords, comprimento, forbidden labels, regex safety, min instances, sample quality
- Cross-merger usa `TYPE_EQUIVALENCE_MAP` conservador (ex: "norma"‚Üí"lei", "acordao"‚Üí"decisao") para evitar merges incorretos
- Keeper selection prioriza tipo predefinido > entity_id mais curto (regex-generated = mais can√¥nico)
- Ambos features s√£o opt-in via env vars (default off) para seguran√ßa em produ√ß√£o

---

## 2026-02-08 ‚Äî Sess√£o 135: Ecossistema Neo4j (GDS + Communities + MCP + Neo4jSaver)

### Objetivo
Implementar 4 fases do plano de ecossistema Neo4j para maximizar valor do grafo jur√≠dico: (1) graphdatascience para PageRank/Leiden/Similarity, (2) Community Summaries via Leiden + LLM, (3) Neo4jSaver para LangGraph checkpoints, (4) Neo4j MCP Server para agentes AI.

### Arquivos Criados
- `apps/api/app/services/rag/core/gds_analytics.py` ‚Äî **Novo**: Neo4jGDSClient wrapper (PageRank, Leiden, Node Similarity) com proje√ß√£o de subgrafo tenant-scoped
- `apps/api/app/services/rag/core/community_summary.py` ‚Äî **Novo**: Pipeline Leiden‚ÜíLLM summarization‚ÜíNeo4j write + retrieval para Stage 9
- `apps/api/app/services/mcp_servers/neo4j_server.py` ‚Äî **Novo**: Neo4j MCP Server (5 tools: search, neighbors, path, stats, ranking)
- `apps/api/tests/test_gds_analytics.py` ‚Äî **Novo**: 14 testes (PageRank, Leiden, Similarity, singleton)
- `apps/api/tests/test_community_summary.py` ‚Äî **Novo**: 8 testes (pipeline, heuristic fallback, retrieval, graceful degradation)
- `apps/api/tests/test_neo4j_mcp_server.py` ‚Äî **Novo**: 14 testes (tools, routing, formatting, config registration)

### Arquivos Modificados
- `apps/api/requirements.txt` ‚Äî Adicionado `graphdatascience>=1.6.0`, `langchain-neo4j>=0.8.0`
- `apps/api/app/services/graph_ask_service.py` ‚Äî Novo RANKING operation + pagerank_score em NEIGHBORS
- `apps/api/app/services/rag/core/kg_builder/legal_schema.py` ‚Äî Community node type + BELONGS_TO relationship
- `apps/api/app/services/rag/pipeline/rag_pipeline.py` ‚Äî Stage 9: injection de community summaries (env: `RAG_USE_COMMUNITY_SUMMARIES`)
- `apps/api/app/api/endpoints/advanced.py` ‚Äî Endpoint POST `/api/advanced/communities/recompute`
- `apps/api/app/services/ai/langgraph_legal_workflow.py` ‚Äî Neo4jSaver como op√ß√£o de checkpointer (env: `LANGGRAPH_CHECKPOINTER=neo4j`)
- `apps/api/app/services/mcp_config.py` ‚Äî Registrado neo4j-graph em BUILTIN_MCP_SERVERS

### Env Vars
- `LANGGRAPH_CHECKPOINTER=neo4j` ‚Äî Ativa Neo4jSaver (default: SQLite)
- `RAG_USE_COMMUNITY_SUMMARIES=true` ‚Äî Ativa community summaries no Stage 9
- `COMMUNITY_SUMMARY_LLM_PROVIDER=gemini|openai|fallback` ‚Äî Provider para sumariza√ß√£o

### Testes
- 38 testes (36 originais + 2 async wrappers): 38 passed, 0 failed
- Suite Neo4j completa: 118 passed, 0 failed
- Suite geral: 1348 passed, 17 failed (pr√©-existentes), 0 regress√µes

### Fixes p√≥s-review (3 Alta + 2 M√©dia)
- **[Alta] Import order**: `import os` movido para linha 22, antes de `os.environ.get` (linha 35)
- **[Alta] Async blocking**: `community_summary.py` agora usa `asyncio.to_thread()` para GDS/LLM e `_neo4j_execute_write/read` com async API preferencial
- **[Alta] PageRank multi-tenant**: Scores em `(:TenantEntityMetric {tenant_id})` via `[:HAS_TENANT_METRIC]` (n√£o mais global em Entity)
- **[M√©dia] KG Builder**: `KG_BUILDER_COMPUTE_PAGERANK=true` aciona PageRank p√≥s-ingest via `asyncio.to_thread`
- **[M√©dia] NEIGHBORS template**: `OPTIONAL MATCH` em `TenantEntityMetric` com `tenant_id` expl√≠cito

### Decis√µes
- ToolsRetriever/HybridCypherRetriever descartados (incompat√≠veis com arquitetura tri-database Qdrant+OpenSearch+Neo4j)
- Neo4jSaver opcional via env var (default mant√©m SQLite para n√£o exigir Neo4j em dev)
- Community summaries off por default (requer GDS plugin + custo de LLM)
- PageRank isolado por tenant via n√≥s dedicados `TenantEntityMetric` (evita sobrescrita cross-tenant)

---

## 2026-02-08 ‚Äî Sess√£o 134: Integra√ß√£o GLiNER ao KG Builder

### Objetivo
Adicionar GLiNER (zero-shot NER) como terceiro extractor no KG Builder pipeline, complementando Regex (padr√µes fixos) e LLM (sem√¢ntico/caro).

### Arquivos Alterados
- `apps/api/requirements.txt` ‚Äî Adicionado `gliner>=0.2.0`
- `apps/api/app/services/rag/core/kg_builder/gliner_extractor.py` ‚Äî **Novo**: GLiNERExtractor component (lazy-load singleton, asyncio.to_thread, dedup via MD5)
- `apps/api/app/services/rag/core/kg_builder/pipeline.py` ‚Äî Adicionado `_run_gliner_extraction()` + integra√ß√£o em `run_kg_builder()` via `KG_BUILDER_USE_GLINER=true`
- `apps/api/app/services/rag/core/kg_builder/__init__.py` ‚Äî Export de GLiNERExtractor
- `apps/api/app/services/rag/core/kg_builder/legal_schema.py` ‚Äî 5 novos node types (OrgaoPublico, Prazo, ValorMonetario, DataJuridica, Local) + 4 patterns
- `apps/api/tests/test_gliner_extractor.py` ‚Äî **Novo**: 24 testes (import, entity ID, label mapping, extraction mock, dedup, empty input, pipeline integration)

### Comandos Executados
- `pip install gliner` ‚Äî OK (v0.2.24)
- `pytest tests/test_gliner_extractor.py -v` ‚Äî 24 passed
- `pytest tests/test_kg_pipeline_graphrag.py tests/test_text2cypher.py tests/test_ragas_integration.py -v` ‚Äî 50 passed, 5 skipped (zero regress√µes)

### Decis√µes Tomadas
- Relik N√ÉO integrado ‚Äî LLM j√° faz extra√ß√£o de rela√ß√µes melhor
- GLiNER desabilitado por padr√£o (`KG_BUILDER_USE_GLINER=false`) para n√£o impactar performance sem opt-in
- Modelo default: `urchade/gliner_medium-v2.1` (~209M params, CPU-friendly)
- Entity IDs com prefixo `gliner_` + MD5 truncado para distinguir de regex entities

---

## 2026-02-08 ‚Äî Sess√£o 133: neo4j-graphrag SimpleKGPipeline + Text2Cypher + RAGAs

### Objetivo
Ativar 3 features Neo4j que estavam incompletas no app:
1. **SimpleKGPipeline** ‚Äî corrigir bug de LLM provider e formato de schema
2. **Text2Cypher** ‚Äî implementar NL‚ÜíCypher com 3 camadas de seguran√ßa multi-tenant
3. **RAGAs** ‚Äî integrar framework de avalia√ß√£o com m√©tricas legais existentes

### Arquivos Alterados
- `apps/api/requirements.txt` ‚Äî adicionado `ragas>=0.2.0`, `datasets>=2.14.0`
- `apps/api/app/services/rag/core/kg_builder/legal_schema.py` ‚Äî adicionado `build_graphrag_schema()` com tipos nativos neo4j-graphrag (GraphSchema, NodeType, RelationshipType, Pattern, PropertyType); adicionado `get_schema_description()` para Text2Cypher
- `apps/api/app/services/rag/core/kg_builder/pipeline.py` ‚Äî corrigido `_run_graphrag_pipeline()` (bug: usava OpenAILLM com modelo Gemini); adicionado multi-provider via `_build_graphrag_llm()` (openai/gemini/anthropic/ollama); reuso de driver singleton
- `apps/api/app/services/graph_ask_service.py` ‚Äî adicionado Text2Cypher engine com 3 camadas de seguran√ßa (keyword blocklist, tenant filter injection, structural validation); `Text2CypherEngine` class com suporte multi-provider LLM; `CypherSecurityError`; m√©todo `text2cypher()` no `GraphAskService`
- `apps/api/app/api/endpoints/graph_ask.py` ‚Äî adicionado `Text2CypherRequest` schema e endpoint `POST /graph-ask/ask/text2cypher`
- `apps/api/app/services/ai/rag_evaluator.py` ‚Äî adicionado `evaluate_with_ragas()` que combina RAGAs (faithfulness, answer_relevancy, context_precision, context_recall) com m√©tricas legais (citation_coverage, temporal_validity, etc.) em score combinado ponderado
- `apps/api/tests/test_text2cypher.py` ‚Äî 25 testes de seguran√ßa Text2Cypher
- `apps/api/tests/test_kg_pipeline_graphrag.py` ‚Äî 14 testes de schema e pipeline
- `apps/api/tests/test_ragas_integration.py` ‚Äî 11 testes de m√©tricas RAGAs + legais

### Comandos Executados
- `pip install neo4j-graphrag ragas datasets` ‚Äî OK (neo4j-graphrag 1.13.0, ragas 0.4.3)
- `pytest tests/test_text2cypher.py tests/test_kg_pipeline_graphrag.py tests/test_ragas_integration.py` ‚Äî 50 passed, 5 skipped, 0 failed

### Decis√µes Tomadas
- Text2Cypher desabilitado por padr√£o (`TEXT2CYPHER_ENABLED=false`) ‚Äî opt-in expl√≠cito
- 3 camadas de seguran√ßa: (1) blocklist tokenizada (evita falsos positivos como CREATED_AT), (2) inje√ß√£o autom√°tica de tenant_id em n√≥s Document, (3) valida√ß√£o estrutural (MATCH/RETURN obrigat√≥rio)
- LLM provider para Text2Cypher via env `TEXT2CYPHER_LLM_PROVIDER` (openai/gemini/anthropic)
- Score RAGAs+Legal combinado com pesos: 50% RAGAs (faithfulness 15%, relevancy 15%, precision 10%, recall 10%) + 50% Legal (citation 15%, temporal 10%, jurisdiction 10%, entity_precision 7.5%, entity_recall 7.5%)
- GraphSchema usa Pattern(source, relationship, target) ‚Äî verificado via introspection

### Env vars novas
```
KG_BUILDER_USE_GRAPHRAG=true          # Ativa SimpleKGPipeline
KG_BUILDER_LLM_PROVIDER=openai        # ou gemini/anthropic/ollama
TEXT2CYPHER_ENABLED=true               # Ativa Text2Cypher
TEXT2CYPHER_LLM_PROVIDER=openai        # ou gemini/anthropic
TEXT2CYPHER_MODEL=gpt-4o-mini
```

---

## 2026-02-05 ‚Äî Sess√£o 132: Plano Agent SDK Integration + ChatInput Layout + UI Audit

### Objetivo
1. Otimizar layout do ChatInput na Ask page (compactar, alinhar √≠cones, textarea expans√≠vel)
2. An√°lise profunda do documento Claude Agent SDK vs implementa√ß√£o Iudex
3. Criar plano de integra√ß√£o faseado com mapeamento dual-mode
4. Code review cruzado Claude√óGPT ‚Äî incorporar bugfixes e Fase 4 operacional
5. Auditoria completa de √≠cones da Ask page ‚Äî plano UI layout-safe + checklist de preserva√ß√£o

### Arquivos Alterados
- `apps/web/src/app/(dashboard)/ask/page.tsx` ‚Äî padding wrapper (`p-4 pb-5` ‚Üí `px-4 py-2`), largura (`max-w-3xl` ‚Üí `max-w-5xl`)
- `apps/web/src/components/chat/chat-input.tsx` ‚Äî container compacto (`rounded-2xl p-2`), textarea expans√≠vel com `resize-y min-h-[96px]`, ContextUsageBar inline, √≠cones `h-7 w-7`, bot√£o Minimize2 para reset
- `docs/PLANO_AGENT_SDK_INTEGRATION.md` ‚Äî documento completo: gap analysis, plano 5 fases (0-4), mapeamento dual-mode, plano UI (Se√ß√£o 10), checklist preserva√ß√£o (Se√ß√£o 11)

### Decis√µes Tomadas
- Textarea 96px min (4 linhas) com resize-y manual + bot√£o discreto de reset
- ContextUsageBar movida para inline ao lado do Send (elimina linha extra)
- Plano SDK cobre 3 modos de execu√ß√£o: Solo, LangGraph, Parallel ‚Äî cada item mapeado nos 3 contextos
- Docs >500pg for√ßam LANGGRAPH (solo n√£o suporta multi-pass)
- Skills t√™m `prefer_workflow` / `prefer_agent` flags para routing
- **Fase 0 bloqueante** adicionada: 4 bugs de runtime (MCP naming, initialize(), RISK_TO_PERMISSION, delegate_research)
- **Plano UI**: 15 features de frontend, TODAS encaixam em componentes existentes ‚Äî zero bot√µes novos
- Tool approval "lembrar" j√° existe (session/always) ‚Äî removido do plano como gap
- ContextSelector/ContextDashboard s√£o da generator page, n√£o da Ask ‚Äî removidos da an√°lise

### 2¬™ Revis√£o T√©cnica (GPT ‚Üí Claude verifica√ß√£o)
Verificados 8 findings por leitura direta do c√≥digo-fonte:

| Finding | Veredicto | Corre√ß√£o |
|---------|:---------:|----------|
| Raw API n√£o usa PermissionManager (usa dict local) | CORRETO | Item 1.6 reescrito: ambos caminhos ignoram PM |
| `async with ClaudeAgentExecutor` inv√°lido | CORRETO | Exemplo delegate_subtask reescrito com instancia√ß√£o direta |
| Prompt caching system em messages[] | CORRETO | Exemplo reescrito: `kwargs["system"]` como content blocks |
| Routing `len(selected_models)>1 ‚Üí PARALLEL` diverge | CORRETO | Se√ß√£o reescrita: estado atual vs proposta separados |
| DataJud "n√£o exposto como tool" | PARCIAL | Existe no Tool Gateway, gap √© s√≥ no SDK path |
| Skills "criar do zero" | CORRETO | Evoluir LibraryItem + template_loader.py existente |
| Test files n√£o existem | CORRETO | Adicionado [criar] em cada refer√™ncia |
| Path parallel_research.py | CORRETO | Corrigido para subgraphs/ |

### 3¬™ Revis√£o T√©cnica (GPT ‚Üí Claude verifica√ß√£o)
Verificados 5 findings (2 HIGH, 2 MEDIUM, 1 LOW OK):

| Finding | Veredicto | Corre√ß√£o |
|---------|:---------:|----------|
| `SSEEventType.CONTENT` inexistente + `resolve_tools()` inexistente | CORRETO | Exemplo reescrito: `SSEEventType.TOKEN` + `load_unified_tools()` |
| Skills sem identidade distinta de agent_template | CORRETO | Nova tag `"skill"`, schema frontmatter, tabela de distin√ß√£o |
| Prompt caching n√£o alinhado com `_call_claude()` real | CORRETO | Exemplo reescrito com 2 system blocks, nota sobre `_build_system_prompt()` |
| Default routing CLAUDE_AGENT = breaking change | CORRETO | Feature flag `IUDEX_DEFAULT_EXECUTOR` + rollout gradual |
| UI layout-safe s√≥lido | OK | Sem altera√ß√£o necess√°ria |

### 4¬™ Revis√£o ‚Äî Corre√ß√£o Estrutural (Arquitetura de Modos)
Descoberta fundamental: plano mapeava 3 modos de execu√ß√£o mas Iudex tem **4 caminhos**:

| Modo UI | Backend | Usa Router? |
|---------|---------|:-----------:|
| ‚ö° R√°pido | `dispatch_turn()` ‚Üí chamada direta ao modelo | N√ÉO |
| ‚öñÔ∏è Comparar | N modelos em paralelo (direto) | N√ÉO |
| üë• Comit√™ | `OrchestrationRouter` ‚Üí LANGGRAPH/AGENT/PARALLEL | SIM |
| üìÑ Canvas | Legacy generateDocument | N√ÉO |

**Corre√ß√µes**: Se√ß√£o 5 reescrita com 4 caminhos, tabelas de fase com coluna R√°pido, regras de routing restritas ao escopo do Comit√™.

### Comandos Executados
- `npx tsc --noEmit` ‚Äî OK (apenas erro pr√©-existente em transcription/page.tsx)

---

## 2026-02-05 ‚Äî Sess√£o 131: Reparo Manual de Job e Rein√≠cio do Worker

### Objetivo
Verificar e reparar persist√™ncia de dados de √°udio e qualidade no job `7531a45f-d56a-45ee-a662-ac6a602fbbe6`.

### A√ß√µes Realizadas
1. Verifica√ß√£o completa dos dados do job
2. Execu√ß√£o manual do quality_service para gerar validation_report e analysis_result
3. Atualiza√ß√£o do result.json com campos faltantes
4. Rein√≠cio do Celery worker para usar c√≥digo atualizado

### Status Final do Job
- ‚úÖ 4 arquivos MP3 em `input/` (29-48 MB cada)
- ‚úÖ `content.md` (147 KB) - conte√∫do formatado
- ‚úÖ `raw.txt` (136 KB) - transcri√ß√£o bruta
- ‚úÖ `audit_issues.json` - 2 issues (tema 1734, ADI 38)
- ‚úÖ `reports.json` - paths dos relat√≥rios
- ‚úÖ `result.json` com quality.validation_report (score 9.9/10)

### Comandos Executados
```bash
# Parar e reiniciar Celery worker
kill -9 25306
nohup .venv/bin/celery -A app.workers.celery_app worker --loglevel=info -Q transcription > /tmp/celery_worker.log 2>&1 &
```

### Resultado
- Worker Celery reiniciado (PID 58349)
- Novos jobs usar√£o c√≥digo atualizado que salva todos os campos
- Job legacy reparado manualmente e agora exibe dados corretamente

---

## 2026-02-05 ‚Äî Sess√£o 130: Fix Celery Worker Dados Incompletos (Auditoria/Reports)

### Objetivo
Corrigir o problema onde o Celery worker salvava dados incompletos no result.json, causando a aus√™ncia de dados de auditoria e relat√≥rios na UI.

### Problema
O `save_data` no Celery worker estava salvando apenas campos b√°sicos:
```python
save_data = {
    "mode": mode,
    "file_names": file_names,
    "content": result.get("content", ""),
    "raw_content": result.get("raw_content"),
    "validation_report": result.get("validation_report"),
    "analysis_result": result.get("analysis_result"),
}
```

Mas o `TranscriptionService.process_batch_with_progress` retorna campos adicionais:
- `reports` (paths dos arquivos gerados)
- `audit_issues` (lista de problemas detectados)
- `audit_summary` (resumo da auditoria consolidada)
- `quality` (payload completo de qualidade)
- `words` (timestamps word-level para player)

### Arquivos Modificados
- `apps/api/app/workers/tasks/document_tasks.py:506-532` ‚Äî Expandido save_data para incluir todos os campos
- `apps/api/app/api/endpoints/transcription.py:725-735` ‚Äî Adicionado carregamento de `reports` e `audit_summary` diretamente do JSON

### Corre√ß√£o Aplicada

**document_tasks.py:**
```python
if isinstance(result, str):
    save_data = {"mode": mode, "file_names": file_names, "content": result, "raw_content": result}
else:
    quality_data = result.get("quality") or {}
    save_data = {
        "mode": mode,
        "file_names": file_names,
        "content": result.get("content", ""),
        "raw_content": result.get("raw_content"),
        "words": result.get("words"),
        "reports": result.get("reports", {}),
        "audit_issues": result.get("audit_issues", []),
        "audit_summary": result.get("audit_summary"),
        "quality": quality_data,
        "validation_report": quality_data.get("validation_report"),
        "analysis_result": quality_data.get("analysis_result"),
    }
```

**transcription.py:**
```python
elif result_data.get("reports"):
    reports = result_data.get("reports")

if not audit_summary and result_data.get("audit_summary"):
    audit_summary = result_data.get("audit_summary")
```

### Resultado
- ‚úÖ Aba de auditoria agora aparece corretamente na UI
- ‚úÖ Dados de qualidade preservados
- ‚úÖ Reports e paths de arquivos dispon√≠veis
- ‚úÖ Compatibilidade mantida com formato legacy

---

## 2026-02-05 ‚Äî Sess√£o 129: Code Artifacts com Streaming e Integra√ß√£o Completa

### Objetivo
Implementar sistema completo de Code Artifacts com streaming, incluindo Shiki (syntax highlighting), Sandpack (React preview), Diff View, Export ZIP, e Pyodide (Python execution).

### Arquivos Criados
- `src/components/dashboard/artifact-code-highlighter.tsx` ‚Äî Syntax highlighting com Shiki + streaming debounce
- `src/components/dashboard/artifact-sandpack-preview.tsx` ‚Äî Preview React/Vue/Svelte com Sandpack
- `src/components/dashboard/artifact-diff-view.tsx` ‚Äî Compara√ß√£o de c√≥digo com 3 modos (linhas, palavras, split)
- `src/components/dashboard/artifact-exporter.tsx` ‚Äî Export ZIP com JSZip
- `src/components/dashboard/artifact-python-runner.tsx` ‚Äî Execu√ß√£o Python no browser com Pyodide

### Arquivos Modificados
- `src/components/dashboard/code-artifact-viewer.tsx` ‚Äî Integra√ß√£o de todos os componentes:
  - CodeHighlighter em vez de CodeBlock simples
  - SandpackPreview para React/JSX/Vue
  - PythonRunner para Python
  - ArtifactExporter no header
  - DiffView como modo alternativo (toggle)
  - Lazy loading para componentes pesados

### Funcionalidades de Streaming
- Debounce de 150ms durante streaming para evitar re-renderiza√ß√µes
- Auto-scroll para o final do c√≥digo durante streaming
- Cursor animado ‚ñå com indicador "Gerando c√≥digo..."
- Borda verde animada indicando streaming ativo
- Bot√£o de copiar oculto durante streaming

### Corre√ß√µes
- `artifact-python-runner.tsx`: Movido `addOutput` antes do `useEffect` que o usa
- `artifact-code-highlighter.tsx`: Corrigido tipo 'text' ‚Üí 'javascript' como fallback

### Verifica√ß√µes
- ‚úÖ Lint passou
- ‚úÖ Type-check passou

### Suporte Multi-Provider para Code Artifacts
Adicionados eventos SSE para artifacts no backend, funcionando com:
- **Claude Agent SDK** (Anthropic)
- **OpenAI Agents SDK** (GPT-5.x, GPT-4o)
- **Google ADK** (Gemini)

Novos eventos no `sse_protocol.py`:
- `ARTIFACT_START` ‚Üí In√≠cio do artifact (id, type, language, title)
- `ARTIFACT_TOKEN` ‚Üí Streaming de c√≥digo
- `ARTIFACT_DONE` ‚Üí Conclus√£o (dependencies, executable)

Imports adicionados aos executors:
- `apps/api/app/services/ai/claude_agent/executor.py`
- `apps/api/app/services/ai/executors/openai_agent.py`
- `apps/api/app/services/ai/executors/google_agent.py`

### Revis√£o GPT-5.2 e Corre√ß√µes Aplicadas
Solicitada segunda opini√£o via MCP codex-bridge. O GPT-5.2 identificou:

1. **Race Condition** (CORRIGIDO)
   - Problema: `codeToHtml` async podia terminar fora de ordem
   - Solu√ß√£o: Adicionado `requestIdRef` para ignorar resultados obsoletos

2. **Auto-scroll agressivo** (CORRIGIDO)
   - Problema: For√ßava scroll mesmo quando usu√°rio rolou para cima
   - Solu√ß√£o: `shouldAutoScrollRef` + threshold de 40px do fundo

3. **Debounce insuficiente** (CORRIGIDO)
   - Problema: 150ms podia ser muito frequente
   - Solu√ß√£o: Aumentado para 250ms durante streaming

4. **Lazy loading Next.js** (CORRIGIDO)
   - Problema: `React.lazy` n√£o ideal para componentes browser-only
   - Solu√ß√£o: Trocado para `next/dynamic` com `ssr: false`

---

## 2026-02-05 ‚Äî Sess√£o 128: Streaming Nativo no Chat (Remo√ß√£o de Overlay)

### Objetivo
Remover o `AskStreamingOverlay` redundante e usar efeitos de streaming nativos do chat (como ChatGPT/Perplexity).

### Problema Identificado
O usu√°rio solicitou que os efeitos de streaming fossem "dentro do pr√≥prio chat", como ChatGPT e Perplexity fazem, n√£o como um overlay separado.

### Solu√ß√£o Implementada
O componente `ChatMessage` j√° possui efeitos de streaming nativos:
- **ActivityPanel**: Mostra etapas de processamento (pesquisando, analisando, etc.)
- **LoadingDots**: Anima√ß√£o de pontos durante escrita
- **Timers**: "Pensando h√° Xs" e "Escrevendo (Xs)"

O `AskStreamingOverlay` era redundante e foi removido.

### Arquivos Modificados
- `apps/web/src/app/(dashboard)/ask/page.tsx` ‚Äî Removido import e uso de AskStreamingOverlay
- `apps/web/src/app/(dashboard)/minuta/page.tsx` ‚Äî Removido import e uso de AskStreamingOverlay

### Verifica√ß√µes
- Lint passou
- TypeScript check passou
- Frontend e backend rodando corretamente

---

## 2026-02-05 ‚Äî Sess√£o 127: Integra√ß√£o Completa SSE, Cita√ß√µes e Follow-ups

### Objetivo
Integrar streaming real via SSE, cita√ß√µes do backend e sugest√µes de follow-up na p√°gina `/ask`.

### Arquivos Modificados
- `apps/web/src/app/(dashboard)/ask/page.tsx` ‚Äî Reescrita completa com integra√ß√£o real

### Funcionalidades Integradas

#### 1. **Streaming Status Real**
- Extrai `activity.steps` do metadata da √∫ltima mensagem do assistente
- Detecta step com `status: 'running'` para mostrar status atual
- Conta steps completados para mensagem final
- Integrado com `AskStreamingStatus` component

#### 2. **Cita√ß√µes Reais**
- Extrai `citations` do metadata da √∫ltima mensagem do assistente
- Converte formato do backend para formato do `AskSourcesPanel`
- Extrai hostname da URL para mostrar fonte
- Mapeia `quote` para `snippet` e mant√©m `signal` (Shepard's)

#### 3. **Sugest√µes de Follow-up**
- **Empty state**: Grid de 4 sugest√µes iniciais (an√°lise, pesquisa, peti√ß√£o, explica√ß√£o)
- **Contextual**: Sugest√µes baseadas em fontes selecionadas
- **Follow-up input**: Input r√°pido ap√≥s resposta do assistente (estilo Perplexity)

### C√≥digo Principal
```typescript
// Extra√ß√£o de dados da √∫ltima mensagem
const { lastAssistantMessage, activitySteps, citations, streamingStatus, stepsCount } = useMemo(() => {
  const msgs = currentChat?.messages || [];
  // Find last assistant message
  // Extract activity steps
  // Extract and format citations
  // Determine streaming status from running steps
}, [currentChat?.messages, isSending]);
```

### Verifica√ß√µes
- ‚úÖ Lint passou
- ‚úÖ Type-check passou
- ‚úÖ Cita√ß√µes formatadas corretamente
- ‚úÖ Status de streaming integrado com activity steps

---

## 2026-02-05 ‚Äî Sess√£o 126: Coordena√ß√£o Multi-Agente e Integra√ß√£o Final

### Objetivo
Coordenar m√∫ltiplos subagentes Sonnet para criar componentes da p√°gina `/ask` em paralelo e integrar tudo na p√°gina principal.

### Estrat√©gia
- Lan√ßamento de 4 subagentes Sonnet em paralelo
- Cada agente respons√°vel por um componente espec√≠fico
- Coordena√ß√£o central para integra√ß√£o e corre√ß√£o de erros de tipo

### Componentes Criados (via subagentes)
1. **AskSourcesPanel** ‚Äî Painel lateral com cita√ß√µes e fontes
2. **AskStreamingStatus** ‚Äî Indicador de status de streaming animado
3. **AskModeToggle** ‚Äî Toggle entre modos Auto/Edit/Answer
4. **index.ts** ‚Äî Barrel exports para todos os componentes

### Arquivos Modificados
- `apps/web/src/app/(dashboard)/ask/page.tsx` ‚Äî Corre√ß√µes de tipo:
  - `canvasState.visible` ‚Üí `canvasState !== 'hidden'` (CanvasState √© string union)
  - Adicionado `chatId` prop obrigat√≥ria ao ChatInterface
  - Adicionado wrapper com largura fixa para AskSourcesPanel

### Verifica√ß√µes
- ‚úÖ Lint passou sem erros
- ‚úÖ Type-check passou para ask/page.tsx
- ‚úÖ Todos os componentes exportados corretamente
- ‚úÖ Integra√ß√£o com stores existentes (useChatStore, useCanvasStore, useContextStore)

### Aprendizados
- `useCanvasStore` retorna `state` como string ('hidden'|'normal'|'expanded'), n√£o objeto
- `ChatInterface` requer `chatId` como prop obrigat√≥ria
- Subagentes Sonnet trabalham eficientemente em paralelo para criar componentes independentes

---

## 2026-02-05 ‚Äî Sess√£o 125: Cria√ß√£o do Componente AskSourcesPanel

### Objetivo
Criar o componente `AskSourcesPanel` para a p√°gina `/ask` do Iudex, exibindo cita√ß√µes com sinais Shepard's e itens de contexto selecionados pelo usu√°rio.

### Arquivos Criados
- `/Users/nicholasjacob/Documents/Aplicativos/Iudex/apps/web/src/components/ask/ask-sources-panel.tsx` ‚Äî Componente React com painel lateral de fontes e cita√ß√µes
- `/Users/nicholasjacob/Documents/Aplicativos/Iudex/apps/web/src/components/ask/ask-sources-panel.example.tsx` ‚Äî Arquivo de exemplo de uso do componente

### Implementa√ß√£o
Componente criado com as seguintes caracter√≠sticas:
- Exibi√ß√£o de cita√ß√µes com sinais Shepard's (positivo/verde, negativo/vermelho, cautela/amarelo, neutro/cinza)
- √çcones lucide-react para cada tipo de sinal (CheckCircle, AlertCircle, MinusCircle)
- HoverCard com preview de snippet ao passar o mouse sobre cita√ß√£o
- Se√ß√µes colaps√°veis para "Cita√ß√µes" e "Contexto"
- Suporte a todos os tipos de contexto da store: file, folder, link, model, legislation, jurisprudence, audio
- √çcones espec√≠ficos por tipo de contexto (FileText, Folder, LinkIcon, BrainCircuit, BookOpen, Scale, Mic)
- Bot√£o de remo√ß√£o de item de contexto (aparece ao hover)
- Links externos clic√°veis para cita√ß√µes com URL
- Estado vazio com mensagem e √≠cone
- ScrollArea para conte√∫do scroll√°vel
- Design compacto para painel lateral usando padr√µes shadcn/ui

### Interface Props
```typescript
interface AskSourcesPanelProps {
  citations: Array<{
    id: string;
    title: string;
    source: string;
    snippet?: string;
    signal?: 'positive' | 'negative' | 'caution' | 'neutral';
    url?: string;
  }>;
  contextItems: ContextItem[]; // Da store context-store
  onRemoveItem: (id: string) => void;
  onClose: () => void;
}
```

### Verifica√ß√£o
- ‚úÖ Lint passou sem erros (`npm run lint`)
- ‚úÖ Componente compat√≠vel com interface `ContextItem` da store
- ‚úÖ Componente j√° exportado corretamente em `index.ts`
- ‚ö†Ô∏è Type-check com erros pr√©-existentes no `page.tsx` (n√£o relacionados ao novo componente)

### Padr√µes Seguidos
- Componentes funcionais com TypeScript estrito
- Uso de tipos importados da store (`ContextItem` de `@/stores/context-store`)
- HoverCard do shadcn/ui para preview de snippets
- Collapsible do shadcn/ui para se√ß√µes expans√≠veis
- Badge com variantes customizadas por sinal Shepard's
- cn() para classes condicionais
- Mensagens em portugu√™s brasileiro
- Estado local com useState para controle de collapse

### Integra√ß√£o com Sistema Existente
O componente foi integrado na p√°gina `/ask` (apps/web/src/app/(dashboard)/ask/page.tsx) e utiliza:
- `useContextStore` para gerenciar itens de contexto
- Fun√ß√£o `removeItem` da store para remo√ß√£o de itens
- Interface consistente com outros componentes do sistema

---

## 2026-02-05 ‚Äî Sess√£o 124: Cria√ß√£o do Componente AskStreamingStatus

### Objetivo
Criar o componente `AskStreamingStatus` para a p√°gina `/ask` do Iudex, exibindo status de streaming com anima√ß√µes e contadores de etapas.

### Arquivos Criados
- `/Users/nicholasjacob/Documents/Aplicativos/Iudex/apps/web/src/components/ask/ask-streaming-status.tsx` ‚Äî Componente React com anima√ß√µes de streaming

### Arquivos Modificados
- `/Users/nicholasjacob/Documents/Aplicativos/Iudex/apps/web/src/components/ask/index.ts` ‚Äî Adicionadas exporta√ß√µes de `AskSourcesPanel` e `AskStreamingStatus`

### Implementa√ß√£o
Componente criado com as seguintes caracter√≠sticas:
- Anima√ß√£o de loader (Loader2) com spin quando `isStreaming=true`
- √çcone de check (Check) quando completado
- Badge pulsante mostrando n√∫mero da etapa atual
- Mensagens de status contextuais em portugu√™s brasileiro
- Design compacto para header usando padr√µes do shadcn/ui
- Classes condicionais com cn() de @/lib/utils
- Cores: indigo para streaming, verde para conclu√≠do

### Interface Props
```typescript
interface AskStreamingStatusProps {
  status: string;        // Mensagem de status
  stepsCount: number;    // N√∫mero da etapa atual
  isStreaming: boolean;  // Se est√° em streaming
}
```

### Verifica√ß√£o
- ‚úÖ Lint passou sem erros (`npm run lint`)
- ‚ö†Ô∏è Type-check com erros pr√©-existentes no `page.tsx` (n√£o relacionados ao novo componente)
- ‚úÖ Componente exportado corretamente em `index.ts`

### Padr√µes Seguidos
- Componentes funcionais com TypeScript estrito
- Uso de lucide-react para √≠cones (Loader2, Check)
- Badge component do shadcn/ui
- Anima√ß√µes com Tailwind (animate-spin, animate-pulse)
- Mensagens em portugu√™s brasileiro
- cn() para classes condicionais

---

## 2026-02-05 ‚Äî Sess√£o 123: Compara√ß√£o Harvey vs Iudex

### Objetivo
Comparar funcionalidades do Harvey AI (workflows) com o Iudex para identificar gaps e confirmar paridade de features.

### An√°lise Realizada

Analisei a p√°gina de workflows do Harvey (`help.harvey.ai/articles/assistant-workflows`) e comparei com os templates existentes em `apps/api/app/scripts/seed_workflow_templates.py`.

### Resultado: ~90% de Paridade

| Harvey | Iudex | Status |
|--------|-------|--------|
| Translate | Traduzir Documento | ‚úÖ |
| Proofread | Revisar Ortografia e Gram√°tica | ‚úÖ |
| Timeline | Extrair Linha do Tempo | ‚úÖ |
| Client Alert | Rascunhar Alerta ao Cliente | ‚úÖ |
| Redline Summary | Resumir Altera√ß√µes de Redline | ‚úÖ |
| Post-Closing Timeline | Cronograma P√≥s-Fechamento | ‚úÖ |
| Deposition Analysis | Analisar Transcri√ß√£o de Depoimento | ‚úÖ |
| Discovery Summary | Resumir Respostas de Discovery | ‚úÖ |
| Diligence Insights | Due Diligence de Fornecedor | ‚úÖ |
| SEC Form 8-K | - | ‚ùå (EUA) |

### Features Exclusivas do Iudex (n√£o no Harvey)
- Cronologia + Teses + Provas (litigation BR)
- Revis√£o de Pol√≠tica de Privacidade (LGPD)

### Conclus√£o
Os √∫nicos gaps s√£o templates US-espec√≠ficos (SEC 8-K, Interim Covenants) que n√£o s√£o relevantes para software jur√≠dico brasileiro. **N√£o h√° implementa√ß√£o necess√°ria.**

### Verifica√ß√£o
- ‚úÖ `@iudex/web` type-check passa sem erros
- ‚ö†Ô∏è Erros pr√©-existentes em `@iudex/tribunais/captcha-solver.ts` (n√£o relacionado)

---

## 2026-02-05 ‚Äî Sess√£o 122: Captura de Anima√ß√µes de Streaming do Harvey

### Objetivo
Capturar screenshots dos v√≠deos do Harvey AI mostrando as anima√ß√µes de streaming din√¢mico para documentar os comportamentos de UI a serem replicados na p√°gina `/ask`.

### Screenshots Capturados (9 novos, 21 total)

| Arquivo | Descri√ß√£o |
|---------|-----------|
| `harvey-video-streaming-1.png` | UI Inicial - Input + Workflows recomendados |
| `harvey-video-streaming-2.png` | Canvas + Sources Panel - Layout completo |
| `harvey-video-streaming-3.png` | Estados de Streaming - "Answering...", "Generating new version..." |
| `harvey-video-streaming-4.png` | LexisNexis Case View - Shepard's Panel com breakdown |
| `harvey-video-streaming-5.png` | Popup de Sugest√£o - Detec√ß√£o autom√°tica de query jur√≠dica |
| `harvey-video-streaming-6.png` | Hover Preview - Cita√ß√£o com snippet destacado |
| `harvey-video-streaming-7.png` | Follow-ups Sugeridos - Lista de perguntas relacionadas |
| `harvey-video-streaming-8.png` | Layout 3 Colunas - Thread + Canvas + Version History |
| `harvey-video-streaming-9.png` | Estados em Tempo Real - "Adding citations...", "Edits complete" |

### Elementos de UI Documentados

1. **Estados de Streaming Din√¢mico**:
   - "Answering..." com spinner
   - "Adding citations..." durante busca
   - "Generating new version..." durante edi√ß√£o do canvas
   - "Finished in N steps" com contador

2. **Popup de Sugest√£o de Fonte**:
   - Detec√ß√£o autom√°tica de query jur√≠dica
   - Jurisdi√ß√µes pr√©-preenchidas
   - Bot√µes "Yes, ask LexisNexis¬Æ" / "No, answer without it"

3. **Hover Preview de Cita√ß√µes**:
   - Shepard's signal colorido
   - Snippet com destaque em amarelo
   - Bot√£o "View reference ‚Üí"

4. **Follow-ups Sugeridos**:
   - Lista de perguntas relacionadas geradas automaticamente

5. **Version History**:
   - Timeline de vers√µes com timestamps
   - Indicador "No code changes"
   - Contagem de steps por vers√£o

6. **Mode Selector**:
   - Toggle: Auto | Edit | Answer

### Plano Atualizado
- Adicionada se√ß√£o 12.4 em `docs/PLAN_HARVEY_CHAT.md` com especifica√ß√µes detalhadas de:
  - Estados de streaming din√¢mico
  - Componentes React propostos
  - Tipos de eventos SSE
  - Implementa√ß√£o do backend

### Pr√≥ximos Passos
1. Implementar estrutura de arquivos da p√°gina `/ask`
2. Criar store `ask-store.ts` com estado inicial
3. Implementar componentes de streaming UI
4. Criar endpoint `/api/ask/chat` com SSE

---

## 2026-02-05 ‚Äî Sess√£o 121: Simplifica√ß√£o UI do Chat

### Objetivo
Simplificar a toolbar do chat removendo √≠cones desnecess√°rios (Scale/balan√ßa, Zap/raio), removendo labels de bot√µes e tornando a barra de contexto mais compacta.

### Arquivos Modificados

#### `apps/web/src/components/chat/chat-input.tsx`
- Removido ~630 linhas de dead code (Legacy AI Controls Popover)
- Removidos labels de Template e Canvas (s√≥ √≠cones)
- Context bar movida para inline compacta junto ao Send
- Removidos bot√µes @, # e Mic (n√£o funcionavam)
- Removido import de Zap, AtSign, Hash, Mic

#### `apps/web/src/components/chat/deep-research-button.tsx`
- √çcone Microscope ‚Üí Search (lupa)
- Removido label "Deep Res."

#### `apps/web/src/components/chat/slash-command-menu.tsx`
- Zap ‚Üí Bot (comandos de modelo)
- Zap ‚Üí Sparkles (fallback)
- Zap ‚Üí Settings2 (comandos de template)
- Scale ‚Üí Columns2 (multi-modelo)

#### `apps/web/src/components/chat/context-dashboard.tsx`
- Zap ‚Üí Sparkles (header "A√ß√µes R√°pidas")

#### `apps/web/src/components/chat/at-command-menu.tsx`
- Scale ‚Üí BookOpen (jurisprud√™ncia)

#### `apps/web/src/components/chat/sources-badge.tsx`
- Scale ‚Üí BookOpen (tipo jurisprud√™ncia)

#### `apps/web/src/components/chat/chat-interface.tsx`
- Scale ‚Üí FileText (sugest√£o "Redija peti√ß√£o")

#### `apps/web/src/components/chat/model-selector.tsx`
- Zap ‚Üí Bot (modo padr√£o)
- Scale ‚Üí Columns2 (modo multi-modelo)

#### `apps/web/src/lib/use-graph.ts`
- Corrigido erro de Rules of Hooks (hooks chamados condicionalmente)

### Adi√ß√£o: Bot√£o de Prompts Salvos

#### `apps/web/src/components/chat/chat-input.tsx`
- Adicionado √≠cone üîñ Bookmark na toolbar (ap√≥s attach)
- Ao clicar, abre o SlashCommandMenu com todos os prompts (predefinidos + salvos)
- Tooltip: "Prompts salvos (ou digite /)"
- Estado visual: amber quando menu est√° aberto

### Resultado Visual
```
ANTES: [==] [Model ‚ñº] [üìÑ Template ‚ñº] [‚ñ¢ Canvas] | [Fontes ‚ñº] [üî¨ Deep Res. ‚ñº] [‚öô] | [üìé] [@] [#] [üé§] [Send]
       [‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê Contexto: 45% (84K / 200K) ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê]

DEPOIS: [==] [Model ‚ñº] [üìÑ] [‚ñ¢] | [Fontes ‚ñº] [üîç ‚ñº] [‚öô] | [üìé] [üîñ] [‚ïê45%‚ïê] [Send]
```

### Verifica√ß√£o
- Lint: ‚úÖ 0 erros
- Type-check: ‚úÖ Passou

---

## 2026-02-04 ‚Äî Sess√£o 120: Implementa√ß√£o Tool ask_graph (Graph Ask)

### Objetivo
Implementar tool `ask_graph` para consultas ao knowledge graph via opera√ß√µes tipadas (NL ‚Üí Intent ‚Üí Template Cypher), seguindo abordagem segura recomendada.

### Arquitetura

**Abordagem segura (NL ‚Üí Intent ‚Üí Template):**
```
Usu√°rio: "Quais artigos da Lei 8.666 citam licita√ß√£o?"
           ‚Üì
LLM interpreta ‚Üí { operation: "cooccurrence", entity1_id: "lei_8666", entity2_id: "licitacao" }
           ‚Üì
Backend compila ‚Üí Template Cypher FIXO com $tenant_id injetado pelo c√≥digo
           ‚Üì
Executa com seguran√ßa garantida
```

**Opera√ß√µes suportadas:**
- `path` ‚Äî Caminho entre entidades
- `neighbors` ‚Äî Vizinhos sem√¢nticos
- `cooccurrence` ‚Äî Co-ocorr√™ncia em documentos
- `search` ‚Äî Busca de entidades
- `count` ‚Äî Contagem com filtros

### Arquivos Criados

#### `apps/api/app/services/graph_ask_service.py`
- Service com templates Cypher seguros
- Valida√ß√£o de par√¢metros por opera√ß√£o
- Inje√ß√£o autom√°tica de `tenant_id`/`scope`/`case_id`
- Limites de seguran√ßa (max_hops=6, limit=100, timeout)

#### `apps/api/app/api/endpoints/graph_ask.py`
- Endpoint `POST /graph/ask` (unificado)
- Endpoints espec√≠ficos: `/ask/path`, `/ask/neighbors`, `/ask/cooccurrence`, `/ask/search`, `/ask/count`
- Health check `/ask/health`

### Arquivos Modificados

#### `apps/api/app/api/routes.py`
- Adicionado import de `graph_ask`
- Registrado router em `/graph` (prefixo)

#### `apps/api/app/services/ai/shared/tool_handlers.py`
- Adicionado handler `handle_ask_graph`
- Registrado em `_register_handlers()`

#### `apps/api/app/services/ai/shared/unified_tools.py`
- Adicionada tool `ASK_GRAPH_TOOL` com schema completo
- Inclu√≠da em `ALL_UNIFIED_TOOLS`

### Seguran√ßa

- ‚úÖ Sem Cypher arbitr√°rio (apenas templates fixos)
- ‚úÖ Tenant/scope injetados pelo backend (n√£o pelo usu√°rio)
- ‚úÖ Limites de `max_hops` (‚â§6) e `limit` (‚â§100)
- ‚úÖ Timeout de 5s por query
- ‚úÖ Blocklist de opera√ß√µes perigosas n√£o se aplica (n√£o h√° Cypher livre)

### Uso pelos Agentes

A tool `ask_graph` est√° dispon√≠vel automaticamente para Claude, GPT e Gemini via Tool Gateway:

```python
# Exemplo de chamada pelo agente
ask_graph({
    "operation": "path",
    "params": {
        "source_id": "art_5_CF",
        "target_id": "sumula_473_STF",
        "max_hops": 4
    }
})
```

### Corre√ß√µes de Seguran√ßa (GPT Review)

Ap√≥s revis√£o do GPT, foram aplicadas corre√ß√µes importantes:

#### 1. ContextVar para isolamento (`sdk_tools.py`)
- Mudou de vari√°vel global para `contextvars.ContextVar`
- Evita vazamento de tenant/case entre requests concorrentes

#### 2. OrgContext no endpoint (`graph_ask.py`)
- Usa `ctx.tenant_id` (organization_id) em vez de `user.id`
- Verifica `UserRole.ADMIN` para `show_template`

#### 3. Valida√ß√µes de scope (`graph_ask_service.py`)
- Bloqueia `scope=group` (evita bypass RBAC)
- Exige `case_id` quando `scope=local`
- Adiciona filtro `sigilo IS NULL OR sigilo = false` em todas queries

#### 4. Tool no Claude SDK (`sdk_tools.py`)
- `ask_graph` registrada em `_ALL_TOOLS` (7 tools total)
- Usa ContextVar para tenant/case isolados

#### 5. Inje√ß√£o de contexto no executor (`executor.py`)
- `set_iudex_tool_context()` chamado antes do loop do SDK
- Resolve `tenant_id` via `organization_id` quando h√° db

#### 6. ToolExecutionContext com tenant_id (`tool_handlers.py`)
- Adicionado campo `tenant_id` ao contexto
- Handler usa `ctx.tenant_id` com fallback para `ctx.user_id`

---

## 2026-02-04 ‚Äî Sess√£o 119: An√°lise Neo4j Aura Agent vs Sistema Iudex

### Objetivo
An√°lise hol√≠stica comparando o novo Neo4j Aura Agent com a arquitetura atual de GraphRAG, agentes LangGraph e visualiza√ß√£o de grafos do Iudex.

### Resultado da An√°lise

**Conclus√£o Principal:** Neo4j Aura Agent **n√£o substitui** o sistema atual do Iudex.

#### Motivos:
| Limita√ß√£o Aura Agent | Sistema Iudex |
|---------------------|---------------|
| Schema gen√©rico | Schema jur√≠dico customizado (Claim, Evidence, Actor, Issue) |
| Agente √∫nico | LangGraph com 22+ n√≥s e debate multi-modelo |
| Sem HIL | 6 pontos de Human-in-the-Loop |
| Cloud-only | Self-hosted poss√≠vel |
| Retrieval simples | RRF fusion (lexical + vector + graph) |

#### Valor potencial:
- **MCP Server** para expor grafo via Claude Desktop/Cursor
- Usar `mcp-neo4j-cypher` (open-source) em vez de Aura Agent

### Arquivos Analisados
- `apps/api/app/services/rag/core/neo4j_mvp.py` ‚Äî GraphRAG Neo4j MVP
- `apps/api/app/services/ai/langgraph_legal_workflow.py` ‚Äî Workflow 22+ n√≥s
- `apps/api/app/services/ai/claude_agent/executor.py` ‚Äî Claude Agent aut√¥nomo
- `apps/web/src/app/(dashboard)/graph/page.tsx` ‚Äî Visualiza√ß√£o NVL

### Documenta√ß√£o Gerada
- `.claude/plans/buzzing-whistling-spindle.md` ‚Äî An√°lise completa com tabelas comparativas

### Fontes Consultadas
- [Neo4j Aura Agent - Developer Guide](https://neo4j.com/developer/genai-ecosystem/aura-agent/)
- [Neo4j MCP Server - GitHub](https://github.com/neo4j-contrib/mcp-neo4j)
- [LangGraph + Neo4j Tutorial](https://neo4j.com/blog/developer/neo4j-graphrag-workflow-langchain-langgraph/)

---

## 2026-02-04 ‚Äî Sess√£o 118: Infer√™ncia Autom√°tica de Pap√©is + Remo√ß√£o de Enrollment

### Objetivo
Substituir enrollment de voz por infer√™ncia autom√°tica de pap√©is via LLM para audi√™ncias/reuni√µes.

### Arquivos Modificados

#### `apps/api/app/services/transcription_service.py`
- Nova fun√ß√£o `_infer_speaker_roles_with_llm()` ‚Äî infere pap√©is (Juiz, Advogado, Testemunha, etc.) baseado no conte√∫do das falas
- Pipeline de audi√™ncias agora usa infer√™ncia LLM em vez de matching de embeddings de voz
- Removido warning "sem_match_enrollment"

#### `apps/api/app/api/endpoints/transcription.py`
- Removido endpoint `POST /hearing/enroll` (deprecado)

#### `apps/web/src/app/(dashboard)/transcription/page.tsx`
- Removidos estados: `enrollName`, `enrollRole`, `enrollFile`, `isEnrolling`
- Removida fun√ß√£o `handleEnrollSpeaker()`
- Removida se√ß√£o de UI "Enrollment de voz"
- Removida refer√™ncia ao warning "sem_match_enrollment"

#### `apps/web/src/lib/api-client.ts`
- Removida fun√ß√£o `enrollHearingSpeaker()`

#### `mlx_vomo.py`
- Atualizado `_segments_to_text()` (v2.29) para agrupar segmentos por intervalo de 60s em APOSTILA/FIDELIDADE
- Fix: timestamps n√£o mais repetidos para cada palavra

### Como Funciona a Infer√™ncia de Pap√©is

```python
# Prompt para o LLM analisa amostras de cada speaker
prompt = """Analise as falas de uma audi√™ncia judicial e identifique o PAPEL de cada falante.
PAP√âIS POSS√çVEIS: Juiz, Advogado, Promotor, Defensor, Testemunha, Perito, Parte, Escriv√£o, Outro

FALAS POR SPEAKER:
SPEAKER 1:
  - "Bom dia. Declaro aberta a audi√™ncia."
  - "Defiro a juntada do documento."
SPEAKER 2:
  - "Jo√£o da Silva Santos."

Responda em JSON: {"roles": {"SPEAKER 1": "Juiz", "SPEAKER 2": "Testemunha"}}
"""
```

### Benef√≠cios
- N√£o requer cadastro pr√©vio de vozes
- Funciona automaticamente com qualquer backend (Whisper, AssemblyAI, ElevenLabs)
- Infer√™ncia baseada em contexto real das falas
- Reduz complexidade do pipeline

---

## 2026-02-04 ‚Äî Sess√£o 117: Recupera√ß√£o de Transcri√ß√µes AssemblyAI/ElevenLabs

### Objetivo
Adicionar funcionalidade para recuperar transcri√ß√µes que ficaram pendentes ou perdidas devido a desconex√£o com AssemblyAI/ElevenLabs.

### Arquivos Modificados

#### `apps/api/app/api/endpoints/transcription.py`
- Novo schema `PendingTranscription` para listar transcri√ß√µes pendentes
- Endpoint `GET /transcription/pending` ‚Äî lista todas transcri√ß√µes em cache
- Endpoint `POST /transcription/resume` ‚Äî retoma polling de transcri√ß√£o AssemblyAI
- Endpoint `DELETE /transcription/cache/{file_hash}` ‚Äî limpa cache de transcri√ß√£o

#### `apps/web/src/app/(dashboard)/transcription/page.tsx`
- Novos estados: `recoveryDialogOpen`, `pendingTranscriptions`, `isLoadingPending`, `isResuming`
- Fun√ß√£o `loadPendingTranscriptions()` ‚Äî busca transcri√ß√µes pendentes da API
- Fun√ß√£o `handleResumeTranscription()` ‚Äî retoma polling no AssemblyAI
- Fun√ß√£o `handleClearTranscriptionCache()` ‚Äî limpa cache local
- Bot√£o "Recuperar transcri√ß√£o anterior" abaixo do bot√£o "Transcrever"
- Di√°logo modal para visualizar e gerenciar transcri√ß√µes pendentes

### Funcionalidades

1. **Listar Pendentes**: Mostra todas transcri√ß√µes em cache (processando, completas, erro)
2. **Retomar AssemblyAI**: Reconecta ao polling do transcript_id salvo
3. **Limpar Cache**: Remove cache de transcri√ß√£o espec√≠fica
4. **UI Integrada**: Bot√£o no painel de configura√ß√£o + di√°logo de gerenciamento

### Uso
1. Clicar em "Recuperar transcri√ß√£o anterior" no painel de nova transcri√ß√£o
2. Visualizar transcri√ß√µes pendentes no di√°logo
3. Clicar "Retomar" para reconectar ao AssemblyAI
4. Transcri√ß√£o recuperada fica dispon√≠vel em cache para reprocessamento

---

## 2026-02-04 ‚Äî Sess√£o 116: Otimiza√ß√£o Pipeline MLX Vomo para √Åudios Longos

### Objetivo
Resolver 429 RESOURCE_EXHAUSTED no pipeline de transcri√ß√£o e acelerar processamento de √°udios longos com paraleliza√ß√£o.

### Problemas Resolvidos

1. **429 RESOURCE_EXHAUSTED** ‚Äî Rate limit do Gemini excedido
2. **React infinite loop** ‚Äî Loop infinito no quality-panel.tsx ao clicar em Qualidade

### Arquivos Modificados

#### `audit_fidelity_preventive.py`
- Adicionada fun√ß√£o `_call_gemini_with_retry()` com backoff exponencial (4s, 8s, 16s, 32s, 64s)
- Paraleliza√ß√£o da auditoria com `ThreadPoolExecutor` (IUDEX_PARALLEL_AUDIT)
- Nova constante `PARALLEL_AUDIT_WORKERS = 3`

#### `mlx_vomo.py`
- Nova constante `PARALLEL_CHUNKS` para paraleliza√ß√£o de chunks (v2.40)
- Fun√ß√£o helper `_process_single_chunk()` para processamento isolado
- Modo paralelo com `asyncio.gather()` + sem√°foro quando `IUDEX_PARALLEL_CHUNKS > 1`
- Split de revis√£o leve para docs > 400k chars (v2.3 em `ai_structure_review_lite`)

#### `apps/web/src/components/dashboard/quality-panel.tsx`
- Removida depend√™ncia circular no useEffect (linha 536)
- Usando `uiStateRef.current` em vez de `storedUiState` para evitar loop

### Novas Vari√°veis de Ambiente

```bash
IUDEX_PARALLEL_CHUNKS=1        # Chunks simult√¢neos (default: 1 = sequencial)
IUDEX_PARALLEL_AUDIT=3         # Auditorias simult√¢neas (default: 3)
IUDEX_SPLIT_REVIEW_THRESHOLD=400000  # Chars para split review
```

### Impacto Estimado

| Cen√°rio | Antes | Depois | Speedup |
|---------|-------|--------|---------|
| √Åudio 2h (20 chunks) | ~15 min | ~5 min | 3x |
| Auditoria 20 chunks | ~5 min | ~1.5 min | 3-4x |
| Rate limit 429 | Falha | Retry com backoff | ‚úì |

### Verifica√ß√£o
- `python3 -m py_compile audit_fidelity_preventive.py` ‚úÖ
- `python3 -m py_compile mlx_vomo.py` ‚úÖ
- `pnpm lint` ‚úÖ

---

## 2026-02-04 ‚Äî Sess√£o 115: Whisper Server para RunPod (GPU Externa)

### Objetivo
Implementar integra√ß√£o completa com servidor Whisper em GPU externa (RunPod) com processamento ass√≠ncrono (job_id + polling) e recupera√ß√£o de jobs interrompidos.

### Arquivos Criados

#### `scripts/whisper_server_runpod.py`
Servidor FastAPI completo para deploy no RunPod:
- `POST /transcribe` ‚Äî Submit arquivo, retorna job_id
- `GET /status/{job_id}` ‚Äî Status e progresso (0-100%)
- `GET /result/{job_id}` ‚Äî Resultado da transcri√ß√£o
- `DELETE /job/{job_id}` ‚Äî Cancela job
- `GET /health` ‚Äî Health check

Features:
- Autentica√ß√£o via Bearer token
- Processamento ass√≠ncrono com sem√°foro (max concurrent jobs)
- Limpeza autom√°tica de jobs antigos
- Suporte a faster-whisper com GPU

### Arquivos Modificados

#### `app/services/transcription_service.py`
Novos m√©todos de integra√ß√£o (~350 linhas):
- `_get_whisper_server_url()` / `_get_whisper_server_key()` ‚Äî Config
- `_is_whisper_server_available()` ‚Äî Verifica disponibilidade
- `_transcribe_whisper_server_with_progress()` ‚Äî Vers√£o async com SSE
- `_poll_whisper_server_job()` ‚Äî Polling async
- `_format_whisper_server_result()` ‚Äî Formata resultado
- `_transcribe_whisper_server_sync()` ‚Äî Vers√£o s√≠ncrona
- `_poll_whisper_server_job_sync()` ‚Äî Polling s√≠ncrono

#### `app/core/config.py`
Novas configura√ß√µes:
- `WHISPER_SERVER_URL` ‚Äî URL do servidor (ex: https://pod-8080.runpod.net)
- `WHISPER_SERVER_API_KEY` ‚Äî API key
- `WHISPER_SERVER_MODEL` ‚Äî Modelo padr√£o (large-v3)

### Arquitetura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    IUDEX (Cliente)                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  1. Verificar cache (hash + config)                         ‚îÇ
‚îÇ     ‚îú‚îÄ COMPLETO ‚Üí Retorna resultado                         ‚îÇ
‚îÇ     ‚îî‚îÄ PROCESSING ‚Üí Retoma polling com job_id               ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  2. Upload arquivo ‚Üí POST /transcribe                        ‚îÇ
‚îÇ     ‚îî‚îÄ Retorna job_id                                        ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  3. SALVAR CACHE IMEDIATAMENTE (job_id, status=processing)  ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  4. Polling ‚Üí GET /status/{job_id}                          ‚îÇ
‚îÇ     ‚îî‚îÄ Atualiza progresso no frontend                       ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  5. Resultado ‚Üí GET /result/{job_id}                        ‚îÇ
‚îÇ     ‚îî‚îÄ Atualiza cache (status=completed)                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 RUNPOD (Servidor GPU)                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  POST /transcribe                                            ‚îÇ
‚îÇ    ‚Üí Salva arquivo tempor√°rio                                ‚îÇ
‚îÇ    ‚Üí Cria job (status=queued)                                ‚îÇ
‚îÇ    ‚Üí Agenda processamento em background                      ‚îÇ
‚îÇ    ‚Üí Retorna job_id                                          ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  Background Task:                                            ‚îÇ
‚îÇ    ‚Üí Carrega Whisper (lazy)                                  ‚îÇ
‚îÇ    ‚Üí Transcreve (atualiza progress)                         ‚îÇ
‚îÇ    ‚Üí Salva resultado                                         ‚îÇ
‚îÇ    ‚Üí Limpa arquivo tempor√°rio                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Deploy no RunPod

```bash
# 1. Criar Pod com GPU (RTX 4090 ou A100)
# 2. Instalar depend√™ncias
pip install fastapi uvicorn faster-whisper python-multipart aiofiles

# 3. Configurar vari√°veis
export WHISPER_API_KEY="sua-chave-secreta"
export WHISPER_MODEL="large-v3"
export WHISPER_DEVICE="cuda"

# 4. Iniciar servidor
uvicorn whisper_server_runpod:app --host 0.0.0.0 --port 8080

# 5. Configurar no .env do Iudex
WHISPER_SERVER_URL=https://your-pod-8080.proxy.runpod.net
WHISPER_SERVER_API_KEY=sua-chave-secreta
```

### Verifica√ß√£o
- `python3 -m py_compile` ‚Äî OK para todos os arquivos

---

## 2026-02-04 ‚Äî Sess√£o 114: Redesign Chat Input (Estilo Perplexity) + Corre√ß√µes

### Objetivo
Redesenhar a UI do chat input inspirado no Perplexity Pro, mantendo todos os √≠cones originais.

### Arquivos Criados
- `apps/web/src/components/chat/sources-badge.tsx` ‚Äî Badge com √≠cones das fontes ativas + dropdown checkboxes
- `apps/web/src/components/chat/deep-research-button.tsx` ‚Äî Bot√£o dedicado Deep Research
- `apps/web/src/components/chat/context-usage-bar.tsx` ‚Äî Barra de % uso do contexto

### Arquivos Modificados
- `apps/web/src/components/chat/chat-input.tsx` ‚Äî Integra√ß√£o + bot√£o Mic adicionado
- `apps/web/src/stores/chat-store.ts` ‚Äî Estado `sourceSelection` granular

### Layout Final
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Digite sua mensagem...                                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
[Columns2] [ModelSelector] [FileText Template] [Canvas] | [SourcesBadge] [DeepResearch] | [Params]
[Paperclip] [AtSign] [Hash] [Mic]                                              [Send]
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ üìä Contexto: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 42% (84K / 200K tokens)                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### √çcones Mantidos
- Columns2 ‚Äî Comparar modelos
- FileText ‚Äî Template selector
- PanelRight ‚Äî Canvas
- SlidersHorizontal ‚Äî Par√¢metros
- Paperclip ‚Äî Anexar
- AtSign ‚Äî Men√ß√£o @
- Hash ‚Äî Tag #
- Mic ‚Äî √Åudio (NOVO)
- Send ‚Äî Enviar

### Valida√ß√£o
- Lint: OK
- Type-check: OK

---

## 2026-02-04 ‚Äî Sess√£o 113: Sistema de Cache para Recupera√ß√£o de Transcri√ß√µes AssemblyAI

### Objetivo
Implementar sistema de cache para persistir `transcript_id` do AssemblyAI imediatamente ap√≥s submit, permitindo recupera√ß√£o de transcri√ß√µes interrompidas por crash, timeout ou perda de conex√£o.

### Problema Resolvido
- Quando um job de transcri√ß√£o usando AssemblyAI era interrompido, o `transcript_id` era perdido (estava apenas em mem√≥ria)
- A transcri√ß√£o j√° processada no AssemblyAI n√£o podia ser recuperada
- O usu√°rio precisava reenviar o √°udio (custo duplicado ~$0.37/hora de √°udio)

### Arquivos Modificados

#### `apps/api/app/services/transcription_service.py`
Novos m√©todos de cache AAI (linhas ~4590-4760):
- `_get_aai_cache_dir()` ‚Äî Retorna diret√≥rio de cache (`storage/aai_transcripts/`)
- `_get_aai_cache_path(file_hash)` ‚Äî Retorna caminho do cache para um arquivo
- `_get_aai_config_hash(...)` ‚Äî Calcula hash da configura√ß√£o para invalida√ß√£o
- `_save_aai_cache(...)` ‚Äî Persiste transcript_id imediatamente ap√≥s submit
- `_update_aai_cache_status(...)` ‚Äî Atualiza status do cache
- `_fetch_aai_transcript_status(transcript_id)` ‚Äî Busca status no AAI
- `_check_aai_cache(file_path, config_hash)` ‚Äî Verifica cache existente

Modifica√ß√µes em `_transcribe_assemblyai_with_progress()`:
- Verifica cache antes do upload
- Se cache completo, retorna resultado cacheado
- Se cache processando, retoma polling
- Persiste transcript_id imediatamente ap√≥s obt√™-lo

Novos m√©todos auxiliares:
- `_extract_aai_result_from_response()` ‚Äî Extrai resultado de resposta AAI (async)
- `_poll_aai_transcript()` ‚Äî Polling para retomar transcri√ß√µes (async)
- `_extract_aai_result_sync()` ‚Äî Vers√£o s√≠ncrona do extrator
- `_poll_aai_transcript_sync()` ‚Äî Polling s√≠ncrono para retomar

Modifica√ß√µes em `_transcribe_assemblyai_with_roles()`:
- Mesma l√≥gica de cache para m√©todo s√≠ncrono

#### `apps/api/app/api/endpoints/transcription.py`
Modifica√ß√£o em `_write_vomo_job_result()`:
- Adicionados campos `transcript_id` e `transcription_backend` ao result.json

### Estrutura do Cache
```
storage/aai_transcripts/{file_hash}.json
{
  "file_hash": "sha256...",
  "file_name": "audio.mp3",
  "file_size_bytes": 54000000,
  "transcript_id": "43bf26d5-...",
  "audio_url": "https://cdn.assemblyai.com/...",
  "submitted_at": "2026-02-04T14:26:00Z",
  "completed_at": "2026-02-04T14:26:58Z",
  "status": "completed",
  "config_hash": "abc12345",
  "result_cached": true
}
```

### Benef√≠cios
| Cen√°rio | Antes | Depois |
|---------|-------|--------|
| Crash durante polling | Perde transcri√ß√£o, paga novamente | Recupera do cache |
| Reenvio do mesmo arquivo | Upload + transcri√ß√£o duplicados | Retorna cacheado |
| Erro de rede tempor√°rio | Job falha, precisa recriar | Retoma de onde parou |

### Verifica√ß√£o
- `python3 -m py_compile` ‚Äî OK para ambos arquivos

### Pr√≥ximos Passos (Opcional)
- Endpoint `/jobs/{job_id}/recover-aai` para recupera√ß√£o manual
- Recovery on-boot para jobs com status="running"
- Limpeza autom√°tica de cache antigo (>30 dias)

---

## 2026-02-04 ‚Äî Sess√£o 113b: Cache para ElevenLabs e Whisper Server

### Objetivo
Estender o sistema de cache para outros motores de transcri√ß√£o: ElevenLabs (s√≠ncrono) e preparar estrutura para Whisper em servidor externo (RunPod).

### An√°lise dos Motores

| Motor | Tipo | Cache Implementado |
|-------|------|-------------------|
| AssemblyAI | Async (job_id + polling) | ‚úÖ Recupera√ß√£o de jobs |
| ElevenLabs | S√≠ncrono (resultado direto) | ‚úÖ Cache de resultados |
| Whisper Server (RunPod) | Futuro - async ou sync | ‚úÖ Estrutura preparada |
| Whisper Local (MLX) | Local | N/A (n√£o h√° servidor) |

### Arquivos Modificados

#### `apps/api/app/services/transcription_service.py`

**Novos m√©todos de cache ElevenLabs** (linhas ~5260-5340):
- `_get_elevenlabs_cache_dir()` ‚Äî Retorna `storage/elevenlabs_transcripts/`
- `_get_elevenlabs_cache_path(file_hash)` ‚Äî Caminho do cache
- `_get_elevenlabs_config_hash(...)` ‚Äî Hash para invalida√ß√£o
- `_save_elevenlabs_cache(...)` ‚Äî Salva resultado completo
- `_check_elevenlabs_cache(...)` ‚Äî Verifica cache existente

**Novos m√©todos de cache Whisper Server** (linhas ~5350-5480):
- `_get_whisper_server_cache_dir()` ‚Äî Retorna `storage/whisper_server_transcripts/`
- `_get_whisper_server_cache_path(file_hash)` ‚Äî Caminho do cache
- `_get_whisper_server_config_hash(...)` ‚Äî Hash para invalida√ß√£o
- `_save_whisper_server_cache(...)` ‚Äî Salva resultado ou job_id
- `_check_whisper_server_cache(...)` ‚Äî Verifica cache existente
- `_update_whisper_server_cache_status(...)` ‚Äî Atualiza status

**Modifica√ß√µes em `_transcribe_elevenlabs_scribe()`**:
- Verifica cache antes de processar
- Salva resultado no cache ap√≥s completar

### Estrutura dos Caches

**ElevenLabs** (`storage/elevenlabs_transcripts/{file_hash}.json`):
```json
{
  "file_hash": "sha256...",
  "config_hash": "abc12345",
  "cached_at": "2026-02-04T...",
  "backend": "elevenlabs",
  "result": { "text": "...", "segments": [...] }
}
```

**Whisper Server** (`storage/whisper_server_transcripts/{file_hash}.json`):
```json
{
  "file_hash": "sha256...",
  "config_hash": "abc12345",
  "job_id": "runpod-job-xxx",
  "status": "processing|completed",
  "backend": "whisper_server",
  "result": { ... }
}
```

### Benef√≠cios

| Motor | Benef√≠cio do Cache |
|-------|-------------------|
| ElevenLabs | Evita reprocessamento do mesmo arquivo (economia ~$0.10/min) |
| Whisper Server | Recupera√ß√£o de jobs + evita reprocessamento |

### Verifica√ß√£o
- `python3 -m py_compile` ‚Äî OK

---

## 2026-02-04 ‚Äî Sess√£o 112: Redesign do Chat Input (Estilo Perplexity)

### Objetivo
Redesenhar a UI do chat input inspirado no Perplexity Pro, com badge de fontes, Deep Research dedicado, e barra de uso de contexto.

### Arquivos Criados
- `/apps/web/src/components/chat/sources-badge.tsx` ‚Äî Badge com √≠cones das fontes ativas + dropdown com checkboxes granulares
- `/apps/web/src/components/chat/deep-research-button.tsx` ‚Äî Bot√£o dedicado para Deep Research com menu Standard/Hard
- `/apps/web/src/components/chat/context-usage-bar.tsx` ‚Äî Barra de progresso mostrando % uso da janela de contexto

### Arquivos Modificados
- `/apps/web/src/components/chat/chat-input.tsx` ‚Äî Integra√ß√£o dos novos componentes
- `/apps/web/src/components/chat/index.ts` ‚Äî Exports dos novos componentes
- `/apps/web/src/stores/chat-store.ts` ‚Äî Novo estado `sourceSelection` com sele√ß√£o granular de fontes

### Funcionalidades Implementadas

1. **SourcesBadge**:
   - Badge com mini-√≠cones das fontes ativas (üìú‚öñÔ∏èüèõÔ∏èüìéüåê)
   - Dropdown com se√ß√µes: Web Search, Anexos do Caso, Corpus Global, Corpus Privado, Conectores MCP
   - Checkboxes granulares por arquivo/categoria/projeto/conector
   - Substitui: RAG Scope (radio), Decis√£o pesquisa, Modo busca

2. **DeepResearchButton**:
   - Bot√£o dedicado üî¨ Deep Research
   - Modos: Standard (1 provider) vs Hard (Multi-Provider)
   - Seletores: Provider (Auto/Google/Perplexity/OpenAI), Esfor√ßo (Low/Medium/High)
   - Hard mode: checkboxes para Gemini, Perplexity, OpenAI, RAG Global, RAG Local

3. **ContextUsageBar**:
   - Barra de progresso: "üìä Contexto: ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë 42% (84K / 200K)"
   - Cores: Verde (0-50%), Amarelo (51-80%), Vermelho (81-100%)
   - Tooltip com breakdown: sistema, hist√≥rico, anexos, RAG, reserva resposta

4. **Novo estado no chat-store**:
   - `sourceSelection` com sele√ß√£o granular por categoria
   - Helpers: `getActiveSourcesCount()`, `getActiveSourceIcons()`
   - Actions: `toggleSource()`, `selectAllInCategory()`, `deselectAllInCategory()`

### Elementos Mantidos (sem altera√ß√£o)
- Model Selector com √≠cones por provider
- Modal de Pontos/Tarifas [?]
- Toggles Standard/Multi-model [‚ö°][‚öñ]
- Barra de Par√¢metros (reasoning, thinking budget, verbosity)
- Context Selector inferior (abas: Arquivos, Biblioteca, √Åudio, Link, Juris)
- Footer Corpus Global/Privado
- √çcones: üìé Anexar, üé§ √Åudio, üìù Canvas, ‚û§ Enviar

### Comandos Executados
- `npm run lint --workspace=apps/web` ‚Äî OK
- `npm run type-check --workspace=apps/web` ‚Äî OK

### Layout Final
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Digite sua mensagem...                                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   üìé  üé§  üìù  ‚û§
‚îÇüìú‚öñÔ∏èüèõÔ∏èüìé Fontes 5‚îÇ ‚îÇüî¨ Deep R.‚îÇ ‚îÇ[‚óê] Claude 4.5 ‚ñº[?]‚ö°‚öñ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ üìä Contexto: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 42% (84K / 200K tokens)               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 2026-02-04 ‚Äî Sessao 111: Cleanup de UI Obsoleta no ChatInput

### Objetivo
Remover elementos de UI obsoletos do `chat-input.tsx` que foram migrados para o novo componente `SourcesBadge`.

### Arquivos Alterados
- `/apps/web/src/components/chat/chat-input.tsx` ‚Äî Remo√ß√£o de se√ß√µes de UI obsoletas
- `/apps/web/src/stores/chat-store.ts` ‚Äî Marca√ß√£o de vari√°veis de estado como deprecated

### Mudan√ßas Realizadas

1. **Se√ß√µes de UI removidas/comentadas**:
   - "Decis√£o de pesquisa" (Auto/Manual) - `researchPolicy` UI
   - "Modo de busca" (Compartilhada/Nativa/H√≠brida) - `searchMode` radio buttons
   - "Multi-query" toggle - `multiQuery` state UI
   - "Breadth-first" toggle - `breadthFirst` state UI
   - "RAG Scope selector" (S√≥ Caso/Caso+Global/S√≥ Global) - `ragScope` UI (agora checkboxes granulares em SourcesBadge)

2. **Coment√°rios DEPRECATED adicionados**:
   - Nos locais onde UI foi removida, adicionados coment√°rios `// DEPRECATED: moved to SourcesBadge`
   - Nos imports de estado, marcados os que n√£o t√™m mais UI neste arquivo

3. **Vari√°veis de estado em chat-store.ts marcadas como @deprecated**:
   - `multiQuery: boolean` - UI moved to SourcesBadge
   - `breadthFirst: boolean` - UI moved to SourcesBadge
   - `searchMode` - UI moved to SourcesBadge
   - `researchPolicy` - UI moved to SourcesBadge
   - `ragScope` - UI moved to SourcesBadge with granular checkboxes

### Elementos MANTIDOS (conforme especifica√ß√£o)
- Model selector e toda sua funcionalidade
- Model parameters UI (reasoning level, thinking budget, etc.)
- Points/pricing modal
- Standard/Multi-model toggles
- Canvas button
- Attach button
- Audio button
- Send button
- Context Selector (bottom tabs)
- Corpus footer (Global/Private display)

### Decis√µes T√©cnicas
- Estado mantido no store para compatibilidade com API backend
- Imports mantidos mas comentados para indicar deprecia√ß√£o
- Lint e type-check passando sem erros

---

## 2026-02-04 ‚Äî Sessao 110: Integracao dos Novos Componentes no ChatInput

### Objetivo
Integrar os novos componentes `SourcesBadge`, `DeepResearchButton` e `ContextUsageBar` no arquivo `chat-input.tsx`, reorganizando o layout do toolbar conforme o design spec.

### Arquivos Alterados
- `/apps/web/src/components/chat/chat-input.tsx` ‚Äî Integracao dos novos componentes

### Mudancas Realizadas

1. **Imports adicionados**:
   - `SourcesBadge` from '@/components/chat/sources-badge'
   - `DeepResearchButton` from '@/components/chat/deep-research-button'
   - `ContextUsageBar` from '@/components/chat/context-usage-bar'

2. **Novo layout do toolbar** (linhas 879-886):
   - Substituido o grande Popover de "AI Controls" (Web Search/Deep Research) pelos novos componentes
   - `<SourcesBadge />` ‚Äî Seletor unificado de fontes (web search, MCP, RAG scope)
   - `<DeepResearchButton />` ‚Äî Controles de Deep Research

3. **ContextUsageBar adicionado** (linhas 2640-2643):
   - Posicionado abaixo do toolbar de botoes
   - Mostra uso de contexto em tempo real

4. **Codigo legado preservado**:
   - O antigo Popover de AI Controls foi envolto em `{false && (...)}` para preservar referencia
   - Marcado como "Legacy AI Controls Popover - hidden but preserved for reference"
   - Pode ser removido em cleanup futuro

### Layout Final
```
+------------------------------------------------------------------+
| Textarea de mensagem                                              |
+------------------------------------------------------------------+
| [Compare] [Model‚ñº] [Template‚ñº] [Canvas] | [Fontes‚ñº] [Deep Res.‚ñº] |
|                                         | [Params‚ñº] [üìé] [@] [#] |
+------------------------------------------------------------------+
| Context: [========] 42% (84K / 200K tokens)                       |
+------------------------------------------------------------------+
```

### Decisoes Tecnicas
- Preservado codigo legado (comentado) para referencia durante transicao
- Mantido segundo Popover de "Parametros por modelo" ativo (nao migrado ainda)
- ContextUsageBar usa modo normal (nao compacto) para melhor visibilidade

### Comandos Executados
- `npm run lint --workspace=apps/web` ‚Äî OK
- `npx tsc --noEmit` ‚Äî OK (sem erros de tipo)

---

## 2026-02-04 ‚Äî Sessao 109: Granular Source Selection State no Chat Store

### Objetivo
Adicionar estado de selecao granular de fontes no chat-store para permitir que usuarios selecionem individualmente quais fontes de dados usar em consultas (web search, anexos, corpus global, corpus privado, conectores MCP).

### Arquivos Alterados
- `/apps/web/src/stores/chat-store.ts` ‚Äî Adicionado sourceSelection state e actions

### Funcionalidades Implementadas

1. **Novos Tipos Exportados**:
   - `CorpusGlobalSelection` ‚Äî Interface para selecao de categorias do corpus global
   - `SourceSelection` ‚Äî Interface principal com todas as categorias de fontes
   - `SourceCategory` ‚Äî Union type das categorias disponiveis

2. **Estado `sourceSelection`** com estrutura:
   ```typescript
   {
     webSearch: boolean,
     attachments: Record<string, boolean>, // fileId -> enabled
     corpusGlobal: {
       legislacao: boolean,
       jurisprudencia: boolean,
       pecasModelo: boolean,
       doutrina: boolean,
       sei: boolean
     },
     corpusPrivado: Record<string, boolean>, // projectId -> enabled
     mcpConnectors: Record<string, boolean> // label -> enabled
   }
   ```

3. **Actions Implementadas**:
   - `setSourceSelection(selection)` ‚Äî Substitui toda a selecao
   - `toggleSource(category, id?)` ‚Äî Toggle individual por categoria/id
   - `selectAllInCategory(category)` ‚Äî Seleciona todos em uma categoria
   - `deselectAllInCategory(category)` ‚Äî Deseleciona todos em uma categoria
   - `setAttachmentEnabled(fileId, enabled)` ‚Äî Controle individual de anexo
   - `setCorpusGlobalEnabled(key, enabled)` ‚Äî Controle individual de corpus global
   - `setCorpusPrivadoEnabled(projectId, enabled)` ‚Äî Controle individual de corpus privado
   - `setMcpConnectorEnabled(label, enabled)` ‚Äî Controle individual de conector MCP
   - `getActiveSourcesCount()` ‚Äî Retorna quantidade de fontes ativas
   - `getActiveSourceIcons()` ‚Äî Retorna array de emojis das fontes ativas

4. **Persistencia**:
   - Estado salvo em localStorage com key `iudex_source_selection`
   - Funcoes `loadSourceSelection()` e `persistSourceSelection()` para gerenciamento

5. **Icones por Categoria**:
   - webSearch: üåê
   - attachments: üìé
   - legislacao: üìú
   - jurisprudencia: ‚öñÔ∏è
   - pecasModelo: üìÑ
   - doutrina: üìö
   - sei: üèõÔ∏è
   - corpusPrivado: üîí
   - mcpConnectors: üîå

### Decisoes Tecnicas
- Mantem compatibilidade com `ragScope` existente
- Valores default: corpusGlobal todo habilitado, outros vazios/desabilitados
- Persistencia automatica em toda alteracao
- Funcoes helper para contagem e icones sao getters (nao state)

### Comandos Executados
- `npm run type-check` ‚Äî OK (erros pre-existentes em outros packages)
- `npm run lint --workspace=apps/web` ‚Äî OK

---

## 2026-02-04 ‚Äî Sessao 108: Criacao do ContextUsageBar para Chat

### Objetivo
Criar componente React `ContextUsageBar` para mostrar visualmente o uso da janela de contexto no chat.

### Arquivos Criados
- `/apps/web/src/components/chat/context-usage-bar.tsx` ‚Äî Componente principal

### Arquivos Alterados
- `/apps/web/src/components/chat/index.ts` ‚Äî Export do novo componente

### Funcionalidades Implementadas
1. **Barra de progresso visual** mostrando % de contexto usado
2. **Formato**: "Contexto: [barra] 42% (84K / 200K tokens)"
3. **Cores por nivel**:
   - 0-50%: Verde (emerald-500)
   - 51-80%: Amarelo (amber-500)
   - 81-100%: Vermelho (red-500) com alerta pulsante
4. **Tooltip detalhado** com breakdown:
   - Nome do modelo e tamanho da janela
   - Sistema + historico: XXK (X%)
   - Anexos (N arquivos): XXK (X%)
   - RAG chunks: XXK (X%)
   - Reserva resposta: XXK (X%)
   - Total usado / Disponivel
5. **Modo compacto** para espacos reduzidos
6. **Calculo dinamico** baseado em:
   - Modelo selecionado (usa menor janela em multi-model)
   - Historico de mensagens
   - Arquivos anexados (context-store)
   - Escopo RAG (case_only, case_and_global, global_only)

### Decisoes Tecnicas
- Estimativa de tokens: ~4 chars = 1 token (aproximacao padrao)
- Reserva de 4096 tokens para resposta
- System prompt estimado em 2000 tokens
- Arquivos anexados: ~2000 tokens cada (media)
- RAG chunks: ~1500 tokens cada

### Comandos Executados
- `npm run lint --workspace=apps/web` ‚Äî OK
- `npm run type-check --workspace=apps/web` ‚Äî Erros pre-existentes em chat-store.ts (nao relacionados)

---

## 2026-02-04 ‚Äî Sessao 107: Criacao do Componente DeepResearchButton

### Objetivo
Criar um componente React dedicado `DeepResearchButton` para a interface de chat do Iudex, extraindo a funcionalidade de Deep Research que estava embutida no `chat-input.tsx`.

### Arquivos Criados
- `apps/web/src/components/chat/deep-research-button.tsx` ‚Äî Novo componente

### Arquivos Alterados
- `apps/web/src/components/chat/index.ts` ‚Äî Adicionado export do novo componente

### Funcionalidades Implementadas

#### 1. Botao Principal com Popover
- Botao compacto "Deep Res." com icone de microscopio
- Indicador visual quando Deep Research esta ativado (verde emerald)
- Popover com configuracoes completas

#### 2. Configuracoes no Popover
- **Toggle principal**: Ativa/desativa Deep Research com badge ALPHA
- **Seletor de modo**: Standard vs Hard (Multi-Provider)
- **Seletor de provider** (modo Standard): Auto, Perplexity, Google, OpenAI
- **Effort level**: Low, Medium, High

#### 3. Modo Hard (Multi-Provider)
- Info box explicando que Claude orquestra multiplos agentes
- Seletor de fontes com checkboxes:
  - Gemini Deep Research
  - Perplexity Sonar
  - ChatGPT Deep Research
  - RAG Global (legislacao, jurisprudencia)
  - RAG Local (documentos do caso)
- Botoes "Todas" e "Nenhuma" para selecao rapida

#### 4. Parametros Avancados (Perplexity)
- Search focus: Auto, Web, Academico, SEC
- Domain filter, datas de publicacao/atualizacao
- Localizacao: Country, Latitude, Longitude

### Comandos Executados
- `npm run lint --workspace=apps/web` ‚Äî OK
- `npx tsc --noEmit` ‚Äî OK (sem erros no novo componente)

### Decisoes Tomadas
- Componente usa diretamente o `useChatStore` para estado (consistencia com arquitetura existente)
- Mantida mesma estrutura visual e UX do UI original em chat-input.tsx
- Botao fecha o popover ao clicar "Deep Research Ativado" para UX fluida

---

## 2026-02-04 ‚Äî Sessao 106: Correcao de observacoes_gerais na Auditoria Preventiva de Fidelidade

### Objetivo
Corrigir o campo `observacoes_gerais` que estava sendo gerado com numeros inventados pela IA (ex: "taxa de compressao 43%") quando os dados reais mostravam valores diferentes (ex: 108.1% de retencao = expansao de 8%).

### Problema
- A IA estava inventando porcentagens de compressao em vez de usar os valores reais calculados
- Exemplo: Metricas reais mostravam `taxa_retencao: 1.081` (108.1% = expansao de 8%)
- Mas `observacoes_gerais` dizia "Apesar da taxa de compressao parecer alta (43%)..."
- O prompt nao fornecia as metricas pre-calculadas para a IA

### Arquivos Alterados
- `/Users/nicholasjacob/Documents/Aplicativos/Iudex/audit_fidelity_preventive.py` ‚Äî Correcao do prompt e logica

### Mudancas Implementadas

#### 1. Nova secao "METRICAS REAIS DO DOCUMENTO" no prompt
- Adicionada secao com metricas pre-calculadas no inicio do prompt
- Inclui: modo, palavras_raw, palavras_fmt, taxa_retencao, dispositivos legais
- Inclui interpretacao clara: "EXPANSAO de X%" ou "COMPRESSAO de X%"

#### 2. Instrucoes explicitas para nao inventar numeros
- Prompt agora diz: "N√ÉO invente ou estime outros valores. Use EXATAMENTE estes numeros"
- Secao "ANALISE AUTOMATICA DE METRICAS" reescrita para enfatizar uso de valores fornecidos
- Explicacao de como interpretar taxa_retencao (>100% = expansao, <100% = compressao)

#### 3. Atualizacao do schema JSON
- Campo `observacoes_gerais` agora inclui instrucao: "Use APENAS os valores da secao METRICAS REAIS"
- Exemplo de formato correto incluido no prompt

#### 4. Codigo que monta o prompt
- Criada variavel `metricas_info` com string formatada das metricas reais
- Inclui texto descritivo: "EXPANSAO de X%" ou "COMPRESSAO de X%" baseado no valor
- Passada para o prompt via parametro `metricas_info`

### Comandos Executados
- `python3 -m py_compile audit_fidelity_preventive.py` ‚Äî OK (sintaxe valida)

### Decisoes Tomadas
- Metricas sao calculadas deterministicamente ANTES de chamar o LLM
- LLM recebe as metricas prontas e deve apenas usa-las, nao recalcular
- Texto interpretativo (expansao/compressao) incluido para evitar confusao da IA

---

## 2026-02-04 ‚Äî Sess√£o 105: Corre√ß√£o Sincroniza√ß√£o Word-Audio na Transcri√ß√£o

### Objetivo
Corrigir a sincroniza√ß√£o entre clique nas palavras e reprodu√ß√£o de √°udio na aba "raw" da p√°gina de transcri√ß√£o.

### Problema
- Clique na palavra levava para timestamp errado no √°udio
- Highlight da palavra ativa n√£o correspondia ao √°udio durante playback
- Problema ocorria em uploads locais e jobs carregados do servidor

### Arquivos Alterados
- `apps/web/src/components/dashboard/word-level-transcript-viewer.tsx` ‚Äî Refatora√ß√£o completa da l√≥gica de sincroniza√ß√£o

### Mudan√ßas Implementadas

#### 1. Substitui√ß√£o de Binary Search por Busca Linear Problem√°tica
- Implementado `useMemo` com binary search para encontrar palavra ativa
- Busca retorna correspond√™ncia exata (start ‚â§ time ‚â§ end) ou √∫ltima palavra antes do tempo atual

#### 2. Memoiza√ß√£o de √çndices Globais
- Removida vari√°vel `globalWordIndex` mut√°vel que causava problemas em re-renders
- Criado `wordGlobalIndices` com `useMemo` para pr√©-calcular mapeamento √≠ndice ‚Üí palavra

#### 3. Throttling do Evento `timeupdate`
- Adicionado `requestAnimationFrame` para limitar atualiza√ß√µes
- Evita re-renders excessivos durante playback
- Cleanup adequado do RAF no unmount

#### 4. Otimiza√ß√£o do Auto-scroll
- Alterado `behavior: 'smooth'` para `behavior: 'auto'` durante playback
- Evita scroll lag quando √°udio avan√ßa rapidamente

### Comandos Executados
- `npm run lint --workspace=apps/web` ‚Äî OK
- `npm run type-check --workspace=apps/web` ‚Äî OK

### Decis√µes Tomadas
- Mantido `setCurrentTime` em `handleSeek` para feedback imediato ao usu√°rio (responsividade)
- Usado `useMemo` para `activeWordIndex` ao inv√©s de `useEffect` + state (evita re-renders intermedi√°rios)

### Atualiza√ß√£o: Suporte a Diariza√ß√£o

#### Mudan√ßas Adicionais
- `groupWordsIntoBlocks` agora agrupa por **mudan√ßa de speaker** quando diariza√ß√£o est√° ativa
- Respeita breaks naturais das frases do Whisper (n√£o for√ßa intervalo de 60s)
- Exibe **label do falante** como badge antes do texto de cada bloco

#### L√≥gica de Agrupamento
- Com diariza√ß√£o: novo bloco a cada mudan√ßa de `word.speaker`
- Sem diariza√ß√£o: mant√©m agrupamento por intervalo de tempo (default 60s)

---

## 2026-02-04 ‚Äî Sess√£o 104: Refatora√ß√£o P√°gina de Casos - Layout Minuta

### Objetivo
Refatorar a p√°gina de casos (`/cases/[id]`) para espelhar a experi√™ncia da p√°gina de minutas, substituindo o GeneratorWizard pelo chat jur√≠dico com canvas integrado.

### Arquivos Alterados
- `apps/web/src/app/(dashboard)/cases/[id]/page.tsx` ‚Äî Refatora√ß√£o completa

### Mudan√ßas Implementadas

#### 1. Central de Contexto (Aba "Arquivos / Autos")
- Layout em grid: documentos do caso (2/3) + sidebar de corpus (1/3)
- Adicionado seletor de Escopo RAG (Apenas Caso | Caso + Corpus | Corpus)
- Integrado Corpus Global via `useCorpusCollections`
- Integrado Corpus Privado via `useCorpusProjects`

#### 2. Nova Aba "Gerar Pe√ßa" (Substituiu GeneratorWizard)
- Layout resiz√°vel com Chat + Canvas lado a lado
- Toolbar compacta com:
  - Toggle de modo (R√°pido vs Comit√™ Multi-Agente)
  - Toggle de layout (Chat | Canvas)
  - Bot√£o "Gerar" para iniciar gera√ß√£o
  - Bot√£o de configura√ß√µes
- `MinutaSettingsDrawer` com 70+ configura√ß√µes de qualidade, modelos, HIL, etc.
- Barra de progresso dos agentes durante gera√ß√£o
- Popover de Corpus integrado no chat panel

#### 3. Funcionalidades Herdadas da Minuta
- Layout resiz√°vel via divider arrast√°vel
- Sincroniza√ß√£o de modo com `setUseMultiAgent`
- Handlers de resize (`handleDividerPointerDown/Move/Up`)
- HIL modal (`OutlineApprovalModal`) para aprova√ß√£o de estrutura
- Todos os handlers de gera√ß√£o (`handleGenerate`, `handleOutlineApprove/Reject`)

### Comandos Executados
- `npm run lint` ‚Äî OK
- `npx tsc --noEmit` ‚Äî OK

### Decis√µes Tomadas
- Removido `GeneratorWizard` em favor do layout integrado Chat+Canvas
- Reutilizados componentes existentes (`MinutaSettingsDrawer`, `CanvasContainer`, `ChatInterface`)
- Mantida aba "Chat Jur√≠dico" separada para consultas que n√£o s√£o gera√ß√£o de documentos

---

## 2026-02-04 ‚Äî Sess√£o 103: Bug Parte 1 Vazia em Batch + Tratamento de Erro

### Problema
Na transcri√ß√£o em lote (batch), a Parte 1 de um arquivo de 5h22min (309MB) ficou vazia no `raw.txt`.

### Investiga√ß√£o
1. Verificado `raw.txt`: Parte 1 tinha apenas o header, conte√∫do estava todo na Parte 2
2. Verificado dura√ß√£o dos arquivos:
   - Parte 1: 19.353 segundos (5h22min) - arquivo extremamente longo
   - Parte 2: 929 segundos (15min) - arquivo normal
3. Identificado que `mlx_vomo.py` **j√° tem** suporte a chunking para √°udios > 2h
4. Por√©m, n√£o havia try/except ao redor da chamada `transcribe_file` no batch

### Causa Raiz
O c√≥digo em `process_batch_with_progress()`:
- N√£o tinha tratamento de exce√ß√£o ao chamar `vomo.transcribe_file()`
- N√£o validava se `transcription_text` estava vazio
- Se o Whisper falhasse silenciosamente (timeout, mem√≥ria), texto ficava vazio

### Corre√ß√£o (v2.34)

**Arquivo 1:** `apps/api/app/services/transcription_service.py`
1. **Adicionado try/except** ao redor de `vomo.transcribe_file()` (linhas 4185-4228)
2. **Fallback para AssemblyAI** se Whisper falhar e AAI key dispon√≠vel
3. **Valida√ß√£o de conte√∫do** ap√≥s transcri√ß√£o (`len(text) < 50` = warning)
4. **Logs de erro** detalhados para debug

**Arquivo 2:** `mlx_vomo.py` - Detec√ß√£o de dura√ß√£o mais robusta
1. **`_get_audio_duration()`** melhorado com:
   - Timeout de 30s no ffprobe
   - Valida√ß√£o do resultado do ffprobe
   - Fallback via `wave` module para arquivos WAV
   - Fallback por estimativa de tamanho de arquivo
2. **Logging detalhado** quando chunking √© ativado/desativado:
   - `üìè Dura√ß√£o detectada: X.XXh (limite: 2h)`
   - `‚ö†Ô∏è ATIVANDO CHUNKING` quando dura√ß√£o > 2h
   - `‚ùå AVISO: Dura√ß√£o n√£o detectada!` quando dura√ß√£o = 0

### Arquivos Existentes que Suportam √Åudios Longos
- `mlx_vomo.py`: Chunking autom√°tico para √°udios > 2h (v2.32+)
- `scripts/transcribe_long_raw.py`: Script CLI para chunking manual

### Melhorias no Chunking (v2.34)

**Arquivo:** `mlx_vomo.py`

1. **Overlap aumentado**: 30s ‚Üí 45s (mais seguro para frases longas)
2. **Merge melhorado** - 4 estrat√©gias de detec√ß√£o de duplicatas:
   - Texto exatamente igual
   - Substring (um cont√©m o outro)
   - Similaridade Jaccard > 80%
   - Primeiras 8 palavras iguais
3. **Logging detalhado**: `üîó Merge: 150 ‚Üí 142 segmentos (removidas duplicatas do overlap)`

**Limita√ß√£o conhecida - Diariza√ß√£o:**
- Speaker IDs podem resetar entre chunks (SPEAKER 1 no chunk A pode virar SPEAKER 2 no chunk B)
- Para diariza√ß√£o consistente em √°udios longos, recomenda-se usar AssemblyAI
- Alternativa: fazer diariza√ß√£o no √°udio inteiro separadamente e alinhar depois

### Pr√≥ximos Passos
- Reiniciar API para aplicar corre√ß√µes
- Retestar arquivo de 5h+ - agora deve aparecer log de chunking ativado

---

## 2026-02-04 ‚Äî Sess√£o 102: Corre√ß√£o do Seletor de Motor de Transcri√ß√£o

### Problema
O seletor de motor de transcri√ß√£o (Whisper vs AssemblyAI) n√£o estava funcionando corretamente:
1. O seletor s√≥ era vis√≠vel para o tipo `apostila`, n√£o para audi√™ncias e legendas
2. Ao mudar de tipo, o engine era resetado para 'whisper' automaticamente
3. O par√¢metro `transcription_engine` n√£o era passado para os endpoints de hearing
4. O servi√ßo `process_hearing_with_progress` n√£o aceitava o par√¢metro

### Arquivos Alterados

**Frontend (`apps/web/src/app/(dashboard)/transcription/page.tsx`):**
- Expandido `showEngineSelector` para todos os tipos de transcri√ß√£o (apostila, hearing, legenda)
- Removido useEffect que resetava engine para 'whisper'
- Adicionado `transcription_engine: transcriptionEngine` a todas as chamadas de hearing (4 ocorr√™ncias)

**Frontend (`apps/web/src/lib/api-client.ts`):**
- Adicionado `transcription_engine` ao payload de `startHearingJob()`
- Adicionado `transcription_engine` ao payload de `startHearingJobFromUrl()`

**Backend (`apps/api/app/api/endpoints/transcription.py`):**
- Adicionado `transcription_engine: str = Form("whisper")` ao endpoint `/hearing/jobs`
- Adicionado `transcription_engine` ao config de hearing
- Adicionado `transcription_engine` √† chamada de `process_hearing_with_progress`
- Adicionado `transcription_engine` ao schema `UrlHearingJobRequest`
- Adicionado `transcription_engine` ao config e chamada no endpoint `/hearing/jobs/url`

**Backend (`apps/api/app/services/transcription_service.py`):**
- Adicionado par√¢metro `transcription_engine: str = "whisper"` em `process_hearing_with_progress`
- Adicionada l√≥gica `_use_aai_hearing` para respeitar a escolha do usu√°rio
- Modificada condi√ß√£o para usar AAI apenas quando `_use_aai_hearing and aai_key`

### Comportamento Corrigido
- Motor de transcri√ß√£o agora √© selecion√°vel para apostilas, audi√™ncias e legendas
- A escolha do motor √© preservada ao trocar de tipo de transcri√ß√£o
- AssemblyAI s√≥ √© usado quando explicitamente selecionado pelo usu√°rio (n√£o mais como padr√£o autom√°tico)

### ElevenLabs para Legendas
- Adicionado `elevenlabs` como terceira op√ß√£o de motor de transcri√ß√£o
- Bot√£o ElevenLabs aparece apenas no modo Legendas (`isLegenda`)
- ElevenLabs Scribe v2 √© especializado em legendas com timestamps precisos
- Identifica√ß√£o autom√°tica de eventos sonoros (m√∫sica, aplausos, etc.)
- Fallback para AssemblyAI ‚Üí Whisper se ElevenLabs falhar

**Arquivos adicionais:**
- Atualizado tipo de `transcriptionEngine` para `'whisper' | 'assemblyai' | 'elevenlabs'`
- Atualizado `api-client.ts` para suportar `transcription_engine: 'elevenlabs'`
- Modificada l√≥gica em `transcription_service.py` para usar ElevenLabs apenas quando selecionado

---

## 2026-02-03 ‚Äî Sess√£o 101: Seletor de Motor de Transcri√ß√£o (Whisper vs AssemblyAI)

### Objetivo
Adicionar seletor na UI de apostilas para escolher entre Whisper (local) e AssemblyAI (nuvem) como motor de transcri√ß√£o.

### Arquivos Alterados

**Frontend:**
- `apps/web/src/app/(dashboard)/transcription/page.tsx`:
  - Estado `transcriptionEngine` ('whisper' | 'assemblyai')
  - UI toggle com bot√µes para selecionar motor
  - Popover explicativo das diferen√ßas
  - Desabilita "Alta Precis√£o" quando AssemblyAI selecionado
  - Passa `transcription_engine` no objeto `options`

**Backend - Schemas:**
- `apps/api/app/schemas/transcription.py`:
  - Tipo `TranscriptionEngineType = Literal["whisper", "assemblyai"]`
  - Campo `transcription_engine` em `TranscriptionRequest`

**Backend - Endpoints:**
- `apps/api/app/api/endpoints/transcription.py`:
  - `transcription_engine` em `UrlVomoJobRequest`
  - Par√¢metro Form em `/vomo/jobs`, `/vomo`, `/vomo/stream`, `/vomo/batch/stream`
  - Passa para service nas chamadas `process_file`, `process_file_with_progress`, `process_batch_with_progress`

**Backend - Service:**
- `apps/api/app/services/transcription_service.py`:
  - Par√¢metro `transcription_engine` em `process_file`, `process_file_with_progress`, `process_batch_with_progress`
  - L√≥gica `_engine_aai = transcription_engine == "assemblyai"` para for√ßar uso de AssemblyAI

### Comportamento
- Whisper (padr√£o): Processamento local no Mac via MLX, gratuito e privado
- AssemblyAI: API na nuvem, mais r√°pido para arquivos longos, custo por minuto
- Seletor vis√≠vel apenas para apostilas (modo `!isHearing`)

---

## 2026-02-03 ‚Äî Sess√£o 100: Speaker Identification por Nome/Papel (AssemblyAI)

### Objetivo
Implementar suporte completo ao Speaker Identification do AssemblyAI, permitindo identificar falantes por **nome** (ex: "Dr. Jo√£o Silva") ou **papel** (ex: "Juiz", "Advogado").

### Arquivos Alterados

**Backend:**
- `apps/api/app/schemas/transcription.py` ‚Äî campos `speaker_id_type` e `speaker_id_values`
- `apps/api/app/services/transcription_service.py` ‚Äî envio de `speech_understanding.speaker_identification` no payload
- `apps/api/app/api/endpoints/transcription.py` ‚Äî Form fields para receber os valores

**Frontend:**
- `apps/web/src/app/(dashboard)/transcription/page.tsx` ‚Äî toggle UI para escolher entre "Nome" e "Papel"
- `apps/web/src/lib/api-client.ts` ‚Äî tipos e envio dos par√¢metros

### Estrutura API AssemblyAI
```json
{
  "speech_understanding": {
    "request": {
      "speaker_identification": {
        "speaker_type": "role",
        "known_values": ["Juiz", "Advogado", "Testemunha"]
      }
    }
  }
}
```

### UI
Toggle na se√ß√£o "Participantes" permite escolher entre:
- **Papel**: Identifica por fun√ß√£o (Juiz, Advogado, Professor)
- **Nome**: Identifica por nome real (Dr. Jo√£o Silva, Maria Santos)

---

## 2026-02-03 ‚Äî Sess√£o 99: Chunking autom√°tico para √°udios longos (v2.32)

### Problema
Transcri√ß√£o de √°udio de ~5.6h (`12_Trabalho_Empresarial_Publico_Parte1e2.mp3`) retornou apenas pontos (`. . . .`) em vez de texto real. O MLX-Whisper degrada silenciosamente quando processa arquivos muito longos de uma vez.

### Diagn√≥stico
1. O arquivo de sa√≠da `_RAW.txt` continha apenas timestamps com pontua√ß√£o
2. Testei trechos individuais do mesmo arquivo - transcri√ß√£o funcionou perfeitamente a partir de 2min
3. O in√≠cio do arquivo tem pouca fala (aplausos/m√∫sica), mas isso n√£o explica a falha completa
4. **Causa raiz**: MLX-Whisper entra em estado de degrada√ß√£o com √°udios > 3-4h

### Solu√ß√£o Implementada
Adicionado chunking autom√°tico no `mlx_vomo.py` (v2.32):

1. **Novas constantes**:
   - `AUDIO_MAX_DURATION_SECONDS = 3 * 60 * 60` (3h)
   - `AUDIO_CHUNK_OVERLAP_SECONDS = 30`

2. **Novas fun√ß√µes**:
   - `_get_audio_duration()` - obt√©m dura√ß√£o via ffprobe
   - `_split_audio_into_chunks()` - divide √°udio longo em WAVs tempor√°rios
   - `_cleanup_audio_chunks()` - remove arquivos tempor√°rios
   - `_merge_chunk_segments()` - mescla segmentos removendo duplicatas do overlap
   - `_transcribe_chunked()` - orquestra transcri√ß√£o em chunks

3. **Modifica√ß√£o em `transcribe()`**:
   - Verifica dura√ß√£o do √°udio antes de processar
   - Se > 3h, redireciona para `_transcribe_chunked()`
   - Timestamps s√£o ajustados automaticamente para cada chunk

### Arquivos Alterados
- `mlx_vomo.py` ‚Äî chunking autom√°tico de √°udio longo

### Comandos Executados
- Testes de transcri√ß√£o em diferentes offsets do √°udio (OK)
- Verifica√ß√£o de importa√ß√£o do m√≥dulo (OK)

### Observa√ß√£o
Usu√°rio tamb√©m criou `scripts/transcribe_long_raw.py` como alternativa standalone para re-processar arquivos com problema.

---

## 2026-02-03 ‚Äî Sess√£o 98: Word-level timestamps para player interativo

### Objetivo
Implementar timestamps por palavra (word-level) no player de transcri√ß√£o, permitindo clicar em qualquer palavra para ir ao momento exato do √°udio.

### Arquitetura Implementada

**Backend (`transcription_service.py`):**
1. Modificado `_transcribe_with_progress_stream()` para usar `transcribe_file_full()`
2. Retorno agora √© `{text, words}` em vez de apenas `str`
3. Adicionado `transcription_words: list` para armazenar timestamps por palavra
4. `words` inclu√≠do no retorno de `process_file_with_progress()`

**mlx_vomo.py (j√° existente):**
- `transcribe_file_full()` retorna `{text, words, segments}`
- `words` √© lista de `{word, start, end, speaker}` para cada palavra

**Frontend (`transcription/page.tsx`):**
1. Novo estado: `transcriptionWords` para armazenar lista de words
2. Extra√ß√£o de `payload.words` nos handlers de resultado
3. Importa√ß√£o de `WordLevelTranscriptViewer`
4. Renderiza√ß√£o condicional: usa `WordLevelTranscriptViewer` quando `transcriptionWords.length > 0`

**Componente `WordLevelTranscriptViewer`:**
- Cada palavra √© clic√°vel e faz seek no √°udio
- Timestamps visuais a cada 60s (configur√°vel via `timestampInterval`)
- Highlighting da palavra ativa durante reprodu√ß√£o
- Auto-scroll para palavra em reprodu√ß√£o

### L√≥gica de Timestamps Visuais
| Modo | Intervalo |
|------|-----------|
| APOSTILA, FIDELIDADE | 60s |
| AUDIENCIA, REUNIAO, LEGENDA | 0 (por utterance) |

### Arquivos Alterados
- `apps/api/app/services/transcription_service.py`:
  - `_transcribe_with_progress_stream()`: usa `transcribe_file_full()`, retorna dict
  - `process_file_with_progress()`: retorna `words` no payload
- `apps/web/src/app/(dashboard)/transcription/page.tsx`:
  - Estado `transcriptionWords`
  - Extra√ß√£o de words do payload
  - Renderiza√ß√£o condicional com `WordLevelTranscriptViewer`

### Compatibilidade
- Retrocompat√≠vel: `SyncedTranscriptViewer` usado quando `words` n√£o dispon√≠vel
- Frontend detecta automaticamente qual viewer usar

---

## 2026-02-03 ‚Äî Sess√£o 97: Progresso tqdm + Otimiza√ß√£o de √°udio para cloud

### Parte 1: Progresso tqdm na UI

**Problema:** Usu√°rio n√£o via progresso detalhado do tqdm na UI durante transcri√ß√µes.

**Causa Raiz:** tqdm escreve diretamente no file descriptor stderr, n√£o passa por `sys.stderr` do Python.

**Solu√ß√£o:** Reescrita de `_transcribe_with_progress_stream` usando `os.pipe()` + `os.dup2()` para interceptar fd 2.

### Parte 2: Otimiza√ß√£o de √°udio para AssemblyAI

**Problema:** Upload de WAV 16kHz para AssemblyAI era lento (690MB para 6h de √°udio).

**An√°lise de Tamanhos (6h de √°udio):**
| Formato | Tamanho | Upload |
|---------|---------|--------|
| WAV 16kHz (atual) | ~690MB | Lento |
| **MP3 64kbps (novo)** | ~173MB | **4x mais r√°pido** |
| V√≠deo original MP4 | 2-8GB | Muito lento |

**Solu√ß√£o:** Novas fun√ß√µes para extra√ß√£o otimizada:
1. `_extract_audio_for_cloud()` - Extrai MP3 64kbps mono para upload
2. `_should_extract_audio_for_cloud()` - Decide quando extrair:
   - V√≠deos: sempre extrair (descarta dados de v√≠deo)
   - Arquivos > 2GB: obrigat√≥rio (limite AssemblyAI = 2.2GB)
   - √Åudios lossless > 100MB: extrair compactado
   - √Åudios compactos: enviar direto

### Arquivos Alterados
- `apps/api/app/services/transcription_service.py`:
  - `_transcribe_with_progress_stream`: reescrita com fd redirect
  - `_extract_audio_for_cloud`: nova fun√ß√£o para MP3 64kbps
  - `_should_extract_audio_for_cloud`: l√≥gica de decis√£o
  - Chamadas AAI/ElevenLabs: agora usam `cloud_audio_path`

### Impacto
- **Upload 4x mais r√°pido** para AssemblyAI (173MB vs 690MB para 6h)
- **Progresso detalhado na UI** durante transcri√ß√µes locais

---

## 2026-02-03 ‚Äî Sess√£o 96: Fix √¢ncoras fake no mlx_vomo.py (v2.33)

### Problema
O Vertex AI estava gerando √¢ncoras ABRE/FECHA usando os **t√≠tulos** dos t√≥picos em vez de **cita√ß√µes verbatim** do texto da transcri√ß√£o. Resultado: 0% de cobertura de √¢ncoras.

### Causa Raiz
O modelo n√£o seguia a instru√ß√£o de copiar frases literais do texto. Gerava:
```
1. Credenciamento | ABRE: "O Credenciamento na Nova Lei" | FECHA: "..."
```
Quando deveria gerar:
```
1. Credenciamento | ABRE: "bom dia pessoal vamos falar sobre o credenciamento" | FECHA: "..."
```

### Solu√ß√£o (v2.33)
Adicionadas 2 fun√ß√µes em [mlx_vomo.py](mlx_vomo.py):

1. **`_similaridade_palavras(a, b)`**: Calcula overlap de palavras entre dois textos (Jaccard). Se > 60%, √¢ncora √© "fake".

2. **`_buscar_ancora_no_texto(texto, titulo, transcricao)`**: Fallback inteligente com 3 estrat√©gias:
   - Busca sequ√™ncia de 2-3 palavras-chave do t√≠tulo
   - Busca frases de transi√ß√£o ("vamos agora", "passemos para") + palavra-chave
   - Busca apenas a palavra mais significativa do t√≠tulo

### Fluxo Corrigido
```
1. Extrai √¢ncora ABRE do modelo
2. Calcula similaridade com t√≠tulo
3. Se > 60%: marca como "fake", pula busca direta
4. Tenta fallback inteligente no texto real
5. Se encontrar: usa como ponto de corte
```

### Arquivos Alterados
- `mlx_vomo.py` ‚Äî fun√ß√µes `_similaridade_palavras`, `_buscar_ancora_no_texto`, l√≥gica em `dividir_sequencial`

### Output Esperado
```
‚ö†Ô∏è  √Çncora fake detectada (sim=85%): 'introdu√ß√£o aos procedimentos...'
üîç √Çncora via busca por t√≠tulo: 'Introdu√ß√£o aos Procedimentos...' @ 1234
```

---

## 2026-02-03 ‚Äî Sess√£o 95: Area e KeyTerms para AssemblyAI (Unificado)

### Objetivo
Implementar suporte a `area` (√°rea de conhecimento) e `custom_keyterms` (termos espec√≠ficos) para melhorar a transcri√ß√£o ASR via AssemblyAI, com arquitetura unificada.

### Arquitetura Escolhida
Fun√ß√£o `_get_assemblyai_prompt_for_mode` retorna tupla `(prompt, keyterms)` unificando:
- Prompt de texto para o modelo
- Lista de keyterms por √°rea + custom do usu√°rio

### Arquivos Alterados
- `apps/api/app/schemas/transcription.py`
  - `AreaType = Literal["juridico", "medicina", "ti", "engenharia", "financeiro", "geral"]`
  - Campos `area` e `custom_keyterms` em `TranscriptionRequest` e `HearingTranscriptionRequest`

- `apps/api/app/services/transcription_service.py`
  - `AREA_KEYTERMS`: dicion√°rio com termos espec√≠ficos por √°rea (classe)
  - `_get_assemblyai_prompt_for_mode`: **refatorado** para retornar `tuple[str, list[str]]`
    - Aceita `area` e `custom_keyterms`
    - Combina keyterms da √°rea + custom (limite 200)
    - Prompts focados em transcri√ß√£o bruta fiel
  - `_transcribe_assemblyai_with_progress`: aceita `area`, `custom_keyterms`, passa keyterms no payload
  - `_transcribe_assemblyai_with_roles`: aceita `area`, `custom_keyterms`, passa keyterms no payload
  - `_run_assemblyai_transcription`: usa SDK com `keyterms_prompt` (l√≥gica pr√≥pria)
  - `process_file` e `process_file_with_progress`: aceitam `area` e `custom_keyterms`

- `apps/api/app/api/endpoints/transcription.py`
  - `transcribe_vomo`, `transcribe_vomo_stream`, `create_vomo_job`: aceitam e passam `area` e `custom_keyterms`

### Fluxo de Dados
```
UI ‚Üí Form(area, custom_keyterms)
    ‚Üí Endpoint (parsing)
    ‚Üí Service.process_file_with_progress(area, custom_keyterms)
    ‚Üí _get_assemblyai_prompt_for_mode(area, custom_keyterms)
    ‚Üí (prompt, keyterms)
    ‚Üí REST API: {prompt, keyterms_prompt}
```

### Benef√≠cios da Arquitetura Unificada
- **Encapsulamento**: toda l√≥gica de prompt/keyterms em 1 fun√ß√£o
- **Reutiliza√ß√£o**: qualquer m√©todo pode usar a mesma fun√ß√£o
- **Testabilidade**: f√°cil testar unitariamente
- **Manuten√ß√£o**: mudan√ßas centralizadas

---

## 2026-02-03 ‚Äî Sess√£o 94: Fix Timestamps AssemblyAI por Modo

### Problema
AssemblyAI retornava apenas 1 utterance para √°udios single-speaker, perdendo granularidade de timestamps.

### Solu√ß√£o
- Quando `len(utterances) <= 2 and len(words) > 50`, usa `words` para construir segmentos
- Intervalos controlados por `_get_timestamp_interval_for_mode()`:
  - **APOSTILA/FIDELIDADE**: 60s (√°udios de aula)
  - **REUNIAO/AUDIENCIA/FILME**: 0 (por utterance/speaker)

### Arquivos Alterados
- `apps/api/app/services/transcription_service.py` ‚Äî l√≥gica de agrupamento de words (linhas 1280-1318)

---

## 2026-02-03 ‚Äî Sess√£o 93: Whisper Prim√°rio para Aulas/Apostilas

### Objetivo
Configurar Whisper como provedor de transcri√ß√£o prim√°rio para modos APOSTILA e FIDELIDADE (aulas).

### Mudan√ßa Implementada
Modificada a l√≥gica de sele√ß√£o do provedor em `transcription_service.py`:

**Antes**: AAI era usado como prim√°rio quando havia `speaker_roles` e `diarization` habilitados, independente do modo.

**Depois**: Para modos APOSTILA e FIDELIDADE, Whisper √© SEMPRE o prim√°rio, mesmo com speaker_roles e diarization. AAI prim√°rio agora s√≥ se aplica a AUDIENCIA e REUNIAO.

### Arquivos Alterados
- `apps/api/app/services/transcription_service.py`
  - Adicionada condi√ß√£o `_mode_upper not in ("APOSTILA", "FIDELIDADE")` na l√≥gica de `_aai_primary`
  - Mesma mudan√ßa aplicada ao fluxo SSE (`_aai_primary_sse`)
  - Atualizadas mensagens de log para refletir que AAI prim√°rio √© para audi√™ncia/reuni√£o

### L√≥gica Atual de Sele√ß√£o
```
1. ElevenLabs prim√°rio: subtitle_format + ElevenLabs key
2. AAI prim√°rio: diariza√ß√£o + speaker_roles + AAI key + modo ‚â† APOSTILA/FIDELIDADE
3. Whisper prim√°rio (padr√£o): todos os outros casos (incluindo APOSTILA/FIDELIDADE)
```

---

## 2026-02-03 ‚Äî Sess√£o 92: Corre√ß√£o de Alucina√ß√µes na Auditoria de Fidelidade

### Objetivo
Corrigir falsos positivos na auditoria de fidelidade que incorretamente identificava nomes de pessoas como "alucina√ß√µes" quando eles existiam no RAW completo mas em chunks diferentes.

### Problema Identificado
A auditoria de fidelidade (`audit_fidelity_preventive.py`) estava reportando que "Nelson Rosenwald" era uma alucina√ß√£o adicionada ao texto formatado, quando na verdade o nome existia no RAW original. Isso ocorria porque:
1. O sistema divide RAW e formatado em chunks proporcionais para an√°lise
2. O LLM analisa cada par de chunks separadamente
3. Se um nome aparece em um chunk do formatado mas o chunk correspondente do RAW n√£o cont√©m esse nome (porque est√° em outro lugar), o LLM erroneamente reporta como alucina√ß√£o

### Solu√ß√£o Implementada (Camada 1: Gera√ß√£o)
Adicionadas duas novas fun√ß√µes em `audit_fidelity_preventive.py`:

#### 1. `_extract_names_from_text(text: str) -> set`
- Extrai nomes pr√≥prios (sequ√™ncias de 2+ palavras capitalizadas)
- Usado para identificar nomes em textos

#### 2. `_filter_hallucination_false_positives(raw_text: str, alucinacoes: list) -> list`
- Verifica se os nomes/trechos reportados como alucina√ß√µes existem no RAW completo
- Remove falsos positivos causados por chunk boundaries
- Reduz confian√ßa de itens suspeitos ao inv√©s de remov√™-los completamente

### Solu√ß√£o Implementada (Camada 2: Consolida√ß√£o)
Adicionada valida√ß√£o extra em `fidelity_matcher.py` e `audit_pipeline.py`:

#### 3. `FidelityMatcher.validate_hallucination_issue()` (fidelity_matcher.py)
- M√©todo espec√≠fico para validar alucina√ß√µes de nomes/autores
- Verifica se trecho exato existe no RAW
- Extrai e verifica nomes pr√≥prios no RAW completo
- Verifica palavras-chave significativas (70%+ presentes = falso positivo)

#### 4. Integra√ß√£o no audit_pipeline.py
- Issues de categoria "alucinacao" agora usam `validate_hallucination_issue()` ao inv√©s de `validate_issue()`
- Garante dupla valida√ß√£o: na gera√ß√£o (preventiva) e na consolida√ß√£o (pipeline)

### Pipeline de Auditoria Mapeado
```
1. Gera√ß√£o (mlx_vomo.py ‚Üí audit_fidelity_preventive.py)
   ‚îî‚îÄ‚îÄ Auditoria preventiva por chunks + filtro de falsos positivos

2. Processamento (transcription_service.py)
   ‚îî‚îÄ‚îÄ quality_service.validate_document_full() ‚Üí validation_report
   ‚îî‚îÄ‚îÄ quality_service.analyze_structural_issues() ‚Üí analysis_result

3. Consolida√ß√£o (audit_pipeline.py)
   ‚îî‚îÄ‚îÄ PreventiveFidelityPlugin + ValidationPlugin + StructuralAnalysisPlugin
   ‚îî‚îÄ‚îÄ FidelityMatcher valida issues (refer√™ncias legais + nomes)
   ‚îî‚îÄ‚îÄ Salva audit_summary.json

4. UI (quality-panel.tsx)
   ‚îî‚îÄ‚îÄ Exibe score, omissions, distortions, observations
```

### Arquivos Alterados
- `audit_fidelity_preventive.py` ‚Äî Filtro de alucina√ß√µes na gera√ß√£o
- `fidelity_matcher.py` ‚Äî Novo m√©todo `validate_hallucination_issue()`
- `audit_pipeline.py` ‚Äî Integra√ß√£o do novo m√©todo para alucina√ß√µes

### Comandos Executados
- `python3 -c "import audit_fidelity_preventive"` ‚Äî OK
- `python3 -c "from app.services.fidelity_matcher import FidelityMatcher; from app.services.audit_pipeline import run_audit_pipeline"` ‚Äî OK

### Verifica√ß√µes
- Confirmado que "Nelson Rosenwald" existe 1x no raw.txt
- Dados de qualidade exibidos corretamente na aba "Qualidade (Resumo)"
- Fluxo completo RAW vs formatado funcionando em todas as camadas

### Problema de Desconex√£o Identificado e Corrigido

**Diagn√≥stico:**
Quando o documento √© revalidado (ap√≥s aplicar corre√ß√µes), a UI mostrava score atualizado (8.46), mas os arquivos de auditoria mantinham o score original (5.44).

| Fonte | Score | Status |
|-------|-------|--------|
| result.json (UI) | 8.46 | Atualizado ap√≥s revalida√ß√£o |
| audit_summary.json | 5.44 | N√ÉO atualizado |
| _FIDELIDADE.json | 5.44 | N√ÉO atualizado |

**Corre√ß√£o em** `transcription.py`:
Ap√≥s revalida√ß√£o bem-sucedida, agora sincroniza automaticamente:
1. `_FIDELIDADE.json` ‚Äî atualizado com dados do novo `validation_report`
2. `audit_summary.json` ‚Äî atualizado com novo score e timestamp de revalida√ß√£o

### Arquivos Adicionais Alterados
- `apps/api/app/api/endpoints/transcription.py` ‚Äî Sincroniza√ß√£o de arquivos de auditoria ap√≥s revalida√ß√£o

---

## 2026-02-03 ‚Äî Sess√£o 91: Corre√ß√£o de Contraste Dark Mode

### Objetivo
Corrigir problemas de contraste no tema escuro onde v√°rios widgets e p√°ginas ainda mostravam fundos claros.

### Mudan√ßas Realizadas

#### 1. globals.css ‚Äî Classes CSS com variantes `dark:`
- `.chat-markdown` ‚Äî texto, blockquote, tabelas, links, cita√ß√µes
- `.ProseMirror` e `.editor-output` ‚Äî texto, code, blockquote, tabelas
- `.tiptap-*` ‚Äî code blocks, mermaid blocks
- `.doc-theme-classic`, `.doc-theme-minimal`, `.doc-theme-executive`, `.doc-theme-academic`
- `.table-style-*` ‚Äî compact, grid, minimal, zebra
- `.panel-card` ‚Äî borda

#### 2. chat-message.tsx ‚Äî Bal√µes de Chat
- Avatar do bot: `bg-white dark:bg-slate-800`
- Bubble do usu√°rio: gradiente `from-slate-800 to-slate-900` em dark
- Bubble do bot: `bg-white dark:bg-slate-900`
- Labels de modelo e badges
- Bot√µes de a√ß√£o (copiar, regerar)

#### 3. minuta/page.tsx ‚Äî Toolbar e Pain√©is
- Toolbar colaps√°vel: `bg-white/90 dark:bg-slate-900/90`
- Bot√µes de modo: active states com `dark:bg-slate-700`
- Settings toggle: `dark:bg-slate-800` quando ativo
- Painel de chat: `bg-white/50 dark:bg-slate-900/50`
- Painel canvas: `bg-white dark:bg-slate-900`
- Divider de resize: `dark:before:bg-slate-700/80`
- Bot√µes de sugest√£o e RAG scope

### Arquivos Alterados
- `src/styles/globals.css` ‚Äî ~50 regras CSS com dark: variants
- `src/components/chat/chat-message.tsx` ‚Äî avatars, bubbles, badges, buttons
- `src/app/(dashboard)/minuta/page.tsx` ‚Äî toolbar, pain√©is, bot√µes

### Comandos Executados
- `npm run lint` ‚Äî OK
- `npm run type-check` ‚Äî OK

---

## 2026-02-03 ‚Äî Sess√£o 90: Remo√ß√£o de Chips Superiores do Chat

### Objetivo
Remover elementos redundantes da parte superior do chat input para simplificar a UI.

### Mudan√ßas Realizadas

#### Elementos Removidos (`chat-input.tsx`)
- Chip "Anexos Auto (count)"
- Bot√£o toggle "Web"
- Bot√£o toggle "Deep research"
- Bot√£o toggle "MCP"
- Campo "Objetivo" (input de tese)

#### Limpeza de C√≥digo
- Removidas vari√°veis n√£o utilizadas: `contextChipBase`, `contextChipActive`, `contextChipInactive`

### Arquivos Alterados
- `src/components/chat/chat-input.tsx`

### Comandos Executados
- `npm run lint` ‚Äî OK
- `npm run type-check` ‚Äî OK

---

## 2026-02-03 ‚Äî Sess√£o 89: Toolbar Colaps√°vel + Dropdown Menu

### Objetivo
Otimizar o layout da p√°gina de minutas para gerar mais espa√ßo √∫til para chat e canvas, sem perder funcionalidades.

### Mudan√ßas Realizadas

#### 1. Toolbar Colaps√°vel (`minuta/page.tsx`)
- Adicionado estado `toolbarCollapsed` para controlar modo da toolbar
- **Modo expandido**: Mostra toggle de modo, playbook, layout, gerar, configura√ß√µes e menu "..."
- **Modo colapsado**: Mostra apenas t√≠tulo, bot√£o configura√ß√µes e bot√£o gerar (~28px altura)
- Economia de ~20-30px de espa√ßo vertical quando colapsado

#### 2. Dropdown Menu para A√ß√µes Secund√°rias
- Importados componentes DropdownMenu do shadcn/ui
- A√ß√µes movidas para dropdown "...":
  - Auditoria
  - Nova Minuta
  - Tela Cheia
  - Minimizar/Expandir Toolbar

#### 3. Remo√ß√£o de Override no Chat Input
- Removidas se√ß√µes "Racioc√≠nio (override)" e "Verbosidade (override)"
- Controles agora centralizados apenas no drawer de configura√ß√µes

### Arquivos Alterados
- `src/app/(dashboard)/minuta/page.tsx` ‚Äî toolbar colaps√°vel + dropdown
- `src/components/chat/chat-input.tsx` ‚Äî remo√ß√£o de overrides

### Novos Imports
```typescript
import { MoreHorizontal, PanelTopClose, PanelTop } from 'lucide-react';
import { DropdownMenu, DropdownMenuContent, DropdownMenuItem, DropdownMenuSeparator, DropdownMenuTrigger } from '@/components/ui/dropdown-menu';
```

### Comandos Executados
- `npm run lint` ‚Äî OK
- `npm run type-check` ‚Äî OK

---

## 2026-02-03 ‚Äî Sess√£o 88: Restaura√ß√£o N√≠vel de Racioc√≠nio no Drawer

### Objetivo
Restaurar "N√≠vel de Racioc√≠nio" (R√°pido/M√©dio/Profundo) no drawer de configura√ß√µes, mantendo no chat-input como override.

### Mudan√ßas Realizadas

#### 1. Drawer (`minuta-settings-drawer.tsx`)
- Adicionadas props `reasoningLevel` e `setReasoningLevel`
- Adicionada se√ß√£o "N√≠vel de Racioc√≠nio" na √°rea de Qualidade (cor violeta)
- Atualizado `qualitySummary` para incluir o n√≠vel de racioc√≠nio

#### 2. P√°gina Minuta (`minuta/page.tsx`)
- Passadas props `reasoningLevel` e `setReasoningLevel` ao drawer

#### 3. Chat Input (`chat-input.tsx`)
- Mantida se√ß√£o de "Racioc√≠nio" mas renomeada para "Racioc√≠nio (override)"
- Adicionada indica√ß√£o "Sobrescreve config"
- Cor alterada para violeta (consistente com drawer)
- "Verbosidade" tamb√©m marcada como override

### Arquivos Alterados
- `src/components/dashboard/minuta-settings-drawer.tsx`
- `src/app/(dashboard)/minuta/page.tsx`
- `src/components/chat/chat-input.tsx`

### Fluxo
1. Usu√°rio define padr√£o no drawer de configura√ß√µes
2. Pode sobrescrever temporariamente no chat-input (popover ADV)

### Comandos Executados
- `npm run lint` ‚Äî OK
- `npm run type-check` ‚Äî OK

---

## 2026-02-03 ‚Äî Sess√£o 87: Simplifica√ß√£o UI Anexos no Contexto

### Objetivo
Remover op√ß√µes manuais de "Anexos no contexto" do chat-input, j√° que a l√≥gica autom√°tica (`resolveAutoAttachmentMode`) foi implementada na Sess√£o 85.

### Mudan√ßas Realizadas

#### 1. Remo√ß√£o de UI Manual de Anexos
- Removido toggle "Auto/Avan√ßado"
- Removidas op√ß√µes manuais "RAG Local" e "Inje√ß√£o direta"
- Mantida apenas indica√ß√£o visual de "Auto" com explica√ß√£o
- Mantidos os limites informativos por modelo

#### 2. Simplifica√ß√£o do Chip de Anexos
- Bot√£o que mudava modo para `rag_local` convertido em span informativo
- Label fixo "Anexos Auto" em vez de din√¢mico

#### 3. Limpeza de C√≥digo
- Removido state `attachmentAdvanced` (n√£o mais usado)
- Removido `setAttachmentMode` das importa√ß√µes do store

### Arquivos Alterados
- `src/components/chat/chat-input.tsx` ‚Äî simplifica√ß√£o da se√ß√£o de anexos

### L√≥gica Mantida
A fun√ß√£o `resolveAutoAttachmentMode()` em `attachment-limits.ts` continua funcionando:
- Modelos ‚â•500K tokens + ‚â§10 arquivos ‚Üí inje√ß√£o direta
- Modelos ‚â•200K tokens + ‚â§5 arquivos ‚Üí inje√ß√£o direta
- Caso contr√°rio ‚Üí RAG local

### Comandos Executados
- `npm run lint` ‚Äî OK
- `npm run type-check` ‚Äî OK

---

## 2026-02-03 ‚Äî Sess√£o 86: Verifica√ß√£o de Work ChatGPT + Corre√ß√£o de Todos Lint Warnings

### Objetivo
1. Verificar trabalho realizado pelo ChatGPT (E2E tests, lint fixes, type fixes)
2. Corrigir TODOS os warnings de lint restantes

### Mudan√ßas Realizadas

#### 1. Corre√ß√£o de Lint Warnings
- `vorbium-nav.tsx` ‚Äî Substitu√≠do `<img>` por `<Image>` do Next.js com `unoptimized` prop
- `use-vorbium-paint.ts` ‚Äî J√° havia sido corrigido para remover `any` cast no ctxOptions

#### 2. Corre√ß√£o de Erros de Tipo
- `use-vorbium-paint.ts` ‚Äî Adicionado guard `|| !ctx` no in√≠cio da fun√ß√£o `frame()` para narrowing de tipo

### Arquivos Alterados
- `src/components/vorbium/vorbium-nav.tsx` ‚Äî Image do Next.js
- `src/hooks/use-vorbium-paint.ts` ‚Äî null check em frame()

### Comandos Executados
- `npm run lint` ‚Äî OK (0 erros, 0 warnings)
- `npm run type-check` ‚Äî OK
- `npx playwright test` ‚Äî OK (5/5 testes passaram)

### Status Final
| Check | Resultado |
|-------|-----------|
| Lint | ‚úÖ 0 erros, 0 warnings |
| Type-check | ‚úÖ Passa |
| E2E Tests | ‚úÖ 5/5 passaram |

---

## 2026-02-03 ‚Äî Sess√£o 85: Unifica√ß√£o de Configura√ß√µes da Minuta + Auto Attachment Mode

### Objetivo
1. Remover redund√¢ncias nas configura√ß√µes da p√°gina de minuta (drawer)
2. Implementar l√≥gica autom√°tica de decis√£o entre inje√ß√£o direta e RAG para anexos

### Mudan√ßas Realizadas

#### 1. Remo√ß√£o de "N√≠vel de Racioc√≠nio" do Drawer
- Removida prop `reasoningLevel` e `setReasoningLevel` de `MinutaSettingsDrawerProps`
- Removido bloco de UI "N√≠vel de Racioc√≠nio" (R√°pido/M√©dio/Profundo) da se√ß√£o Qualidade
- Removidas props passadas ao drawer em `minuta/page.tsx`

**Motivo:** Cada modelo tem seus pr√≥prios par√¢metros espec√≠ficos (Thinking Level para Gemini, Reasoning Effort para GPT, Thinking Budget para Claude) que s√£o configurados no popover "ADV" do chat-input.

#### 2. Implementa√ß√£o de Auto Attachment Mode
- Criada fun√ß√£o `resolveAutoAttachmentMode()` em `attachment-limits.ts`
- Integrada em todos os 5 pontos do `chat-store.ts` onde `attachment_mode` √© enviado ao backend

**L√≥gica de Decis√£o:**
- Modelos com contexto ‚â•500K tokens + ‚â§10 arquivos ‚Üí inje√ß√£o direta
- Modelos com contexto ‚â•200K tokens + ‚â§5 arquivos ‚Üí inje√ß√£o direta
- Caso contr√°rio ‚Üí RAG local (mais seguro para precis√£o e custo)

### Arquivos Alterados
- `src/components/dashboard/minuta-settings-drawer.tsx` ‚Äî removido reasoningLevel
- `src/app/(dashboard)/minuta/page.tsx` ‚Äî removidas props reasoningLevel
- `src/lib/attachment-limits.ts` ‚Äî adicionada fun√ß√£o resolveAutoAttachmentMode
- `src/stores/chat-store.ts` ‚Äî integra√ß√£o da l√≥gica em 5 pontos de envio

### Comandos Executados
- `rm -rf .next` ‚Äî limpeza de cache
- `npx tsc --noEmit` ‚Äî verifica√ß√£o de tipos (OK)

---

## 2026-02-03 ‚Äî Sess√£o 84: Fix 422 Error on Transcription File Upload

### Objetivo
Corrigir erro 422 "Unprocessable Entity" quando usu√°rio tenta transcrever arquivos no modo apostila.

### Problema Identificado
O axios estava configurado com `Content-Type: application/json` como header padr√£o. Quando enviando FormData, esse header sobrescrevia o content-type correto (`multipart/form-data` com boundary), causando o FastAPI a n√£o reconhecer os arquivos.

### Corre√ß√£o Aplicada
Adicionado `headers: { 'Content-Type': undefined }` em todas as chamadas axios.post que usam FormData para permitir que o axios defina automaticamente o content-type correto.

### Arquivos Alterados
- `apps/web/src/lib/api-client.ts`:
  - `startTranscriptionJob()` ‚Äî adicionado Content-Type: undefined
  - `startHearingJob()` ‚Äî adicionado Content-Type: undefined
  - `uploadDocumentFromUrl()` ‚Äî adicionado Content-Type: undefined
  - `indexDocuments()` ‚Äî adicionado Content-Type: undefined
  - `extractTemplateVariables()` ‚Äî adicionado Content-Type: undefined
  - `applyTemplate()` ‚Äî adicionado Content-Type: undefined
  - `/transcription/vomo` endpoint ‚Äî adicionado Content-Type: undefined

- `apps/web/src/app/(dashboard)/transcription/page.tsx`:
  - Adicionado logs de debug para rastrear arquivos sendo enviados

- `apps/web/src/app/api/[...path]/route.ts`:
  - Adicionado log do Content-Type no proxy para debug

### Li√ß√£o Aprendida
Quando axios √© configurado com um Content-Type padr√£o no construtor, esse header √© enviado mesmo para FormData, corrompendo o multipart/form-data. A solu√ß√£o √© definir explicitamente `Content-Type: undefined` em chamadas que usam FormData.

---

## 2026-02-03 ‚Äî Sessao 83: Frontend UI for Review Tables (Dynamic Columns, Ask Table, Cell Verification)

### Objetivo
Implementar a interface frontend completa para Review Tables, incluindo Dynamic Columns, Ask Table (chat), Cell Verification com indicadores de confianca, e tabela virtual para suporte a 2000+ documentos.

### Arquivos Criados

**Tipos TypeScript:**
- `apps/web/src/types/review-table.ts`:
  - Tipos para DynamicColumn, CellExtraction, ReviewTable, ExtractionJob
  - Enums ExtractionType, CellStatus, JobStatus, FilterOperator
  - Interfaces para AskTable (chat), VerificationStats, FilterValue
  - Estado completo ReviewTableState para a store

**Store Zustand:**
- `apps/web/src/stores/review-table-store.ts`:
  - Estado centralizado para tabela, colunas, celulas, documentos
  - UI state: visibleColumns, sortColumn, filters, showVerifiedOnly
  - Actions: loadTable, addColumn, updateCell, setFilter, etc.
  - Getters computados: getFilteredDocuments, getSortedDocuments, getVisibleColumns

**Componentes de Review Tables:**
- `apps/web/src/components/review-tables/table-cell.tsx`:
  - Indicador de confianca color-coded (verde >0.8, amarelo 0.5-0.8, vermelho <0.5)
  - Badge de verificacao, modo de edicao para correcoes
  - Popover com fonte, acoes de verificar/corrigir

- `apps/web/src/components/review-tables/column-builder-modal.tsx`:
  - Input de linguagem natural para prompt de extracao
  - Preview em documento de amostra
  - Seletor de tipo de extracao (text, number, date, boolean, currency, list, entity)
  - Sugestoes de perguntas pre-definidas

- `apps/web/src/components/review-tables/ask-table-drawer.tsx`:
  - Interface de chat similar ao chat principal
  - Sugestoes dinamicas baseadas nas colunas
  - Display estruturado (tabelas, listas, charts)
  - Referencias a documentos nas respostas

- `apps/web/src/components/review-tables/manage-columns-panel.tsx`:
  - Lista de colunas com drag-to-reorder
  - Toggle show/hide por coluna
  - Acoes: reprocessar, excluir coluna

- `apps/web/src/components/review-tables/verification-stats.tsx`:
  - Barra de progresso de verificacao
  - Contadores: verificadas, pendentes, baixa confianca
  - Filtros rapidos por status

- `apps/web/src/components/review-tables/extraction-progress.tsx`:
  - Progress bar com percentual e ETA
  - Botoes pause/resume/cancel
  - Lista de erros expansivel
  - Polling automatico de status

- `apps/web/src/components/review-tables/virtual-table.tsx`:
  - Virtualizacao para 2000+ linhas (ROW_HEIGHT=48, OVERSCAN=5)
  - Scroll horizontal para muitas colunas
  - Selecao de linhas com checkbox
  - Ordenacao por clique no header

**Paginas:**
- `apps/web/src/app/(dashboard)/review-tables/page.tsx`:
  - Lista de tabelas com cards
  - Criar nova tabela (dialog)
  - Busca/filtro, delete com confirmacao

- `apps/web/src/app/(dashboard)/review-tables/[id]/page.tsx`:
  - Toolbar: Ask Table, Nova Coluna, filtros, export
  - Dropdown de colunas visiveis
  - VerificationStats bar
  - ExtractionProgress quando job ativo
  - VirtualTable como componente principal

**UI Components adicionados:**
- `apps/web/src/components/ui/separator.tsx`
- `apps/web/src/components/ui/collapsible.tsx`

**API Client:**
- `apps/web/src/lib/api-client.ts`: +50 metodos adicionados
  - Review Tables: get, list, create, delete
  - Dynamic Columns: create, list, update, delete, reprocess, reorder, preview
  - Cells: get, verify, bulkVerify, getLowConfidence
  - Ask Table: ask, getChatHistory, clearHistory
  - Extraction Jobs: start, get, list, pause, resume, cancel
  - Export: CSV, XLSX, JSON

### Comandos Executados
- `npm install @radix-ui/react-separator` ‚Äî OK
- `npm run lint` ‚Äî OK (apenas warnings pre-existentes)
- `npm run type-check` ‚Äî OK

### Decisoes Tecnicas
1. Virtualizacao manual com CSS (ROW_HEIGHT constante) para evitar dependencia extra
2. Store Zustand com Map para celulas (key: `${docId}:${colId}`) para acesso O(1)
3. Polling de job status a cada 2s durante extracao
4. Filtros aplicados no frontend para responsividade

### Performance
- VirtualTable renderiza apenas ~20 linhas visiveis + 5 overscan
- Scroll suave com spacers virtuais
- Celulas carregadas em background apos load inicial

---

## 2026-02-03 ‚Äî Sessao 82: Scalable Batch Processing for 2000+ Documents

### Objetivo
Implementar processamento em lote escalavel para Review Tables que suporte 2000+ documentos, com job queue assincrono, tracking de progresso, pause/resume e retry com backoff exponencial.

### Arquivos Criados
- `apps/api/app/models/extraction_job.py`:
  - `ExtractionJobStatus` enum: pending, running, paused, completed, failed, cancelled
  - `ExtractionJobType` enum: full_extraction, column_extraction, reprocess, incremental
  - `DocumentExtractionStatus` enum: pending, queued, processing, completed, failed, skipped
  - `ExtractionJob` model: Job de extracao em lote com tracking de progresso
    - `total_documents`, `processed_documents`, `failed_documents`, `skipped_documents`
    - `progress_percent`, `documents_per_second` para rate tracking
    - `started_at`, `completed_at`, `paused_at` para timing
    - `max_concurrent`, `batch_size`, `max_retries` para configuracao
    - Property `estimated_time_remaining` para ETA
    - Property `can_resume` para verificar se pode retomar
  - `ExtractionJobDocument` model: Status por documento
    - `retry_count`, `next_retry_at` para backoff exponencial
    - `processing_time_ms`, `queue_position`

- `apps/api/app/services/batch_extraction_service.py`:
  - `BatchExtractionService` com metodos:
    - `create_extraction_job()` ‚Äî Cria job e enfileira documentos
    - `process_job()` ‚Äî Loop principal de processamento com semaphore
    - `_process_documents()` ‚Äî Processa documentos em batches
    - `_process_single_document()` ‚Äî Extracao individual com retry
    - `_extract_row_with_retry()` ‚Äî Extrai todas colunas em paralelo
    - `pause_job()`, `resume_job()`, `cancel_job()` ‚Äî Controle de job
    - `get_job_progress()` ‚Äî Progresso detalhado com status por documento
    - `list_jobs_for_table()` ‚Äî Listar jobs de uma tabela
    - `get_next_pending_job()` ‚Äî Para worker background
  - Constantes: MAX_CONCURRENT=10, BATCH_SIZE=50, MAX_RETRIES=3
  - Backoff exponencial: base 5s, max 5min

- `apps/api/app/workers/tasks/extraction_tasks.py`:
  - `process_extraction_job_task` ‚Äî Celery task para processamento
  - `start_extraction_job_task` ‚Äî Celery task para criar e iniciar job
  - `ExtractionWorker` class ‚Äî Worker async alternativo ao Celery
  - `process_job_background()` ‚Äî Para FastAPI BackgroundTasks

- `apps/api/app/api/endpoints/extraction_jobs.py`:
  - Schemas: StartExtractionRequest, ExtractionJobResponse, JobProgressResponse, JobListResponse
  - Endpoints (prefix /review-tables):
    - `POST /{table_id}/extract` ‚Äî Iniciar job de extracao
    - `GET /{table_id}/jobs` ‚Äî Listar jobs
    - `GET /{table_id}/jobs/{job_id}` ‚Äî Detalhes do job
    - `GET /{table_id}/jobs/{job_id}/progress` ‚Äî Progresso detalhado
    - `POST /{table_id}/jobs/{job_id}/pause` ‚Äî Pausar job
    - `POST /{table_id}/jobs/{job_id}/resume` ‚Äî Retomar job
    - `POST /{table_id}/jobs/{job_id}/cancel` ‚Äî Cancelar job
    - `GET /{table_id}/jobs/{job_id}/stream` ‚Äî SSE para progresso em tempo real

- `apps/api/alembic/versions/x6y7z8a9b0c1_add_extraction_jobs_tables.py`:
  - Cria tabelas `extraction_jobs` e `extraction_job_documents`
  - Enums para PostgreSQL
  - Indices para queries de status e progresso

### Arquivos Alterados
- `apps/api/app/models/__init__.py`: Exports dos novos modelos
- `apps/api/app/core/database.py`: Import dos novos modelos no init_db()
- `apps/api/app/api/routes.py`: Incluido extraction_jobs router
- `apps/api/app/workers/tasks/__init__.py`: Exports das novas tasks

### Decisoes Tecnicas
1. Semaphore para controlar concorrencia (padrao 10 docs em paralelo)
2. Commits em batch (padrao 50 docs) para reducao de I/O
3. Resultados incrementais salvos a cada batch
4. SSE endpoint para progresso em tempo real (atualiza a cada 2s)
5. Backoff exponencial para retries (5s, 10s, 20s... max 5min)
6. Job pode ser pausado/retomado preservando progresso
7. Worker pode rodar via Celery ou async standalone

### Performance Esperada
- 2000 documentos: ~15-20 minutos (com 10 docs paralelos)
- Rate: ~2-3 docs/segundo por coluna
- Memory: constante (processa em batches)

### Proximos Passos
- Frontend: UI para monitorar jobs com progress bar
- Notificacoes: Email/webhook quando job completa
- Otimizacao: Batch LLM calls onde possivel

---

## 2026-02-03 ‚Äî Sessao 81: Dynamic Column Builder via Natural Language Prompts

### Objetivo
Implementar o Dynamic Column Builder para Review Tables, permitindo que usuarios criem colunas de extracao via perguntas em linguagem natural (similar ao Harvey AI).

### Arquivos Criados
- `apps/api/app/models/dynamic_column.py`:
  - `ExtractionType` enum: text, boolean, number, date, currency, enum, list, verbatim, risk_rating, compliance_check
  - `VerificationStatus` enum: pending, verified, rejected, corrected
  - `DynamicColumn` model: Coluna criada via prompt com schema inferido
  - `CellExtraction` model: Valor extraido com confianca, fonte e verificacao

- `apps/api/app/services/column_builder_service.py`:
  - `ColumnBuilderService` com metodos:
    - `infer_column_schema()` ‚Äî Usa LLM para inferir tipo e nome da coluna a partir do prompt
    - `create_column_from_prompt()` ‚Äî Cria coluna com schema inferido ou fornecido
    - `extract_for_document()` ‚Äî Extrai valor de um documento para uma coluna
    - `extract_column_for_all_documents()` ‚Äî Processa todos docs em paralelo (semaphore)
    - `reprocess_column()` ‚Äî Reprocessa extracoes (todos ou docs especificos)
    - `get_column_extractions()` ‚Äî Lista extracoes com filtros
    - `verify_cell()` ‚Äî Verifica/corrige uma celula

### Arquivos Alterados
- `apps/api/app/models/__init__.py`:
  - Adicionados exports: DynamicColumn, CellExtraction, ExtractionType, VerificationStatus

- `apps/api/app/core/database.py`:
  - Adicionado import dos novos modelos no init_db()

- `apps/api/app/api/endpoints/review_tables.py`:
  - Adicionados schemas: CreateDynamicColumnRequest, DynamicColumnResponse, etc.
  - Novos endpoints:
    - `POST /{table_id}/dynamic-columns` ‚Äî Criar coluna via prompt
    - `GET /{table_id}/dynamic-columns` ‚Äî Listar colunas dinamicas
    - `GET /{table_id}/dynamic-columns/{col_id}` ‚Äî Obter coluna com extracoes e stats
    - `DELETE /{table_id}/dynamic-columns/{col_id}` ‚Äî Soft/hard delete
    - `POST /{table_id}/dynamic-columns/{col_id}/reprocess` ‚Äî Reprocessar extracoes
  - Background tasks: `_extract_column_background()`, `_reprocess_column_background()`
  - Helper: `_dynamic_column_to_response()` com contagens de extracoes

### Decisoes Tecnicas
1. Schema inference usa LLM para determinar extraction_type e column_name
2. Fallback para tipo "text" se LLM falhar
3. Processamento em paralelo com semaphore (MAX_CONCURRENT_EXTRACTIONS=5)
4. Extracoes existentes sao atualizadas (upsert) ao reprocessar
5. Soft delete por padrao para colunas (preserva dados)

### Proximos Passos
- Frontend: UI para criar colunas dinamicas
- Batch processing: Otimizar para 2000+ documentos
- Export: Incluir colunas dinamicas no XLSX/CSV

---

## 2026-02-03 ‚Äî Sessao 80: Cell-Level Verification and Confidence Scores

### Objetivo
Implementar verificacao a nivel de celula com scores de confianca para Review Tables, inspirado no Harvey AI "verified cells" toggle.

### Arquivos Criados
- `apps/api/app/services/cell_verification_service.py`:
  - `CellVerificationService` com metodos:
    - `verify_cell()` ‚Äî Verificar/rejeitar/corrigir uma celula individual
    - `bulk_verify()` ‚Äî Verificar multiplas celulas de uma vez
    - `get_verification_stats()` ‚Äî Estatisticas: total, verified, rejected, corrected, pending, avg_confidence
    - `get_low_confidence_cells()` ‚Äî Celulas abaixo do threshold para revisao humana
    - `get_cell_by_position()` ‚Äî Buscar celula por (review_table, document, column)
    - `get_cells_by_dynamic_column()` ‚Äî Celulas de uma coluna dinamica
    - `get_cells_for_document()` ‚Äî Todas celulas de um documento
    - `get_cells_for_review_table()` ‚Äî Todas celulas com filtros
    - `recalculate_confidence()` ‚Äî Recalcular score de confianca
  - `calculate_confidence()` ‚Äî Funcao que calcula confianca baseado em:
    - Confianca base do LLM
    - Tamanho do source snippet
    - Validacao de tipo (date, boolean, currency, etc.)
    - Deteccao de incerteza no reasoning
  - `VerificationStats` dataclass para respostas estruturadas

- `apps/api/alembic/versions/x6y7z8a9b0c1_add_dynamic_columns_cell_extractions.py`:
  - Migracao para criar tabelas `dynamic_columns` e `cell_extractions`
  - Enums `extractiontype` e `verificationstatus` (PostgreSQL)
  - Indices para performance em queries frequentes

### Arquivos Alterados
- `apps/api/app/models/dynamic_column.py`:
  - Adicionados campos ao `CellExtraction`:
    - `correction_note` ‚Äî Nota explicando a correcao
    - `source_char_start`, `source_char_end` ‚Äî Posicao no documento
    - `extraction_model` ‚Äî Modelo de IA usado
    - `extraction_reasoning` ‚Äî Raciocinio do modelo
    - `column_name` ‚Äî Para colunas de template (nao dinamicas)
    - `created_at` ‚Äî Timestamp de criacao
  - `dynamic_column_id` agora e nullable (para colunas de template)
  - Adicionada property `is_verified` ‚Äî True se verified ou corrected
  - Atualizado `to_dict()` com todos os novos campos

- `apps/api/app/api/endpoints/review_tables.py`:
  - Adicionados schemas:
    - `VerifyCellRequest` ‚Äî { verified, correction?, note? }
    - `BulkVerifyRequest` ‚Äî { cell_ids, verified }
    - `BulkVerifyResponse` ‚Äî { success, updated_count }
    - `CellExtractionResponse` ‚Äî Representacao completa de uma celula
    - `VerificationStatsResponse` ‚Äî Estatisticas de verificacao
    - `CellSourceResponse` ‚Äî Detalhes da fonte de uma celula
  - Adicionados endpoints:
    - `PATCH /{table_id}/cells/{cell_id}/verify` ‚Äî Verificar celula individual
    - `POST /{table_id}/cells/bulk-verify` ‚Äî Verificar em lote
    - `GET /{table_id}/verification-stats` ‚Äî Estatisticas de verificacao
    - `GET /{table_id}/cells/low-confidence` ‚Äî Celulas de baixa confianca
    - `GET /{table_id}/cells/{cell_id}/source` ‚Äî Detalhes da fonte
    - `GET /{table_id}/cells` ‚Äî Listar todas celulas com filtros

### Decisoes Tecnicas
1. **Celulas de template vs dinamicas**: O modelo `CellExtraction` suporta ambos os tipos. Para colunas de template, `dynamic_column_id` e null e `column_name` e preenchido.

2. **Calculo de confianca**: A funcao `calculate_confidence()` usa multiplos fatores:
   - Confianca base do LLM (0.1-0.95)
   - Boost de +0.1 se source snippet > 150 chars
   - Boost de +0.1 se valor passa validacao de tipo
   - Penalidade de -0.15 se reasoning contem marcadores de incerteza
   - Penalidade de -0.2 se valor e vazio/erro

3. **Verificacao em lote**: O `bulk_verify` usa UPDATE com IN para performance, atualizando ate 100 celulas de uma vez.

4. **Audit logging**: Todas as acoes de verificacao sao logadas na tabela `audit_logs`.

### Endpoints Adicionados
```
PATCH /review-tables/{table_id}/cells/{cell_id}/verify
POST  /review-tables/{table_id}/cells/bulk-verify
GET   /review-tables/{table_id}/verification-stats
GET   /review-tables/{table_id}/cells/low-confidence?threshold=0.7
GET   /review-tables/{table_id}/cells/{cell_id}/source
GET   /review-tables/{table_id}/cells?status=pending&min_confidence=0.5
```

### Proximos Passos
- [ ] Integrar calculo de confianca no `review_table_service.process_review()`
- [ ] Criar CellExtraction para cada celula extraida (atualmente em JSON)
- [ ] Frontend: Toggle de "Show verified only" na UI
- [ ] Frontend: Indicadores visuais de confianca (cores, badges)

---

## 2026-02-03 ‚Äî Sessao 79: Ask Table Chat Feature para Review Tables

### Objetivo
Implementar a funcionalidade "Ask Table" para Review Tables, permitindo que usuarios facam perguntas em linguagem natural sobre os dados extraidos (similar ao "Ask Harvey" do Harvey AI).

### Arquivos Criados
- `apps/api/app/models/table_chat.py`:
  - Modelo `TableChatMessage` para armazenar historico de chat
  - Enum `MessageRole` (user, assistant, system)
  - Enum `QueryType` (filter, aggregation, comparison, summary, specific, general)
  - Indices para performance em queries por table_id e created_at

- `apps/api/app/services/table_chat_service.py`:
  - `TableChatService` com metodos:
    - `ask_table()` ‚Äî Processa perguntas em linguagem natural
    - `get_chat_history()` ‚Äî Retorna historico de mensagens
    - `clear_chat_history()` ‚Äî Limpa historico
    - `execute_data_query()` ‚Äî Queries estruturadas (filter, aggregation)
    - `get_table_statistics()` ‚Äî Estatisticas resumidas da tabela
  - Prompts especializados para analise de dados tabulares
  - Deteccao automatica de tipo de query
  - Sugestao de visualizacao (bar_chart, pie_chart, table, list)

- `apps/api/alembic/versions/x6y7z8a9b0c1_add_table_chat_messages.py`:
  - Migracao para criar tabela `table_chat_messages`
  - Enums `messagerole` e `querytype`
  - Indices para performance

### Arquivos Alterados
- `apps/api/app/models/__init__.py`:
  - Adicionado import de `TableChatMessage`, `MessageRole`, `QueryType`

- `apps/api/app/core/database.py`:
  - Adicionado import de `TableChatMessage` no init_db

- `apps/api/app/api/endpoints/review_tables.py`:
  - Adicionados schemas: `AskTableRequest`, `AskTableResponse`, `DocumentReference`, `ChatMessageResponse`, `ChatHistoryResponse`, `TableStatisticsResponse`
  - Adicionados endpoints:
    - `POST /{table_id}/chat` ‚Äî Ask Table principal
    - `GET /{table_id}/chat/history` ‚Äî Historico de chat
    - `DELETE /{table_id}/chat/history` ‚Äî Limpar historico
    - `GET /{table_id}/chat/statistics` ‚Äî Estatisticas da tabela
  - Endpoint `/query` marcado como deprecated em favor de `/chat`

### Tipos de Query Suportados
1. **FILTER**: "Quais documentos tem Demand Rights?"
2. **AGGREGATION**: "Quantos/qual porcentagem tem blackout provisions?"
3. **COMPARISON**: "Compare prioridades entre documentos"
4. **SUMMARY**: "Resuma os achados principais"
5. **SPECIFIC**: "O que documento X diz sobre Y?"
6. **GENERAL**: Perguntas gerais

### Formato de Resposta
```python
{
  "answer": "Resposta em linguagem natural",
  "query_type": "filter|aggregation|...",
  "documents": [{"id": "...", "name": "...", "relevance": "..."}],
  "data": {"type": "count|list|...", "data": ...},
  "visualization_hint": "bar_chart|pie_chart|table|list",
  "message_id": "uuid-da-mensagem"
}
```

### Verificacoes
- Sintaxe Python validada para todos os arquivos
- Migracao Alembic criada corretamente

### Status
- [x] Modelo TableChatMessage
- [x] TableChatService com todos os metodos
- [x] Endpoints de chat
- [x] Migracao Alembic
- [x] Validacao de sintaxe

---

## 2026-02-03 ‚Äî Sessao 78: Extracao de Legendas (SRT/VTT) + ElevenLabs Scribe v2

### Objetivo
Implementar novo modo de transcricao para extracao de legendas de filmes/videos. Gera arquivos SRT e VTT a partir de segments com timestamps. ElevenLabs Scribe v2 como backend primario, AssemblyAI e Whisper como fallbacks. Suporte a traducao e idiomas expandidos.

### Arquivos Alterados
- `mlx_vomo.py`:
  - Expandido `SUPPORTED_LANGUAGES` de 6 para 21 idiomas (pt, en, es, fr, de, it, ja, ko, zh, ru, ar, hi, nl, pl, tr, sv, da, fi, no, uk)

- `apps/api/app/core/config.py`:
  - Adicionado `ELEVENLABS_API_KEY: Optional[str] = None` para Scribe v2

- `apps/api/app/services/transcription_service.py`:
  - Adicionado `_format_timestamp_srt()` ‚Äî formata seconds para `HH:MM:SS,mmm`
  - Adicionado `_format_timestamp_vtt()` ‚Äî formata seconds para `HH:MM:SS.mmm`
  - Adicionado `_generate_srt()` ‚Äî gera conteudo SRT com speaker prefix
  - Adicionado `_generate_vtt()` ‚Äî gera conteudo WebVTT com voice tags `<v SPEAKER>`
  - Adicionado `_get_elevenlabs_key()` ‚Äî obtem API key do config ou env
  - Adicionado `_transcribe_elevenlabs_scribe()` ‚Äî transcricao via ElevenLabs API com word-level timestamps, agrupa palavras em segments por speaker/pausas
  - Modificado `_persist_transcription_outputs()` ‚Äî aceita `segments` e `subtitle_format`, salva .srt/.vtt/.json
  - Modificado `process_file()` ‚Äî param `subtitle_format`, logica ElevenLabs primario para legendas
  - Modificado `process_file_with_progress()` ‚Äî param `subtitle_format`, logica ElevenLabs primario para legendas
  - Coleta de segments prioriza: ElevenLabs > AAI > Whisper

- `apps/api/app/api/endpoints/transcription.py`:
  - Adicionado `subtitle_format` param nos 4 endpoints vomo (/vomo, /vomo/jobs, /vomo/jobs/url, /vomo/stream)
  - Adicionado media types: `.srt` (application/x-subrip), `.vtt` (text/vtt)
  - Adicionado `subtitle_format` em `UrlVomoJobRequest`

- `apps/web/src/lib/api-client.ts`:
  - Adicionado tipo `subtitle_format?: 'srt' | 'vtt' | 'both'` em funcoes de transcricao

- `apps/web/src/app/(dashboard)/transcription/page.tsx`:
  - Adicionado tipo de transcricao "Legendas (SRT/VTT)"
  - Adicionado seletor de formato (SRT/VTT/Ambos)
  - Expandido dropdown de idiomas de 6 para 21 opcoes
  - Adicionados botoes de download SRT/VTT na aba export

### Fluxo de Transcricao para Legendas
```
Legenda (qualquer idioma):
  ‚îú‚îÄ‚îÄ ElevenLabs Scribe v2 (primario, word-level timestamps, diarizacao)
  ‚îú‚îÄ‚îÄ AssemblyAI (fallback, speaker_labels=True)
  ‚îú‚îÄ‚îÄ Whisper (fallback final, segments locais)
  ‚îú‚îÄ‚îÄ Gera SRT e/ou VTT a partir dos segments
  ‚îî‚îÄ‚îÄ Salva: _RAW.txt, .srt, .vtt, _segments.json
```

### Decisoes Tomadas
- ElevenLabs como primario para legendas devido a word-level timestamps de alta qualidade
- Agrupamento de palavras em segments usa: mudanca de speaker OU pausa > 1.5s
- Fallback chain (ElevenLabs > AAI > Whisper) para robustez
- SRT usa formato `HH:MM:SS,mmm` (virgula), VTT usa `HH:MM:SS.mmm` (ponto)
- Speaker em SRT: prefixo "SPEAKER: texto", em VTT: voice tag `<v SPEAKER>texto`

### Verificacoes
- Sintaxe Python validada
- Sintaxe TypeScript validada
- Endpoints com tipagem correta

### Status
- [x] Expandir idiomas em mlx_vomo.py
- [x] Adicionar geracao SRT/VTT
- [x] Implementar ElevenLabs Scribe v2 como primario
- [x] Modificar endpoints com subtitle_format
- [x] Atualizar UI com tipo "Legendas"
- [x] Validar sintaxe

---

## 2026-02-03 ‚Äî Sessao 77: Gaps 9, 10, 11, 12 ‚Äî Word Online + Prompt Library + Historico + Recomendacoes

### Objetivo
Implementar gaps 9-12 do Word Add-in: suporte a Word Online (fallback), biblioteca de prompts curados, historico de analises e recomendacao de playbooks.

### Arquivos Criados
- `apps/office-addin/src/data/prompt-library.ts` ‚Äî Biblioteca com 23 prompts curados para edicao juridica, organizados por categoria (editing, drafting, analysis, translation, compliance)
- `apps/office-addin/src/components/prompts/PromptLibrary.tsx` ‚Äî Componente de UI para selecao de prompts com busca e filtros por categoria, inclui modal e seletor rapido
- `apps/office-addin/src/components/playbook/HistoryPanel.tsx` ‚Äî Painel de historico de analises com restauracao de runs, inclui modal e botao

### Arquivos Alterados
- `apps/office-addin/src/office/redline-engine.ts`:
  - Adicionada funcao `isWordOnline()` ‚Äî detecta se esta no Word Online
  - Adicionada funcao `getOfficePlatform()` ‚Äî retorna plataforma atual (online/windows/mac/ios/android)
  - Adicionada funcao `supportsFullOOXML()` ‚Äî verifica se suporta tracked changes OOXML
  - Adicionada funcao `applyRedlineAsFallback()` ‚Äî fallback com comentarios + highlight para Word Online
  - Modificada funcao `applyRedlineAsTrackedChange()` ‚Äî detecta Word Online e usa fallback automatico
  - Adicionado campo `method` em `RedlineResult` ‚Äî indica metodo usado (ooxml/fallback/comment)
- `apps/office-addin/src/components/drafting/DraftPanel.tsx`:
  - Adicionado import de `PromptLibraryModal` e `PromptTemplate`
  - Adicionado estado `showPromptLibrary` e handler `handlePromptSelect`
  - Adicionado botao para abrir biblioteca de prompts
  - Adicionado modal da biblioteca no render
- `apps/office-addin/src/api/client.ts`:
  - Adicionados tipos para Gap 11: `PlaybookRunHistoryItem`, `PlaybookRunHistoryResponse`, `RestorePlaybookRunResponse`
  - Adicionadas funcoes: `getPlaybookRunHistory()`, `restorePlaybookRun()`
  - Adicionados tipos para Gap 12: `RecommendPlaybookRequest`, `RecommendedPlaybook`, `RecommendPlaybookResponse`
  - Adicionada funcao `recommendPlaybook()`
- `apps/office-addin/src/components/playbook/PlaybookPanel.tsx`:
  - Adicionados imports de `HistoryButton`, `HistoryModal`, `recommendPlaybook`, `useDocumentStore`
  - Adicionados estados para historico e recomendacoes
  - Adicionado efeito para carregar recomendacoes baseado no documento
  - Adicionada UI para mostrar playbooks recomendados com score de relevancia
  - Adicionado botao de historico e modal
- `apps/api/app/api/endpoints/word_addin.py`:
  - Adicionados imports: `BaseModel`, `Field`, `List`, `Optional`
  - **Gap 11**: Adicionado endpoint `GET /user/playbook-runs` ‚Äî lista historico de execucoes do usuario
  - **Gap 12**: Adicionado endpoint `POST /playbook/recommend` ‚Äî recomenda playbooks baseado no documento
  - Adicionada funcao `classify_document_type()` ‚Äî classifica tipo de documento usando heuristicas
  - Adicionada funcao `rank_playbooks_by_relevance()` ‚Äî rankeia playbooks por relevancia
  - Adicionado mapeamento `DOCUMENT_TYPE_TO_AREA` para relacionar tipos de documento a areas de playbook

### Decisoes Tomadas
- Word Online fallback usa comentarios com sugestoes de alteracao manual (OOXML nao e confiavel)
- Biblioteca de prompts com 23 templates em 5 categorias focadas em contexto juridico brasileiro
- Historico limitado a 10 execucoes mais recentes (configuravel)
- Recomendacao usa heuristicas simples (keywords) para classificacao rapida; em producao pode usar LLM
- Excerpt de 2000 caracteres para classificacao de documento (suficiente para identificar tipo)

### Verificacoes
- Arquivos TypeScript criados com sintaxe valida
- Endpoints Python com tipagem correta
- Integracao com stores existentes

### Status
- [x] Gap 9: Suporte a Word Online com fallback automatico
- [x] Gap 10: Prompt Library com 23 prompts curados
- [x] Gap 11: Historico de analises anteriores
- [x] Gap 12: Recomendacao de playbooks baseada no documento

---

## 2026-02-03 ‚Äî Sessao 76: Gaps 1, 2 e 3 ‚Äî Cache de Redlines + Endpoints Apply Funcionais

### Objetivo
Corrigir os gaps 1, 2 e 3 do Word Add-in: implementar cache de redlines (PlaybookRunCache) e tornar os endpoints de apply funcional com OOXML real.

### Arquivos Criados
- `apps/api/app/models/playbook_run_cache.py` ‚Äî Modelo SQLAlchemy para cache tempor√°rio de execu√ß√µes de playbook (TTL 24h)
- `apps/api/alembic/versions/v4w5x6y7z8a9_add_playbook_run_cache_table.py` ‚Äî Migration Alembic para tabela `playbook_run_cache`

### Arquivos Alterados
- `apps/api/app/models/__init__.py` ‚Äî Adicionado export de `PlaybookRunCache`
- `apps/api/app/schemas/word_addin.py`:
  - Adicionado campo `cache_results: bool` em `RunPlaybookRequest`
  - Adicionado campo `playbook_run_id: str` em `RunPlaybookResponse`
  - Adicionado campo `playbook_run_id: str` em `ApplyRedlineRequest`, `RejectRedlineRequest`, `ApplyAllRedlinesRequest`
  - Adicionado schema `RestorePlaybookRunResponse`
- `apps/api/app/api/endpoints/word_addin.py`:
  - Adicionados imports: `hashlib`, `json`, `timedelta`, `delete`, `PlaybookRunCache`
  - Adicionada fun√ß√£o `_cleanup_expired_caches()` ‚Äî limpa caches expirados
  - Adicionada fun√ß√£o `_get_cached_run()` ‚Äî recupera cache por ID
  - Modificado endpoint `POST /playbook/run`:
    - Salva resultados no cache se `cache_results=True`
    - Retorna `playbook_run_id` para uso posterior
  - Adicionado endpoint `GET /playbook/run/{playbook_run_id}/restore`:
    - Recupera redlines e resultados do cache
    - Permite continuar revis√£o sem re-executar an√°lise
  - **Gap 1 corrigido**: `POST /redline/apply`:
    - Recupera redlines do cache pelo `playbook_run_id`
    - Gera OOXML real para cada redline usando `redline_service.generate_single_redline_ooxml()`
    - Persiste estado como `applied` usando `RedlineState`
    - Retorna mapa `ooxml_data: {redline_id: ooxml_string}`
  - Modificado `POST /redline/reject`:
    - Valida exist√™ncia do cache
    - Persiste estado como `rejected` usando `RedlineState`
  - **Gap 2 corrigido**: `POST /redline/apply-all`:
    - Recupera redlines do cache
    - Filtra pendentes (n√£o aplicados/rejeitados)
    - Gera OOXML package completo com `redline_service.generate_ooxml_redlines()`
    - Suporta filtro por `redline_ids` opcionais
    - Persiste estados como `applied`
    - Retorna `ooxml_package` com todos tracked changes

### Decis√µes Tomadas
- TTL de 24 horas para cache de redlines
- Limpeza autom√°tica de caches expirados a cada execu√ß√£o de playbook
- Hash SHA256 do documento armazenado para identifica√ß√£o futura
- `cache_results=True` por padr√£o em `RunPlaybookRequest`
- Redlines armazenados como JSON serializado (compacto)
- Integra√ß√£o com `RedlineState` para persistir applied/rejected

### Verifica√ß√µes
- Python syntax OK (todos os arquivos compilam)
- Module import OK: `PlaybookRunCache`, endpoints word_addin

### Status
- [x] Gap 1: Endpoint Apply Individual funcional com OOXML real
- [x] Gap 2: Endpoint Apply All funcional com OOXML package
- [x] Gap 3: Cache de redlines com TTL 24h
- [x] Endpoint Restore para recuperar an√°lise

---

## 2026-02-03 ‚Äî Sessao 75: Gap 4 ‚Äî Persist√™ncia de Estado de Redlines

### Objetivo
Implementar persist√™ncia de estado de redlines no backend para permitir que o usu√°rio feche e reabra o Word Add-in sem perder o progresso da revis√£o.

### Arquivos Criados
- `apps/api/app/models/redline_state.py` ‚Äî Modelo SQLAlchemy para persistir estados de redlines (pending, applied, rejected) com √≠ndices e constraints
- `apps/api/alembic/versions/w5x6y7z8a9b0_add_redline_states_table.py` ‚Äî Migration Alembic para criar a tabela `redline_states`

### Arquivos Alterados
- `apps/api/app/models/__init__.py` ‚Äî Adicionado export de `RedlineState` e `RedlineStatus`
- `apps/api/app/core/database.py` ‚Äî Adicionado import do modelo `RedlineState` no `init_db()`
- `apps/api/app/schemas/word_addin.py` ‚Äî Adicionados schemas: `RedlineStateData`, `RedlineStateResponse`, `GetRedlineStatesResponse`
- `apps/api/app/api/endpoints/word_addin.py`:
  - Adicionados imports de `RedlineState`, `RedlineStatus` e novos schemas
  - Adicionado endpoint `POST /word-addin/redline/state/{playbook_run_id}/{redline_id}/applied`
  - Adicionado endpoint `POST /word-addin/redline/state/{playbook_run_id}/{redline_id}/rejected`
  - Adicionado endpoint `GET /word-addin/redline/state/{playbook_run_id}`
- `apps/office-addin/src/api/client.ts`:
  - Adicionados types: `RedlineStateData`, `RedlineStateResponse`, `GetRedlineStatesResponse`
  - Adicionado `playbook_run_id` em `RunPlaybookResponse`
  - Adicionadas fun√ß√µes: `persistRedlineApplied()`, `persistRedlineRejected()`, `getRedlineStates()`
- `apps/office-addin/src/stores/playbook-store.ts`:
  - Adicionados imports das novas fun√ß√µes de API
  - Adicionadas actions: `loadSavedRedlineStates()`, `persistAppliedState()`, `persistRejectedState()`
  - Modificado `runPlaybookAnalysis()` para usar `playbook_run_id` do backend e carregar estados salvos
  - Modificado `markRedlineApplied()` para chamar `persistAppliedState()`
  - Modificado `markRedlineRejected()` para chamar `persistRejectedState()`

### Decis√µes Tomadas
- Upsert (criar ou atualizar) para opera√ß√µes de estado
- √çndice composto em `(playbook_run_id, status)` para performance de busca
- UniqueConstraint em `(playbook_run_id, redline_id)` para garantir unicidade
- Persist√™ncia fire-and-forget (n√£o bloqueia UI se API falhar)
- Carregamento de estados salvos √© ass√≠ncrono ap√≥s an√°lise

### Verifica√ß√µes
- Python syntax OK (models, schemas, endpoints)
- TypeScript sem erros nos arquivos modificados
- Model import OK: `RedlineState`, `RedlineStatus`
- Schema import OK: `RedlineStateData`, `RedlineStateResponse`, `GetRedlineStatesResponse`
- Endpoint import OK: router word_addin

---

## 2026-02-03 ‚Äî Sessao 74: Extra√ß√£o de Legendas (SRT/VTT) com AssemblyAI

### Objetivo
Implementar nova funcionalidade de extra√ß√£o de legendas (SRT/VTT) de filmes/v√≠deos usando AssemblyAI como backend principal, com suporte a tradu√ß√£o e idiomas expandidos.

### Arquivos Alterados
- `mlx_vomo.py` ‚Äî Expandido `SUPPORTED_LANGUAGES` de 6 para 21 idiomas (incluindo japon√™s, coreano, chin√™s, russo, √°rabe, hindi, etc.)
- `apps/api/app/services/transcription_service.py`:
  - Adicionados m√©todos est√°ticos `_format_timestamp_srt()`, `_format_timestamp_vtt()`, `_generate_srt()`, `_generate_vtt()`
  - Modificado `_persist_transcription_outputs()` para aceitar `segments` e `subtitle_format`, salvando arquivos `.srt`, `.vtt` e `_segments.json`
  - Adicionado param `subtitle_format` em `process_file()` e `process_file_with_progress()`
  - L√≥gica para coletar segments (de AAI ou Whisper) e pass√°-los ao persist
- `apps/api/app/api/endpoints/transcription.py`:
  - Adicionado `subtitle_format` em `UrlVomoJobRequest`
  - Adicionado param `subtitle_format` nos 4 endpoints vomo (`/vomo`, `/vomo/jobs`, `/vomo/jobs/url`, `/vomo/stream`)
  - Registrados media types `.srt` (application/x-subrip) e `.vtt` (text/vtt) no download endpoint
- `apps/web/src/lib/api-client.ts` ‚Äî Adicionado `subtitle_format?: 'srt' | 'vtt' | 'both'` em `startTranscriptionJob()` e `startTranscriptionJobFromUrl()`
- `apps/web/src/app/(dashboard)/transcription/page.tsx`:
  - Expandido `transcriptionType` para incluir `'legenda'`
  - Adicionado estado `subtitleFormat`
  - Nova op√ß√£o "üé¨ Legendas (SRT/VTT)" no seletor de tipo de transcri√ß√£o
  - Se√ß√£o de configura√ß√£o de legendas (formato SRT/VTT/Ambos) quando isLegenda
  - Expandidos dropdowns de idioma de 6 para 21 op√ß√µes
  - Bot√µes de download SRT/VTT na aba export quando dispon√≠veis

### Decis√µes Tomadas
- AssemblyAI como backend principal para legendas (melhor precis√£o de timestamps)
- Whisper como fallback (tamb√©m tem segments com timestamps)
- Formato SRT usa v√≠rgula como separador decimal (padr√£o SubRip): `HH:MM:SS,mmm`
- Formato VTT usa ponto como separador decimal (padr√£o WebVTT): `HH:MM:SS.mmm`
- VTT usa tags `<v SPEAKER>` para identifica√ß√£o de falantes
- SRT usa prefixo `SPEAKER: ` no texto
- Segments s√£o salvos tamb√©m como `_segments.json` para poss√≠vel uso futuro

### Verifica√ß√µes
- Python syntax OK (transcription_service.py, endpoints/transcription.py, mlx_vomo.py)
- TypeScript sem erros (tsc --noEmit)

---

## 2026-02-03 ‚Äî Sessao 73: Gaps 5 e 6 ‚Äî Sincronizacao entre abas + Tracking de modificacoes

### Objetivo
Implementar Gap 5 (sincronizacao de estado de redlines entre abas do Word) e Gap 6 (tracking de modificacoes no documento apos analise) no Office Add-in.

### Arquivos Alterados
- `apps/office-addin/src/office/document-bridge.ts` ‚Äî Adicionadas funcoes `getDocumentHash()` (calcula SHA-256 do texto do documento via Web Crypto API) e `checkDocumentModified()` (compara hash atual com esperado).
- `apps/office-addin/src/stores/playbook-store.ts` ‚Äî Adicionados: constantes SYNC_KEY, TAB_ID_KEY, POLLING_INTERVAL; funcao `getTabId()` (gera/recupera UUID da aba via sessionStorage); funcao `broadcastStateChange()` (envia mudanca para outras abas via localStorage); interface `RedlineApplication`; novos campos de estado (playbookRunId, documentHashBeforeAnalysis, documentHashAfterRedlines, documentModified, redlineApplications); metodos `markRedlineApplied()` agora async (captura hash apos aplicacao e faz broadcast), `markRedlineRejected()` agora faz broadcast, `syncRedlineState()`, `initSyncListener()` (listener de storage events + polling fallback), `checkDocumentModification()`, `updateDocumentHash()`, `clearModificationWarning()`.
- `apps/office-addin/src/components/playbook/PlaybookPanel.tsx` ‚Äî Adicionado useRef para interval de verificacao; useEffect para inicializar sync listener entre abas; useEffect para verificar modificacoes periodicamente (10s) quando em estado results; handlers `handleReanalyze()` e `handleIgnoreModification()`; componente de warning visual (banner amber com icone, mensagem e botoes Reanalisar/Ignorar).

### Decisoes Tomadas
- Gap 5: localStorage para broadcast entre abas (storage event) + polling fallback (30s) para casos onde storage event nao funciona (ex: iframes)
- Gap 5: sessionStorage para tabId unico por aba (persiste apenas na aba atual)
- Gap 5: playbookRunId UUID gerado a cada execucao para garantir que sync so ocorre entre abas analisando o mesmo playbook run
- Gap 6: SHA-256 via Web Crypto API (nativo, sem dependencias externas)
- Gap 6: Hash capturado antes da analise e atualizado apos cada redline aplicado
- Gap 6: Verificacao periodica a cada 10s quando em resultados
- Gap 6: UI warning com opcoes Reanalisar (re-executa playbook) ou Ignorar (atualiza hash baseline)

### Verificacoes
- TypeScript sem erros nos arquivos modificados (tsc --noEmit)
- Nota: erro pre-existente em Toast.tsx (nao relacionado a esta implementacao)

---

## 2026-02-02 ‚Äî Sessao 72: Busca Cross-Collection (Legacy + Novas Collections Qdrant)

### Objetivo
Resolver o problema critico de documentos ja ingeridos nas collections legadas (lei, juris, doutrina, pecas_modelo, sei, local_chunks) nao serem buscaveis pelo smart-search do embedding_router, que so buscava nas collections novas (legal_br, legal_international, legal_eu, general).

### Arquivos Alterados
- `apps/api/app/services/rag/embedding_router.py` ‚Äî Adicionados: constante LEGACY_COLLECTIONS (mapeamento jurisdicao -> collections legadas), constante LEGACY_EMBEDDING_DIMENSIONS, funcao `reciprocal_rank_fusion()` para merge de rankings, campo `include_legacy` no SmartSearchRequest, campo `collections_searched` no SmartSearchResponse, metodo `_search_legacy_collections()` que busca em paralelo nas collections legadas usando embedding OpenAI 3072d, metodo `migrate_collection()` para re-ingestao futura. O metodo `search_with_routing()` agora busca nas collections novas E legadas, fazendo merge via RRF.
- `apps/api/app/api/endpoints/rag.py` ‚Äî Endpoint `/smart-search` agora passa `include_legacy` ao router e retorna `collections_searched` na response.

### Decisoes Tomadas
- Legacy search sempre usa embedding OpenAI 3072d (independente do provider do routing) pois e o que as collections legadas usam
- RRF com k=60 (valor padrao da literatura) para merge justo entre fontes com scores de escalas diferentes
- Busca nas collections legadas eh feita em paralelo (asyncio.gather) para minimizar latencia
- Flag `include_legacy=True` como default para nao quebrar nada; pode ser desabilitado para buscar apenas nas collections novas
- `migrate_collection()` criado mas nao executa automaticamente; para uso futuro controlado
- Collections legadas NAO sao modificadas

### Verificacoes
- Sintaxe Python OK em ambos os arquivos (ast.parse)

---

## 2026-02-02 ‚Äî Sessao 71: Correcao de 3 problemas menores da auditoria

### Objetivo
Corrigir 3 problemas identificados na auditoria: QdrantClient sem connection pooling, EMBEDDING_DIMENSION inconsistente, e CITATION_PATTERNS duplicado.

### Arquivos Alterados
- `apps/api/app/services/rag/embedding_router.py` ‚Äî QdrantClient agora e compartilhado (lazy init via `_get_qdrant_client`) ao inves de criado a cada chamada de `_search_qdrant`. Adicionados `_qdrant_client` e `_qdrant_lock` ao `__init__`.
- `apps/api/app/core/config.py` ‚Äî Adicionado comentario explicativo em `EMBEDDING_DIMENSION` (768) referenciando que e para provider local/fallback e apontando para `rag/config.py`.
- `apps/api/app/services/rag/config.py` ‚Äî Adicionado comentario explicativo em `embedding_dimensions` (3072) referenciando que e para provider primario e apontando para `core/config.py`.
- `apps/api/app/services/jurisprudence_verifier.py` ‚Äî Removida duplicacao de CITATION_PATTERNS. Agora importa de `legal_vocabulary.py` e converte via `_adapt_citation_patterns()` com mapeamento `_NAME_TO_CTYPE`. Pattern exclusivo `acordao` mantido como adicao.

### Decisoes Tomadas
- QdrantClient usa double-checked locking (mesmo padrao de `_get_provider`)
- Valores de EMBEDDING_DIMENSION nao alterados, apenas documentados
- Para CITATION_PATTERNS, criado adaptador que mapeia nomes do legal_vocabulary para os ctypes esperados por `_normalize_citation`
- Pattern `acordao` generico mantido exclusivamente no verifier (cobertura mais ampla que legal_vocabulary)

### Verificacoes
- Sintaxe Python OK em todos os 4 arquivos (ast.parse)

---

## 2026-02-02 ‚Äî Sessao 70: Correcao de 2 problemas da auditoria (Migration + RoutingDecision duplicado)

### Objetivo
Corrigir 2 problemas identificados na auditoria anterior: migration Alembic ausente para `citation_verifications` e nome duplicado `RoutingDecision`.

### Arquivos Alterados
- `apps/api/alembic/versions/u3v4w5x6y7z8_add_citation_verifications_table.py` ‚Äî CRIADO: migration para tabela `citation_verifications` com ForeignKeys para `documents.id` e `users.id`, indices compostos (user+status, citation_type), downgrade com drop_table. down_revision aponta para `t2u3v4w5x6y7` (head atual).
- `apps/api/app/services/rag/embedding_router.py` ‚Äî Renomeado `RoutingDecision` para `EmbeddingRoutingDecision` (todas as 15+ ocorrencias no arquivo)
- `apps/api/app/api/endpoints/rag.py` ‚Äî Atualizado import de `RoutingDecision` para `EmbeddingRoutingDecision` e stub de fallback

### Decisoes Tomadas
- Migration criada manualmente (sem autogenerate) para evitar problemas de config do Alembic
- Nome `EmbeddingRoutingDecision` escolhido para diferenciar claramente da `RoutingDecision` dataclass do `hybrid_router.py`
- `hybrid_router.py` e `core/__init__.py` NAO foram alterados (existentes, sem risco de quebra)
- Verificado que nenhum outro arquivo importa `RoutingDecision` do `embedding_router`

### Verificacoes
- Sintaxe Python OK em todos os 3 arquivos (ast.parse)
- Cadeia de migrations verificada: 491a07bb915f -> ... -> t2u3v4w5x6y7 -> u3v4w5x6y7z8

---

## 2026-02-02 ‚Äî Sessao 69: Code Review Rigoroso do Sistema RAG (Embeddings + Routing + Verifier)

### Objetivo
Code review completo dos arquivos recentes do sistema RAG: embedding_router, voyage_embeddings, legal_embeddings, legal_vocabulary, kanon_embeddings, jurisbert_embeddings, jurisprudence_verifier, model_router, citation_verification.

### Correcoes Aplicadas
1. `legal_embeddings.py` ‚Äî Singleton `get_legal_embeddings_service()` corrigido para thread-safety com `threading.Lock()` (double-check locking). Antes nao tinha lock, risco de race condition em FastAPI.
2. `legal_embeddings.py` ‚Äî `asyncio.get_event_loop()` deprecado substituido por `asyncio.get_running_loop()` com try/except RuntimeError (2 ocorrencias).
3. `core/embeddings.py` ‚Äî Mesmo fix de `asyncio.get_event_loop()` deprecado para `asyncio.get_running_loop()`.
4. `jurisprudence_verifier.py` ‚Äî Migrado de SDK antigo `google.generativeai` (genai.configure + GenerativeModel) para SDK novo `google.genai` (genai.Client + client.models.generate_content), consistente com o resto do projeto (2 ocorrencias).
5. `kanon_embeddings.py` ‚Äî Docstring corrigido: dimensoes nativas sao 1792, usamos 1024 via Matryoshka (antes dizia "1792 default" o que confundia com o default do codigo que e 1024).

### Problemas Identificados (requerem decisao humana)
- Migration Alembic ausente para `citation_verifications` (models/citation_verification.py)
- RoutingDecision nome duplicado: Pydantic BaseModel em embedding_router.py vs dataclass em core/hybrid_router.py
- Sistema de collections paralelo: collections existentes (lei, juris, pecas) com 3072d vs novas (legal_br 768d, legal_international 1024d, legal_eu 1024d)
- core/config.py EMBEDDING_DIMENSION=768 vs rag/config.py embedding_dimensions=3072
- Duplicacao funcional entre legal_embeddings.py e pipeline RAG existente (query expansion, HyDE)
- QdrantClient criado por busca em embedding_router._search_qdrant (sem connection pooling)

### Verificacoes
- Imports: todos os modulos referenciados existem e sao importaveis
- web_search_service.search_legal: confirmado que existe
- record_api_call: confirmado que existe
- requirements.txt: voyageai, isaacus, langdetect, rank-bm25 presentes
- Endpoints rag.py: imports lazy com try/except, nao quebram se modulos ausentes

---

## 2026-02-02 ‚Äî Sessao 68: Routing Multi-Embedding por Jurisdicao (JurisBERT, Kanon 2, Voyage, OpenAI)

### Arquivos Criados
- `apps/api/app/services/rag/kanon_embeddings.py` ‚Äî Provider Kanon 2 Embedder (Isaacus): #1 no MLEB benchmark, 1024d Matryoshka, 16K tokens, SDK async + REST fallback, retry com backoff, fallback para voyage-law-2, cache LRU, cost tracker
- `apps/api/app/services/rag/jurisbert_embeddings.py` ‚Äî Provider JurisBERT para direito BR: modelo juridics/bertlaw-base-portuguese-sts-scale (768d), self-hosted via sentence-transformers, lazy loading, GPU support (CUDA/MPS), fallback para voyage-multilingual-2, thread-safe
- `apps/api/app/services/rag/embedding_router.py` ‚Äî Router multi-embedding com 3 camadas: (1) heuristica rapida por keywords/idioma/regex <1ms, (2) LLM routing via Gemini Flash quando incerto, (3) fallback OpenAI. Roteamento: BR‚ÜíJurisBERT, US/UK/INT‚ÜíKanon2, EU‚ÜíVoyage, GENERAL‚ÜíOpenAI. Collections Qdrant separadas por jurisdicao. Schemas Pydantic para smart-search e smart-ingest.

### Arquivos Alterados
- `apps/api/app/api/endpoints/rag.py` ‚Äî Novos endpoints: POST /smart-search (busca com routing automatico), POST /smart-ingest (ingestao com classificacao automatica), GET /embedding-router/stats (metricas de todos os providers). Endpoints existentes NAO alterados.
- `apps/api/requirements.txt` ‚Äî Adicionados: `isaacus>=0.1.0` (SDK Kanon 2), `langdetect>=1.0.9` (deteccao de idioma)
- `apps/api/.env.example` ‚Äî Adicionadas variaveis: ISAACUS_API_KEY, JURISBERT_MODEL_NAME, JURISBERT_DEVICE, SMART_SKIP_RAG_CHARS

### Decisoes Tomadas
- Modelo JurisBERT verificado no HuggingFace: `juridics/bertlaw-base-portuguese-sts-scale` (768d, sentence-transformer, STS para PT-BR juridico)
- Kanon 2 Embedder confirmado via docs Isaacus: modelo "kanon-2-embedder", tasks "retrieval/document" e "retrieval/query", dimensoes Matryoshka 1792‚Üí1024‚Üí768‚Üí512‚Üí256 (usamos 1024 como default)
- Router usa heuristica com threshold 0.8 antes de chamar LLM (economia de custo)
- Collections Qdrant separadas: legal_br (768d), legal_international (1024d), legal_eu (1024d), general (3072d)
- Skip RAG para docs < 400K chars (~100 pgs) - envio direto ao LLM
- Todos os providers com cadeia de fallback em cascata
- Endpoints smart-search e smart-ingest sao NOVOS, nao quebram endpoints existentes

### Verificacoes
- Sintaxe de todos os arquivos Python validada com ast.parse: OK
- kanon_embeddings.py, jurisbert_embeddings.py, embedding_router.py, rag.py: todos OK

---

## 2026-02-02 ‚Äî Sessao 67: Integracao Voyage AI como provider primario de embeddings juridicos

### Arquivos Criados
- `apps/api/app/services/rag/voyage_embeddings.py` ‚Äî Provider completo Voyage AI: VoyageEmbeddingsProvider com suporte a voyage-law-2 (juridico), voyage-3-large (geral), voyage-3-lite (rapido); cache LRU thread-safe; retry com backoff exponencial; fallback automatico Voyage -> OpenAI; tracking de custos; batch processing com rate limit

### Arquivos Alterados
- `apps/api/requirements.txt` ‚Äî Adicionado `voyageai>=0.3.2` como dependencia
- `apps/api/app/services/rag/legal_embeddings.py` ‚Äî Integrado Voyage AI como provider primario: LegalEmbeddingConfig com opcoes Voyage; cadeia de fallback Voyage -> OpenAI -> SentenceTransformers; input_type assimetrico (document vs query); modelo voyage-law-2 para legal_mode=True, voyage-3-large para legal_mode=False
- `apps/api/app/services/rag/core/embeddings.py` ‚Äî EmbeddingsService agora suporta provider "voyage" via RAG_EMBEDDINGS_PROVIDER; auto-detection de VOYAGE_API_KEY; metodo _embed_voyage para chamadas async; fallback transparente
- `apps/api/app/services/rag/.env.example` ‚Äî Adicionadas variaveis Voyage AI (VOYAGE_API_KEY, VOYAGE_DEFAULT_MODEL, VOYAGE_FALLBACK_MODEL, RAG_EMBEDDINGS_PROVIDER)
- `apps/api/.env.example` ‚Äî Adicionada secao Voyage AI com documentacao

### Decisoes Tomadas
- Voyage AI e opt-in: funciona sem VOYAGE_API_KEY, cai automaticamente no OpenAI
- Provider "auto" prioriza: Voyage > OpenAI > SentenceTransformers local
- Cache LRU separado no VoyageEmbeddingsProvider (2048 entradas) para nao conflitar com TTLCache do EmbeddingsService
- input_type assimetrico ("document" vs "query") e passado ao Voyage para otimizacao de retrieval
- Dimensoes ajustadas automaticamente quando Voyage esta ativo (1024 vs 3072 do OpenAI)
- Retry com backoff exponencial (3 tentativas) antes de cair no fallback

### Verificacoes
- Sintaxe de todos os arquivos Python validada com ast.parse: OK

---

## 2026-02-02 ‚Äî Sessao 66: Vorbium Fase 2 ‚Äî Redlines OOXML + Run Playbook no Word

### Arquivos Criados
- `apps/api/app/services/redline_service.py` ‚Äî Servico completo de redlines OOXML: geracao de tracked changes (w:ins, w:del, w:commentRangeStart/End), RedlineItem dataclass, build de pacotes OOXML, run_playbook_on_word_document() integrando com PlaybookService, apply/reject operations

### Arquivos Alterados
- `apps/api/app/schemas/word_addin.py` ‚Äî Adicionados schemas Fase 2: RedlineData, ClauseData, PlaybookRunStats, RunPlaybookRequest/Response, ApplyRedlineRequest/Response, RejectRedlineRequest/Response, ApplyAllRedlinesRequest/Response, PlaybookListItem, PlaybookListResponse
- `apps/api/app/api/endpoints/word_addin.py` ‚Äî Adicionados 5 endpoints: POST /playbook/run, POST /redline/apply, POST /redline/reject, POST /redline/apply-all, GET /playbook/list
- `apps/office-addin/src/api/client.ts` ‚Äî Adicionadas interfaces e funcoes API Fase 2: RedlineData, ClauseData, PlaybookRunStats, runPlaybook (120s timeout), getPlaybooksForAddin, applyRedlines, rejectRedlines, applyAllRedlines
- `apps/office-addin/src/stores/playbook-store.ts` ‚Äî Reescrito para Fase 2: suporte a redlines/clauses separados, review tabs (All/Reviewed/Pending), filtros por classificacao e severidade, toRedlineOperations(), reviewProgress(), getRedlineForClause()
- `apps/office-addin/src/components/playbook/PlaybookPanel.tsx` ‚Äî Reescrito: risk score, barra de progresso de revisao, review tabs, filtros, acoes batch (Apply All, Comentar tudo, Destacar tudo), acoes individuais com tracked changes
- `apps/office-addin/src/components/playbook/ClauseCard.tsx` ‚Äî Reescrito: suporte a ClauseData + RedlineData, classificacoes novas e legacy, barra de confianca, botoes Apply/Preview/Rejeitar
- `apps/office-addin/src/components/playbook/RedlinePreview.tsx` ‚Äî Reescrito: ClauseData + RedlineData, labels de severidade/classificacao, confianca, raciocinio da IA, indicador OOXML
- `apps/office-addin/src/office/redline-engine.ts` ‚Äî Adicionado campo `ooxml?: string` ao RedlineOperation, applyRedlineAsTrackedChange agora prefere OOXML pre-gerado pelo servidor, highlightClauses suporta classificacao 'compliant'

### Decisoes Tomadas
- OOXML do servidor tem prioridade sobre geracao client-side no redline-engine.ts
- Classificacoes legacy (conforme/nao_conforme/ausente/parcial) mantidas no frontend para backward compatibility
- Store usa getPlaybooksForAddin() (novo endpoint com filtro de acesso) em vez de getPlaybooks()
- Timeout de 120s para runPlaybook (analise pode ser demorada)
- Tracked changes como estrategia primaria, fallback para highlight+comentario quando OOXML nao suportado

### Verificacoes
- `npx tsc --noEmit` ‚Äî OK (zero erros de tipo)
- ESLint nao configurado para office-addin (eslint.config.js ausente) ‚Äî nao bloqueante

---

## 2026-02-02 ‚Äî Sessao 65: Embeddings Juridicos Brasileiros Especializados

### Arquivos Alterados
- `apps/api/app/services/rag/legal_vocabulary.py` ‚Äî **NOVO** Vocabulario juridico brasileiro completo: 204 abreviacoes, 47 grupos de sinonimos (193 termos), 75 termos preservados, 19 padroes de citacao regex, 61 stopwords juridicas, hierarquia normativa, funcoes de extracao de citacoes e deteccao de nivel normativo
- `apps/api/app/services/rag/legal_embeddings.py` ‚Äî **NOVO** Servico de embeddings juridicos: preprocessamento (normalizacao, expansao de abreviacoes, remocao de ruido), segmentacao inteligente respeitando artigos/clausulas, BM25 com vocabulario juridico, query augmentation (HyDE juridico, multi-query, sinonimos), integracao plug-and-play com pipeline RAG existente
- `apps/api/app/api/endpoints/rag.py` ‚Äî Adicionado `legal_mode` flag em SearchRequest, LocalIngestRequest e GlobalIngestRequest. Novo endpoint POST /embeddings/compare para comparar resultados com e sem otimizacao juridica. Integracao de preprocessing juridico nos fluxos de busca e ingestao

### Decisoes Tomadas
- Estrategia multi-embedding: OpenAI text-embedding-3-large como primario, SentenceTransformers multilingual como fallback, BM25 como lexico
- Modo juridico e opt-in (legal_mode=True) para backward compatibility total
- Preprocessamento juridico expande abreviacoes (art. -> artigo, STF -> Supremo Tribunal Federal) e remove ruido processual
- Segmentacao inteligente respeita limites de artigos/clausulas em vez de quebrar mecanicamente por tamanho
- Score combinado usa peso 70% semantico + 30% BM25 para busca hibrida juridica
- Endpoint /embeddings/compare permite avaliar impacto da otimizacao lado a lado

### Comandos Executados
- `python3 -c "import ast; ..."` ‚Äî Verificacao de sintaxe dos 3 arquivos (OK)
- Testes de funcionalidade: extracao de citacoes, preprocessamento, segmentacao, query augmentation (OK)

---

## 2026-02-02 ‚Äî Sessao 64: Column Builder para Review Tables (estilo Harvey AI)

### Arquivos Alterados
- `apps/api/app/models/review_table.py` ‚Äî Adicionados 7 novos tipos de coluna ao enum ColumnType: summary, date_extraction, yes_no_classification, verbatim_extraction, risk_rating, compliance_check, custom
- `apps/api/app/services/review_table_service.py` ‚Äî Reescrito com novas funcionalidades: generate_columns() (Column Builder via IA), fill_table() (preenchimento incremental), exportacao XLSX avancada com 3 abas (dados, resumo, metadados), color coding por tipo de coluna (risk_rating, compliance_check), mapeamento completo COLUMN_TYPE_DESCRIPTIONS
- `apps/api/app/api/endpoints/review_tables.py` ‚Äî Adicionados 5 novos endpoints: POST /columns/generate (standalone), POST /{id}/columns/generate (por review), POST /{id}/fill, POST /{id}/export/xlsx, POST /{id}/export/csv. Novos schemas: ColumnGenerateRequest, ColumnGenerateResponse, FillTableRequest, FillTableResponse. Nova background task _fill_table_background. Refatorado export com _do_export() compartilhado.

### Decisoes Tomadas
- Column Builder usa prompt especializado (COLUMN_BUILDER_PROMPT) que instrui a IA a gerar 3-15 colunas com tipos e prompts de extracao
- fill_table() e incremental: pode adicionar novos documentos a uma tabela existente sem perder resultados anteriores
- Exportacao XLSX agora tem 3 abas: dados (com color coding por tipo), resumo (estatisticas), metadados (definicoes)
- Color coding especifico para risk_rating (verde/amarelo/vermelho/critico) e compliance_check (conforme/parcialmente/nao conforme)
- Validacao de tipos de coluna contra enum ColumnType ao gerar colunas via IA
- Background tasks para fill_table com mesma pattern de process_review

### Testes Executados
- Validacao de sintaxe Python (ast.parse) dos 3 arquivos ‚Äî OK

---

## 2026-02-02 ‚Äî Sessao 63: Verificacao de Vigencia de Jurisprudencia (Shepardizacao BR)

### Arquivos Criados
- `apps/api/app/services/jurisprudence_verifier.py` ‚Äî Servico completo de shepardizacao brasileira: extrai citacoes (regex + LLM), verifica vigencia via web search + analise LLM, classifica status (vigente/superada/revogada/alterada/inconstitucional), cache em disco com TTL de 7 dias
- `apps/api/app/models/citation_verification.py` ‚Äî Modelo SQLAlchemy para persistencia de verificacoes (CitationVerification, CitationStatus, CitationType)
- `apps/api/app/schemas/citation_verification.py` ‚Äî Schemas Pydantic para request/response dos endpoints (VerifyCitationsRequest, ShepardizeRequest, etc.)

### Arquivos Alterados
- `apps/api/app/api/endpoints/knowledge.py` ‚Äî Adicionados 2 endpoints: POST /knowledge/verify-citations (texto ou lista de citacoes) e POST /knowledge/shepardize (por document_id)

### Decisoes Tomadas
- Regex como primeira camada de extracao (rapido, sem custo) + LLM para cobertura extra
- Web search via web_search_service.search_legal() (fontes juridicas BR) como fonte primaria de verificacao
- Gemini Flash como LLM de analise (custo baixo, rapido)
- Cache em disco com TTL 7 dias para evitar re-verificacoes desnecessarias
- Concorrencia controlada (semaphore max_concurrent=3) para nao sobrecarregar APIs
- Padroes de regex cobrem: sumulas, sumulas vinculantes, leis, artigos, CF, decretos, MPs, processos CNJ, acordaos (REsp, RE, HC, ADI, etc.)

### Testes Executados
- Validacao de sintaxe Python (ast.parse) de todos os 4 arquivos ‚Äî OK

---

## 2026-02-02 ‚Äî Sessao 62: Implementacao Model Router (Roteamento Inteligente de Modelos)

### Arquivos Criados
- `apps/api/app/services/ai/model_router.py` ‚Äî Servico de roteamento inteligente de modelos por tipo de tarefa (inspirado Harvey AI). Define 8 categorias de tarefa juridica, tabela de roteamento com fallbacks cross-provider, metricas in-memory, suporte a override do usuario, filtro por janela de contexto
- `apps/api/app/api/endpoints/models.py` ‚Äî Endpoints REST: POST /models/route, GET /models/routes, GET /models/metrics, GET /models/available

### Arquivos Alterados
- `apps/api/app/api/routes.py` ‚Äî Registrado router de models com prefix="/models"
- `apps/api/app/services/ai/__init__.py` ‚Äî Exportado model_router, ModelRouter, TaskCategory
- `apps/api/app/services/ai/model_registry.py` ‚Äî pick_model_for_job() atualizado para aceitar parametro task= e delegar ao ModelRouter quando informado (backward compatible)

### Decisoes Tomadas
- Tabela de roteamento estatica (nao ML) por simplicidade e previsibilidade
- Fallbacks sempre cross-provider para resiliencia
- Override do usuario tem prioridade absoluta sobre o router
- Metricas in-memory (sem persistencia) para MVP ‚Äî pode evoluir para Redis/DB
- Singleton model_router para compartilhar metricas entre requests

### Testes Executados
- Import e execucao do router via python3.11 ‚Äî OK
- DRAFTING -> claude-4.5-opus (anthropic) com fallbacks [claude-4.5-sonnet, gpt-5.2]
- RESEARCH (fast) -> gemini-3-flash
- SUMMARIZATION (override gpt-5.2) -> gpt-5.2 (is_override=True)
- Metricas de chamada e error_rate ‚Äî OK
- Route table com 8 categorias ‚Äî OK

---

## 2026-02-02 ‚Äî Sessao 61: Atualiza√ß√£o Claude Models (4.5 family) + Model Registry Fix

### Arquivos Alterados
- `apps/api/app/services/ai/claude_agent/executor.py` ‚Äî `CLAUDE_AGENT_DEFAULT_MODEL` atualizado de `claude-sonnet-4-20250514` para `claude-sonnet-4-5`. `MODEL_CONTEXT_WINDOWS` atualizado com toda fam√≠lia 4.5 (Opus/Sonnet/Haiku) + aliases + legacy models
- `apps/api/app/services/ai/model_registry.py` ‚Äî Claude 4.5 Opus: `thinking_category` de `xml` para `native`, `max_output_tokens` de 8192 para 64000. Claude 4.5 Sonnet: `max_output_tokens` de 8192 para 64000. Claude 4.5 Haiku: `for_agents` True, `thinking_category` de `agent` para `native`, `max_output_tokens` 64000, capabilities atualizadas

### Verifica√ß√£o contra docs oficiais (platform.claude.com/docs/en/about-claude/models/overview)
- **N√£o existe "Claude Haiku 4"** ‚Äî modelo atual Haiku √© **4.5** (`claude-haiku-4-5-20251001`)
- Todos os modelos 4.5 suportam extended thinking (incluindo Haiku)
- Max output: 64K tokens para todos os 4.5
- 3.5 Haiku deprecated (Jan 2026), 3.7 Sonnet deprecated (Nov 2025)

---

## 2026-02-02 ‚Äî Sessao 60: Code Review Completo + Corre√ß√£o de 117 Issues (Corpus & Playbooks)

### Resumo
Revis√£o completa da implementa√ß√£o Corpus + Playbooks seguida de corre√ß√£o massiva em paralelo.
4 agentes de review encontraram 117 issues ‚Üí 6 agentes de fix corrigiram em paralelo.

### Agente 1: Auth Guards em Endpoints Desprotegidos
- `auth.py` ‚Äî Guard de ambiente em `/login-test`
- `chat.py` ‚Äî Auth em `create_thread`, `list_threads`, `get_thread`
- `advanced.py` ‚Äî Auth em todos os 10 endpoints
- `transcription.py` ‚Äî Auth em todos os 26 endpoints
- `health.py` ‚Äî Auth + admin check em `reset-circuits`
- `webhooks.py` ‚Äî Valida√ß√£o de webhook secret

### Agente 2: Migra√ß√µes Alembic Faltantes
- `t0u1v2w3x4y5_add_shared_spaces_tables.py` ‚Äî shared_spaces + space_invites + space_resources
- `t1u2v3w4x5y6_fix_guest_sessions_chain.py` ‚Äî guest_sessions re-encadeada
- `t2u3v4w5x6y7_add_missing_model_tables.py` ‚Äî rag_eval_metrics, rag_ingestion_events, etc.
- `ef2c21b089eb_restore_missing_columns.py` ‚Äî try/except para colunas existentes
- Removido `d9a3f7e2c1b4_add_guest_sessions_table.py` (orphaned, substitu√≠do por t1u2)

### Agente 3: Seguran√ßa Backend
- `url_scraper_service.py` ‚Äî Prote√ß√£o SSRF (bloqueia IPs privados)
- `user.py` ‚Äî CPF/CNPJ removidos de UserResponse (LGPD)
- `workflow.py` ‚Äî webhook_secret removido de to_dict()
- `marketplace.py` ‚Äî Escape de wildcards SQL em search
- `shared_space.py` ‚Äî Token removido de SpaceInviteResponse
- Sanitiza√ß√£o de erros em auth, cases, word_addin, chat_integration

### Agente 4: Frontend Bugs Cr√≠ticos
- `analyze/page.tsx` ‚Äî State-during-render fixado com useEffect
- `alert-dialog.tsx` ‚Äî Novo componente shadcn/ui AlertDialog
- `playbooks/page.tsx`, `playbook-card.tsx`, `playbook-rule-editor.tsx` ‚Äî AlertDialog em deletes
- `playbooks/hooks.ts` ‚Äî Mapeamento de campos corrigido

### Agente 5: Frontend API Client
- `api-client.ts` ‚Äî 25 console.logs protegidos com NODE_ENV check, Content-Type removido de uploads
- `use-corpus.ts` ‚Äî Toasts de sucesso/erro em 6 mutations

### Agente 6: Frontend Search + Review
- `corpus-global-tab.tsx`, `corpus-private-tab.tsx` ‚Äî Busca client-side funcional
- `corpus-private-tab.tsx` ‚Äî confirm()/prompt() substitu√≠dos por AlertDialog/Dialog
- `playbook-share-dialog.tsx` ‚Äî try/catch no clipboard
- `playbooks/[id]/page.tsx` ‚Äî try/catch com toasts em save

### Verifica√ß√µes Finais
- `npx tsc --noEmit` ‚Äî OK (sem erros)
- Cadeia Alembic ‚Äî 28 migra√ß√µes, linear, sem forks
- Fork `d9a3f7e2c1b4` removido (era duplicate apontando para b7c42f)

---

## 2026-02-02 ‚Äî Sessao 59: Security - Authentication Guards on Unprotected Endpoints

### Arquivos Alterados

**Backend:**
- `apps/api/app/api/endpoints/auth.py` ‚Äî Added environment check to `/auth/login-test`: returns 404 when `DEBUG=False` and `ENVIRONMENT != "development"`.
- `apps/api/app/api/endpoints/chat.py` ‚Äî Added `current_user: User = Depends(get_current_user)` to `create_thread`, `list_threads`, and `get_thread` endpoints.
- `apps/api/app/api/endpoints/advanced.py` ‚Äî Added auth imports and `current_user` dependency to all 10 endpoints (renumber, audit-structure, consistency-check, verify-citation, dry-run-analysis, cross-file-duplicates, apply-structural-fixes, transcribe-advanced, audit-with-rag, diarization/align).
- `apps/api/app/api/endpoints/transcription.py` ‚Äî Added auth imports (`Depends`, `get_current_user`, `User`) and `current_user` dependency to all 26 endpoints.
- `apps/api/app/api/endpoints/health.py` ‚Äî Added auth imports and `current_user` dependency to `POST /health/rag/reset-circuits` with admin role check (403 if not admin).
- `apps/api/app/api/endpoints/webhooks.py` ‚Äî Implemented webhook secret validation using `settings.TRIBUNAIS_WEBHOOK_SECRET`. Rejects with 401 if secret is set and doesn't match. Logs warning if secret is not configured.

### Decis√µes Tomadas
- login-test: Returns generic 404 (not 403) in production to avoid information leakage.
- health reset-circuits: Checks `role.value` with fallback to string comparison for enum flexibility.
- webhooks: Uses `getattr` with fallback for settings access safety. Logs warning when secret not configured instead of blocking.
- All changes are additive auth guards only -- no business logic was modified.

---

## 2026-02-02 ‚Äî Sessao 59: Revis√£o completa Code Execution (todos providers) + Corre√ß√µes cr√≠ticas

### Erros Encontrados e Corrigidos

**OpenAI:**
1. **SDK version**: `openai==1.55.3` N√ÉO tem `client.responses` (Responses API). Precisa `>=1.66.0` ‚Üí Atualizado em `requirements.txt`
2. **Event name errado**: `response.code_interpreter_call.code.delta` ‚Üí correto: `response.code_interpreter_call_code.delta` (underscore, n√£o ponto)
3. **Event inexistente**: `response.code_interpreter_call_output.done` n√£o existe ‚Üí outputs v√™m em `response.code_interpreter_call.completed`
4. **GPT-5.2 variantes**: Adicionados `gpt-5.2-instant`, `gpt-5.2-pro`, `gpt-5.2-codex` no MODEL_CONTEXT_WINDOWS do executor
5. **include param**: Adicionado `include=["code_interpreter_call.outputs"]` para garantir outputs completos

**Anthropic:**
1. **effort N√ÉO vai na tool definition**: Movido de `ce_tool["effort"]` para `output_config: {"effort": "medium"}` no body da request
2. **effort requer beta header separado**: `effort-2025-11-24` (al√©m de `code-execution-2025-08-25`)
3. **effort s√≥ Opus 4.5**: Adicionado check `model.startswith("claude-opus-4")`
4. **Modelos compat√≠veis**: Adicionados `claude-sonnet-4-5`, `claude-opus-4-5`, `claude-opus-4-1`. Corrigido `claude-3-5-haiku-latest` ‚Üí `claude-3-5-haiku` (prefix match mais correto)

### Arquivos Alterados
- `apps/api/requirements.txt` ‚Äî `openai==1.55.3` ‚Üí `openai>=1.66.0`
- `apps/api/app/services/ai/agent_clients.py` ‚Äî Responses API event names corrigidos, effort movido para output_config + beta header, model compat lists atualizadas
- `apps/api/app/services/ai/claude_agent/executor.py` ‚Äî effort movido de tool def para output_config + effort beta header, model compat lists atualizadas
- `apps/api/app/services/ai/executors/openai_agent.py` ‚Äî MODEL_CONTEXT_WINDOWS com GPT-5.2 variantes

---

## 2026-02-02 ‚Äî Sessao 58: OpenAI Code Interpreter via Responses API + Container Reuse

### Arquivos Alterados

**Backend:**
- `apps/api/app/services/ai/agent_clients.py` ‚Äî `stream_openai_async()`: adicionados params `enable_code_interpreter` e `container_id`. Quando habilitado e Responses API dispon√≠vel, usa `client.responses.create(stream=True)` com `tools=[{"type":"code_interpreter","container":{"type":"auto"}}]` em vez de Chat Completions. Processa eventos streaming: `response.output_text.delta`, `response.code_interpreter_call.code.delta`, `response.code_interpreter_call_output.done`, `response.completed` (para extrair container_id). Fallback para Chat Completions se Responses API falhar.
- `apps/api/app/services/ai/executors/openai_agent.py` ‚Äî `HOSTED_TOOLS["code_interpreter"]`: atualizado para incluir `"container": {"type": "auto"}` (container reus√°vel).
- `apps/api/app/api/endpoints/chats.py` ‚Äî Handler GPT: leitura de `openai_container_id` do `chat.context`, passa como param. Handlers para `code_execution`, `code_execution_result` e `container_id` chunks. Container_id persistido em `chat.context["openai_container_id"]`.

### Problema Detectado
- `stream_openai_async` usava apenas Chat Completions API, que N√ÉO suporta code_interpreter
- Agora usa Responses API quando code_interpreter est√° habilitado, com fallback para Chat Completions

### Decis√µes Tomadas
- Responses API como path prim√°rio quando code_interpreter habilitado (Chat Completions como fallback)
- Container mode "auto" para reuso autom√°tico de containers
- Container_id persistido em `chat.context["openai_container_id"]` (sem migration)
- Containers OpenAI expiram ap√≥s 20min idle ‚Äî tratados como ef√™meros

---

## 2026-02-02 ‚Äî Sessao 57: Gemini Code Execution + Fallback Vertex AI para Claude

### Arquivos Alterados

**Backend:**
- `apps/api/app/services/ai/agent_clients.py`:
  - `stream_vertex_gemini_async()`: adicionado filtro de compatibilidade (`flash-lite` n√£o suporta code execution)
  - `get_async_claude_direct_client()`: **NOVA FUN√á√ÉO** ‚Äî client direto (non-Vertex) para features n√£o suportadas no Vertex AI
  - `stream_anthropic_async()`: quando client √© Vertex e code execution est√° habilitado, faz **fallback autom√°tico** para client direto via `ANTHROPIC_API_KEY`
- `apps/api/app/services/ai/executors/google_agent.py` ‚Äî `_convert_tools_to_gemini_format()`: filtro de modelo `flash-lite` + cascading fallback para `ToolCodeExecution` class ref (novo SDK) antes de `{}` (SDK antigo)

### Problema Detectado (CR√çTICO)
- **Code execution do Claude (`code_execution_20250825`) N√ÉO √© suportado no Vertex AI** ‚Äî apenas na API direta da Anthropic e Amazon Bedrock
- O sistema prioriza `AsyncAnthropicVertex` quando `GOOGLE_CLOUD_PROJECT` est√° configurado, o que desabilitava silenciosamente o code execution para Claude no chat comum
- O executor do Claude Agent (`ClaudeAgentExecutor`) j√° usava API direta (`AsyncAnthropic`) ‚Äî sem problema
- **Solu√ß√£o**: dual-client ‚Äî Vertex como padr√£o, fallback para client direto quando code execution √© necess√°rio

### Verifica√ß√£o Gemini
- `types.Tool(code_execution=types.ToolCodeExecution)` ‚Äî corretamente implementado com cascading fallback
- Vertex AI path funciona nativamente para Gemini (code execution suportado)
- Multi-turn no Gemini preserva estado automaticamente (sem container_id expl√≠cito)
- Flash Lite n√£o suporta code execution ‚Äî filtro adicionado
- Modelos Gemini 3.0 Pro/Flash j√° registrados

### Decis√µes Tomadas
- Dual-client para Claude: Vertex padr√£o + fallback direto para code execution
- Requer `ANTHROPIC_API_KEY` configurada al√©m do `GOOGLE_CLOUD_PROJECT` para code execution funcionar
- Gemini code execution funciona normalmente no Vertex ‚Äî sem necessidade de fallback

---

## 2026-02-02 ‚Äî Sessao 56: Effort Parameter + Container Reuse (Anthropic Code Execution)

### Arquivos Alterados

**Backend:**
- `apps/api/app/services/ai/claude_agent/executor.py` ‚Äî `AgentConfig`: adicionado `code_execution_effort: str = "medium"`. `AgentState`: adicionado `container_id: Optional[str] = None`. `_call_claude()`: aceita `container_id`, passa `effort` na tool definition e `container` no kwargs da API. Extra√ß√£o de `container_id` da resposta (`response.container.id`) em ambos os loops do agente. `to_dict()` inclui `container_id`.
- `apps/api/app/services/ai/agent_clients.py` ‚Äî `stream_anthropic_async()`: novos params `code_execution_effort` e `container_id`. Tool definition inclui campo `effort`. Container passado nos kwargs quando dispon√≠vel. Emite `('container_id', value)` ao final da stream (capturado de `message_stop` event ou `get_final_message()`).
- `apps/api/app/api/endpoints/chats.py` ‚Äî Leitura de `anthropic_container_id` do `chat.context` antes de cada chamada. Handler para `container_id` chunks que persiste o valor no `chat.context` via DB.

### Decis√µes Tomadas
- Container reuse persistido no campo `chat.context` (JSON) do modelo Chat, sem necessidade de migration
- Effort default = "medium" (equil√≠brio custo/qualidade)
- Container passado apenas quando existir (primeira chamada n√£o envia, recebe de volta)
- Extra√ß√£o do container_id usa `message_stop` event + fallback `get_final_message()`

---

## 2026-02-02 ‚Äî Sessao 55: Code Execution no Chat Comum (todos os providers)

### Arquivos Alterados

**Backend:**
- `apps/api/app/services/ai/agent_clients.py` ‚Äî `stream_anthropic_async()`: adicionado param `enable_code_execution=True`, tool `code_execution_20250825` injetada, chamada migrada para `client.beta.messages.stream()` com beta header; processamento de `content_block_start` (server_tool_use) e `content_block_stop` (bash/text_editor results). `stream_vertex_gemini_async()`: adicionado param `enable_code_execution=True`, `Tool(code_execution)` injetada no config; `_yield_parts()` atualizado para processar `executable_code` e `code_execution_result`.
- `apps/api/app/api/endpoints/chats.py` ‚Äî Handlers SSE atualizados para Claude e Gemini: novos tipos `code_execution` e `code_execution_result` emitidos via SSE para o frontend.

### Decis√µes Tomadas
- OpenAI Chat Completions API n√£o suporta code_interpreter nativamente (s√≥ Responses API/Assistants API) ‚Äî code_interpreter habilitado apenas no OpenAI Agent executor
- Claude e Gemini habilitados tanto no chat comum quanto no agent mode
- Eventos SSE de code execution seguem mesmo formato nos dois caminhos (agent + chat)

---

## 2026-02-02 ‚Äî Sessao 54: Correcao de conflitos Alembic + TypeScript

### Arquivos Alterados

**Alembic Migrations (chain fix):**
- `p7q8r9s0t1u2_add_folder_path_to_corpus_docs.py` ‚Äî down_revision corrigido: o5p6... ‚Üí p6q7...
- `q7r8s9t0u1v2_add_audit_logs_table.py` ‚Äî down_revision corrigido: p6q7... ‚Üí p7q8...
- `r8s9t0u1v2w3_enhance_dms_integrations.py` ‚Üí renomeado para `s0t1u2v3w4x5_enhance_dms_integrations.py` (revision e down_revision atualizados)
- `q7r8s9t0u1v2_add_party_perspective_cell_history.py` ‚Üí renomeado para `s9t0u1v2w3x4_add_party_perspective_cell_history.py` (revision e down_revision atualizados)

**Frontend TypeScript fix:**
- `apps/web/src/app/(dashboard)/corpus/components/corpus-private-tab.tsx` ‚Äî Import de `CorpusDocument`, fix tipo `sortDocuments` (conditional type `never` ‚Üí `CorpusDocument[]`)

### Decisoes Tomadas
- Cadeia linear Alembic: ...o5p6 ‚Üí p6q7 ‚Üí p7q8 ‚Üí q7r8 ‚Üí r8s9 ‚Üí s0t1 ‚Üí s9t0
- IDs duplicados resolvidos com novos IDs unicos (s0t1u2v3w4x5, s9t0u1v2w3x4)

### Comandos Executados
- `npx tsc --noEmit` ‚Äî 7 erros antes, 0 apos fix (OK)

---

## 2026-02-02 ‚Äî Sessao 53: Playbook UX Improvements (4 Tasks)

### Arquivos Alterados

**Backend:**
- `apps/api/app/schemas/playbook_analysis.py` ‚Äî Adicionado campo `comment` (Optional[str]) ao ClauseAnalysisResult
- `apps/api/app/services/playbook_prompts.py` ‚Äî Atualizado CLAUSE_ANALYSIS_PROMPT para gerar campo `comment`
- `apps/api/app/services/playbook_service.py` ‚Äî Atualizado analyze_clause para parsear e propagar `comment`
- `apps/api/app/api/endpoints/playbooks.py` ‚Äî Endpoint GET /{id}/versions, helper _create_version_snapshot, auto-versioning
- `apps/api/app/models/playbook.py` ‚Äî Novo modelo PlaybookVersion
- `apps/api/app/models/__init__.py` ‚Äî Export de PlaybookVersion
- `apps/api/app/schemas/playbook.py` ‚Äî PlaybookVersionResponse e PlaybookVersionListResponse
- `apps/api/alembic/versions/r8s9t0u1v2w3_add_playbook_versions_table.py` ‚Äî Migration playbook_versions

**Frontend:**
- `apps/web/src/app/(dashboard)/playbooks/hooks.ts` ‚Äî comment field, PlaybookVersionEntry, usePlaybookVersions
- `apps/web/src/app/(dashboard)/playbooks/components/playbook-analysis-panel.tsx` ‚Äî CommentBubble, StatusFilterChips
- `apps/web/src/app/(dashboard)/playbooks/[id]/page.tsx` ‚Äî PlaybookVersionTimeline, botao Historico

### Decisoes Tomadas
- Task 2 (Mark as Reviewed) ja implementada ‚Äî sem alteracao
- Comment Bubbles: icone clicavel com popover
- Status Filter: chips com contadores, dual-filter com revisao
- Version History: timeline vertical, auto-versioning em create/update/delete rule

---

## 2026-02-02 ‚Äî Sessao 52: Habilitar Code Interpreter/Execution em Todos os Agentes

### Arquivos Alterados

**Backend:**
- `apps/api/app/services/ai/executors/openai_agent.py` ‚Äî `enable_code_interpreter` mudado de `False` para `True` no default da config
- `apps/api/app/services/ai/executors/google_agent.py` ‚Äî Adicionado campo `enable_code_execution: bool = True` na config; `_convert_tools_to_gemini_format()` reescrito para incluir `Tool(code_execution={})`; processamento de `executable_code` e `code_execution_result` adicionado nos modos chat e ADK
- `apps/api/app/services/ai/claude_agent/executor.py` ‚Äî Adicionado `enable_code_execution: bool = True`; chamada API migrada para `client.beta.messages.create()` com beta header `code-execution-2025-08-25`; tool `code_execution_20250825` injetada; `_extract_response_content()` expandido para processar `server_tool_use`, `bash_code_execution_tool_result`, `text_editor_code_execution_tool_result`; tratamento de `pause_turn` stop reason
- `apps/api/app/services/ai/shared/sse_protocol.py` ‚Äî Novos tipos SSE: `CODE_EXECUTION`, `CODE_EXECUTION_RESULT`
- `apps/api/app/services/ai/orchestration/router.py` ‚Äî `enable_code_interpreter=True` no OpenAI config; `enable_code_execution=True` no Google config
- `apps/api/requirements.txt` ‚Äî `anthropic>=0.50.0` (permitir upgrade para suporte ao beta)

**Frontend:**
- `apps/web/src/stores/chat-store.ts` ‚Äî Handlers para eventos SSE `code_execution` e `code_execution_result`

### Decis√µes Tomadas
- OpenAI: Usa `code_interpreter` hosted tool (j√° implementado, s√≥ precisava habilitar)
- Google/Gemini: Usa `Tool(code_execution={})` nativa do SDK
- Claude/Anthropic: Usa beta API `code-execution-2025-08-25` com `code_execution_20250825` server tool
- Frontend: Eventos de code execution mapeados para `lastToolCall` store (reutiliza UI de tool calls)

---

## 2026-02-02 ‚Äî Sessao 51: Folder Hierarchy + Multiple Views para Corpus

### Arquivos Alterados

**Backend:**
- `apps/api/app/models/corpus_project.py` ‚Äî Adicionado campo `folder_path` (String, nullable) ao modelo CorpusProjectDocument + indice composto (project_id, folder_path)
- `apps/api/alembic/versions/p7q8r9s0t1u2_add_folder_path_to_corpus_docs.py` ‚Äî Nova migration Alembic adicionando coluna folder_path
- `apps/api/app/schemas/corpus_project.py` ‚Äî Novos schemas: FolderNode, FolderTreeResponse, MoveDocumentRequest, CreateFolderRequest. Atualizado CorpusProjectDocumentAdd e CorpusProjectDocumentResponse com folder_path
- `apps/api/app/api/endpoints/corpus_projects.py` ‚Äî 4 novos endpoints: GET folders, POST folders, GET documents (com filtro por pasta/status/sort), PATCH move document

**Frontend:**
- `apps/web/src/lib/api-client.ts` ‚Äî 4 novos metodos: getCorpusProjectFolders, createCorpusProjectFolder, getCorpusProjectDocuments, moveCorpusProjectDocument
- `apps/web/src/app/(dashboard)/corpus/hooks/use-corpus.ts` ‚Äî Novos tipos (FolderNode, FolderTreeResponse, ProjectDocumentResponse) + 4 novos hooks (useProjectFolders, useProjectDocuments, useCreateProjectFolder, useMoveProjectDocument)
- `apps/web/src/app/(dashboard)/corpus/components/corpus-folder-tree.tsx` ‚Äî Novo componente: arvore de pastas colapsavel com criacao de pastas e contagem de docs
- `apps/web/src/app/(dashboard)/corpus/components/corpus-view-controls.tsx` ‚Äî Novo componente: toggle de views (Lista/Grade/Agrupado) + dropdown de ordenacao, com persistencia em localStorage
- `apps/web/src/app/(dashboard)/corpus/components/corpus-document-views.tsx` ‚Äî Novo componente: 3 views (ListView, GridView, GroupedView) com acoes de delete/reindex/mover
- `apps/web/src/app/(dashboard)/corpus/components/corpus-private-tab.tsx` ‚Äî Reescrita integrando folder tree sidebar, breadcrumb navigation, view controls, e sorting

### Decisoes Tomadas
- Pastas virtuais (derivadas de folder_path nos documentos, sem tabela propria) ‚Äî simples e flexivel
- Arvore de pastas reconstruida no endpoint GET /folders a partir de folder_paths distintos
- View preference persistida em localStorage para manter entre sessoes
- 3 views: Lista (padrao), Grade (cards), Agrupado (por pasta)
- 3 opcoes de ordenacao: Mais recentes, Mais antigos, Ordem alfabetica
- Breadcrumb para navegacao de pastas + sidebar colapsavel em telas grandes
- Mover documentos via prompt simples (pode ser melhorado com dialog dedicado)

---

## 2026-02-02 ‚Äî Sessao 50: Dashboard Homepage Personalizada

### Arquivos Alterados
- `apps/api/app/api/endpoints/dashboard.py` ‚Äî Novo endpoint GET /dashboard/recent-activity com atividade recente e stats do usuario
- `apps/api/app/api/routes.py` ‚Äî Registro do router dashboard com prefix /dashboard
- `apps/web/src/lib/api-client.ts` ‚Äî Novo metodo getDashboardRecentActivity()
- `apps/web/src/app/(dashboard)/dashboard/page.tsx` ‚Äî Reescrita completa com welcome section, quick actions, stats bar, e grid 2x2 de atividade recente

### Decisoes Tomadas
- Endpoint unico /dashboard/recent-activity retorna tudo em uma chamada (playbooks, corpus, chats, reviews + stats)
- Playbooks com rule_count via LEFT JOIN + GROUP BY para evitar N+1
- Frontend usa useState + useCallback em vez de React Query (padrao existente do projeto)
- Loading skeletons dedicados para cada secao (welcome, stats, activity grid)
- Labels em portugues brasileiro, datas relativas (agora mesmo, Xmin atras, ontem, etc.)
- Quick actions apontam para rotas existentes (/minuta, /playbooks, /corpus, /workflows)
- Empty states com CTA para criacao quando nao ha dados

### Comandos Executados
- Leitura extensiva de modelos, endpoints, componentes e stores existentes

---

## 2026-02-02 ‚Äî Sessao 49: Inline Cell Editing + Natural Language Query para Review Tables

### Arquivos Alterados
- `apps/api/app/api/endpoints/review_tables.py` ‚Äî Novos endpoints PATCH `/{id}/cell` (editar celula) e POST `/{id}/query` (consulta LLM)
- `apps/api/app/services/review_table_service.py` ‚Äî Metodo `query_review_table` + `_format_table_for_query` para consulta em linguagem natural
- `apps/web/src/app/(dashboard)/corpus/review/page.tsx` ‚Äî Celulas editaveis inline (click-to-edit), checkbox de verificacao, barra de consulta em linguagem natural com exibicao de resposta e fontes

### Decisoes Tomadas
- Cell edits sao rastreados em campo `_edits` dentro do JSON results (metadata por celula: edited_by, edited_at, verified)
- Optimistic updates com rollback no frontend para melhor UX
- Query usa formatacao textual da tabela como contexto para o LLM, com truncamento em 25000 chars para tabelas grandes
- Resposta do LLM em JSON estruturado com answer + referenced_documents

### Comandos Executados
- Leitura e analise de arquivos existentes (OK)
- Edicao de 3 arquivos backend + frontend (OK)

---

## 2026-02-02 ‚Äî Sessao 48: Review Table Export ‚Äî Color Coding XLSX + Loading States

### Arquivos Alterados
- `apps/api/app/services/review_table_service.py` ‚Äî XLSX export com color coding (verde/vermelho/amarelo), borders, freeze panes, font bold no documento
- `apps/web/src/app/(dashboard)/corpus/review/page.tsx` ‚Äî Loading state nos bot√µes de export, filename din√¢mico do header Content-Disposition, bot√µes com labels em PT-BR ("Exportar Excel", "Exportar CSV"), bot√µes de CSV e Excel na list view

### Decis√µes Tomadas
- Color coding por conte√∫do da c√©lula: verde para valores extra√≠dos com sucesso, vermelho para erros/n√£o encontrado, amarelo para "n√£o"/"n/a", cinza para vazio
- Freeze panes em B2 para fixar header e coluna Documento ao scrollar
- Max column width aumentado de 50 para 60 chars
- Frontend extrai filename do header Content-Disposition para nome correto do arquivo

---

## 2026-02-02 ‚Äî Sessao 47: Pesquisa Harvey AI + Relat√≥rio Comparativo

### Contexto
Pesquisa extensiva sobre Harvey AI (Vault, Playbooks, Workflows) usando 5 agentes paralelos: documenta√ß√£o, help center, blog posts, Playwright screenshots e UI details.

### Arquivos Criados
- `docs/HARVEY_VS_IUDEX_COMPARISON.md` ‚Äî Relat√≥rio comparativo completo Harvey vs Iudex

### Resultados da Pesquisa
- Harvey Vault: 100k arquivos/vault, 7 tipos de coluna em Review Tables, workflows one-click com 96-99% recall
- Harvey Playbooks: classifica√ß√£o 3 n√≠veis, Word Add-In nativo, "Winning Language" extraction
- Harvey Workflows: builder visual no-code com 19k+ workflows criados
- Harvey Design System: tokens sem√¢nticos, Shadcn + custom, Cursor AI rules

### An√°lise de Gaps
- **Paridade**: Knowledge bases, review tables, playbooks 3 n√≠veis, compartilhamento, guest accounts
- **P1 Gaps**: Export Review Tables, workflows one-click, AI auto-gera√ß√£o de regras
- **P2 Gaps**: Edi√ß√£o inline, query NL sobre tabelas, views m√∫ltiplas, SAML SSO
- **P3 Gaps**: Workflow builder, DMS profundo, mobile apps, audit logs

### Decis√µes
- Diferencial Iudex = especializa√ß√£o mercado jur√≠dico brasileiro (LGPD, PJe, legisla√ß√£o BR)
- Foco P1 em: export com cores, workflows para contratos BR, gera√ß√£o autom√°tica de playbooks

---

## 2026-02-02 ‚Äî Sessao 46: Corre√ß√£o de Todos os Issues Restantes

### Arquivos Criados
- `apps/api/app/core/credential_encryption.py` ‚Äî Fernet encrypt/decrypt com prefixo `enc:`

### Corre√ß√µes Aplicadas
- **Encryption**: Senha PJe agora encriptada (Fernet) antes de salvar, descriptografada ao ler
- **Admin Role**: Endpoints admin usam `require_role("ADMIN")` (via `security.py`)
- **HIL Checkpointer**: `MemorySaver` adicionado ao `graph.compile()` para HIL resume
- **Upload Limit**: 10MB max por arquivo, UUID validation + path traversal check no delete
- **Published App**: L√≥gica `allow_org` corrigida (False = s√≥ owner)
- **BudgetExceededError**: Handling espec√≠fico com mensagem user-friendly
- **BNP Singleton**: Token cache OAuth2 reutilizado entre chamadas
- **Corpus Session**: Results processados dentro do `async with` DB session
- **Limits**: `_load_legal_db`, `_load_corpus`, `_load_bnp` clamped 1-20
- **Frontend**: Unused import removido, corpus max 2 validado no onConfirm

### Build: Python 7/7 OK, TypeScript compiled successfully

---

## 2026-02-02 ‚Äî Revisao Critica e Correcoes (Word Add-in)

### Objetivo
Auditoria completa do codebase do Office Add-in. 43 issues identificadas, correcoes aplicadas.

### Issues Corrigidas (12 criticas/medias)
1. **XSS ‚Äî ChatMessage.tsx**: DOMPurify agora usa whitelist restrita de tags (ALLOWED_TAGS, ALLOWED_ATTR, ALLOW_DATA_ATTR:false)
2. **Race condition ‚Äî chat-store.ts**: abortController movido para closure do store (nao mais module-level), abort automatico do stream anterior ao iniciar novo
3. **Stale closure ‚Äî ChatPanel.tsx**: initChat protegido com useRef para executar apenas uma vez, handleSend com useCallback e acesso via getState()
4. **Race condition ‚Äî drafting-store.ts**: guard contra edits concorrentes (abort automatico), try/catch envolvendo streamEditContent + loadSelection
5. **Error handling ‚Äî PlaybookPanel.tsx**: try/catch em todos os handlers de batch (highlightAll, batchComments, clearHighlights)
6. **Inconsistencia ‚Äî redline-engine.ts**: padronizado search text slice para 200 chars em applyRedlineAsComment (era 100)
7. **extraContext ‚Äî chat-store.ts**: contexto do corpus agora consumido automaticamente no sendMessage e limpo apos uso

### Dead Code Removido
- `src/hooks/useSSEStream.ts` ‚Äî hook nunca importado (deletado)
- `getPlaybookPrompt()` ‚Äî funcao nunca chamada (removida de client.ts)
- `EditContentRequest` interface ‚Äî tipo nao usado (removido de client.ts)
- `TranslateRequest` interface ‚Äî tipo nao usado (removido de client.ts)

### Issues Conhecidas (aceitas/nao-criticas)
- localStorage para JWT: documentado como aceitavel no contexto iframe do Office Add-in (HTTPS obrigatorio, origem isolada)
- `insertOoxml()`, `getTableCount()`, `getParagraphs()` em document-bridge: mantidos como API publica para uso futuro
- LCS diff O(n^2) com MAX=500: aceitavel para textos de clausulas juridicas (geralmente < 500 palavras)

### Verificacao Final
- `tsc --noEmit` ‚Äî OK (zero erros)
- `vite build` ‚Äî OK (322KB JS, 18KB CSS)
- 32 arquivos fonte, 0 dead code hooks

---

## 2026-02-02 ‚Äî Fase 5: Workflows Avancados (Word Add-in)

### Objetivo
Adicionar aba "Ferramentas" com workflows automatizados: traducao juridica (SSE streaming) e anonimizacao LGPD.

### Arquivos Criados
- `apps/office-addin/src/components/workflows/WorkflowPanel.tsx` ‚Äî Menu de workflows com cards clicaveis, navegacao para sub-formularios
- `apps/office-addin/src/components/workflows/TranslationForm.tsx` ‚Äî Traducao com SSE: seletor de idiomas (6 idiomas), swap, preview streaming, substituir/inserir apos/copiar/descartar, abort
- `apps/office-addin/src/components/workflows/AnonymizationForm.tsx` ‚Äî Anonimizacao LGPD: seletor de entidades (CPF/nome/endereco/telefone/email/RG/OAB), escopo selecao/documento inteiro, tabela de entidades encontradas com aplicacao individual, preview do texto anonimizado, aplicar tudo em batch

### Arquivos Alterados
- `apps/office-addin/src/api/client.ts` ‚Äî Adicionado types e funcao `anonymizeContent()` para POST /word-addin/anonymize
- `apps/office-addin/src/api/sse-client.ts` ‚Äî Adicionado `streamTranslateContent()` para POST /word-addin/translate (SSE)
- `apps/office-addin/src/components/layout/TabNavigation.tsx` ‚Äî Nova tab 'workflows' com label "Ferramentas"
- `apps/office-addin/src/components/layout/TaskPane.tsx` ‚Äî Import e render do WorkflowPanel

### Verificacao
- `tsc --noEmit` ‚Äî OK (zero erros)
- `vite build` ‚Äî OK (321KB JS, 18KB CSS)

---

## 2026-02-02 ‚Äî Fase 4: Corpus/RAG Integration (Word Add-in)

### Objetivo
Aprimorar a aba "Corpus" com store dedicado, componentes separados, filtros, selecao multipla e integracao com chat.

### Arquivos Criados
- `apps/office-addin/src/stores/corpus-store.ts` ‚Äî Store com busca, historico, filtros, selecao multipla
- `apps/office-addin/src/components/corpus/ReferenceCard.tsx` ‚Äî Card com checkbox, score, 4 acoes

### Arquivos Alterados
- `apps/office-addin/src/components/corpus/CorpusPanel.tsx` ‚Äî Refatorado com corpus-store, filtros, batch insert
- `apps/office-addin/src/stores/chat-store.ts` ‚Äî Adicionado `extraContext` + `setDocumentContext()`

### Verificacao
- `tsc --noEmit` + `vite build` ‚Äî OK (309KB JS)

---

## 2026-02-02 ‚Äî Fase 3: Drafting/Editing com IA (Word Add-in)

### Objetivo
Aprimorar a aba "Editar" do Word Add-in com modos de edicao pre-definidos, diff visual word-by-word, historico de edicoes e abort de stream.

### Arquivos Criados
- `apps/office-addin/src/stores/drafting-store.ts` ‚Äî Zustand store com: 6 modos de edicao (custom, improve, simplify, formalize, rewrite, insert-after), abort via AbortController, historico de edicoes (20 entradas), replay de historico.
- `apps/office-addin/src/components/drafting/DiffPreview.tsx` ‚Äî Dois componentes: `DiffPreview` (inline word-level diff com LCS algorithm, cores vermelho/verde) e `SideBySideDiff` (original vs editado lado a lado). Inclui stats de palavras adicionadas/removidas.

### Arquivos Alterados
- `apps/office-addin/src/components/drafting/DraftPanel.tsx` ‚Äî Refatorado para usar drafting-store. Adicionado: chips de modo de edicao, toggle inline/side-by-side diff, Cmd+Enter para enviar, botao de abort durante streaming, historico de edicoes com replay, sugestoes rapidas contextuais.

### Verificacao
- `tsc --noEmit` ‚Äî OK (zero erros)
- `vite build` ‚Äî OK (302KB JS, 17KB CSS)

---

## 2026-02-02 ‚Äî Fase 2: Playbook Analysis + Redlines (Word Add-in)

### Objetivo
Implementar a Fase 2 do Word Add-in Vorbium: an√°lise de playbooks com redlines OOXML, navega√ß√£o de cl√°usulas, filtros e opera√ß√µes em batch.

### Arquivos Criados
- `apps/office-addin/src/office/redline-engine.ts` ‚Äî Motor de redlines com 4 estrat√©gias: coment√°rio, highlight, substitui√ß√£o direta, tracked changes OOXML (`<w:ins>/<w:del>`). Inclui navega√ß√£o, highlight de cl√°usulas em batch e limpeza.
- `apps/office-addin/src/stores/playbook-store.ts` ‚Äî Zustand store com estado de an√°lise, filtros (classifica√ß√£o/severidade), tracking de redlines aplicados, computed filteredClauses e toRedlineOperations.
- `apps/office-addin/src/components/playbook/ClauseCard.tsx` ‚Äî Card individual de cl√°usula com badges de severidade/classifica√ß√£o, texto original, sugest√£o de redline, e menu de a√ß√µes (coment√°rio/destacar/preview/substituir).
- `apps/office-addin/src/components/playbook/RedlinePreview.tsx` ‚Äî Modal de preview mostrando diff visual (original em vermelho, sugerido em verde) com aceitar/rejeitar.

### Arquivos Alterados
- `apps/office-addin/src/components/playbook/PlaybookPanel.tsx` ‚Äî Refatorado para usar playbook-store, ClauseCard, RedlinePreview. Adicionado: filtros por classifica√ß√£o/severidade, barra de stats, a√ß√µes em batch (destacar tudo, comentar tudo, limpar destaques), navega√ß√£o cl√°usula‚Üídocumento.

### Verifica√ß√£o
- `tsc --noEmit` ‚Äî OK (zero erros)
- `vite build` ‚Äî OK (294KB JS, 17KB CSS)

### Decis√µes
- Redlines OOXML usam fallback para highlight+coment√°rio quando o formato tracked changes n√£o √© suportado (ex: Word Online)
- Aplica√ß√£o em batch √© sequencial (n√£o paralela) para evitar conflitos no Office.js context.sync()
- Filtros s√£o toggle no chip de severidade (clique duplo remove filtro)

---

## 2026-02-02 ‚Äî Implementa√ß√£o Corpus (RAG) + Playbooks (Harvey AI Parity)

### Objetivo
Implementar features equivalentes ao Harvey AI Vault ("Corpus") e Playbook no Iudex, incluindo backend completo, frontend, integra√ß√£o com chat/minuta e verifica√ß√£o de paridade.

### Arquivos Criados (Backend)
- `apps/api/app/models/playbook.py` ‚Äî Modelos Playbook, PlaybookRule, PlaybookShare, PlaybookAnalysis
- `apps/api/app/models/corpus_project.py` ‚Äî CorpusProject, CorpusProjectDocument, CorpusProjectShare
- `apps/api/app/models/corpus_retention.py` ‚Äî CorpusRetentionConfig
- `apps/api/app/models/review_table.py` ‚Äî ReviewTableTemplate, ReviewTable
- `apps/api/app/schemas/playbook.py` ‚Äî Schemas CRUD para Playbook e regras
- `apps/api/app/schemas/playbook_analysis.py` ‚Äî Schemas de an√°lise, classifica√ß√£o, import/export
- `apps/api/app/schemas/corpus.py` ‚Äî Schemas Corpus (stats, search, admin, retention)
- `apps/api/app/schemas/corpus_project.py` ‚Äî Schemas para projetos e knowledge bases
- `apps/api/app/services/playbook_service.py` ‚Äî Servi√ßo de an√°lise, gera√ß√£o, import/export
- `apps/api/app/services/playbook_prompts.py` ‚Äî 8 prompts PT-BR para an√°lise contratual
- `apps/api/app/services/corpus_service.py` ‚Äî Servi√ßo agregando OpenSearch + Qdrant + PostgreSQL
- `apps/api/app/services/corpus_chat_tool.py` ‚Äî Integra√ß√£o Corpus ‚Üî Chat (auto-search + fallback)
- `apps/api/app/services/review_table_service.py` ‚Äî Extra√ß√£o estruturada multi-documento
- `apps/api/app/services/review_table_templates.py` ‚Äî 5 templates jur√≠dicos BR
- `apps/api/app/api/endpoints/playbooks.py` ‚Äî 20+ endpoints (CRUD, share, analyze, import/export)
- `apps/api/app/api/endpoints/corpus.py` ‚Äî 16 endpoints (CRUD + admin)
- `apps/api/app/api/endpoints/corpus_projects.py` ‚Äî 10 endpoints (projetos + knowledge bases)
- `apps/api/app/api/endpoints/review_tables.py` ‚Äî 9 endpoints (templates + reviews + export)
- `apps/api/app/core/rate_limit.py` ‚Äî Rate limiting Redis para Corpus/Playbook
- `apps/api/app/tasks/corpus_cleanup.py` ‚Äî Cleanup de documentos expirados
- 5 migra√ß√µes Alembic

### Arquivos Criados (Frontend)
- `apps/web/src/app/(dashboard)/corpus/page.tsx` ‚Äî P√°gina principal (3 tabs: Global/Privado/Local)
- `apps/web/src/app/(dashboard)/corpus/hooks/use-corpus.ts` ‚Äî 19 hooks React Query
- `apps/web/src/app/(dashboard)/corpus/admin/page.tsx` ‚Äî Dashboard admin
- `apps/web/src/app/(dashboard)/corpus/review/page.tsx` ‚Äî Review Tables
- 8 componentes Corpus (stats, tabs, upload, admin panels)
- `apps/web/src/app/(dashboard)/playbooks/page.tsx` ‚Äî Lista de playbooks
- `apps/web/src/app/(dashboard)/playbooks/[id]/page.tsx` ‚Äî Editor de regras
- `apps/web/src/app/(dashboard)/playbooks/[id]/analyze/page.tsx` ‚Äî An√°lise de contratos
- `apps/web/src/app/(dashboard)/playbooks/hooks.ts` ‚Äî 15+ hooks com mapeamento backend
- 9 componentes Playbook (card, rule-editor, share, analysis-panel, etc.)

### Arquivos Alterados
- `apps/web/src/lib/api-client.ts` ‚Äî ~30 novos m√©todos API
- `apps/web/src/stores/chat-store.ts` ‚Äî Integra√ß√£o Playbook no chat
- `apps/web/src/components/layout/sidebar-pro.tsx` ‚Äî Links Corpus e Playbooks
- `apps/web/src/app/(dashboard)/minuta/page.tsx` ‚Äî PlaybookSelector no toolbar
- `apps/api/app/schemas/chat.py` ‚Äî Campo playbook_prompt
- `apps/api/app/api/endpoints/chats.py` ‚Äî Inje√ß√£o playbook + corpus fallback
- `apps/api/app/services/ai/langgraph_legal_workflow.py` ‚Äî Playbook no state
- `apps/api/app/services/rag/pipeline_adapter.py` ‚Äî Auto-fill RAG sources
- `apps/api/app/models/__init__.py` ‚Äî Registro dos novos modelos

### Verifica√ß√µes
- Python syntax check: 18/18 OK
- TypeScript check: 0 erros
- Todas as integra√ß√µes (Corpus‚ÜîChat, Playbook‚ÜîMinuta) conectadas

### An√°lise de Gap vs Harvey AI
- Corpus: 3 ‚úÖ, 8 ‚ö†Ô∏è, 14 ‚ùå ‚Üí Implementados todos P0+P1
- Playbook: 5 ‚úÖ, 6 ‚ö†Ô∏è, 7 ‚ùå ‚Üí Implementados todos P0+P1

### Explora√ß√£o de Features P2
Verifica√ß√£o completa do codebase revelou que **todas as 6 features P2 j√° existiam**:
- DMS Integrations (Google Drive, SharePoint/OneDrive)
- Caching multi-camada (RAG, embeddings, HTTP, Redis, React Query)
- 23+ tipos de arquivo com OCR h√≠brido
- Workflow Builder visual completo (React Flow ‚Üí LangGraph, 11 node types)
- Cita√ß√µes com grounding, ABNT, provenance tracking
- Shared Spaces + Guest Sessions

### Decis√µes Tomadas
- Nome "Corpus" (de corpus juris) para o sistema RAG
- Corpus e Biblioteca mantidos como features separadas
- Playbook‚ÜîMinuta via frontend (Option B: prompt no payload)
- Corpus‚ÜîChat via 2 camadas (pipeline auto-fill + chat tool fallback)
- Review Tables com extra√ß√£o paralela (semaphore MAX_CONCURRENT=5)

---

## 2026-02-02 ‚Äî Arquitetura H√≠brida: Fail-Fast, Agent Fallback, Self-Healing

### Objetivo
Implementar arquitetura h√≠brida nos packages `tribunais-playwright` e `sei-playwright`: fail-fast (timeout 3s), agent fallback via Claude API, self-healing de seletores com persist√™ncia em JSON, e execu√ß√£o especulativa opcional.

### Arquivos Criados
- `packages/tribunais-playwright/src/core/resilience.ts` ‚Äî Motor de resili√™ncia (failFast, withRetry, classifyError)
- `packages/tribunais-playwright/src/core/selector-store.ts` ‚Äî Persist√™ncia de seletores descobertos (JSON)
- `packages/tribunais-playwright/src/core/agent-fallback.ts` ‚Äî Integra√ß√£o Claude API para descoberta de seletores
- `packages/sei-playwright/src/core/resilience.ts` ‚Äî Mesma l√≥gica para SEI
- `packages/sei-playwright/src/core/selector-store.ts` ‚Äî Mesma l√≥gica para SEI
- `packages/sei-playwright/src/core/agent-fallback.ts` ‚Äî Mesma l√≥gica para SEI

### Arquivos Alterados
- `packages/tribunais-playwright/src/types/index.ts` ‚Äî Adicionados tipos ResilienceConfig, AgentFallbackConfig, SelectorStoreEntry
- `packages/tribunais-playwright/src/core/base-client.ts` ‚Äî M√©todos *Smart agora seguem cascata: ARIA ‚Üí CSS ‚Üí Store ‚Üí Agent
- `packages/tribunais-playwright/src/index.ts` ‚Äî Exporta novos m√≥dulos
- `packages/tribunais-playwright/package.json` ‚Äî Adicionado @anthropic-ai/sdk como optionalDependency
- `packages/sei-playwright/src/types.ts` ‚Äî Adicionados mesmos tipos
- `packages/sei-playwright/src/browser/client.ts` ‚Äî M√©todos *Smart com cascata de resili√™ncia
- `packages/sei-playwright/src/index.ts` ‚Äî Exporta novos m√≥dulos
- `packages/sei-playwright/package.json` ‚Äî Adicionado @anthropic-ai/sdk como optionalDependency

### Comandos Executados
- `npm install` ‚Äî Instala√ß√£o de depend√™ncias (OK)
- `npx tsup` em tribunais-playwright ‚Äî Build OK (ESM + CJS + DTS)
- `npx tsup` em sei-playwright ‚Äî Build OK (ESM + CJS + DTS)

### Decis√µes Tomadas
- `@anthropic-ai/sdk` como optionalDependency (n√£o quebra quem n√£o usa agent fallback)
- Lazy-load do SDK via dynamic import (s√≥ carrega quando agentFallback.enabled = true)
- SelectorStore persiste em `~/.tribunais-playwright/selector-cache.json` e `~/.sei-playwright/selector-cache.json`
- Execu√ß√£o especulativa via `Promise.all` (n√£o `Promise.race`) para evitar descarte de resultados
- Fail-fast timeout padr√£o: 3000ms (configur√°vel)

---

## 2026-02-02 ‚Äî Compound Legal Citation Parsing

### Objetivo
Implementar extra√ß√£o de cita√ß√µes jur√≠dicas compostas (hier√°rquicas) no LegalEntityExtractor, cobrindo padr√µes como "Lei 8.666/1993, Art. 23, ¬ß 1¬∫, inciso II" e "Art. 5¬∫, caput, da Constitui√ß√£o Federal".

### Arquivos Alterados
- `apps/api/app/services/rag/core/neo4j_mvp.py` ‚Äî Adicionado dataclass CompoundCitation, mapa de c√≥digos brasileiros (CODE_MAP), regex COMPOUND_PATTERN e COMPOUND_PATTERN_INVERTED, m√©todos extract_compound_citations() e extract_all()
- `apps/api/app/services/ai/citations/grounding.py` ‚Äî Adicionado status PARTIAL, fun√ß√µes extract_compound_citations_from_response() e verify_compound_against_context(), integra√ß√£o no verify_citations()

### Arquivos Criados
- `apps/api/tests/test_compound_citations.py` ‚Äî 48 testes cobrindo backward compatibility, cita√ß√µes compostas, normaliza√ß√£o de IDs, edge cases (par√°grafo √∫nico, caput, numerais romanos)

### Comandos Executados
- `pytest tests/test_compound_citations.py` ‚Äî 48 passed (OK)
- `py_compile` nos arquivos alterados ‚Äî OK

### Decis√µes Tomadas
- Regex compounds s√£o complementares √† extra√ß√£o simples (backward compat mantida)
- normalized_id segue padr√£o: `{lei/codigo}_{art}_{paragrafo}_{inciso}_{alinea}`
- Pontos em n√∫meros de lei (8.666) removidos na normaliza√ß√£o
- Padr√£o invertido ("Art. X da Lei Y") tratado separadamente
- Status PARTIAL no grounding para cita√ß√µes compostas com match parcial (confidence 0.6)

---

## 2026-02-02 ‚Äî React Query Prefetching para Navegacao

### Objetivo
Implementar prefetch de dados via React Query ao passar o mouse sobre links de navegacao e ao mudar de rota, reduzindo latencia percebida.

### Arquivos Criados
- `apps/web/src/lib/prefetch.ts` ‚Äî Hook `usePrefetchOnHover`, funcoes de prefetch centralizadas, `prefetchForRoute`
- `apps/web/src/components/providers/prefetch-provider.tsx` ‚Äî Provider que escuta mudancas de rota e prefetcha dados

### Arquivos Alterados
- `apps/web/src/components/layout/sidebar-pro.tsx` ‚Äî Adicionado prefetch on hover nos nav items (Corpus, Playbooks, Workflows, Biblioteca)
- `apps/web/src/components/providers/index.tsx` ‚Äî Integrado PrefetchProvider dentro do QueryProvider
- `apps/web/src/app/(dashboard)/workflows/page.tsx` ‚Äî Prefetch de detalhe do workflow on hover na lista
- `apps/web/src/app/(dashboard)/playbooks/components/playbook-card.tsx` ‚Äî Prefetch de detalhe do playbook on hover no card

### Decisoes Tomadas
- Debounce de 200ms no hover para evitar prefetches excessivos
- Todas as chamadas de prefetch falham silenciosamente (try/catch vazio)
- Query keys de playbooks reutilizam os mesmos patterns dos hooks existentes
- Workflows e Library nao tinham hooks React Query, entao as query keys foram definidas em `prefetch.ts`
- PrefetchProvider usa `usePathname()` do Next.js App Router (sem router events do Pages Router)

---

## 2026-02-02 ‚Äî Verbatim Mode + Source Provenance

### Objetivo
Implementar modo verbatim (extra√ß√£o literal de trechos) e proveni√™ncia de fontes (p√°gina, linha, arquivo) no pipeline de cita√ß√µes do Iudex.

### Arquivos Alterados
- `apps/api/app/services/document_processor.py` ‚Äî Adicionados `PageText`, `extract_pages_from_pdf()`, `extract_paragraphs_from_docx()` com metadados de p√°gina/linha; `chunk_by_pages` inclui `page_number`
- `apps/api/app/services/rag/utils/ingest.py` ‚Äî `Chunk` dataclass expandido com `line_start`, `line_end`, `source_file`, `doc_id`; `chunk_document()` e `chunk_pdf()` agora emitem `page_number`, `line_start`, `line_end`, `source_file` nos dicts
- `apps/api/app/services/ai/citations/grounding.py` ‚Äî Adicionado `CitationProvenance` dataclass; `CitationVerification` recebe `provenance`; `verify_citations()` aceita `rag_chunks` e popula provenance via index de chunks; `to_dict()` serializa provenance
- `apps/api/app/services/ai/citations/base.py` ‚Äî `Source` expandido com `page_number`, `line_start`, `line_end`, `source_file`, `doc_id`; `sources_to_citations()` inclui provenance
- `apps/api/app/schemas/corpus.py` ‚Äî Adicionados `VerbatimExcerpt`, `VerbatimRequest`, `VerbatimResponse`
- `apps/api/app/api/endpoints/corpus.py` ‚Äî Adicionado endpoint `POST /corpus/verbatim`
- `apps/web/src/components/workflows/citations-panel.tsx` ‚Äî Adicionado `CitationProvenance` interface; `formatProvenance()` helper; exibi√ß√£o de proveni√™ncia (Fonte, p√°gina, linhas) no painel expandido
- `apps/web/src/components/editor/extensions/citation-mark.ts` ‚Äî Adicionados atributos `pageNumber`, `lineStart`, `lineEnd`, `sourceFile`; tooltip inclui proveni√™ncia

### Decis√µes Tomadas
- Proveni√™ncia √© opcional (campos nullable) para compatibilidade retroativa
- `extract_pages_from_pdf` usa `pdfplumber.page.page_number` nativo
- Para DOCX, √≠ndice do par√°grafo √© usado como proxy de "p√°gina" (DOCX n√£o tem p√°ginas nativas)
- Endpoint verbatim reutiliza busca existente do CorpusService sem LLM
- UI em portugu√™s brasileiro conforme conven√ß√£o do projeto

---

## 2026-02-02 ‚Äî Implementacao de Guest Accounts (Acesso Anonimo/Temporario)

### Objetivo
Implementar sistema de contas guest (visitante) com acesso anonimo, temporario e somente leitura para o Iudex. Permite que usuarios externos visualizem recursos compartilhados via SharedSpaces sem necessidade de cadastro.

### Arquivos Criados
- `apps/api/app/models/guest_session.py` ‚Äî Modelo SQLAlchemy GuestSession (token, permissoes, expiracao, vinculo com space)
- `apps/api/app/schemas/guest.py` ‚Äî Schemas Pydantic para guest (create, response, info)
- `apps/api/app/api/endpoints/guest_auth.py` ‚Äî Endpoints REST: POST /auth/guest, POST /auth/guest/from-share/{token}, GET /auth/guest/me, POST /auth/guest/invalidate
- `apps/api/app/tasks/guest_cleanup.py` ‚Äî Tarefa de limpeza de sessoes expiradas
- `apps/api/alembic/versions/d9a3f7e2c1b4_add_guest_sessions_table.py` ‚Äî Migration Alembic
- `apps/web/src/app/guest/[token]/page.tsx` ‚Äî Pagina de acesso guest via link de compartilhamento
- `apps/web/src/components/guest-banner.tsx` ‚Äî Banner de visitante com countdown e CTA "Criar conta"

### Arquivos Alterados
- `apps/api/app/core/security.py` ‚Äî Adicionados: create_guest_token(), UserOrGuest dataclass, get_current_user_or_guest(), require_authenticated_user()
- `apps/api/app/core/database.py` ‚Äî Registro do modelo GuestSession no init_db
- `apps/api/app/api/routes.py` ‚Äî Registro do router guest_auth
- `apps/api/app/api/endpoints/spaces.py` ‚Äî Endpoints get_space e list_resources aceitam guests
- `apps/web/src/stores/auth-store.ts` ‚Äî Novos: isGuest, guestSession, loginAsGuest(), checkGuestExpiration()
- `apps/web/src/lib/api-client.ts` ‚Äî Novos: loginAsGuest(), createGuestSession(), getGuestInfo()
- `apps/web/src/components/layout/main-layout.tsx` ‚Äî Integrado GuestBanner

### Decisoes Tomadas
- GuestSession como tabela separada (nao campos no User) para isolamento e limpeza facil
- JWT guest com claim `is_guest=true` e mesma chave de assinatura (simplifica decodificacao)
- Sessoes guest expiram em 24h por padrao, somente leitura
- Guest vinculado a SpaceInvite token para rastreabilidade
- Backward compatible: todos os endpoints existentes continuam funcionando com auth regular

---

## 2026-02-02 ‚Äî Implementacao de Integracoes DMS (Google Drive, SharePoint, OneDrive)

### Objetivo
Implementar sistema completo de integra√ß√µes com Document Management Systems (DMS) para permitir que usu√°rios conectem Google Drive, SharePoint e OneDrive e importem/sincronizem documentos para o Corpus.

### Arquivos Criados
- `apps/api/app/models/dms_integration.py` ‚Äî Modelo SQLAlchemy para integra√ß√µes DMS
- `apps/api/app/schemas/dms.py` ‚Äî Schemas Pydantic (providers, connect, files, import, sync)
- `apps/api/app/services/dms_service.py` ‚Äî Service com DMSProvider abstrato, GoogleDriveProvider, SharePointProvider e facade DMSService
- `apps/api/app/api/endpoints/dms.py` ‚Äî Endpoints REST (providers, connect, callback, integrations CRUD, files, import, sync)
- `apps/api/alembic/versions/p6q7r8s9t0u1_add_dms_integrations_table.py` ‚Äî Migration Alembic
- `apps/web/src/components/settings/dms-integrations.tsx` ‚Äî Componente de configura√ß√£o DMS na Settings
- `apps/web/src/components/corpus/dms-file-browser.tsx` ‚Äî File browser com navega√ß√£o, busca e importa√ß√£o

### Arquivos Alterados
- `apps/api/app/core/config.py` ‚Äî Adicionadas vari√°veis DMS OAuth (GOOGLE_DRIVE_CLIENT_ID/SECRET, MICROSOFT_CLIENT_ID/SECRET/TENANT_ID, DMS_OAUTH_REDIRECT_URL)
- `apps/api/app/models/__init__.py` ‚Äî Registrado DMSIntegration
- `apps/api/app/api/routes.py` ‚Äî Registrado router DMS em `/dms`
- `apps/web/src/lib/api-client.ts` ‚Äî Adicionados m√©todos DMS (getDMSProviders, startDMSConnect, getDMSIntegrations, disconnectDMS, getDMSFiles, importDMSFiles, triggerDMSSync)
- `apps/web/src/app/(dashboard)/settings/page.tsx` ‚Äî Adicionada se√ß√£o DMS Integrations

### Decis√µes Tomadas
- Padr√£o Strategy com providers abstratos para facilitar adi√ß√£o de novos DMS
- OneDrive reutiliza SharePointProvider (mesma Microsoft Graph API)
- Credenciais OAuth encriptadas com Fernet (derivado do SECRET_KEY), fallback base64 em dev
- OAuth flow via popup no frontend com postMessage callback
- Import de arquivos salva no storage local; integra√ß√£o com Corpus RAG pipeline fica para pr√≥xima fase

---

## 2026-02-02 ‚Äî CDN/Edge Caching, Compression Headers e Service Worker

### Objetivo
Implementar cache headers, compression, service worker e offline fallback para melhorar performance e experiencia offline.

### Arquivos Alterados
- `apps/web/next.config.js` ‚Äî Adicionado `headers()` com Cache-Control para assets estaticos, fonts, imagens + security headers (X-Content-Type-Options, X-Frame-Options, Referrer-Policy)
- `apps/web/src/app/layout.tsx` ‚Äî Adicionado link para manifest.json e meta theme-color
- `apps/web/public/sw.js` ‚Äî Service Worker com cache-first (assets), network-first (API), stale-while-revalidate (catalogs/stats), offline fallback
- `apps/web/public/offline.html` ‚Äî Pagina offline em portugues
- `apps/web/public/manifest.json` ‚Äî Web App Manifest para PWA
- `apps/web/src/lib/register-sw.ts` ‚Äî Helper de registro/desregistro do SW com toast de atualizacao
- `apps/web/src/components/providers/sw-provider.tsx` ‚Äî Provider que registra SW no mount
- `apps/web/src/components/providers/index.tsx` ‚Äî Wiring do ServiceWorkerProvider
- `apps/api/app/middleware/__init__.py` ‚Äî Init do modulo middleware
- `apps/api/app/middleware/cache_headers.py` ‚Äî Middleware Cache-Control + ETag para respostas da API
- `apps/api/app/main.py` ‚Äî Adicionado CacheHeadersMiddleware (GZipMiddleware ja existia)

### Decisoes Tomadas
- GZipMiddleware ja existia no main.py, mantido como estava (minimum_size=1000)
- SSE/streaming endpoints excluidos do cache e do SW
- SW so registra em producao (opt-in via NEXT_PUBLIC_SW_DEV em dev)
- ETag gerado apenas para respostas GET < 10MB com suporte a 304 Not Modified
- Cache rules no FastAPI baseadas em regex de path

---

## 2026-02-02 ‚Äî Sessao 45: Corpus + Playbook (Harvey AI Parity) + Gap Analysis

### Objetivo
Implementar features equivalentes ao Harvey AI Vault ("Corpus") e Playbook no Iudex, com verifica√ß√£o do que j√° existia antes de implementar.

### Fase 1: Implementa√ß√£o Inicial (5 agentes paralelos)
- Backend: Playbook model/migration/API (13 endpoints), Playbook AI Service + prompts
- Frontend: Corpus page (3 tabs), Playbooks pages
- Backend: Corpus API (11 endpoints)

### Fase 2: Review + Fixes
- 4 agentes de review encontraram 5 critical, 7 moderate, 34 minor issues
- 2 agentes de fix resolveram todos os critical/moderate

### Fase 3: Gap Analysis contra Harvey AI
- Corpus vs Harvey Vault: 3 ‚úÖ, 8 ‚ö†Ô∏è, 14 ‚ùå (de 25 features)
- Playbook vs Harvey Playbook: 5 ‚úÖ, 6 ‚ö†Ô∏è, 7 ‚ùå (de 20 features)

### Fase 4: P0 Implementations (6 agentes)
- P0: Corpus hooks ‚Üí API, Playbook hooks ‚Üí API
- P0: Corpus ‚Üî Chat integration, Playbook ‚Üî Minuta integration
- P1: Playbook analysis persistence, import/export

### Fase 5: P1 Implementations (6 agentes)
- Corpus Projects + Knowledge Bases, Rate limiting + Retention
- Review tracking UI, Playbook permission enforcement
- Corpus Admin Dashboard, Review Tables (extraction)

### Fase 6: Verifica√ß√£o do que j√° existia (6 agentes explora√ß√£o)
Resultado ‚Äî features que J√Å EXISTIAM:
- ‚úÖ Workflow Builder completo (ReactFlow, 11 n√≥s, NL-to-Graph, LangGraph, HIL)
- ‚úÖ Shared Spaces (SharedSpace model, SpaceInvite, share links)
- ‚úÖ Citation Grounding (RAG + Neo4j, ABNT, multi-provider, CitationMark)
- ‚úÖ Caching (Redis service, ResultCache, React Query, file cache)
- ‚úÖ File Types (PDF, DOCX, DOC, ODT, TXT, RTF, HTML, imagens OCR, √°udio, v√≠deo, ZIP)
- ‚ùå DMS Integrations (nenhuma ‚Äî iManage, NetDocuments, SharePoint, Google Drive)

### Gaps Restantes (P2-P3)
1. P2: Verbatim Mode (extra√ß√£o exata + page/line ref)
2. P2: Compound Citation Parsing
3. P2: Source Provenance Chain
4. P2: React Query Prefetching
5. P3: Guest Accounts, DMS Integrations, CDN/Edge, Redis Cache migration

### Arquivos Criados/Modificados (~60 arquivos)
**Backend:** models/playbook.py, corpus_project.py, corpus_retention.py, review_table.py; schemas/playbook.py, playbook_analysis.py, corpus.py, corpus_project.py; services/playbook_service.py, playbook_prompts.py, corpus_service.py, corpus_chat_tool.py, review_table_service.py; endpoints/playbooks.py, corpus.py, corpus_projects.py, review_tables.py; core/rate_limit.py; tasks/corpus_cleanup.py; 5 Alembic migrations
**Frontend:** corpus/ (page + 5 components + hooks + admin + review), playbooks/ (3 pages + 9 components + hooks), playbook-selector.tsx, playbook-active-badge.tsx
**Modified:** api-client.ts (~30 novos m√©todos), chat-store.ts, sidebar-pro.tsx, routes.py, models/__init__.py, database.py, chats.py, jobs.py, chat.py schema, pipeline_adapter.py, langgraph_legal_workflow.py, minuta/page.tsx

### Build
- Python syntax check: 18/18 OK
- TypeScript: 0 errors

---

## 2026-02-02 ‚Äî Sessao 45: Auditoria Completa + Corre√ß√µes de Seguran√ßa

### Objetivo
Revis√£o completa de todos os 152 arquivos implementados. Auditoria de seguran√ßa e l√≥gica. Corre√ß√£o de 17 issues HIGH e 10 MEDIUM.

### Arquivos Alterados
- `apps/api/app/api/endpoints/users.py` ‚Äî PUT response agora redata senha; valida√ß√£o contra senha vazia
- `apps/api/app/api/endpoints/workflows.py` ‚Äî Auth no clone (template/own/same-org); admin endpoints scopados por org; approve verifica org; webhook injeta user_id; HIL resume passa user_id
- `apps/api/app/services/ai/knowledge_source_loader.py` ‚Äî Vault permission fix (user_id=None ‚Üí s√≥ shared); PJe erro sanitizado; STJ URL quote_plus; BNP passa tribunal + limit clamped
- `apps/api/app/services/ai/workflow_compiler.py` ‚Äî Erro de LLM sanitizado (sem detalhes internos)
- `apps/api/app/services/ai/workflow_runner.py` ‚Äî resume_after_hil recebe e injeta user_id
- `apps/web/src/app/(dashboard)/settings/page.tsx` ‚Äî pjeSenhaSet atualizado ap√≥s save

### Issues Corrigidos (HIGH)
1. PUT /preferences retornava senha em plaintext ‚Üí redatada
2. Vault file/folder acess√≠vel sem user_id ‚Üí s√≥ shared items
3. Clone sem autoriza√ß√£o ‚Üí requer template/own/same-org
4. Admin endpoints sem scope ‚Üí filtrados por org
5. Approve sem verifica√ß√£o de org ‚Üí 403 se outra org
6. Webhook trigger sem user_id ‚Üí injeta wf.user_id
7. HIL resume perdia user_id ‚Üí param expl√≠cito + injection
8. Senha vazia podia sobrescrever existente ‚Üí removida antes do merge

### Issues Corrigidos (MEDIUM)
1. PJe/LLM erros expunham detalhes internos ‚Üí mensagens gen√©ricas
2. STJ URL sem encoding ‚Üí quote_plus
3. BNP sem param tribunal ‚Üí passado ao client
4. BNP limit sem clamp ‚Üí min 1, max 20
5. pjeSenhaSet n√£o atualizava ap√≥s save ‚Üí corrigido

### Issues Conhecidos (n√£o corrigidos - arquiteturais)
- Senha PJe em plaintext no JSON preferences (precisa encryption layer)
- HIL checkpointer ausente no LangGraph (resume pode n√£o funcionar corretamente)
- Falta role admin formal (usando org_id como proxy)

### Build
- Python syntax: 5/5 OK
- TypeScript: 0 erros
- `npx next build`: Compiled successfully

---

## 2026-02-02 ‚Äî Sessao 44: PJe Credenciais Per-User + Pipeline user_id

### Objetivo
Completar corre√ß√£o de credenciais PJe per-user. Cada advogado tem seu pr√≥prio CPF/senha MNI, que n√£o pode ser global via env vars.

### Arquivos Alterados
- `apps/api/app/services/ai/workflow_compiler.py` ‚Äî Adicionado `user_id: Optional[str]` ao `WorkflowState`; passado `user_id` para `load_sources()`
- `apps/api/app/services/ai/workflow_runner.py` ‚Äî `initial_state` agora inclui `user_id` de `input_data`
- `apps/api/app/api/endpoints/workflows.py` ‚Äî Endpoints `run_workflow` e `test_workflow` injetam `current_user.id` no `input_data`
- `apps/web/src/app/(dashboard)/settings/page.tsx` ‚Äî Nova se√ß√£o "Credenciais PJe" com campos CPF e senha MNI, salva em `preferences.pje_credentials`

### Decis√µes Tomadas
- Credenciais PJe usam fallback de 3 n√≠veis: source config ‚Üí user preferences ‚Üí env vars
- `user_id` √© propagado: endpoint ‚Üí input_data ‚Üí WorkflowState ‚Üí load_sources ‚Üí _load_pje
- Senha PJe n√£o √© exibida ap√≥s salva (placeholder "j√° configurada"), s√≥ o CPF √© carregado no load

### Build
- `npx next build` ‚Äî OK, sem erros

---

## 2026-02-02 ‚Äî Sessao 43: Microsoft Word Office Add-in (Harvey AI Parity)

### Objetivo
Criar integra√ß√£o do Iudex com Microsoft 365 via Word Office Add-in, inspirado no Harvey AI.
O add-in √© uma React SPA carregada em task pane (sidebar) no Word, usando Office.js para
interagir com o documento e a API REST/SSE do Iudex para IA.

### Pesquisa Realizada
- Analisado como Harvey AI integra com Word, Outlook, SharePoint
- Harvey usa Office Add-ins (task pane) servidos via HTTPS
- Features: drafting, redlines, playbook reviews, Q&A, knowledge sources
- Arquitetura: React + Office.js + API REST/SSE

### Arquivos Criados

**Office Add-in (`apps/office-addin/`):**
- `package.json` ‚Äî Deps: React 18, Office.js, Fluent UI, Zustand, Vite, TailwindCSS
- `manifest.xml` ‚Äî Manifesto Office Add-in (Word host, task pane, ribbon)
- `vite.config.ts` ‚Äî Vite com HTTPS (dev-certs)
- `tsconfig.json`, `tailwind.config.ts`, `postcss.config.js` ‚Äî Config
- `index.html` ‚Äî Entry point HTML com Office.js script
- `src/main.tsx` ‚Äî Entry React com Office.onReady + FluentProvider
- `src/App.tsx` ‚Äî Root com auth guard
- `src/office/document-bridge.ts` ‚Äî Bridge Office.js (getDocumentText, getSelectedText, replaceText, addComment, etc.)
- `src/api/client.ts` ‚Äî HTTP client com JWT auto-refresh
- `src/api/sse-client.ts` ‚Äî SSE streaming consumer
- `src/stores/auth-store.ts` ‚Äî Zustand auth com persist
- `src/stores/chat-store.ts` ‚Äî Zustand chat com streaming
- `src/stores/document-store.ts` ‚Äî Estado do documento Word
- `src/components/layout/TaskPane.tsx` ‚Äî Layout principal (header + tabs)
- `src/components/layout/TabNavigation.tsx` ‚Äî Tabs: Chat, Playbook, Corpus, Editar
- `src/components/layout/Header.tsx` ‚Äî Header com user info
- `src/components/auth/LoginForm.tsx` ‚Äî Login email/senha
- `src/components/auth/AuthGuard.tsx` ‚Äî Guard de autentica√ß√£o
- `src/components/chat/ChatPanel.tsx` ‚Äî Chat Q&A com contexto do documento
- `src/components/chat/ChatInput.tsx` ‚Äî Input com envio + streaming
- `src/components/chat/ChatMessage.tsx` ‚Äî Renderiza√ß√£o de mensagens
- `src/components/playbook/PlaybookPanel.tsx` ‚Äî An√°lise com playbooks + redlines
- `src/components/corpus/CorpusPanel.tsx` ‚Äî Busca no corpus RAG
- `src/components/drafting/DraftPanel.tsx` ‚Äî Edi√ß√£o com IA + diff preview
- `src/hooks/useOfficeDocument.ts` ‚Äî Hook para document bridge
- `src/hooks/useSSEStream.ts` ‚Äî Hook gen√©rico SSE
- `src/styles/globals.css` ‚Äî TailwindCSS + Office theme

**Backend (API):**
- `apps/api/app/schemas/word_addin.py` ‚Äî Schemas Pydantic (InlineAnalyze, EditContent, Translate, Anonymize)
- `apps/api/app/services/word_addin_service.py` ‚Äî WordAddinService (analyze, edit, translate, anonymize)
- `apps/api/app/api/endpoints/word_addin.py` ‚Äî 4 endpoints: analyze-content, edit-content (SSE), translate (SSE), anonymize

### Arquivos Alterados
- `apps/api/app/core/config.py` ‚Äî Adicionado CORS origins para Office Add-in (localhost:3100)
- `apps/api/app/api/routes.py` ‚Äî Registrado router /word-addin

### Decis√µes Tomadas
- React + Vite (n√£o webpack) para o add-in ‚Äî mais r√°pido, moderno
- Manifest XML (n√£o unified JSON) ‚Äî compatibilidade mais ampla com Word desktop/Mac/Online
- Fluent UI para look-and-feel nativo do Office
- JWT em localStorage (seguro no contexto do iframe isolado do Office Add-in)
- Reutilizar PlaybookService existente para an√°lise inline
- SSE para streaming (mesmo padr√£o do apps/web)

### Pr√≥ximos Passos
- Instalar depend√™ncias (`cd apps/office-addin && npm install`)
- Gerar dev certs (`npx office-addin-dev-certs install`)
- Testar sideload no Word desktop
- Implementar Fase 2: Playbook analysis com redlines OOXML avan√ßados
- Implementar Fase 5: Workflows (tradu√ß√£o, anonimiza√ß√£o, template fill)

---

## 2026-02-02 ‚Äî Sessao 42: Review Tables (Extracao Estruturada de Documentos)

### Objetivo
Implementar Review Tables inspiradas no Harvey AI Vault: templates pre-construidos para extracao de dados estruturados de documentos em formato tabular. Permite extrair party names, datas, valores, clausulas de N documentos automaticamente.

### Arquivos Criados

**Backend (API):**
- `apps/api/app/models/review_table.py` ‚Äî Modelos ReviewTableTemplate e ReviewTable (SQLAlchemy)
- `apps/api/app/services/review_table_templates.py` ‚Äî 5 templates pre-construidos (trabalhista, TI, societario, imobiliario, franquia)
- `apps/api/app/services/review_table_service.py` ‚Äî ReviewTableService com create, process, export (CSV/XLSX), seed
- `apps/api/app/api/endpoints/review_tables.py` ‚Äî 8 endpoints REST completos
- `apps/api/alembic/versions/n4o5p6q7r8s9_add_review_table_models.py` ‚Äî Migration Alembic

**Frontend (Web):**
- `apps/web/src/app/(dashboard)/corpus/review/page.tsx` ‚Äî Pagina completa com 4 views (list, templates, create, detail/spreadsheet)

### Arquivos Alterados
- `apps/api/app/models/__init__.py` ‚Äî Registrado ReviewTable e ReviewTableTemplate
- `apps/api/app/core/database.py` ‚Äî Import do modelo na init_db
- `apps/api/app/api/routes.py` ‚Äî Registrado router /review-tables
- `apps/web/src/app/(dashboard)/corpus/page.tsx` ‚Äî Adicionado botao "Review Tables" no header

### Decisoes Tomadas
- Background processing via FastAPI BackgroundTasks para nao bloquear request
- Extracao coluna-por-coluna com IA (Gemini Flash + fallback Claude) para maior precisao
- Templates system com is_system=True, seed idempotente
- Export XLSX com openpyxl (headers estilizados), CSV com BOM UTF-8
- Frontend como pagina separada /corpus/review com navegacao de volta ao corpus
- Schemas inline no endpoint (seguindo padrao simples do projeto)

### Comandos Executados
- `python3 -c "import ast; ast.parse(...)"` ‚Äî Verificacao de sintaxe de todos os arquivos (OK)

---

## 2026-02-02 ‚Äî Sessao 41: Corpus Admin Dashboard

### Objetivo
Criar painel administrativo completo para o Corpus, inspirado no Harvey AI, dando visibilidade total sobre documentos, usuarios e atividades da organizacao.

### Arquivos Alterados

**Backend (API):**
- `apps/api/app/schemas/corpus.py` ‚Äî Adicionados schemas admin: CorpusAdminOverview, CorpusAdminUserStats, CorpusAdminUserList, CorpusAdminActivity, CorpusAdminActivityList, CorpusTransferRequest, CorpusTransferResponse
- `apps/api/app/services/corpus_service.py` ‚Äî Adicionados metodos admin: get_admin_overview, get_corpus_users, get_user_documents, transfer_ownership, get_corpus_activity
- `apps/api/app/api/endpoints/corpus.py` ‚Äî Adicionados 5 endpoints admin: /admin/overview, /admin/users, /admin/users/{user_id}/documents, /admin/transfer/{document_id}, /admin/activity

**Frontend (Web):**
- `apps/web/src/lib/api-client.ts` ‚Äî Adicionados metodos admin: getCorpusAdminOverview, getCorpusAdminUsers, getCorpusAdminUserDocuments, transferCorpusDocument, getCorpusAdminActivity
- `apps/web/src/app/(dashboard)/corpus/hooks/use-corpus.ts` ‚Äî Adicionados types e hooks admin: useCorpusAdminOverview, useCorpusAdminUsers, useCorpusAdminUserDocuments, useCorpusAdminActivity, useTransferDocumentOwnership
- `apps/web/src/app/(dashboard)/corpus/admin/page.tsx` ‚Äî Pagina admin com tabs (Visao Geral, Usuarios, Atividade)
- `apps/web/src/app/(dashboard)/corpus/admin/corpus-admin-overview.tsx` ‚Äî Cards de stats, top contribuidores, atividade recente, distribuicao por colecao
- `apps/web/src/app/(dashboard)/corpus/admin/corpus-admin-users.tsx` ‚Äî Tabela de usuarios com linhas expansiveis mostrando documentos e opcao de transferir propriedade
- `apps/web/src/app/(dashboard)/corpus/admin/corpus-admin-activity.tsx` ‚Äî Feed de atividades com filtros por acao e paginacao
- `apps/web/src/app/(dashboard)/corpus/page.tsx` ‚Äî Adicionado botao "Painel Admin" visivel apenas para admins

### Comandos Executados
- `python3 -m py_compile` em todos os arquivos Python ‚Äî OK
- `npx tsc --noEmit` ‚Äî OK (zero erros)

### Decisoes Tomadas
- Endpoints admin verificam UserRole.ADMIN via _require_admin_org helper
- Reutilizou CorpusDocumentList para documentos de usuario (visao admin)
- Transferencia de propriedade verifica se novo dono pertence a mesma org
- Activity log derivado dos metadados dos documentos (status, timestamps)
- Frontend com prote√ß√£o client-side: redirect se nao admin + UI placeholder

---

## 2026-02-02 ‚Äî Sessao 40: Dynamic Corpus Projects com Knowledge Base

### Objetivo
Implementar projetos dinamicos de corpus (similar ao "Vault Projects" do Harvey AI) com suporte a Knowledge Base para consulta workspace-wide.

### Arquivos Criados
- `apps/api/app/models/corpus_project.py` ‚Äî Modelos SQLAlchemy: CorpusProject, CorpusProjectDocument, CorpusProjectShare com enums e relationships
- `apps/api/app/schemas/corpus_project.py` ‚Äî Schemas Pydantic: Create, Update, Response, List, DocumentAdd, Share, Transfer
- `apps/api/app/api/endpoints/corpus_projects.py` ‚Äî Endpoints REST completos: CRUD de projetos, gerenciamento de documentos, compartilhamento e transferencia
- `apps/api/alembic/versions/o5p6q7r8s9t0_add_corpus_projects_tables.py` ‚Äî Migration para 3 tabelas: corpus_projects, corpus_project_documents, corpus_project_shares

### Arquivos Alterados
- `apps/api/app/models/__init__.py` ‚Äî Registrado CorpusProject, CorpusProjectDocument, CorpusProjectShare
- `apps/api/app/core/database.py` ‚Äî Import dos novos modelos em init_db()
- `apps/api/app/api/routes.py` ‚Äî Registrado router corpus_projects em /corpus/projects
- `apps/web/src/lib/api-client.ts` ‚Äî 10 novos metodos para API de projects (CRUD, documents, share, transfer)
- `apps/web/src/app/(dashboard)/corpus/hooks/use-corpus.ts` ‚Äî 7 novos hooks React Query para projects
- `apps/web/src/app/(dashboard)/corpus/components/corpus-private-tab.tsx` ‚Äî Secao de Projects com cards, dialog de criacao, e badge de Knowledge Base

### Decisoes Tomadas
- Soft-delete para projetos (is_active flag) em vez de hard-delete
- collection_name auto-gerado como slug unico para OpenSearch/Qdrant
- Projects vis√≠veis: proprios + compartilhados + KB da organizacao
- Migration encadeada apos n4o5p6q7r8s9 (retention configs)

### Comandos Executados
- `python3 -m py_compile` em todos os arquivos Python ‚Äî OK
- `npx tsc --noEmit` ‚Äî OK (exit 0)

---

## 2026-02-02 ‚Äî Sessao 39: BNP (Banco Nacional de Precedentes) MCP Server

### Objetivo
Criar servidor MCP customizado para o BNP/Pangea, integrado na plataforma Iudex como servidor built-in, endpoint HTTP e knowledge source para workflows.

### Arquivos Criados
- `apps/api/app/services/mcp_servers/__init__.py` ‚Äî Init do modulo mcp_servers
- `apps/api/app/services/mcp_servers/bnp_server.py` ‚Äî BNPClient (OAuth2 client_credentials) + BNPMCPServer (JSON-RPC handler) com 3 tools: search_precedentes, search_recursos_repetitivos, search_repercussao_geral
- `apps/api/app/api/endpoints/mcp_bnp.py` ‚Äî Endpoint FastAPI JSON-RPC para o BNP MCP server

### Arquivos Alterados
- `apps/api/app/services/mcp_config.py` ‚Äî Adicionado BUILTIN_MCP_SERVERS config e load_builtin_mcp_servers() para servidores MCP in-process
- `apps/api/app/services/mcp_hub.py` ‚Äî Suporte a servidores built-in: _is_builtin(), _get_builtin_handler(), roteamento direto em _rpc() sem HTTP
- `apps/api/app/api/routes.py` ‚Äî Registrado mcp_bnp router
- `apps/api/app/services/ai/knowledge_source_loader.py` ‚Äî Adicionado source_type "bnp" com metodo _load_bnp()
- `apps/web/src/components/workflows/properties-panel.tsx` ‚Äî Adicionado BNP como opcao de knowledge source (icone, label, dropdown, handler)

### Decisoes Tomadas
- BNP registrado como servidor built-in (url builtin://bnp) para evitar overhead HTTP quando chamado internamente pelo MCPHub
- Endpoint HTTP /mcp/bnp/rpc tambem disponivel para consumo externo
- OAuth2 token cacheado com margem de 30s antes da expiracao
- Busca "todos" faz merge de recursos repetitivos + repercussao geral
- Knowledge source usa BNPClient diretamente (sem passar pelo MCP) para eficiencia

---

## 2026-02-02 ‚Äî Sessao 38: Rate Limiting Corpus/Playbook + Retention Policy Persistence

### Objetivo
Implementar rate limiting nos endpoints de Corpus e Playbook (inspirado nos limites da Harvey AI), e tornar as retention policies persistiveis por organizacao no banco de dados.

### Arquivos Criados
- `apps/api/app/core/rate_limit.py` ‚Äî Dependencias reutilizaveis de rate-limiting (RateLimitDep) com limites pre-configurados para Corpus e Playbook
- `apps/api/app/models/corpus_retention.py` ‚Äî Modelo SQLAlchemy CorpusRetentionConfig para persistencia de politicas de retencao por organizacao
- `apps/api/app/tasks/__init__.py` ‚Äî Init do modulo de tasks
- `apps/api/app/tasks/corpus_cleanup.py` ‚Äî Background task para limpeza automatica de documentos expirados com base nas retention policies
- `apps/api/alembic/versions/n4o5p6q7r8s9_add_corpus_retention_configs.py` ‚Äî Migration para tabela corpus_retention_configs

### Arquivos Alterados
- `apps/api/app/api/endpoints/corpus.py` ‚Äî Adicionado rate limiting (Depends) a todos os endpoints: 10/min search, 30/min reads, 5/min writes
- `apps/api/app/api/endpoints/playbooks.py` ‚Äî Adicionado rate limiting: 30/min reads, 10/min writes, 5/min analyze, 3/min generate
- `apps/api/app/services/corpus_service.py` ‚Äî get_retention_policies() agora busca politicas no banco com fallback para RAGConfig; update_retention_policy() agora persiste via upsert
- `apps/api/app/models/__init__.py` ‚Äî Registrado CorpusRetentionConfig
- `apps/api/app/core/database.py` ‚Äî Registrado CorpusRetentionConfig no init_db

### Decisoes Tomadas
- Rate limiting usa o RateLimiter existente (core/rate_limiter.py) via Redis, com dependency injection (Depends) em vez de decorators manuais
- Limites por endpoint-scope evitam que um tipo de operacao afete outro (ex: buscas nao competem com escritas)
- Retention policies usam UniqueConstraint (org_id, scope, collection) para garantir uma policy por combinacao
- Cleanup task projetada como funcao async standalone para flexibilidade (Celery, BackgroundTasks, cron)

---

## 2026-02-02 ‚Äî Sessao 37: Integra√ß√£o PJe via TecJusti√ßa REST API

### Objetivo
Integrar a API REST TecJusti√ßa como fonte de conhecimento (knowledge source) no sistema de workflows do Iudex, permitindo consultar dados de processos do PJe diretamente nos prompts.

### Arquivos Alterados
- `apps/api/app/services/ai/knowledge_source_loader.py` ‚Äî Adicionado tipo `pje` no dispatch table, m√©todos `_load_pje`, `_format_pje_processo` e `_format_pje_capa`, documenta√ß√£o de env vars
- `apps/web/src/components/workflows/properties-panel.tsx` ‚Äî Adicionada op√ß√£o PJe no dropdown de fontes, √≠cone no SOURCE_ICONS, label no display, handler no onChange

### Decis√µes Tomadas
- Autentica√ß√£o via headers (X-API-KEY, X-MNI-CPF, X-MNI-SENHA) configurada por env vars, seguindo padr√£o de seguran√ßa do projeto
- Extra√ß√£o autom√°tica de n√∫mero CNJ do query via regex quando n√£o especificado na config da source
- Modo `auto` consulta dados do processo + lista de documentos + capa; modos `processo`, `documentos` e `capa` dispon√≠veis
- √çcone `Scale` reutilizado para PJe (consistente com outras fontes jur√≠dicas)

### Comandos Executados
- `python3 -m py_compile` ‚Äî OK (sem erros de sintaxe)
- `npx tsc --noEmit` ‚Äî OK (sem erros de tipo no arquivo modificado)

---

## 2026-02-02 ‚Äî Sessao 36: Shared Spaces (Workspaces para Clientes Externos)

### Objetivo
Implementar feature "Shared Spaces" ‚Äî workspaces branded onde organizacoes podem convidar clientes externos (guests) com acesso controlado a workflows, documentos e runs.

### Arquivos Criados
- `apps/api/app/models/shared_space.py` ‚Äî Modelos SQLAlchemy: SharedSpace, SpaceInvite, SpaceResource com enums SpaceRole e InviteStatus
- `apps/api/app/schemas/shared_space.py` ‚Äî Schemas Pydantic para request/response dos endpoints
- `apps/api/app/api/endpoints/spaces.py` ‚Äî API completa com 12 endpoints: CRUD de spaces, convites, join por token, recursos
- `apps/web/src/app/(dashboard)/spaces/page.tsx` ‚Äî Pagina de listagem de spaces com grid de cards e dialog de criacao
- `apps/web/src/app/(dashboard)/spaces/[id]/page.tsx` ‚Äî Pagina de detalhes com tabs: Recursos, Membros, Configuracoes

### Arquivos Alterados
- `apps/api/app/api/routes.py` ‚Äî Registrado spaces.router com prefix "/spaces"
- `apps/api/app/models/__init__.py` ‚Äî Exportados SharedSpace, SpaceInvite, SpaceResource, SpaceRole, InviteStatus
- `apps/api/app/core/database.py` ‚Äî Importados modelos para auto-criacao de tabelas no init_db
- `apps/web/src/components/layout/sidebar-pro.tsx` ‚Äî Adicionado link "Spaces" com icone Share2 na navegacao principal

### Decisoes Tomadas
- Modelos SQLAlchemy proprios (nao JSONB) seguindo padrao existente do projeto para Organization/Team
- Convites via token unico (secrets.token_urlsafe) para seguranca ‚Äî nao depende de email magic link
- Acesso verificado por: membro da org dona do space OU convite aceito com role adequada
- Soft delete para spaces (is_active=False) mantendo historico
- Frontend usa apiClient.request() generico (nao metodos dedicados) para simplificar integracao inicial
- SpaceResource armazena resource_name cacheado para exibicao sem necessidade de join com tabelas de recursos

---

## 2026-02-02 ‚Äî Sessao 35: Custom Published Workflows (Standalone App URLs)

### Objetivo
Permitir que organizacoes publiquem workflows como apps standalone com URLs dedicadas (/app/{slug}) acessiveis diretamente por usuarios internos ou externos.

### Arquivos Criados
- `apps/web/src/components/workflows/publish-dialog.tsx` ‚Äî Dialog para publicar/despublicar workflow com slug customizavel
- `apps/web/src/app/app/[slug]/page.tsx` ‚Äî Pagina standalone do app publicado com runner UI
- `apps/api/alembic/versions/m3n4o5p6q7r8_add_workflow_published_app.py` ‚Äî Migracao para campos published_slug e published_config

### Arquivos Alterados
- `apps/api/app/models/workflow.py` ‚Äî Adicionados campos published_slug (String unique indexed) e published_config (JSON)
- `apps/api/app/core/security.py` ‚Äî Adicionada dependency get_current_user_optional para endpoints com auth opcional
- `apps/api/app/api/endpoints/workflows.py` ‚Äî Endpoint publish reescrito com suporte a slug/config; adicionados endpoints unpublish e GET /app/{slug}; WorkflowResponse atualizado com campos de publicacao
- `apps/web/src/lib/api-client.ts` ‚Äî Interface WorkflowResponse atualizada com published_slug e published_config
- `apps/web/src/components/workflows/workflow-builder.tsx` ‚Äî Botao "Publicar" na toolbar com PublishDialog integrado

### Decisoes Tomadas
- Slug armazenado como campo unico indexado no modelo Workflow (nao em JSON generico) para performance de lookup
- Auth opcional via get_current_user_optional que retorna None em vez de 403
- Endpoint publish aceita workflows em qualquer status (nao exige aprovacao previa) para flexibilidade
- Pagina standalone (/app/[slug]) e completamente independente do layout do dashboard

### Comandos Executados
- `python3 -c "import ast; ..."` ‚Äî Validacao de sintaxe Python (OK)
- `npx tsc --noEmit` ‚Äî Verificacao de tipos TypeScript (OK)

---

## 2026-02-02 ‚Äî Sessao 34: Assistente Contextual (Harvey AI Assistant Parity)

### Objetivo
Implementar feature de Assistente Contextual que permite ao usuario conversar com IA dentro de qualquer workflow, documento ou corpus com contexto persistente.

### Arquivos Criados
- `apps/api/app/api/endpoints/assistant.py` ‚Äî Endpoint POST /assistant/chat com SSE streaming
- `apps/web/src/components/assistant/assistant-panel.tsx` ‚Äî Painel slide-over com chat
- `apps/web/src/components/assistant/index.ts` ‚Äî Barrel export

### Arquivos Alterados
- `apps/api/app/api/routes.py` ‚Äî Registro do router assistant
- `apps/web/src/components/workflows/workflow-builder.tsx` ‚Äî Botao "Assistente" + AssistantPanel

### Decisoes Tomadas
- OpenAI como provider primario com fallback para Claude
- Panel fixo no lado direito (400px) com minimizacao
- SSE streaming seguindo padrao existente do codebase

---

## 2026-02-02 ‚Äî Sessao 33: Audit Trail para Workflow Runs

### Objetivo
Implementar audit trail completo para execucoes de workflows: endpoint de auditoria paginado no backend e componente visual no frontend.

### Arquivos Criados
- `apps/web/src/components/workflows/audit-trail.tsx` ‚Äî Componente AuditTrail com lista expandivel de execucoes, paginacao, detalhes de input/output/erro por entrada

### Arquivos Alterados
- `apps/api/app/api/endpoints/workflows.py` ‚Äî Adicionado import de Query, novo endpoint GET `/{workflow_id}/audit` com join User+WorkflowRun, paginacao, summaries de input/output, duracao
- `apps/web/src/components/workflows/workflow-builder.tsx` ‚Äî Importados AuditTrail e VersionHistory, renderizados no painel lateral direito quando nenhum no esta selecionado
- `apps/web/src/components/workflows/index.ts` ‚Äî Adicionado export do AuditTrail

### Decisoes Tomadas
- Reutilizou o modelo WorkflowRun existente (ja possui user_id, input_data, output_data, started_at, completed_at, error_message, trigger_type)
- Endpoint de audit faz JOIN com User para retornar nome/email de quem executou
- Summaries de input/output truncados em 200 chars para nao sobrecarregar a resposta
- AuditTrail e VersionHistory ficam no painel direito quando nenhum no esta selecionado, evitando poluir a interface
- Paginacao com load-more no frontend (10 itens por pagina)

### Comandos Executados
- TypeScript type-check ‚Äî OK (sem erros)
- Python syntax check ‚Äî OK

---

## 2026-02-02 ‚Äî Sess√£o 32: Vault Analytics Dashboard

### Objetivo
Implementar dashboard de Analytics inspirado no Harvey AI Vault Analytics, com metricas de Corpus, Workflows e Documentos.

### Arquivos Criados
- `apps/api/app/api/endpoints/analytics.py` ‚Äî 5 endpoints de analytics (corpus/overview, corpus/trending, corpus/usage-over-time, workflows/stats, documents/insights)
- `apps/web/src/app/(dashboard)/analytics/page.tsx` ‚Äî Pagina de dashboard com cards de resumo, graficos de uso, trending topics, e stats de workflows

### Arquivos Alterados
- `apps/api/app/api/routes.py` ‚Äî Registro do router de analytics
- `apps/web/src/components/layout/sidebar-pro.tsx` ‚Äî Link de navegacao "Analytics" com icone BarChart3

### Decisoes Tomadas
- Usa RAGTraceEvent como fonte primaria de dados de busca, com fallback para ChatMessage como proxy
- Usa COLLECTION_DISPLAY do corpus_service para manter consistencia nos nomes das colecoes
- Endpoints usam get_org_context para suporte multi-tenant
- Frontend usa fetchWithAuth nativo (sem axios) para chamadas simples de GET

### Comandos Executados
- Import test do analytics router ‚Äî OK
- TypeScript type-check do analytics page ‚Äî OK (sem erros)

---

## 2026-02-02 ‚Äî Sess√£o 31: Mega-sess√£o Corpus + Playbook (Harvey AI Parity)

### Objetivo
Implementar dois m√≥dulos completos inspirados no Harvey AI: **Corpus** (equivalente ao Vault ‚Äî RAG unificado) e **Playbook** (regras estruturadas para revis√£o de contratos). Inclui cria√ß√£o, revis√£o, corre√ß√£o de bugs, gap analysis contra documenta√ß√£o oficial do Harvey, e implementa√ß√£o de P0/P1.

### Fases da Sess√£o

**Fase 1 ‚Äî Implementa√ß√£o inicial (5 agentes em paralelo)**
- Backend Playbook: modelo + migration + 13 endpoints CRUD
- Playbook AI Service: an√°lise de contratos + gera√ß√£o autom√°tica + 6 prompts PT-BR
- Frontend Corpus: p√°gina `/corpus` com 3 tabs (Global/Privado/Local)
- Frontend Playbooks: editor de regras, wizard de gera√ß√£o, painel de an√°lise
- Backend Corpus API: 11 endpoints + servi√ßo unificado dos 3 backends RAG

**Fase 2 ‚Äî Revis√£o de c√≥digo (4 agentes em paralelo)**
- 5 issues cr√≠ticos encontrados e corrigidos (imports errados, bug order==0, tipo incompat√≠vel)
- 7 issues moderados corrigidos (enums, stale state, imports n√£o usados)
- 34 issues menores documentados

**Fase 3 ‚Äî Gap Analysis vs Harvey AI (2 agentes em paralelo)**
- Corpus: 3 ‚úÖ, 8 ‚ö†Ô∏è parciais, 14 ‚ùå ausentes (de 25 features)
- Playbook: 5 ‚úÖ, 6 ‚ö†Ô∏è parciais, 7 ‚ùå ausentes (de 20 features)

**Fase 4 ‚Äî P0 + P1 (6 agentes em paralelo)**
- P0: Hooks frontend conectados √† API real (zero mock data)
- P0: Corpus ‚Üî Chat (auto-busca com heur√≠stica jur√≠dica)
- P0: Playbook ‚Üî Minuta (seletor + inje√ß√£o no agente)
- P1: Persist√™ncia de an√°lises (modelo + migration + review tracking)
- P1: Import de playbook existente (PDF/Word ‚Üí regras via IA)
- P1: Export (JSON/PDF/DOCX com reportlab + python-docx)

### Arquivos Criados (~40 novos)

**Backend:**
- `app/models/playbook.py` ‚Äî Playbook, PlaybookRule, PlaybookShare, PlaybookAnalysis
- `app/schemas/playbook.py` ‚Äî Schemas CRUD
- `app/schemas/playbook_analysis.py` ‚Äî Schemas de an√°lise + import/export
- `app/schemas/corpus.py` ‚Äî 12 schemas do Corpus
- `app/api/endpoints/playbooks.py` ‚Äî 20+ endpoints
- `app/api/endpoints/corpus.py` ‚Äî 11 endpoints
- `app/services/playbook_service.py` ‚Äî An√°lise, gera√ß√£o, import, export
- `app/services/playbook_prompts.py` ‚Äî 8 prompts PT-BR
- `app/services/corpus_service.py` ‚Äî Agrega√ß√£o OpenSearch + Qdrant + PostgreSQL
- `app/services/corpus_chat_tool.py` ‚Äî Integra√ß√£o Corpus ‚Üî Chat
- 2 migrations Alembic (playbooks + playbook_analyses)

**Frontend:**
- `/corpus/` ‚Äî page + 5 componentes + hooks
- `/playbooks/` ‚Äî 3 pages + 9 componentes + hooks
- `playbook-selector.tsx` + `playbook-active-badge.tsx` (integra√ß√£o /minuta)

**Modificados (~15):**
- `api/routes.py`, `models/__init__.py`, `core/database.py`
- `sidebar-pro.tsx`, `api-client.ts`, `chat-store.ts`
- `minuta/page.tsx`, `chats.py`, `jobs.py`, `chat.py` schema
- `pipeline_adapter.py`, `langgraph_legal_workflow.py`

### Verifica√ß√£o Final
- Python: 18/18 arquivos OK (py_compile)
- TypeScript: 0 erros (tsc --noEmit)

### Decis√µes Tomadas
- Nome "Corpus" em vez de "Vault" (remete a corpus juris, mais adequado ao mercado BR)
- Corpus e Biblioteca mantidos separados (fun√ß√µes distintas: IA vs usu√°rio)
- Playbook ‚Üî Minuta usa Option B (frontend busca prompt e envia no payload)
- Corpus ‚Üî Chat usa heur√≠stica + fallback (2 camadas de integra√ß√£o)
- `CORPUS_AUTO_SEARCH=true` como default (control√°vel por env)

### Gap Analysis Pendente (P1/P2 para pr√≥ximas sess√µes)
- Projetos din√¢micos no Corpus + Knowledge Bases ilimitadas
- Admin dashboard cross-org
- Sharing com permiss√µes granulares (Corpus + enforcement no Playbook)
- Review Tables (extra√ß√£o one-click com templates BR)
- Upload paralelo + per-file status tracking (SSE)
- Rate limiting (slowapi)
- Tracking de revis√£o na UI (reviewed/unreviewed no analysis panel)
- DMS integrations (Google Drive, SharePoint)

---

## 2026-02-02 ‚Äî Sessao 30: Integrar Playbook na pagina /minuta

### Objetivo
Permitir que usuarios selecionem um Playbook ao revisar contratos em /minuta, injetando as regras no system prompt do agente de IA.

### Arquivos Editados

**Frontend:**
- `apps/web/src/stores/chat-store.ts` ‚Äî Adicionados campos `selectedPlaybookId`, `selectedPlaybookName`, `selectedPlaybookPrompt`, `isPlaybookLoading` no ChatState, com setters `setSelectedPlaybook()` e `clearPlaybook()`. Injetado `playbook_prompt` nos payloads de `sendMessage`, `startAgentGeneration` (legacy) e `startLangGraphJob`.
- `apps/web/src/app/(dashboard)/playbooks/hooks.ts` ‚Äî Adicionados `usePlaybookPrompt()` (busca prompt formatado via GET /playbooks/{id}/prompt) e `useActivePlaybooks()`.
- `apps/web/src/app/(dashboard)/playbooks/components/playbook-selector.tsx` ‚Äî Novo componente dropdown para selecao de playbook na toolbar do /minuta.
- `apps/web/src/app/(dashboard)/playbooks/components/playbook-active-badge.tsx` ‚Äî Novo componente badge inline mostrando playbook ativo no painel de chat.
- `apps/web/src/app/(dashboard)/minuta/page.tsx` ‚Äî Integrado PlaybookSelector na toolbar e PlaybookActiveBadge no painel de chat.

**Backend:**
- `apps/api/app/schemas/chat.py` ‚Äî Adicionado campo `playbook_prompt: Optional[str]` ao MessageCreate.
- `apps/api/app/api/endpoints/chats.py` ‚Äî Injecao do playbook_prompt no base_instruction antes do streaming.
- `apps/api/app/api/endpoints/jobs.py` ‚Äî Passagem do playbook_prompt no state do LangGraph job.
- `apps/api/app/services/ai/langgraph_legal_workflow.py` ‚Äî Adicionado `playbook_prompt` ao LegalWorkflowState TypedDict. Injecao em 4 pontos do workflow (planner, web search, drafter, committee).

### Decisoes Tomadas
- **Option B (Frontend fetches prompt)**: O frontend busca o prompt formatado via GET /playbooks/{id}/prompt e o envia como `playbook_prompt` nos payloads. Mais simples e desacoplado.
- O prompt e injetado em TODOS os caminhos de geracao: chat streaming, LangGraph jobs, e geracao legacy.
- O playbook_prompt e concatenado ao system_instruction, nao o substitui.

### Comandos Executados
- `npx tsc --noEmit` ‚Äî OK
- `npx eslint` ‚Äî OK
- `python3 -c "import ast; ast.parse(...)"` ‚Äî OK (todos os .py)

---

## 2026-02-02 ‚Äî Sess√£o 29: Implementar Import/Export de Playbooks

### Objetivo
Implementar duas features inspiradas no Harvey AI que estavam faltando nos Playbooks:
1. **Import**: Upload de um documento existente (PDF/DOCX) e extra√ß√£o de regras via IA
2. **Export**: Download do playbook como PDF, DOCX ou JSON

### Arquivos Editados

**Backend:**
- `apps/api/app/services/playbook_prompts.py` ‚Äî Adicionado `PLAYBOOK_IMPORT_PROMPT` para extra√ß√£o de regras de documentos existentes
- `apps/api/app/services/playbook_service.py` ‚Äî Adicionados m√©todos `import_playbook_from_document()` e `export_playbook()` com helpers `_export_as_json()`, `_export_as_pdf()` (reportlab) e `_export_as_docx()` (python-docx)
- `apps/api/app/schemas/playbook_analysis.py` ‚Äî Adicionados schemas `PlaybookImportRequest` e `PlaybookImportResponse`
- `apps/api/app/api/endpoints/playbooks.py` ‚Äî Adicionados endpoints `POST /playbooks/import` e `GET /playbooks/{id}/export?format=json|pdf|docx`

**Frontend:**
- `apps/web/src/app/(dashboard)/playbooks/hooks.ts` ‚Äî Adicionados `useImportPlaybook()` hook e `getPlaybookExportUrl()` helper
- `apps/web/src/app/(dashboard)/playbooks/components/create-playbook-dialog.tsx` ‚Äî Adicionada 4a op√ß√£o "Importar de documento" com formul√°rio completo
- `apps/web/src/app/(dashboard)/playbooks/[id]/page.tsx` ‚Äî Adicionado dropdown "Exportar" com op√ß√µes JSON/PDF/DOCX

### Decis√µes Tomadas
- Usou `reportlab` (j√° no requirements.txt) para PDF e `python-docx` (j√° no requirements.txt) para DOCX
- Export endpoint retorna `Response` com `Content-Disposition: attachment` para download direto
- Import segue mesmo padr√£o de `generate_playbook_from_contracts` mas com prompt dedicado
- Frontend usa `<a href download>` para export (sem hook, download direto)

### Comandos Executados
- `python3 -m py_compile` em todos os 4 arquivos backend ‚Äî OK
- `npx tsc --noEmit` ‚Äî OK (apenas 1 erro pre-existente n√£o relacionado)

---

## 2026-02-02 ‚Äî Sess√£o 28: Integrar busca do Corpus no chat (RAG autom√°tico)

### Objetivo
Fazer o agente de chat buscar automaticamente no Corpus (base RAG) quando o usu√°rio faz perguntas, sem precisar selecionar fontes manualmente. Sem isso, o Corpus ficava inutilizado no chat.

### Arquivos Criados
- `apps/api/app/services/corpus_chat_tool.py` ‚Äî Novo m√≥dulo com fun√ß√µes `search_corpus_for_chat()`, `format_corpus_context()`, `should_search_corpus()` e `_search_corpus_direct()`. Busca h√≠brida (lexical + vetorial) no Corpus e formata resultados como contexto XML para inje√ß√£o no prompt.

### Arquivos Editados
- `apps/api/app/api/endpoints/chats.py` ‚Äî Import do `corpus_chat_tool`. Adicionada busca autom√°tica do Corpus em 2 pontos: (1) fluxo streaming `send_message_stream` ap√≥s `build_rag_context` quando `rag_context` est√° vazio, (2) fluxo simples `send_message` antes do budget check. Ambos usam `should_search_corpus()` para decidir e `search_corpus_for_chat()` para buscar.
- `apps/api/app/services/rag/pipeline_adapter.py` ‚Äî Adicionado fallback autom√°tico de fontes: quando `rag_sources` est√° vazio e n√£o √© `adaptive_routing`, usa fontes padr√£o do Corpus (`lei`, `juris`, `doutrina`, `pecas_modelo`, `sei`). Controlado por env `CORPUS_AUTO_SEARCH` (default: true).

### Decis√µes Tomadas
- Abordagem dupla: (1) pipeline_adapter auto-sources e (2) corpus_chat_tool como fallback no chat
- `should_search_corpus()` usa heur√≠sticas (palavras-chave jur√≠dicas, interrogativas, tamanho) para evitar buscas desnecess√°rias em sauda√ß√µes
- Formato de contexto usa XML com tags `<corpus_context>` e `<chunk>` com metadados para cita√ß√µes
- Busca pode ser desativada via `CORPUS_AUTO_SEARCH=false`
- N√£o duplica busca: se `rag_sources` foi selecionado explicitamente, o fluxo normal cuida

### Comandos Executados
- `python3 -c "import ast; ast.parse(...)"` para cada arquivo ‚Äî OK (sem erros de sintaxe)

---

## 2026-02-02 ‚Äî Sess√£o 27: Conectar hooks do Corpus ao backend real

### Objetivo
Substituir todos os dados mock nos hooks do Corpus por chamadas reais √† API backend.

### Arquivos Editados
- `apps/web/src/lib/api-client.ts` ‚Äî Adicionados 7 m√©todos de Corpus √† classe ApiClient (getCorpusStats, getCorpusCollections, getCorpusDocuments, ingestCorpusDocuments, deleteCorpusDocument, promoteCorpusDocument, extendCorpusDocumentTTL)
- `apps/web/src/app/(dashboard)/corpus/hooks/use-corpus.ts` ‚Äî Substitu√≠dos todos os mocks por chamadas reais via apiClient; tipos alinhados com schemas backend (CorpusStats, CorpusCollectionInfo, CorpusDocument, CorpusDocumentList, CorpusIngestResponse, CorpusPromoteResponse, CorpusExtendTTLResponse)
- `apps/web/src/app/(dashboard)/corpus/components/corpus-stats.tsx` ‚Äî Adaptado para novos campos (storage_size_mb, pending_ingestion, failed_ingestion em vez de storage_used_bytes, ingestion_queue, total_collections)
- `apps/web/src/app/(dashboard)/corpus/components/corpus-global-tab.tsx` ‚Äî Adaptado para CorpusCollectionInfo sem slug/id/last_updated_at; usa name/display_name
- `apps/web/src/app/(dashboard)/corpus/components/corpus-local-tab.tsx` ‚Äî Adaptado doc.size_bytes em vez de doc.file_size; removido doc.created_at
- `apps/web/src/app/(dashboard)/corpus/components/corpus-private-tab.tsx` ‚Äî Adaptado size_bytes, file_type, remo√ß√£o de token_count/created_at, pagina√ß√£o calculada
- `apps/web/src/app/(dashboard)/corpus/components/corpus-upload-dialog.tsx` ‚Äî Adaptado payload para usar document_ids em vez de File

### Decis√µes Tomadas
- Tipos frontend alinhados 1:1 com schemas Pydantic do backend (corpus.py)
- useCorpusCollections() n√£o recebe mais par√¢metro scope (backend n√£o aceita)
- Pagina√ß√£o total_pages calculada no frontend (backend retorna apenas total/per_page)
- Upload dialog adaptado para enviar document_ids (backend n√£o aceita file upload direto no /ingest)

### Comandos Executados
- `npx tsc --noEmit | grep corpus` ‚Äî OK (0 erros relacionados ao corpus)

---

## 2026-02-02 ‚Äî Sess√£o 26: Fechar Gaps Iudex vs Harvey AI (6 Batches)

### Objetivo
Implementar 6 batches de melhorias para fechar gap de cobertura de ~68% para ~90% comparado ao Harvey AI.

### Arquivos Criados
- `apps/api/app/scripts/__init__.py` ‚Äî Pacote scripts
- `apps/api/app/scripts/seed_workflow_templates.py` ‚Äî 12 workflow templates pr√©-built (seed data)
- `apps/web/src/components/workflows/corpus-picker-modal.tsx` ‚Äî Modal para selecionar cole√ß√µes do Corpus
- `apps/web/src/components/library/workflow-picker-modal.tsx` ‚Äî Modal para selecionar workflow a partir da biblioteca

### Arquivos Editados
- `apps/api/app/services/ai/knowledge_source_loader.py` ‚Äî Handler `corpus` (busca h√≠brida OpenSearch + Qdrant)
- `apps/api/app/api/endpoints/workflows.py` ‚Äî Endpoints `clone` e `share-org`
- `apps/web/src/components/workflows/properties-panel.tsx` ‚Äî Corpus picker, √≠cones por tipo, counter 0/2, warning max, bot√£o duplicar, drag-to-reorder sections
- `apps/web/src/components/workflows/workflow-builder.tsx` ‚Äî Bulk select (Shift+drag), performance warning >25 n√≥s, SelectionMode
- `apps/web/src/app/(dashboard)/workflows/catalog/page.tsx` ‚Äî Bot√£o "Instalar" (clone), fix apiClient.fetch ‚Üí getWorkflowCatalog
- `apps/web/src/components/workflows/run-viewer.tsx` ‚Äî Toggle "Toda organiza√ß√£o" no share dialog
- `apps/web/src/components/dashboard/library-sidebar.tsx` ‚Äî Menu item "Executar workflow"
- `apps/web/src/lib/api-client.ts` ‚Äî 4 novos m√©todos: shareRunWithOrg, getWorkflowCatalog, cloneWorkflowTemplate

### Bugs Pr√©-Existentes Corrigidos
- `version-history.tsx` ‚Äî `apiClient.axios` (private) ‚Üí `apiClient.fetchWithAuth`
- `[id]/test/page.tsx` ‚Äî `apiClient.fetch` ‚Üí `apiClient.fetchWithAuth`

### Verifica√ß√£o
- `npx next build` ‚Äî OK (compila√ß√£o + type check passou)
- `python -c "from app.services.ai.knowledge_source_loader import KnowledgeSourceLoader"` ‚Äî OK
- `python -c "from app.scripts.seed_workflow_templates import TEMPLATES"` ‚Äî 12 templates OK

---

## 2026-02-02 ‚Äî Sessao 25: Bug fixes criticos em corpus, playbooks e modelos

### Objetivo
Corrigir 9 issues identificadas: imports errados, bugs logicos, imports nao utilizados, enums nao aplicados nos modelos, e registro de modelos no init_db.

### Arquivos Alterados
- `apps/api/app/services/corpus_service.py` ‚Äî Corrigido `get_pipeline` -> `get_rag_pipeline` e `get_embedding` -> `get_embeddings_service().embed_query()`
- `apps/api/app/api/endpoints/playbooks.py` ‚Äî Fix order==0 bug (2 ocorrencias), removidos imports nao usados (selectinload, PlaybookGenerateRequest), adicionado `# noqa: E712`
- `apps/api/app/services/playbook_service.py` ‚Äî Removido import nao usado `selectinload`
- `apps/api/app/schemas/playbook.py` ‚Äî Removida classe duplicada `PlaybookGenerateRequest` (versao correta em playbook_analysis.py)
- `apps/api/app/models/playbook.py` ‚Äî Enums agora usados nas colunas via SQLEnum (scope, action_on_reject, severity, permission)
- `apps/api/app/core/database.py` ‚Äî Registrados modelos Playbook, PlaybookRule, PlaybookShare no init_db()
- `apps/api/app/api/endpoints/corpus.py` ‚Äî Removidos imports nao usados (get_current_user, require_org_role)

### Comandos Executados
- `python3 -m py_compile` em todos os 7 arquivos ‚Äî OK

### Decisoes Tomadas
- `get_embeddings_service()` retorna `EmbeddingsService` com metodo sincrono `embed_query()`, entao substituicao direta sem await
- Enums aplicados com SQLEnum para validacao no banco (padrao consistente com outros modelos do projeto)
- `PlaybookGenerateRequest` removido de playbook.py pois playbook_analysis.py tem a versao completa usada pelo endpoint

---

## 2026-02-02 ‚Äî Sessao 24: Follow-ups e Compartilhamento de Runs ‚Äî P2 #14 e #16

### Objetivo
Implementar follow-ups (perguntas sobre resultado de runs concluidos) e compartilhamento de runs com outros usuarios, itens P2 #14 e #16 do plano Harvey AI parity.

### Arquivos Alterados
- `apps/api/app/api/endpoints/workflows.py` ‚Äî Endpoints POST /runs/{run_id}/follow-up (streaming via Claude) e POST /runs/{run_id}/share; Request models FollowUpRequest e ShareRunRequest
- `apps/web/src/lib/api-client.ts` ‚Äî Metodos followUpRun (SSE streaming) e shareRun no apiClient
- `apps/web/src/components/workflows/run-viewer.tsx` ‚Äî Chat de follow-up com streaming progressivo, botao Compartilhar com popover para IDs/emails e mensagem

### Decisoes Tomadas
- Follow-up usa stream_anthropic_async (mesmo padrao do orchestration router) para streaming de tokens
- Compartilhamento armazena registros em output_data._shares (JSON simples, sem tabela nova)
- Follow-up so disponivel para runs com status COMPLETED
- Chat inline abaixo do log de eventos, com input e respostas progressivas via SSE
- Botao Compartilhar com popover mostrando input de IDs/emails e mensagem opcional

### Comandos Executados
- `eslint run-viewer.tsx` ‚Äî OK
- `eslint api-client.ts` ‚Äî OK
- `tsc --noEmit` ‚Äî OK (sem erros nos arquivos modificados)
- `python3 ast.parse workflows.py` ‚Äî Syntax OK

---

## 2026-02-02 ‚Äî Sessao 23: Words to Workflows (NL to Graph) ‚Äî P2 #11

### Objetivo
Implementar feature "Words to Workflows" que converte descricoes em linguagem natural em grafos de workflow visuais usando IA.

### Arquivos Criados
- `apps/api/app/services/ai/nl_to_graph.py` ‚Äî NLToGraphParser com suporte a Claude, OpenAI e Gemini
- `apps/web/src/components/workflows/nl-input-dialog.tsx` ‚Äî Dialog com textarea, exemplos clicaveis e geracao via IA

### Arquivos Alterados
- `apps/api/app/api/endpoints/workflows.py` ‚Äî Endpoint POST /generate-from-nl adicionado antes de /{workflow_id}
- `apps/web/src/lib/api-client.ts` ‚Äî Metodo generateWorkflowFromNL no apiClient
- `apps/web/src/components/workflows/workflow-builder.tsx` ‚Äî Botao "Criar com IA" e NLInputDialog integrado
- `apps/web/src/components/workflows/index.ts` ‚Äî Export do NLInputDialog

### Decisoes Tomadas
- Parser usa chamadas diretas aos SDKs (anthropic, openai, google-genai) seguindo padrao do agent_clients.py
- Retry com correcao automatica: se grafo falha validacao, reenvia erros ao LLM para corrigir (max 2 retries)
- System prompt detalha todos os 9 tipos de no com configs esperadas
- Endpoint colocado antes de /{workflow_id} para evitar conflito de rotas FastAPI
- Botao com estilo violet para destacar feature de IA

---

## 2026-02-02 ‚Äî Sess√£o 22: Draft Editor (Rich Text) para Workflows

### Objetivo
Implementar o editor de rascunhos (P2 #18 do plano Harvey AI parity) para edi√ß√£o de outputs de workflow runs.

### Arquivos Criados
- `apps/web/src/components/workflows/draft-editor.tsx` ‚Äî Componente TipTap com toolbar, modo leitura/edi√ß√£o, salvar/descartar

### Arquivos Alterados
- `apps/web/src/components/workflows/index.ts` ‚Äî Adicionado export do DraftEditor

### Decis√µes Tomadas
- Reutilizado TipTap (ja instalado) com StarterKit + Underline + Placeholder
- Toolbar simplificada vs DocumentEditor (sem tabelas, alinhamento, mermaid) ‚Äî foco em edi√ß√£o de output
- `immediatelyRender: false` para compatibilidade SSR conforme CLAUDE.md
- Labels em portugues: "Salvar Edi√ß√µes", "Descartar", "Editando", "Leitura"
- Status bar "Altera√ß√µes n√£o salvas" para feedback visual

### Comandos Executados
- `npx tsc --noEmit` ‚Äî OK (0 erros no draft-editor; erros pre-existentes em run-viewer.tsx)

---

## 2026-02-02 ‚Äî Sess√£o 21: PlaybookService ‚Äî An√°lise de Contratos com IA

### Objetivo
Criar o servi√ßo PlaybookService para an√°lise de contratos usando regras de Playbook, inspirado no Harvey AI Playbook.

### Arquivos Criados
- `apps/api/app/schemas/playbook_analysis.py` ‚Äî Schemas Pydantic para resultados de an√°lise
- `apps/api/app/services/playbook_prompts.py` ‚Äî 6 prompts especializados em pt-BR
- `apps/api/app/services/playbook_service.py` ‚Äî Servi√ßo principal com analyze, generate e prompt

### Arquivos Alterados
- `apps/api/app/api/endpoints/playbooks.py` ‚Äî Implementa√ß√£o real do /generate e novos endpoints /analyze e /prompt
- `apps/api/app/schemas/playbook.py` ‚Äî Docstring atualizada

### Decis√µes Tomadas
- Gemini Flash prim√°rio, Claude fallback; Gemini Pro para gera√ß√£o
- Concorr√™ncia limitada a 5 an√°lises paralelas via Semaphore
- Risk score com pesos severidade x classifica√ß√£o
- Redlines apenas para action_on_reject = redline|suggest
- GET /prompt retorna texto para inje√ß√£o no system prompt do agente /minuta

---

## 2026-02-02 ‚Äî Sess√£o 20: Export Functionality (Word/Excel/PDF) para Workflow Runs (P2 #13)

### Objetivo
Implementar funcionalidade de exporta√ß√£o de resultados de workflow runs em formato Word (.docx), Excel (.xlsx) e PDF (.pdf) ‚Äî item P2 #13 do plano de paridade Harvey AI.

### Arquivos Alterados
- `apps/api/app/services/workflow_export_service.py` (NOVO) ‚Äî Servi√ßo com m√©todos export_to_docx, export_to_xlsx, export_to_pdf
- `apps/api/app/api/endpoints/workflows.py` ‚Äî Adicionado endpoint GET /runs/{run_id}/export/{format}
- `apps/api/requirements.txt` ‚Äî Adicionado reportlab==4.1.0 para gera√ß√£o de PDF
- `apps/web/src/components/workflows/run-viewer.tsx` ‚Äî Dropdown de exporta√ß√£o no header (Word/Excel/PDF)

### Decis√µes Tomadas
- python-docx e openpyxl j√° estavam no requirements.txt; apenas reportlab precisou ser adicionado
- Endpoint posicionado antes do /runs/{run_id}/resume para evitar conflitos de rota
- Export service usa import din√¢mico com try/except para mensagens de erro claras se deps faltarem
- Frontend usa window.open() para download direto (evita complexidade de blob handling)
- Dropdown aparece apenas quando runStatus === 'completed'
- Labels em portugu√™s no backend (se√ß√µes do documento)
- PDF usa ReportLab (mais leve que weasyprint, sem deps de sistema)
- Excel com 3 sheets: Resumo, Resultado, Logs ‚Äî com headers estilizados
- Word com headings hier√°rquicos e formata√ß√£o de se√ß√µes

---

## 2026-02-02 ‚Äî Sess√£o 19: Progress Indicators para Workflow Execution (P2 #12)

### Objetivo
Implementar indicadores de progresso na execu√ß√£o de workflows, item P2 #12 do plano de paridade Harvey AI.

### Arquivos Alterados
- `apps/api/app/services/ai/workflow_runner.py` ‚Äî Adicionado tracking de progresso (step_number, total_steps, elapsed_seconds) nos eventos SSE de workflow
- `apps/web/src/components/workflows/run-viewer.tsx` ‚Äî Adicionada barra de progresso visual com "Etapa X de Y" e resumo de conclus√£o com tempo

### Decis√µes Tomadas
- Contagem de steps baseada em graph_json nodes (total_steps) com incremento em on_chain_start (current_step)
- step_number e total_steps inclu√≠dos tanto nos eventos workflow_node_start quanto workflow_node_end
- elapsed_seconds calculado com time.time() e inclu√≠do no done_event metadata
- Frontend usa useMemo para derivar progresso dos runEvents (sem estado extra)
- Barra de progresso com bg-blue-500 e transition-all para anima√ß√£o suave
- Resumo de conclus√£o mostra total de etapas e tempo formatado (Xm Ys)
- Labels em portugu√™s: "Etapa X de Y", "Conclu√≠do em N etapas"

---

## 2026-02-02 ‚Äî Sess√£o 18: Playbook Backend (Model + Migration + CRUD API)

### Objetivo
Implementar o backend completo de Playbooks para revis√£o de contratos, inspirado no Harvey AI Playbook. Inclui modelo de dados, schemas Pydantic, API RESTful completa e migra√ß√£o Alembic.

### Arquivos Criados
- `apps/api/app/models/playbook.py` ‚Äî Modelos SQLAlchemy: Playbook, PlaybookRule, PlaybookShare com enums, relacionamentos e to_dict
- `apps/api/app/schemas/playbook.py` ‚Äî Schemas Pydantic: Create/Update/Response para Playbook, PlaybookRule, PlaybookShare + schemas auxiliares (Reorder, Duplicate, Generate, ListResponse)
- `apps/api/app/api/endpoints/playbooks.py` ‚Äî Router FastAPI completo com 14 endpoints: CRUD de playbooks, gerenciamento de regras, compartilhamento, duplica√ß√£o e gera√ß√£o (placeholder)
- `apps/api/alembic/versions/k1l2m3n4o5p6_add_playbook_tables.py` ‚Äî Migra√ß√£o Alembic: tabelas playbooks, playbook_rules, playbook_shares com √≠ndices

### Arquivos Alterados
- `apps/api/app/models/__init__.py` ‚Äî Registrado Playbook, PlaybookRule, PlaybookShare
- `apps/api/app/api/routes.py` ‚Äî Registrado router playbooks no prefix /playbooks

### Decis√µes Tomadas
- Segui exatamente os padr√µes existentes de workflow.py (String PKs com uuid4, mapped_column, utcnow, to_dict)
- CRUD inline no router (sem camada crud/ separada) pois o projeto n√£o usa essa camada
- Schemas inline no arquivo de schemas (n√£o no router) seguindo padr√£o de library.py/marketplace.py
- PlaybookShare como tabela separada (n√£o reuso de Share gen√©rica) para suportar org_id e permission=admin
- Endpoint /generate como placeholder ‚Äî futuro job ass√≠ncrono com LLM para extra√ß√£o de regras de contratos
- metadata_ com Column("metadata") para evitar conflito com SQLAlchemy metadata

### Endpoints Implementados
| M√©todo | Rota | Descri√ß√£o |
|--------|------|-----------|
| POST | /playbooks | Criar playbook (com regras opcionais) |
| GET | /playbooks | Listar com filtros (scope, area, template, search) |
| GET | /playbooks/{id} | Obter com regras e shares |
| PUT | /playbooks/{id} | Atualizar |
| DELETE | /playbooks/{id} | Deletar (cascade rules/shares) |
| POST | /playbooks/{id}/rules | Adicionar regra |
| PUT | /playbooks/{id}/rules/{rule_id} | Atualizar regra |
| DELETE | /playbooks/{id}/rules/{rule_id} | Deletar regra |
| POST | /playbooks/{id}/rules/reorder | Reordenar regras |
| POST | /playbooks/{id}/share | Compartilhar |
| DELETE | /playbooks/{id}/share/{share_id} | Remover compartilhamento |
| POST | /playbooks/{id}/duplicate | Duplicar playbook + regras |
| POST | /playbooks/generate | Gerar de contratos (placeholder) |

---

## 2026-02-02 ‚Äî Sess√£o 17: Harvey AI Parity Feature #10 ‚Äî Test Mode + P1 Migration

### Objetivo
Implementar modo de teste de workflow (endpoint + pagina) e migracao Alembic P1 com publishing, versioning, permissions e catalog.

### Arquivos Criados
- `apps/web/src/app/(dashboard)/workflows/[id]/test/page.tsx` ‚Äî Pagina de teste de workflow com SSE streaming, exibicao de eventos e resultado
- `apps/api/alembic/versions/j0k1l2m3n4o5_harvey_parity_p1.py` ‚Äî Migracao P1: campos de publishing, catalog, tabelas workflow_versions, workflow_permissions, workflow_role em org members

### Arquivos Alterados
- `apps/api/app/api/endpoints/workflows.py` ‚Äî Adicionado endpoint POST /{workflow_id}/test para execucao transiente (trigger_type=test)
- `apps/web/src/components/workflows/workflow-builder.tsx` ‚Äî Adicionado botao "Testar" com FlaskConical icon que abre pagina de teste em nova aba

### Decisoes Tomadas
- Test run cria registro no banco com trigger_type="test" para rastreabilidade, mas e marcado como transiente
- Pagina de teste usa SSE streaming identico ao run normal
- Migracao P1 consolida todos os campos que ja existiam no modelo mas faltavam na migracao

---

## 2026-02-02 ‚Äî Sess√£o 16: Harvey AI Parity Feature #8 ‚Äî Permissions System (2 layers)

### Objetivo
Implementar sistema de permiss√µes de workflow em 2 camadas: roles de workspace (Layer 1) e permiss√µes per-workflow (Layer 2).

### Arquivos Criados
- `apps/api/app/models/workflow_permission.py` ‚Äî Modelo WorkflowPermission + enums (WorkflowBuilderRole, BuildAccess, RunAccess)
- `apps/api/app/services/workflow_permission_service.py` ‚Äî Servi√ßo centralizado de checagem de permiss√µes (can_build, can_run, can_approve, can_publish, grant/revoke)
- `apps/web/src/components/workflows/permissions-dialog.tsx` ‚Äî Dialog React com tabs (Atuais/Adicionar) para gerenciar permiss√µes

### Arquivos Alterados
- `apps/api/app/models/organization.py` ‚Äî Adicionado campo `workflow_role` em OrganizationMember (Layer 1)
- `apps/api/app/api/endpoints/workflows.py` ‚Äî 3 endpoints: GET/POST /{id}/permissions, DELETE /{id}/permissions/{user_id}
- `apps/api/app/core/database.py` ‚Äî Import de WorkflowPermission em init_db()
- `apps/web/src/components/workflows/index.ts` ‚Äî Export de PermissionsDialog

### Decis√µes Tomadas
- Layer 1 usa campo `workflow_role` em OrganizationMember (string nullable) em vez de enum SQLAlchemy, para flexibilidade
- Layer 2 usa tabela dedicada `workflow_permissions` com unique constraint (workflow_id, user_id)
- Owner do workflow sempre tem acesso total (bypass de permiss√µes)
- Admin de workflow n√£o pode aprovar pr√≥prio workflow (seguran√ßa)

---

## 2026-02-02 ‚Äî Sess√£o 15: Implementa√ß√£o dos 5 Gaps em Paralelo

### Objetivo
Implementar os 5 gaps identificados na verifica√ß√£o da plataforma, lan√ßando 5 agentes em paralelo.

### Gap 1 ‚Äî Alembic Migration
- `alembic/env.py` ‚Äî imports de Workflow, WorkflowRun, MarketplaceItem, MarketplaceReview
- `app/core/database.py` ‚Äî imports em init_db()
- `app/models/workflow.py` ‚Äî campos schedule_cron, schedule_enabled, schedule_timezone, last_scheduled_run, webhook_secret, trigger_type
- `alembic/versions/h8i9j0k1l2m3_add_workflows_tables.py` ‚Äî migration completa

### Gap 2 ‚Äî Scheduler/Triggers (Celery Beat)
- `app/workers/tasks/workflow_tasks.py` ‚Äî 3 tasks: run_scheduled_workflow, run_webhook_workflow, sync_workflow_schedules
- `app/workers/celery_app.py` ‚Äî beat_schedule workflow-schedule-sync (cada 5min)
- `app/api/endpoints/workflows.py` ‚Äî GET/PUT /{id}/schedule, POST /{id}/trigger (webhook)
- `requirements.txt` ‚Äî croniter>=2.0.0

### Gap 3 ‚Äî User MCP Server UI
- `app/services/mcp_config.py` ‚Äî load_user_mcp_servers()
- `app/services/mcp_hub.py` ‚Äî with_user_servers() merge
- `app/api/endpoints/mcp.py` ‚Äî CRUD /user-servers + /test
- `apps/web/src/components/settings/mcp-servers-config.tsx` ‚Äî componente React
- `apps/web/src/app/(dashboard)/settings/page.tsx` ‚Äî integra√ß√£o
- `apps/web/src/lib/api-client.ts` ‚Äî 4 m√©todos MCP + request() gen√©rico

### Gap 4 ‚Äî Sandboxing & Hardening
- `app/services/ai/sandbox/` ‚Äî ExecutionLimits, ExecutionBudget, NetworkPolicy, validate_url
- `app/services/ai/workflow_compiler.py` ‚Äî valida√ß√£o de grafo (ciclos, max nodes)
- `app/services/ai/workflow_runner.py` ‚Äî timeout enforcement via budget
- `app/services/ai/tool_gateway/policy_engine.py` ‚Äî cost tracking

### Gap 5 ‚Äî Public Marketplace
- `app/models/marketplace.py` ‚Äî MarketplaceItem, MarketplaceReview, MarketplaceCategory
- `app/schemas/marketplace.py` ‚Äî schemas Pydantic
- `app/api/endpoints/marketplace.py` ‚Äî 8 endpoints (browse, publish, install, review)
- `alembic/versions/i9j0k1l2m3n4_add_marketplace_tables.py` ‚Äî migration
- `apps/web/src/app/(dashboard)/marketplace/page.tsx` ‚Äî p√°gina completa
- `apps/web/src/components/layout/sidebar-pro.tsx` ‚Äî link Marketplace
- `app/api/routes.py` ‚Äî router marketplace registrado
- `app/models/__init__.py` ‚Äî exports marketplace

### Decis√µes
- Celery Beat escolhido para scheduler (j√° existia infra Redis)
- MCP user servers prefixados com "user_" para evitar colis√£o
- Sandboxing warn-only no compiler para n√£o quebrar workflows existentes
- Marketplace usa clone/install (copia recurso) em vez de refer√™ncia
- SSRF protection com allowlist de dom√≠nios jur√≠dicos

### Guia de Planejamento
- `docs/PLAN_GAPS.md` ‚Äî planejamento completo dos 5 gaps

### Fixes P√≥s-Implementa√ß√£o
1. **marketplace.py import errado** ‚Äî `from app.api.deps` ‚Üí `from app.core.security` (crashava API inteira)
2. **Route conflict /workflows** ‚Äî Marketing page movida para `/solucoes/workflows`, links atualizados em vorbium-nav.tsx e footer.tsx
3. **Workflow creation "table has no column schedule_cron"** ‚Äî ALTER TABLE adicionou 5 colunas em workflows + 1 em workflow_runs (migration n√£o executada contra SQLite dev)
4. **Model selector no workflow builder** ‚Äî Substitu√≠do hardcoded 4 modelos ‚Üí import din√¢mico de MODEL_REGISTRY (26 modelos, 7 providers) com `<optgroup>` por provider

### An√°lise Harvey AI vs Iudex
- Compara√ß√£o em 10 dimens√µes: hierarquia, workflow engine, thinking states, citation engine, agentic search, multi-agent, workflow builder, HIL, eval, seguran√ßa
- **Implementado (85%+)**: Block types, HIL+checkpoints, Multi-agent orchestration, Agentic search
- **Parcial (50-70%)**: 4-level hierarchy, Thinking states, Citation engine, LLM-as-Judge, Workflow Builder (s√≥ drag-drop)
- **Faltando (0%)**: Component-level evals
- **Gaps priorit√°rios P0**: NL‚ÜíGraph parser, Component-level evals, Model/AgentSystem hierarchy

---

## 2026-02-02 ‚Äî Sess√£o 14: Gap 4 ‚Äî Sandboxing & Hardening

### Objetivo
Implementar limites de execucao, budget tracking, protecao de rede (SSRF) e validacao de grafos de workflow para hardening de producao.

### Arquivos Criados
- `apps/api/app/services/ai/sandbox/__init__.py` ‚Äî Modulo sandbox com exports
- `apps/api/app/services/ai/sandbox/execution_limits.py` ‚Äî ExecutionLimits, ExecutionBudget, BudgetExceededError, validacao de grafo, enforce_workflow_limits
- `apps/api/app/services/ai/sandbox/network_policy.py` ‚Äî NetworkPolicy com allowlist de dominios juridicos, protecao SSRF contra IPs privados, validate_url

### Arquivos Alterados
- `apps/api/app/services/ai/workflow_compiler.py` ‚Äî Adicionada validacao de limites de execucao (warn-only) no metodo compile()
- `apps/api/app/services/ai/workflow_runner.py` ‚Äî Adicionado ExecutionBudget com timeout enforcement no run_streaming()
- `apps/api/app/services/ai/tool_gateway/policy_engine.py` ‚Äî Adicionado cost tracking (record_cost/get_cost) ao PolicyEngine

### Decisoes Tomadas
- Validacao de limites no compiler e warn-only (nao bloqueia) para nao quebrar workflows existentes
- Timeout no runner checa a cada evento do stream
- NetworkPolicy com allowlist especifica para dominios juridicos brasileiros (tribunais, governo, bases juridicas)
- Protecao SSRF bloqueia ranges privados IPv4 e IPv6

---

## 2026-02-01 ‚Äî Sess√£o 13: Native Tool Calling para Agent Models no Chat

### Objetivo
Habilitar tool calling (web_search, search_jurisprudencia, search_legislacao) para modelos de agente (openai-agent, google-agent, claude-agent) no chat stream.

### Arquivos Criados
- `apps/api/app/services/ai/chat_tools.py` ‚Äî M√≥dulo de native tool calling com defini√ß√µes de tools, handlers, e tool loops para OpenAI/Claude/Gemini

### Arquivos Alterados
- `apps/api/app/api/endpoints/chats.py` ‚Äî Integra√ß√£o do native tool calling no chat stream. Flag `use_native_tools` detecta modelos agente. Blocos GPT/Claude/Gemini agora executam tool loop antes do streaming normal.

### Bugs Corrigidos
1. **AsyncOpenAI client**: `gpt_stream_client` √© s√≠ncrono (`openai.OpenAI`), n√£o async. `await client.chat.completions.create()` falhava com `'ChatCompletion' object can't be awaited`. Fix: usar `get_async_openai_client()`.
2. **API sem hot-reload**: uvicorn rodava sem `--reload`, mudan√ßas n√£o eram detectadas. Reiniciado com `--reload`.
3. **JWT_SECRET_KEY vs SECRET_KEY**: Token gerado com `SECRET_KEY` era rejeitado. API usa `JWT_SECRET_KEY` para auth.

### Teste de Agent Models com Tools
| Modelo | Status | Tools |
|--------|--------|-------|
| openai-agent (gpt-4o) | ‚úÖ | web_search funcionando (retornou Selic 15% com fontes) |
| google-agent (gemini-3-flash-preview) | ‚úÖ | Tool loop executa, modelo decide se precisa |
| claude-agent | ‚ö†Ô∏è | Cr√©ditos Anthropic esgotados |

### Arquitetura
- Tools dispon√≠veis: `web_search` (‚Üí WebSearchService/Perplexity), `search_jurisprudencia` (‚Üí JurisprudenceService), `search_legislacao` (‚Üí LegislationService)
- Native tool calling tem prioridade sobre MCP. Se `use_native_tools=True`, executa primeiro. Se n√£o usar tools, cai para streaming normal.
- Deep research intercepta antes do streaming normal para queries complexas (jurisprud√™ncia, etc.)

### Decis√µes
- Usar native function calling (OpenAI tools API / Claude tool_use / Gemini function calling) em vez de MCP para evitar depend√™ncia de servidores externos
- Subset de 3 tools (web_search, jurisprudencia, legislacao) para chat ‚Äî n√£o incluir tools que requerem case_id
- Tool loop n√£o-streaming (max 4 rounds) + streaming da resposta final

---

## 2026-02-01 ‚Äî Sess√£o 12: Performance Chat + Gemini ThinkingLevel Fix

### Objetivo
Corrigir lat√™ncia excessiva do chat (18s para "oi") e erro 400 do Gemini Thinking.

### Arquivos Alterados
- `apps/api/app/api/endpoints/chats.py` ‚Äî Fast-path para mensagens triviais (skip RAG), thinking budget reduzido, thinking_mode mapeamento corrigido
- `apps/api/app/services/ai/agent_clients.py` ‚Äî System prompt atualizado, ThinkingConfig construtor (n√£o setattr), thinking_level UPPERCASE, LOW/MINIMAL sem thinking_level

### Bugs Corrigidos
1. **ThinkingLevel lowercase**: SDK Gemini espera UPPERCASE (LOW, MEDIUM, HIGH), c√≥digo passava lowercase ‚Üí `PydanticSerializationUnexpectedValue`
2. **setattr bypass Pydantic**: `setattr(thinking_config, "thinking_level", "LOW")` n√£o converte string‚Üíenum. Corrigido usando construtor: `ThinkingConfig(include_thoughts=True, thinking_level="LOW")`
3. **Vertex rejeita thinking_level**: `gemini-2.5-flash` via Vertex AI n√£o suporta `thinking_level` param. Fix: LOW/MINIMAL usam apenas `include_thoughts=True` sem `thinking_level`
4. **RAG pipeline para triviais**: `build_rag_context()` rodava para TODA mensagem (~4.6s). Adicionado fast-path: skip para mensagens ‚â§4 palavras + padr√£o de sauda√ß√£o
5. **System prompt errado**: `router.py` n√£o √© usado pelo chat streaming. O prompt real est√° em `agent_clients.py:DEFAULT_LEGAL_SYSTEM_INSTRUCTION`

### Resultados de Performance
| Modelo | Antes | Depois | Melhoria |
|--------|-------|--------|----------|
| Gemini 3 Flash "oi" | 18s+ (erro/offline) | 5.4s (lat√™ncia do preview) | Funcional |
| Gemini 2.5 Flash "oi" | 18s+ | 3.3s | ~82% |
| GPT-5/4o "oi" | ~8s | 0.5-1.3s | ~86% |
| Preprocessing (RAG) | 4.6s | 7ms | ~99.8% |

### Teste de Todos os Modelos
| Modelo | Status | Nota |
|--------|--------|------|
| gemini-3-flash | ‚úÖ | 5.4s TTFT (lat√™ncia inerente do modelo preview) |
| gemini-3-pro | ‚úÖ | 7.1s TTFT |
| gpt-5 (‚Üígpt-4o) | ‚úÖ | 0.5s TTFT |
| gpt-4o | ‚úÖ | 1.3s TTFT |
| claude-4.5-sonnet | ‚ö†Ô∏è | Cr√©ditos Anthropic esgotados |
| claude-4.5-haiku | ‚ö†Ô∏è | Cr√©ditos Anthropic esgotados |

### Decis√µes
- Para Gemini LOW/MINIMAL thinking: usar `include_thoughts=True` sem `thinking_level` (compatibilidade Vertex)
- Fast-path trivial: ‚â§4 palavras + match set de sauda√ß√µes/despedidas comuns
- Mensagens triviais + reasoning_level low: desabilita thinking no Gemini completamente
- Claude offline por billing (a√ß√£o do usu√°rio: recarregar cr√©ditos Anthropic)

---

## 2026-02-01 ‚Äî Sess√£o 11: Melhorias UI/UX Chat (Harvey AI + Perplexity)

### Objetivo
Melhorar a experi√™ncia visual e qualidade do chat, inspirado em Harvey AI e Perplexity.

### Arquivos Alterados
- `apps/api/app/services/ai/orchestration/router.py` ‚Äî Regra de intera√ß√£o no system prompt (respostas naturais a sauda√ß√µes)
- `apps/web/src/components/chat/chat-interface.tsx` ‚Äî Welcome screen estilo Perplexity + follow-up input
- `apps/web/src/components/chat/activity-panel.tsx` ‚Äî Header din√¢mico "Trabalhando...", steps colaps√°veis, barra de progresso
- `apps/web/src/components/chat/chat-message.tsx` ‚Äî Code block copy delegado + ResponseSourcesTabs (Perplexity style)
- `apps/web/src/lib/markdown-parser.ts` ‚Äî Code blocks com header de linguagem + bot√£o copiar
- `apps/web/src/styles/globals.css` ‚Äî CSS dark code blocks estilo Perplexity

### Decis√µes
- Welcome screen: grid 2x2 de sugest√µes jur√≠dicas clic√°veis que enviam mensagem direto
- ActivityPanel: "Trabalhando..." quando h√° steps reais, "Pensando" quando s√≥ thinking
- Code blocks: dark theme (slate-900) com header de linguagem e copy via event delegation
- Follow-up: mini input ap√≥s √∫ltima resposta assistant, submit via handleSendMessage
- Response tabs: tab "Fontes" com favicon, quote e external link (aparece quando ActivityPanel fechado)

---

## 2026-02-01 ‚Äî Sess√£o 10: Diagn√≥stico Chat Gemini

### Problema
Chat possivelmente retornando "modo offline" ao selecionar Gemini.

### Investiga√ß√£o
Testamos todas as rotas de acesso ao Gemini:
- **Vertex AI + service account** (`GOOGLE_APPLICATION_CREDENTIALS`): ‚úÖ Funciona perfeitamente com streaming e thinking
- **Direct API (`GOOGLE_API_KEY`)**: ‚ùå Quota zero (billing desabilitado)
- **`GEMINI_API_KEY` (antiga)**: ‚ùå Formato inv√°lido (token OAuth, n√£o API key)

O fluxo real da API usa `python-dotenv` para carregar `.env` incluindo `GOOGLE_APPLICATION_CREDENTIALS`, e a service account `vertex-express@gen-lang-client-0727883752` tem as permiss√µes corretas para Vertex AI.

### Descobertas
1. O streaming Gemini via `stream_vertex_gemini_async()` funciona com a service account
2. O fallback para API direta (quando Vertex d√° 404) falha porque a API key n√£o tem quota
3. Bug de indenta√ß√£o no endpoint `send_message` (n√£o-streaming): `ai_content = None` fora do `except`

### Arquivos Alterados
- `apps/api/app/api/endpoints/chats.py` ‚Äî Fix indenta√ß√£o do bloco except/failsafe
- `apps/api/.env` ‚Äî GEMINI_API_KEY atualizada para key v√°lida do projeto `gen-lang-client-0781186103`
- `apps/web/.env.local` ‚Äî Fix API_PROXY_TARGET de porta 8001 para 8000

### Fix Login Visitante
O login de visitante falhava porque o proxy Next.js (`API_PROXY_TARGET`) apontava para `http://127.0.0.1:8001` mas o backend roda na porta `8000`.

### Verifica√ß√£o Geral de Modelos
Testados todos os modelos:
- **gemini-3-flash / gemini-3-pro**: ‚úÖ Funcionam via Vertex AI + service account
- **gpt-5.2**: ‚úÖ Fix aplicado ‚Äî `OPENAI_FORCE_DIRECT=true` (estava roteando via Vertex AI)
- **claude-4.5-sonnet**: ‚ùå Cr√©ditos Anthropic insuficientes (billing)
- **sonar-pro**: ‚ùå `PERPLEXITY_API_KEY` n√£o configurada no .env

### Fix GPT roteamento errado
`init_openai_client()` priorizava Vertex AI quando `GOOGLE_CLOUD_PROJECT` existia, tentando `gpt-4o` no Model Garden do Google (inexistente). Fix: `OPENAI_FORCE_DIRECT=true`.

### Fix Neo4j bloqueante
Driver Neo4j bloqueava o servidor com retries infinitos quando Neo4j n√£o rodava. Adicionado port check TCP (1s), health check com timeout (5s), e `max_transaction_retry_time=2`.

### Auditoria SSE Streaming
Issues encontrados e **corrigidos**:
- ‚úÖ Missing "done" event no error path ‚Äî agora `stream_with_session()` envia `done` ap√≥s `error`
- ‚úÖ STREAM_SESSIONS memory leak ‚Äî cleanup agora remove sess√µes stuck (>15min) + limite absoluto de 200
- ‚úÖ Schema de erro inconsistente ‚Äî evento `error` agora inclui `turn_id` e `request_id`

### Deep Research
Todos os 3 providers implementados:
- **Gemini**: `interactions.create()` com agent deep-research-pro
- **Perplexity**: `sonar-deep-research` com citations nativas
- **OpenAI**: `o4-mini-deep-research` via Responses API
- **Hard mode**: Claude orquestra multi-provider

### Arquivos Alterados Adicionais
- `apps/api/.env` ‚Äî `OPENAI_FORCE_DIRECT=true`
- `apps/api/app/services/rag/core/neo4j_mvp.py` ‚Äî Fix timeout bloqueante

---

## 2026-02-01 ‚Äî Sess√£o 9: Fix Anima√ß√µes Safari ‚Äî Todas as P√°ginas

### Problema
Anima√ß√µes de fundo (CSS Paint Worklets / Houdini API) n√£o funcionavam no Safari ‚Äî apenas Chrome/Edge. Afetava:
- Landing page (verbium-particles)
- Todas as marketing pages (nebula-flow via PageHero)
- Login e Register (grid-pulse)

### Causa Raiz
CSS Paint Worklets (`paint()`) n√£o s√£o suportados no Safari/Firefox. O `backgroundImage: 'paint(worklet-name)'` era descartado silenciosamente, deixando o fundo sem anima√ß√£o. As `@property` + `@keyframes` que alimentam os worklets tamb√©m n√£o funcionam nesses browsers.

### Solu√ß√£o ‚Äî Canvas 2D Fallback para Todos os 4 Worklets
- **Refatora√ß√£o completa de `use-vorbium-paint.ts`** (~800 linhas):
  - Framework `createCanvasFallback()` compartilhado: canvas setup, DPR, pointer/touch tracking, MutationObserver para tema, animation loop
  - 4 renderers Canvas 2D portados pixel-a-pixel dos worklets JS:
    - `verbium-particles` ‚Äî ring particles, constellation, cursor orbit, ambient/cursor glow
    - `nebula-flow` ‚Äî layered noise grid, cursor attraction, color gradients, central glow
    - `grid-pulse` ‚Äî dot grid, pulse ring, ambient wave, connection lines, cursor glow
    - `wave-field` ‚Äî 7 sine wave layers, cursor distortion, interference dots
  - Sprite caching (offscreen canvas, drawImage 3-5x mais r√°pido que arc+fill)
  - `desynchronized: true` para async rendering no Safari
  - Hook aceita `options: { seed, color }` para customiza√ß√£o por p√°gina

- **Fix `PaintBackground`** ‚Äî CSS `paint()` agora condicional:
  - Chrome: aplica `backgroundImage: paint(worklet)` + animations
  - Safari: aplica apenas `--theme-color`, canvas fallback cuida do resto
  - Passa `seed` e `color` para o hook

- **Z-index expl√≠cito** em todas as camadas de overlay:
  - Canvas fallback: z-0
  - Overlays (dotted grid, noise, gradient mesh): z-[1]
  - Gradient fade: z-[2]
  - Conte√∫do: z-10

### Arquivos Alterados
- `src/hooks/use-vorbium-paint.ts` ‚Äî Reescrito: framework + 4 renderers Canvas 2D (~800 linhas)
- `src/components/ui/paint-background.tsx` ‚Äî CSS condicional, passa seed/color ao hook
- `src/components/vorbium/hero-section.tsx` ‚Äî z-[1] overlays, z-[2] gradient fade
- `src/components/vorbium/page-hero.tsx` ‚Äî z-[1] no overlay container
- `src/app/(auth)/login/page.tsx` ‚Äî z-[1] no gradient mesh overlay
- `src/app/(auth)/register/page.tsx` ‚Äî z-[1] no gradient mesh overlay

### Corre√ß√µes de Fidelidade Visual (continua√ß√£o)
- **Orbit ring sempre desenhado**: No worklet, as part√≠culas do orbit s√£o desenhadas sempre (intensity afeta alpha, n√£o visibilidade). No canvas, estavam dentro de `if (orbitIntensity > 0.1)`. Corrigido: glow fica condicional, part√≠culas sempre desenham.
- **PRNG sequence**: `w1Dir` usa `hash(seed+10)` (n√£o PRNG), ranges de `randomInt` corrigidos para corresponder ao worklet
- **Timing**: Todos os 4 renderers usam `((elapsed % 6) / 6) * Math.PI * 2` (ciclo de 6s), matching `animTick * 2œÄ`
- **ringBreathe**: Anima√ß√£o 120‚Üí200 ease-in-out alternate (12s ciclo completo)
- **Cursor smoothing**: Lerp com `LERP_SPEED = 8` matching Chrome CSS `transition: 0.3s cubic-bezier(...)`
- **Position check**: S√≥ define `position: relative` se `static`, evitando sobrescrever `absolute` do Tailwind

### Verifica√ß√£o
- `npx tsc --noEmit` ‚Äî zero erros

---

## 2026-02-01 ‚Äî Sess√£o 8: Gemini Fix + LangGraph Quick Chat + Canvas + Frontend Improvements

### Objetivo
Corrigir Gemini no chat, adicionar quick_chat ao LangGraph para respostas r√°pidas (2-5s), melhorar detec√ß√£o de canvas e otimizar streaming.

### Arquivos Alterados ‚Äî Backend (apps/api)

- `app/services/ai/agent_clients.py` ‚Äî Corrigido retorno silencioso do Gemini:
  - `stream_vertex_gemini_async()`: agora faz yield `("error", msg)` em vez de `return` silencioso
  - `init_vertex_client()`: logs descritivos para Vertex AI vs Direct API

- `app/services/ai/chat_service.py` ‚Äî 3 mudan√ßas:
  - Tratamento de error tuples do Gemini streaming
  - Fun√ß√£o `_detect_canvas_suggestion()`: heur√≠stica baseada em marcadores estruturais (headings, artigos, cl√°usulas, numera√ß√£o)
  - Todos os 5 pontos de `done` event agora incluem `canvas_suggestion: true/false`

- `app/services/ai/model_registry.py` ‚Äî Atualizado:
  - `gemini-2.5-pro/flash`: adicionado `thinking_category="native"`, `max_output_tokens=8192`
  - `google-agent`: api_model default alterado para `gemini-3-flash-preview`
  - `DEFAULT_CHAT_MODEL` e `DEFAULT_JUDGE_MODEL` = `gemini-3-flash`

- `app/services/ai/executors/google_agent.py` ‚Äî Default model alterado para `gemini-3-flash`
  - `MODEL_CONTEXT_WINDOWS` expandido com entries do Gemini 3.x

- `app/services/ai/langgraph_legal_workflow.py` ‚Äî Adicionado quick_chat bypass:
  - `_is_quick_chat(state)`: detecta mensagens curtas sem keywords de documento
  - `quick_chat_node(state)`: RAG m√≠nimo (top-3) + LLM direta, target 2-5s
  - `entry_router(state)`: roteia `__start__` ‚Üí quick_chat | gen_outline
  - Docstring do fluxo atualizada

### Arquivos Alterados ‚Äî Frontend (apps/web)

- `src/components/chat/chat-interface.tsx` ‚Äî Regex `isDocumentRequest()` expandida com 16 novos tipos jur√≠dicos: embargos, memorial, defesa, impugna√ß√£o, r√©plica, contrarraz√µes, despacho, senten√ßa, ac√≥rd√£o, voto, ementa, not√≠cia, procura√ß√£o, den√∫ncia, queixa, libelo, argui√ß√£o

- `src/stores/chat-store.ts` ‚Äî 2 mudan√ßas:
  - Throttle adaptativo do canvas: 40ms (<8k), 100ms (8-20k), 200ms (>20k chars)
  - Handler de `done` event: auto-abre canvas quando `canvas_suggestion: true`

### Decis√µes
- Apenas Gemini 3 Pro e Flash ‚Äî todos os defaults apontam para esses modelos
- Quick chat usa heur√≠stica simples: <600 chars + sem keywords de documento ‚Üí bypass do pipeline de 26 n√≥s
- Canvas suggestion √© heur√≠stica conservadora: ‚â•3 marcadores estruturais + ‚â•600 chars

### Verifica√ß√£o
- `npx tsc --noEmit` ‚Äî zero erros
- Todos os 3 agentes de implementa√ß√£o completaram sem erros

---

## 2026-02-01 ‚Äî Sess√£o 7: Streaming UI Harvey.ai Style

### Objetivo
Redesign do painel de atividade/racioc√≠nio (activity-panel) para estilo Harvey.ai ‚Äî timeline vertical com √≠cones contextuais, detalhes vis√≠veis por padr√£o, chips de busca e fontes com favicons.

### Arquivos Alterados
- `src/components/chat/activity-panel.tsx` ‚Äî Reescrito completo:
  - **Antes**: Card com border, header "Activity", bullet points colapsados, se√ß√µes separadas (Thinking/Steps/Sources)
  - **Depois**: Timeline vertical Harvey.ai style com linha conectora entre steps
  - Header "Trabalhando..." / "Pesquisa conclu√≠da" colaps√°vel (sem card/border)
  - √çcones circulares por tipo (Search, Globe, Brain, FileText, BookOpen, Scale, Gavel, Eye, etc.)
  - Status visual: azul=running, verde=done, vermelho=error, cinza=pending
  - Detalhes vis√≠veis por padr√£o (n√£o colapsados)
  - Tags categorizadas automaticamente: dom√≠nios (com favicon) vs termos de busca (chip azul)
  - Fontes consultadas em footer com chips favicon+dom√≠nio+t√≠tulo+link
  - Auto-scroll durante streaming

### Componentes Novos (internos)
- `TimelineStep` ‚Äî Step da timeline com √≠cone circular, t√≠tulo, detalhe, chips
- `ThinkingTimelineStep` ‚Äî Step de racioc√≠nio com √≠cone Brain
- `SourceChip` ‚Äî Chip de fonte com favicon + dom√≠nio + link externo
- `SearchTermChip` ‚Äî Chip de termo de busca com √≠cone Search (azul)
- `SourcesFooter` ‚Äî Grid de fontes consultadas com "ver mais"

### Decis√µes
- Removido wrapper card/border ‚Äî painel agora √© inline no fluxo da mensagem
- √çcone mapping expandido para contexto jur√≠dico (Scale=legisla√ß√£o, Gavel=jurisprud√™ncia)
- Tags com "." e sem espa√ßo = dom√≠nios (mostram favicon), demais = termos de busca

### Verifica√ß√£o
- `npx tsc --noEmit` ‚Äî zero erros

---

## 2026-01-31 ‚Äî Sess√£o 6: Redesign P√°gina Minuta (Perplexity/ChatGPT-style)

### Objetivo
Redesign da p√°gina de minutas para UI minimalista inspirada em Perplexity e ChatGPT, preservando todas as funcionalidades.

### Arquivos Criados
- `src/components/dashboard/minuta-settings-drawer.tsx` ‚Äî Sheet lateral com todas as ~30 configura√ß√µes organizadas em 8 se√ß√µes Accordion (Modo, Documento, Qualidade, Pesquisa, Modelos, Controle HIL, Avan√ßado, Checklist)

### Arquivos Alterados
- `src/app/(dashboard)/minuta/page.tsx` ‚Äî Reduzido de **2588 para 873 linhas**:
  - Toolbar: de ~15 bot√µes para 5 (R√°pido/Comit√™ + Settings + Layout + Novo Chat + Gerar)
  - Settings panel inline (~1400 linhas) substitu√≠do pelo MinutaSettingsDrawer
  - Empty state: centrado estilo Perplexity com t√≠tulo "Iudex" + ChatInput + chips de a√ß√£o r√°pida
  - Status bar: removida barra fixa, substitu√≠da por progress horizontal inline (s√≥ quando agentes rodam)
  - Fontes RAG: compacto, s√≥ aparece quando h√° itens
- `src/components/dashboard/index.ts` ‚Äî Adicionado export do MinutaSettingsDrawer
- `components.json` ‚Äî Removido caractere inv√°lido no final

### Componentes Instalados
- `src/components/ui/sheet.tsx` ‚Äî j√° existia
- `src/components/ui/accordion.tsx` ‚Äî atualizado via shadcn CLI

### Decis√µes
- Todas as configura√ß√µes movidas para drawer lateral em vez de painel inline que empurrava o conte√∫do
- Empty state com chips de tipo de documento para onboarding r√°pido
- Toolbar mostra apenas controles essenciais ‚Äî o resto vai no drawer
- Canvas permanece inalterado ‚Äî split panel resizable preservado

### Verifica√ß√£o
- `npx tsc --noEmit` ‚Äî zero erros
- `pnpm dev` ‚Äî compila√ß√£o OK (5494 modules)

---

## 2026-01-31 ‚Äî Sess√£o 5: CSS Houdini Paint Worklets ‚Äî Efeitos Avan√ßados

### Objetivo
Aprimorar o worklet verbium-particles (mais impressionante como Antigravity) e criar worklets variados para todas as p√°ginas.

### Arquivos Criados
- `public/worklets/nebula-flow.js` ‚Äî Nebulosa fluida com noise 2D multicamada, cursor attraction, cor gradiente (para marketing pages)
- `public/worklets/grid-pulse.js` ‚Äî Grid de pontos com pulso radial do cursor, onda ambiente, linhas de conex√£o (para auth/security)
- `public/worklets/wave-field.js` ‚Äî Campo de ondas senoidais com interfer√™ncia, distor√ß√£o do cursor, dots nas interse√ß√µes (para customers/workflows)
- `src/components/ui/paint-background.tsx` ‚Äî Componente reutiliz√°vel para renderizar qualquer worklet como background

### Arquivos Alterados
- `public/worklets/verbium-particles.js` ‚Äî Enhanced v2: glow ambiente, cursor glow, color pulse (oscila√ß√£o de cor), constellation connections entre part√≠culas pr√≥ximas, orbit glow
- `src/hooks/use-vorbium-paint.ts` ‚Äî Refatorado para suportar m√∫ltiplos worklets (type WorkletName), carregamento lazy por worklet
- `src/components/vorbium/page-hero.tsx` ‚Äî Props worklet/workletColor/workletSeed + PaintBackground integrado
- `src/app/platform/page.tsx` ‚Äî worklet=nebula-flow (indigo, seed 63)
- `src/app/security/page.tsx` ‚Äî worklet=grid-pulse (emerald #10b981, seed 91)
- `src/app/customers/page.tsx` ‚Äî worklet=wave-field (indigo, seed 88)
- `src/app/assistant/page.tsx` ‚Äî worklet=nebula-flow (purple #8b5cf6, seed 47)
- `src/app/research/page.tsx` ‚Äî worklet=grid-pulse (blue #3b82f6, seed 71)
- `src/app/workflows/page.tsx` ‚Äî worklet=wave-field (amber #f59e0b, seed 29)
- `src/app/collaboration/page.tsx` ‚Äî worklet=nebula-flow (cyan #06b6d4, seed 83)
- `src/app/(auth)/login/page.tsx` ‚Äî PaintBackground grid-pulse (indigo, seed 42)
- `src/app/(auth)/register/page.tsx` ‚Äî PaintBackground grid-pulse (purple #8b5cf6, seed 67)

### Mapeamento de Worklets por P√°gina
| P√°gina | Worklet | Cor | Efeito |
|--------|---------|-----|--------|
| Landing Hero | verbium-particles | indigo | Ring + constellation + glow |
| Platform | nebula-flow | indigo | Nebulosa fluida |
| Assistant | nebula-flow | purple | Nebulosa fluida |
| Collaboration | nebula-flow | cyan | Nebulosa fluida |
| Security | grid-pulse | emerald | Grid + pulso radial |
| Research | grid-pulse | blue | Grid + pulso radial |
| Login | grid-pulse | indigo | Grid + pulso radial |
| Register | grid-pulse | purple | Grid + pulso radial |
| Customers | wave-field | indigo | Ondas + interfer√™ncia |
| Workflows | wave-field | amber | Ondas + interfer√™ncia |

### Comandos Executados
- `npx tsc --noEmit` ‚Äî OK (sem erros)

---

## 2026-01-31 ‚Äî Sess√£o 4: Corre√ß√µes de Acentos, Tema e Cotejo Cr√≠tico

### Objetivo
Corre√ß√µes identificadas no cotejo cr√≠tico: acentos faltantes em p√°ginas de marketing, inconsist√™ncia de tema entre login/register.

### Arquivos Alterados
- `src/app/customers/page.tsx` ‚Äî Corrigidos 13 acentos faltantes (mensur√°vel, opera√ß√£o, Redu√ß√£o, jur√≠dica, etc.)
- `src/app/security/page.tsx` ‚Äî Corrigidos 10 acentos (Certifica√ß√µes, Prote√ß√£o, seguran√ßa, tr√¢nsito, etc.)
- `src/app/platform/page.tsx` ‚Äî Corrigidos 3 acentos (Redu√ß√£o, dispon√≠veis, pr√°tica jur√≠dica)
- `src/app/(auth)/register/page.tsx` ‚Äî Unificado tema com login: bg-gradient responsivo em vez de dark hardcoded, Card com bg-white/80 + dark:bg-white/5, labels e inputs com cores theme-aware, selects com tokens CSS do shadcn

### Comandos Executados
- `npx tsc --noEmit` ‚Äî OK (sem erros)

### Decis√µes
- Register unificado com login: ambos usam `from-primary/10 via-background to-secondary/10`
- Substitu√≠das cores hardcoded (text-white, text-gray-300, bg-[#0F1115]) por tokens do tema (text-foreground, text-muted-foreground, bg-background)

---

## 2026-01-31 ‚Äî Sess√£o 3: Harvey/Poe/Antigravity Enhancements

### Objetivo
Melhorias inspiradas em Harvey.ai (mega-menu, security badges), Poe.com (multi-provider) e Antigravity (video demos, screenshots mockups).

### Arquivos Modificados
- `src/components/vorbium/vorbium-nav.tsx` ‚Äî Reescrito com mega-menu Harvey-style (dropdowns Plataforma/Empresa com descri√ß√µes, AnimatePresence, hover com delay, mobile accordion)
- `src/app/page.tsx` ‚Äî Se√ß√£o video demo placeholder + se√ß√£o Multi-Provider AI
- `src/app/assistant/page.tsx` ‚Äî Mockup de interface de chat com browser chrome + fix contraste Limites
- `src/app/research/page.tsx` ‚Äî Mockup de resultados de pesquisa com browser chrome
- `src/app/workflows/page.tsx` ‚Äî Browser chrome wrapper no mockup JSON
- `src/app/platform/page.tsx` ‚Äî Se√ß√£o m√©tricas de impacto (70%, 4+, 100%, 24/7)
- `src/app/customers/page.tsx` ‚Äî Cards de impacto visuais, se√ß√£o testimonials, setores melhorados
- `src/app/security/page.tsx` ‚Äî Badge cards (SOC2, ISO 27001, LGPD, GDPR), se√ß√£o prote√ß√£o em camadas
- `src/components/vorbium/footer.tsx` ‚Äî Fix contraste dark mode (gray-700‚Üígray-500)

### Verifica√ß√£o
- `npx tsc --noEmit` ‚Äî OK

---

## 2026-01-31 ‚Äî Auditoria de contraste light/dark mode nas marketing pages

### Objetivo
Auditar e corrigir problemas de contraste em todas as 6 marketing pages (research, workflows, collaboration, customers, security, platform) e nos componentes compartilhados (vorbium-nav, footer, page-hero, feature-section).

### Resultado da Auditoria
As 6 p√°ginas de marketing j√° estavam com classes dual-mode corretas (`text-slate-900 dark:text-white`, `text-slate-600 dark:text-gray-400`, etc.), provavelmente corrigidas durante a cria√ß√£o.

### Problemas encontrados e corrigidos (componentes compartilhados)

#### `src/components/vorbium/vorbium-nav.tsx`
- Links "Resources" e "About" usavam `text-gray-400` sozinho (muito claro em fundo branco)
- Corrigido para `text-gray-500 dark:text-gray-400`

#### `src/components/vorbium/footer.tsx`
- Copyright usava `dark:text-gray-700` (quase invis√≠vel em fundo escuro)
- Links do rodap√© usavam `dark:text-gray-600` (pouco leg√≠vel em fundo escuro)
- Ambos corrigidos para `dark:text-gray-500`

### Verifica√ß√£o
- `npx tsc --noEmit` ‚Äî OK, sem erros

---

## 2026-01-31 ‚Äî UI/UX Premium Completo (Estilo Antigravity/Apple)

### Objetivo
Melhorias abrangentes de UI/UX em TODAS as p√°ginas do Iudex, inspiradas no Google Antigravity e Apple.com. Framer Motion + CSS moderno + Tailwind.

### Arquivos Criados (6)
- `src/components/ui/motion.tsx` ‚Äî Presets Framer Motion (transitions, variants, componentes wrapper)
- `src/components/ui/animated-container.tsx` ‚Äî Scroll-reveal gen√©rico com useInView (cross-browser)
- `src/components/ui/animated-counter.tsx` ‚Äî Contador num√©rico animado com Framer Motion
- `src/hooks/use-tilt.ts` ‚Äî 3D tilt effect para cards (perspective + rotateX/Y)
- `src/hooks/use-scroll-progress.ts` ‚Äî Scroll progress 0-1
- `src/components/providers/page-transition.tsx` ‚Äî AnimatePresence page transitions

### Arquivos Modificados (20+)
**Infraestrutura:**
- `globals.css` ‚Äî shimmer-premium, glow-hover, card-premium, scroll-progress, prefers-reduced-motion
- `tailwind.config.ts` ‚Äî keyframes slide-up-fade, slide-down-fade, scale-in, blur-in, glow-pulse
- `skeleton.tsx` ‚Äî shimmer-premium no lugar de animate-pulse
- `dialog.tsx` ‚Äî backdrop-blur-md, bg-background/95, rounded-2xl

**Dashboard:**
- `(dashboard)/layout.tsx` ‚Äî PageTransition wrapper, loading state premium com logo animado
- `sidebar-pro.tsx` ‚Äî layoutId sliding active indicator, AnimatePresence labels
- `dashboard/page.tsx` ‚Äî StaggerContainer para stat cards, AnimatedCounter
- `quick-actions.tsx` ‚Äî StaggerContainer, card-premium glow-hover
- `stat-card.tsx` ‚Äî value prop ReactNode para AnimatedCounter

**Landing:**
- `hero-section.tsx` ‚Äî Framer Motion stagger, TiltCard 3D, scroll indicator
- `feature-section.tsx` ‚Äî AnimatedContainer cross-browser, glow-hover
- `footer.tsx` ‚Äî StaggerContainer fadeUp
- `page.tsx` (landing) ‚Äî scroll progress bar, AnimatedContainer sections

**Auth:**
- `login/page.tsx` ‚Äî gradient mesh bg animado, MotionDiv scaleIn, focus glow inputs
- `register/page.tsx` ‚Äî gradient mesh bg, scaleIn card, focus glow
- `register-type/page.tsx` ‚Äî gradient mesh, StaggerContainer cards

**Feature pages:**
- `cases/page.tsx` ‚Äî AnimatedContainer, StaggerContainer, card-premium glow-hover
- `documents/page.tsx` ‚Äî AnimatedContainer header
- `legislation/page.tsx` ‚Äî AnimatedContainer header
- `jurisprudence/page.tsx` ‚Äî AnimatedContainer, StaggerContainer resultados
- `library/page.tsx` ‚Äî AnimatedContainer header
- `transcription/page.tsx` ‚Äî AnimatedContainer header

**Marketing:**
- `platform/page.tsx` ‚Äî AnimatedContainer CTA
- `assistant/page.tsx` ‚Äî AnimatedContainer se√ß√µes
- `research/page.tsx` ‚Äî AnimatedContainer se√ß√µes

### Decis√µes Tomadas
- Framer Motion para anima√ß√µes (cross-browser, j√° instalado v12.23.24)
- AnimatePresence mode="wait" para page transitions (pathname como key)
- useInView substituindo animationTimeline: 'view()' (Chrome-only)
- layoutId para sidebar active indicator (spring animation)
- 3D tilt cards com perspective(600px) no hero
- prefers-reduced-motion global reset para acessibilidade

### Verifica√ß√£o
- `npx tsc --noEmit` ‚Äî OK (sem erros)
- ESLint com problemas pr√©-existentes (migra√ß√£o ESLint 9, n√£o relacionado)

---

## 2026-01-31 ‚Äî Melhorias Antigravity na Landing Page Vorbium

### Objetivo
Aplicar 3 melhorias de alto impacto visual inspiradas no Google Antigravity √† landing page.

### Arquivos Alterados
- `apps/web/src/styles/globals.css` ‚Äî Adicionados keyframes `wobble`, `scale-reveal` e `scroll-fade-up`
- `apps/web/src/components/vorbium/feature-section.tsx` ‚Äî Wobble icons com delay staggered + scroll-driven fade-in (substituiu useInView por animation-timeline: view())
- `apps/web/src/app/page.tsx` ‚Äî CTA final com scale-reveal no scroll + se√ß√£o "Por que" com scroll-driven fade. Removido useInView (n√£o mais necess√°rio)

### Decis√µes Tomadas
- Scroll-driven animations (CSS puras) em vez de IntersectionObserver JS para melhor performance
- Wobble com 4s duration e 0.3s stagger por card para efeito cascata natural
- Scale-reveal de 0.88‚Üí1.0 com opacity 0.6‚Üí1.0 para CTA dram√°tico
- CTA envolvido em card com backdrop-blur para profundidade visual

### Tipografia ‚Äî Google Sans Flex
- Expandido range de pesos CDN: 400..800 ‚Üí 100..900
- Removido import duplicado de Google Sans Text no globals.css
- Adicionada fam√≠lia `font-google-sans` no Tailwind config com Google Sans Flex como prim√°ria
- Aplicada no `<body>` via classe Tailwind (removido inline style)
- Adicionados estilos de tipografia vari√°vel (eixos `opsz`, `ROND`, `GRAD`) para headings e body text
- Atualizado fallback em `.font-google-sans-text` para incluir Google Sans Flex

### Sess√£o Anterior (mesmo dia)
- Implementado dual-ring particle system no worklet (anel est√°tico + √≥rbita din√¢mica)
- Cursor repulsion com cubic falloff no anel central
- Ring breathing animation (120‚Üí200 radius)
- Drift suave do centro (15% blend com cursor)

---

## 2026-01-28 ‚Äî Ado√ß√£o completa do rag.md para GraphRAG/Neo4j

### Objetivo
Adotar todas as configura√ß√µes e modo do GraphRAG com Neo4j conforme documentado no `rag.md` (Cap√≠tulo 5).

### Arquivos Modificados

#### `apps/api/docker-compose.rag.yml`
Atualizado servi√ßo Neo4j:
- **Imagem**: `neo4j:5.15-community` ‚Üí `neo4j:5.21.0-enterprise`
- **Plugins**: Adicionado `graph-data-science` (GDS) al√©m de APOC
- **Licen√ßa**: `NEO4J_ACCEPT_LICENSE_AGREEMENT=yes` (Developer License)
- **Mem√≥ria**: heap 1G-2G, pagecache 1G (conforme rag.md)
- **Config**: `strict_validation_enabled=false` (necess√°rio para GraphRAG vetorial)
- **APOC**: Habilitado export/import de arquivos
- **Restart**: `unless-stopped`

#### `apps/api/app/services/rag/config.py`
- **graph_backend**: `"networkx"` ‚Üí `"neo4j"` (default agora √© Neo4j)
- **enable_graph_retrieval**: `False` ‚Üí `True` (Neo4j como 3¬™ fonte no RRF por padr√£o)

### Mudan√ßas de Comportamento
| Antes | Depois |
|-------|--------|
| NetworkX como backend padr√£o (local) | Neo4j como backend padr√£o |
| Graph retrieval desabilitado | Graph retrieval habilitado no RRF |
| Neo4j Community 5.15 | Neo4j Enterprise 5.21.0 |
| Apenas APOC | APOC + Graph Data Science |

### Para usar NetworkX (fallback local)
Se n√£o tiver Neo4j rodando:
```bash
export RAG_GRAPH_BACKEND=networkx
export RAG_ENABLE_GRAPH_RETRIEVAL=false
```

### Refer√™ncia
Baseado no Cap√≠tulo 5 do `rag.md` - "O RAG em Grafos: GraphRAG"

---

## 2026-01-28 ‚Äî Implementa√ß√£o Phase 4: Frontend + SSE Events (CogGRAG)

### Objetivo
Implementar Phase 4 do plano CogGRAG: Eventos SSE para visualiza√ß√£o em tempo real da √°rvore de decomposi√ß√£o no frontend.

### Arquivos Criados
- `apps/api/app/services/ai/shared/sse_protocol.py` ‚Äî Adicionados eventos CogGRAG:
  - `COGRAG_DECOMPOSE_START/NODE/COMPLETE` ‚Äî Eventos de decomposi√ß√£o
  - `COGRAG_RETRIEVAL_START/NODE/COMPLETE` ‚Äî Eventos de busca de evid√™ncias
  - `COGRAG_VERIFY_START/NODE/COMPLETE` ‚Äî Eventos de verifica√ß√£o
  - `COGRAG_INTEGRATE_START/COMPLETE` ‚Äî Eventos de integra√ß√£o final
  - Event builders: `cograg_decompose_start_event()`, `cograg_retrieval_node_event()`, etc.
  - Dataclass `CogRAGNodeData` para dados de n√≥s
- `apps/web/src/components/chat/cograg-tree-viewer.tsx` ‚Äî Novo componente React:
  - Visualiza√ß√£o hier√°rquica da √°rvore de decomposi√ß√£o
  - Estados por n√≥: pending, decomposing, retrieving, verified, rejected
  - Badges: contagem de evid√™ncias, confidence %, n√≥s rejeitados
  - Collapsible por n√≠vel, auto-scroll

### Arquivos Modificados
- `apps/web/src/stores/chat-store.ts`:
  - Tipos exportados: `CogRAGNode`, `CogRAGStatus`, `CogRAGNodeState`
  - Estado: `cogragTree: CogRAGNode[] | null`, `cogragStatus: CogRAGStatus`
  - Handlers SSE para todos eventos CogGRAG (decompose/retrieval/verify/integrate)
  - Reset de estado em `setIsAgentMode(false)`
  - Whitelist de eventos SSE atualizada com CogGRAG events
- `apps/web/src/components/chat/chat-interface.tsx`:
  - Import de `CogRAGTreeViewer`
  - Integra√ß√£o do viewer no chat (renderiza quando `cogragTree` existe)

### Verifica√ß√£o
- `npm run type-check --workspace=apps/web` ‚Äî OK
- `npm run lint` nos arquivos modificados ‚Äî OK
- `pytest tests/test_cograg*.py` ‚Äî **114 passed**

### Decis√µes
- Visualiza√ß√£o opt-in: s√≥ aparece quando `cogragTree.length > 0`
- Cores consistentes com UX existente (cyan para CogGRAG, amber para retrieval, purple para verify)
- SSE events seguem padr√£o existente do JobManager v1 envelope

---

## 2026-01-28 ‚Äî Implementa√ß√£o Phase 3: Reasoning + Verification (Dual-LLM)

### Objetivo
Implementar Phase 3 do plano CogGRAG: Reasoner (gera√ß√£o de respostas bottom-up), Verifier (verifica√ß√£o dual-LLM), Query Rewriter (hallucination loop), e Integrator (s√≠ntese final).

### Arquivos Criados
- `app/services/rag/core/cograg/nodes/reasoner.py` ‚Äî N√≥ Reasoner:
  - `LEAF_ANSWER_PROMPT`, `SYNTHESIS_PROMPT` ‚Äî Prompts em portugu√™s jur√≠dico
  - `_format_evidence_for_prompt()` ‚Äî Formata evid√™ncias para LLM
  - `_compute_answer_confidence()` ‚Äî Score de confian√ßa baseado em: qtd evid√™ncias, qualidade, conflitos, subst√¢ncia
  - `reasoner_node()` ‚Äî Gera respostas para cada sub-quest√£o (paralelo), extrai cita√ß√µes via regex
- `app/services/rag/core/cograg/nodes/verifier.py` ‚Äî N√≥ Verifier + Query Rewriter:
  - `VERIFICATION_PROMPT`, `RETHINK_PROMPT` ‚Äî Prompts de verifica√ß√£o
  - `_parse_verification_result()` ‚Äî Parse JSON de resposta do verificador
  - `verifier_node()` ‚Äî Verifica consist√™ncia respostas vs evid√™ncias, detecta alucina√ß√µes
  - `query_rewriter_node()` ‚Äî Incrementa rethink_count para loop de corre√ß√£o
- `app/services/rag/core/cograg/nodes/integrator.py` ‚Äî N√≥ Integrator:
  - `INTEGRATION_PROMPT`, `ABSTAIN_PROMPT` ‚Äî Prompts de s√≠ntese
  - `_format_sub_answers()`, `_collect_citations()` ‚Äî Helpers de formata√ß√£o
  - `_rule_based_integration()` ‚Äî Fallback quando LLM falha
  - `integrator_node()` ‚Äî Sintetiza resposta final, coleta cita√ß√µes, suporta abstain mode
- `tests/test_cograg_reasoning.py` ‚Äî 27 testes para Phase 3 nodes

### Arquivos Modificados
- `app/services/rag/core/cograg/nodes/__init__.py` ‚Äî Exports: `reasoner_node`, `verifier_node`, `query_rewriter_node`, `integrator_node`
- `app/services/ai/langgraph/subgraphs/cognitive_rag.py`:
  - Imports lazy para Phase 3 nodes (`_import_reasoner`, `_import_verifier`, `_import_query_rewriter`, `_import_integrator`)
  - Substitui√ß√£o dos stubs pelos n√≥s reais no graph builder
  - Adi√ß√£o de `cograg_verification_enabled`, `cograg_abstain_mode` no state e runner
  - Docstring atualizada: "All phases implemented"

### Testes
- `pytest tests/test_cograg*.py` ‚Äî **114/114 passed**

### Decis√µes
- `cograg_verification_enabled=False` por default ‚Äî verifica√ß√£o dual-LLM √© opcional (custo adicional de LLM calls)
- `cograg_abstain_mode=True` por default ‚Äî quando evid√™ncia insuficiente, explica em vez de tentar responder
- Reasoner gera respostas em paralelo para todas sub-quest√µes
- Verifier usa temperatura baixa (0.1) para verifica√ß√£o mais consistente
- Integrator usa LLM para s√≠ntese m√∫ltiplas respostas, com fallback rule-based se LLM falhar
- Cita√ß√µes extra√≠das via regex (Art., Lei, S√∫mula) sem LLM adicional

### Pipeline Completo CogGRAG
```
planner ‚Üí theme_activator ‚Üí dual_retriever ‚Üí evidence_refiner ‚Üí
memory_check ‚Üí reasoner ‚Üí verifier ‚Üí [query_rewriter ‚Ü∫ | integrator] ‚Üí
memory_store ‚Üí END
```

---

## 2026-01-28 ‚Äî Implementa√ß√£o Phase 2.5: Evidence Refiner + Memory Nodes

### Objetivo
Implementar Phase 2.5 do plano CogGRAG: Evidence Refiner (detec√ß√£o de conflitos, quality scoring) e Memory Nodes (check + store para reutiliza√ß√£o de consultas similares).

### Arquivos Criados
- `app/services/rag/core/cograg/nodes/evidence_refiner.py` ‚Äî N√≥ Evidence Refiner:
  - `_extract_legal_numbers()` ‚Äî Extra√ß√£o de refer√™ncias legais (Art., Lei, S√∫mula, Decreto)
  - `_detect_contradiction_signals()` ‚Äî Detec√ß√£o de sinais de contradi√ß√£o (nega√ß√£o, proibi√ß√£o, conclus√µes opostas)
  - `_compute_evidence_quality_score()` ‚Äî Score de qualidade (0-1) baseado em: retrieval score, tipo de fonte, tamanho do texto, refer√™ncias legais
  - `evidence_refiner_node()` ‚Äî N√≥ LangGraph que refina evid√™ncias, detecta conflitos intra/cross-node, ordena chunks por qualidade
- `app/services/rag/core/cograg/nodes/memory.py` ‚Äî Memory Nodes:
  - `ConsultationMemory` ‚Äî Backend simples file-based para MVP (JSON files + index)
  - `memory_check_node()` ‚Äî Busca consultas similares por overlap de keywords (Jaccard similarity)
  - `memory_store_node()` ‚Äî Armazena consulta atual para reutiliza√ß√£o futura
- `tests/test_cograg_evidence_refiner.py` ‚Äî 21 testes para refiner
- `tests/test_cograg_memory.py` ‚Äî 18 testes para memory nodes

### Arquivos Modificados
- `app/services/rag/core/cograg/nodes/__init__.py` ‚Äî Exports dos novos n√≥s
- `app/services/ai/langgraph/subgraphs/cognitive_rag.py`:
  - Imports lazy para Phase 2.5 nodes (`_import_evidence_refiner`, `_import_memory_check`, `_import_memory_store`)
  - Substitui√ß√£o dos stubs pelos n√≥s reais no graph builder
  - Adi√ß√£o de `cograg_memory_enabled` no state e runner
  - Stubs mantidos como fallback se imports falharem

### Testes
- `pytest tests/test_cograg*.py` ‚Äî **87/87 passed**

### Decis√µes
- Memory backend MVP: file-based JSON com keyword similarity (Jaccard). Produ√ß√£o: trocar por vector store + embedding similarity
- Conflict detection heur√≠stica: detecta contradi√ß√µes por sinais de nega√ß√£o + conclus√µes opostas sobre mesma refer√™ncia legal
- Quality scoring ponderado: 40% retrieval score, 30% tipo de fonte (jurisprud√™ncia > lei > doutrina), 15% tamanho, 15% refer√™ncias legais
- `cograg_memory_enabled=False` por default ‚Äî memory √© opcional

---

## 2026-01-28 ‚Äî Implementa√ß√£o Phase 2: Pipeline Integration

### Objetivo
Integrar CogGRAG no pipeline RAG existente com branching condicional e fallback autom√°tico.

### Arquivos Criados
- `tests/test_cograg_integration.py` ‚Äî 15 testes para integra√ß√£o no pipeline

### Arquivos Modificados
- `app/services/rag/pipeline/rag_pipeline.py`:
  - Imports lazy: `run_cognitive_rag`, `cograg_is_complex` (try/except pattern)
  - 4 novos valores no enum `PipelineStage`: `COGRAG_DECOMPOSE`, `COGRAG_RETRIEVAL`, `COGRAG_REFINE`, `COGRAG_VERIFY`
  - Branching no `search()`: detecta `use_cograg` (feature flag + query complexa) ‚Üí chama `_cograg_pipeline()`
  - M√©todo `_cograg_pipeline()` (~120 linhas): invoca `run_cognitive_rag()`, fallback se ‚â§1 sub-question, merge de resultados

### Testes
- `pytest tests/test_cograg_integration.py` ‚Äî **15/15 passed**

### Decis√µes
- Complexidade detectada por: word count > 12 OU patterns (compare, m√∫ltiplas conjun√ß√µes, etc.)
- Fallback autom√°tico: se CogGRAG retorna ‚â§1 sub-question ‚Üí pipeline normal
- `enable_cograg=False` por default ‚Äî zero impacto quando desligado

---

## 2026-01-28 ‚Äî Implementa√ß√£o Phase 1: Core CogGRAG (LangGraph)

### Objetivo
Implementar Phase 1 do plano CogGRAG: data structures, n√≥s LangGraph (Planner, Theme Activator, Dual Retriever), StateGraph principal, configs, e testes.

### Arquivos Criados
- `app/services/rag/core/cograg/__init__.py` ‚Äî Package exports
- `app/services/rag/core/cograg/mindmap.py` ‚Äî Data structures: `NodeState`, `MindMapNode`, `CognitiveTree`
- `app/services/rag/core/cograg/nodes/__init__.py` ‚Äî Nodes package
- `app/services/rag/core/cograg/nodes/planner.py` ‚Äî N√≥ Planner: decomposi√ß√£o top-down, heur√≠stica de complexidade, prompts PT jur√≠dico
- `app/services/rag/core/cograg/nodes/retriever.py` ‚Äî N√≥s Theme Activator + Dual Retriever: fan-out paralelo, dedup, Neo4j entity/triple/subgraph
- `app/services/ai/langgraph/subgraphs/cognitive_rag.py` ‚Äî StateGraph principal: `CognitiveRAGState`, 10 n√≥s (6 stubs para Phase 2.5/3), edges condicionais, `run_cognitive_rag()`
- `tests/test_cograg_mindmap.py` ‚Äî 22 testes para NodeState/MindMapNode/CognitiveTree
- `tests/test_cograg_planner.py` ‚Äî 12 testes para complexity detection + planner node

### Arquivos Modificados
- `app/services/rag/config.py` ‚Äî 14 novos campos CogGRAG no `RAGConfig` + env vars no `from_env()`

### Testes
- `pytest tests/test_cograg_mindmap.py tests/test_cograg_planner.py` ‚Äî **34/34 passed**

### Decis√µes
- `max_depth` sem√¢ntica: `>=` (max_depth=3 ‚Üí levels 0,1,2)
- Phase 2.5/3 n√≥s como stubs no StateGraph (placeholder ‚Üí implementa√ß√£o incremental)
- `_call_gemini` isolada no planner (n√£o depende de QueryExpansion)
- LegalEntityExtractor reusado para key extraction (zero LLM)

---

## 2026-01-28 ‚Äî Plano: Integra√ß√£o CogGRAG no Pipeline RAG

### Objetivo
Integrar o padr√£o CogGRAG (Cognitive Graph RAG ‚Äî paper 2503.06567v2) como modo alternativo de processamento no pipeline RAG existente, com feature flag `enable_cograg`.

### Pesquisa Realizada
- Leitura completa do paper CogGRAG (2503.06567v2 ‚Äî AAAI 2026): decomposi√ß√£o top-down em mind map, retrieval estruturado local+global, racioc√≠nio bottom-up com verifica√ß√£o dual-LLM
- Leitura completa do paper MindMap (2308.09729v5): KG prompting com graph-of-thoughts, evidence mining path-based + neighbor-based
- An√°lise do c√≥digo-fonte oficial CogGRAG (github.com/cy623/RAG): `mindmap.py`, `retrieval.py`, `Agent.py`, `prompts.json` (6 templates)
- Explora√ß√£o completa da infraestrutura existente: rag_pipeline.py (10 stages), query_expansion.py, neo4j_mvp.py, orchestrator.py, ClaudeAgentExecutor, LangGraph workflows, parallel_research subgraph, model_registry

### Plano Aprovado (5 Phases)

**Phase 1 ‚Äî Core CogGRAG (standalone)**
- `app/services/rag/core/cograg/mindmap.py` ‚Äî Data structures: `NodeState`, `MindMapNode`, `CognitiveTree`
- `app/services/rag/core/cograg/decomposer.py` ‚Äî `CognitiveDecomposer`: BFS level-by-level com Gemini Flash, heur√≠stica de complexidade, prompts em portugu√™s jur√≠dico
- `app/services/rag/core/cograg/structured_retrieval.py` ‚Äî `StructuredRetriever`: fan-out paralelo por sub-quest√£o, reusa `LegalEntityExtractor` (regex), Neo4j + Qdrant + OpenSearch

**Phase 2 ‚Äî Integra√ß√£o no Pipeline**
- `app/services/rag/config.py` ‚Äî 9 novos campos: `enable_cograg`, `cograg_max_depth`, `cograg_similarity_threshold`, etc.
- `app/services/rag/pipeline/rag_pipeline.py` ‚Äî Branching no `search()`: CogGRAG path (Stages COGRAG_DECOMPOSE + COGRAG_STRUCTURED_RETRIEVAL) ‚Üí Stage 5+ normal. Fallback autom√°tico para queries simples

**Phase 3 ‚Äî Verifica√ß√£o Dual-LLM**
- `app/services/rag/core/cograg/reasoner.py` ‚Äî `BottomUpReasoner`: LLM_res gera resposta, LLM_ver verifica, re-think se inconsistente

**Phase 4 ‚Äî Frontend + SSE**
- Novos eventos SSE: `COGRAG_DECOMPOSE_*`, `COGRAG_RETRIEVAL_*`, `COGRAG_VERIFY_*`
- `cograg-tree-viewer.tsx` ‚Äî Visualiza√ß√£o da √°rvore em tempo real

**Phase 5 ‚Äî Testes**
- 4 arquivos: `test_cograg_mindmap.py`, `test_cograg_decomposer.py`, `test_cograg_retrieval.py`, `test_cograg_integration.py`

### Decis√µes Arquiteturais
- Feature-flagged (`enable_cograg=False` default) ‚Äî zero impacto quando desligado
- Fallback autom√°tico: query simples (‚â§1 folha) ‚Üí pipeline normal
- Gemini Flash para decomposi√ß√£o (consistente com HyDE/Multi-Query existentes)
- LegalEntityExtractor (regex) para key extraction ‚Äî zero LLM
- Incremental: Phase 1-2 sem Phase 3, cada phase com seu flag
- Budget: decomposi√ß√£o ~2-3 LLM calls, verifica√ß√£o ~2N calls

### Arquivo do Plano
- `/Users/nicholasjacob/.claude/plans/cuddly-herding-crystal.md` ‚Äî Plano detalhado completo

---

## 2026-01-28 ‚Äî Feature: Multi-tenancy Organizacional ‚Äî Fase 1 (P2)

### Objetivo
Adicionar multi-tenancy organizacional (escrit√≥rio ‚Üí equipes ‚Üí usu√°rios) sem quebrar usu√°rios existentes. Fase 1: modelos, auth, endpoints, migration.

### Arquitetura
```
Organization (escrit√≥rio) ‚Üí OrganizationMember (v√≠nculo + role) ‚Üí User
Organization ‚Üí Team (equipe) ‚Üí TeamMember ‚Üí User
```

Roles: `admin` (gerencia org), `advogado` (acesso completo), `estagi√°rio` (restrito).
Retrocompat√≠vel: `organization_id` nullable em tudo. Users sem org continuam funcionando.

### Arquivos Criados
- `app/models/organization.py` ‚Äî Organization, OrganizationMember, OrgRole, Team, TeamMember
- `app/schemas/organization.py` ‚Äî OrgCreate, OrgResponse, MemberResponse, InviteRequest, TeamCreate, etc.
- `app/api/endpoints/organizations.py` ‚Äî 11 endpoints CRUD (org, membros, equipes)
- `alembic/versions/g7h8i9j0k1l2_add_multi_tenancy.py` ‚Äî Migration (4 tabelas + 4 colunas nullable)
- `tests/test_organization.py` ‚Äî 34 testes

### Arquivos Modificados
- `app/models/user.py` ‚Äî Adicionado `organization_id` FK nullable + relationships
- `app/models/case.py` ‚Äî Adicionado `organization_id` FK nullable
- `app/models/chat.py` ‚Äî Adicionado `organization_id` FK nullable
- `app/models/document.py` ‚Äî Adicionado `organization_id` FK nullable
- `app/models/__init__.py` ‚Äî Exports dos novos modelos
- `app/core/security.py` ‚Äî OrgContext dataclass, get_org_context, require_org_role
- `app/api/routes.py` ‚Äî Registrado router `/organizations`
- `app/api/endpoints/auth.py` ‚Äî JWT payload inclui `org_id`

### OrgContext (core do multi-tenancy)
```python
@dataclass
class OrgContext:
    user: User
    organization_id: Optional[str]  # None = single-user mode
    org_role: Optional[str]         # admin/advogado/estagiario
    team_ids: List[str]

    @property
    def tenant_id(self) -> str:
        """org_id se membro, sen√£o user_id (para RAG/Neo4j)."""
        return self.organization_id or self.user.id
```

### Endpoints
```
POST   /organizations/                    ‚Üí Criar org (user vira admin)
GET    /organizations/current             ‚Üí Detalhes da org
PUT    /organizations/current             ‚Üí Atualizar (admin)
GET    /organizations/members             ‚Üí Listar membros
POST   /organizations/members/invite      ‚Üí Convidar (admin)
PUT    /organizations/members/{uid}/role  ‚Üí Alterar role (admin)
DELETE /organizations/members/{uid}       ‚Üí Remover (admin)
POST   /organizations/teams              ‚Üí Criar equipe
GET    /organizations/teams              ‚Üí Listar equipes
POST   /organizations/teams/{tid}/members ‚Üí Add membro
DELETE /organizations/teams/{tid}/members/{uid} ‚Üí Remove
```

### Testes
- 34/34 passando ‚úÖ
- 27/27 citation grounding (regress√£o) ‚úÖ

### Pr√≥ximos Passos (Fase 2)
- ~~Migrar endpoints existentes de `get_current_user` ‚Üí `get_org_context`~~ ‚úÖ
- ~~Data isolation: Cases/Chats/Documents filtrados por org_id~~ ‚úÖ
- ~~Frontend: org store, p√°gina de gest√£o, org switcher~~ ‚úÖ

---

## 2026-01-28 ‚Äî Feature: Multi-tenancy ‚Äî Fase 2 (Data Isolation) + Fase 3 (Frontend)

### Objetivo
Migrar todos os endpoints de dados para usar `OrgContext` (isolamento por org) e criar UI de gest√£o organizacional no frontend.

### Fase 2 ‚Äî Backend Data Isolation

#### Arquivos Modificados
- `app/core/security.py` ‚Äî Adicionado `build_tenant_filter(ctx, model_class)` helper
- `app/services/case_service.py` ‚Äî Todos m√©todos aceitam `Union[OrgContext, str]`, `create_case` seta `organization_id`
- `app/api/endpoints/cases.py` ‚Äî 9 endpoints migrados de `get_current_user` ‚Üí `get_org_context`
- `app/api/endpoints/chats.py` ‚Äî 10+ endpoints migrados, `create_chat`/`duplicate_chat` setam `organization_id`
- `app/api/endpoints/documents.py` ‚Äî 18+ endpoints migrados, `upload_document` seta `organization_id`
- `app/schemas/user.py` ‚Äî `UserResponse` inclui `organization_id`
- `app/api/endpoints/auth.py` ‚Äî Refresh endpoint inclui `org_id` no JWT

#### Padr√£o de Migra√ß√£o
```python
# ANTES
current_user: User = Depends(get_current_user)
query = select(Case).where(Case.user_id == current_user.id)

# DEPOIS
ctx: OrgContext = Depends(get_org_context)
current_user = ctx.user  # alias para retrocompatibilidade
query = select(Case).where(build_tenant_filter(ctx, Case))
```

### Fase 3 ‚Äî Frontend

#### Arquivos Criados
- `stores/org-store.ts` ‚Äî Zustand store para organiza√ß√£o (fetch, CRUD, membros, equipes)
- `app/(dashboard)/organization/page.tsx` ‚Äî P√°gina de gest√£o: criar org, membros, equipes, convites

#### Arquivos Modificados
- `stores/auth-store.ts` ‚Äî User interface expandida com `role`, `plan`, `account_type`, `organization_id`
- `stores/index.ts` ‚Äî Export do `useOrgStore`
- `lib/api-client.ts` ‚Äî 11 novos m√©todos de organiza√ß√£o (CRUD, membros, equipes)
- `components/layout/sidebar-pro.tsx` ‚Äî Footer din√¢mico com dados do user + indicador de org
- `components/chat/chat-interface.tsx` ‚Äî Sincroniza `tenantId` do chat com `organization_id` do user

### Verifica√ß√£o
- 34/34 testes Python passando ‚úÖ
- TypeScript compila sem erros ‚úÖ

---

## 2026-01-28 ‚Äî Otimiza√ß√£o de Lat√™ncia do Pipeline RAG

### Objetivo
Reduzir lat√™ncia do pipeline RAG (3 databases em paralelo) com result cache, per-DB timeouts, m√©tricas de percentil e warm-start de conex√µes. Target: P50 < 80ms, P95 < 120ms, P99 < 180ms (retrieval).

### Arquivos Criados
- `app/services/rag/core/result_cache.py` ‚Äî ResultCache thread-safe com TTL, LRU eviction, invalida√ß√£o por tenant
- `app/services/rag/core/metrics.py` ‚Äî LatencyCollector com sliding window P50/P95/P99 por stage
- `tests/test_result_cache.py` ‚Äî 12 testes (TTL, invalida√ß√£o, max_size, thread safety)
- `tests/test_latency_collector.py` ‚Äî 7 testes (percentis, sliding window, singleton, thread safety)
- `tests/test_per_db_timeout.py` ‚Äî 5 testes (timeout ‚Üí [], parallel degradation, min_sources)

### Arquivos Modificados
- `app/services/rag/config.py` ‚Äî 9 novos campos: result cache (enable, ttl, max_size), per-DB timeouts (lexical 0.5s, vector 1.0s, graph 0.5s, min_sources), warmup_on_startup
- `app/services/rag/pipeline/rag_pipeline.py` ‚Äî 3 mudan√ßas:
  - Cache check ap√≥s trace init (early return se cache hit)
  - `_with_timeout` wrapper com `asyncio.wait_for` nos 3 DB searches (retorna [] no timeout)
  - M√©tricas recording das stage durations + cache set antes do return
- `app/api/endpoints/rag.py` ‚Äî Endpoint `GET /rag/metrics` (latency + cache stats), invalida√ß√£o de cache nos 2 endpoints de ingest
- `app/main.py` ‚Äî Warm-start expandido: health-check paralelo de Qdrant, OpenSearch, Neo4j no boot (5s timeout cada), defaults de preload mudados para `true`

### Padr√£o de Timeout
```python
async def _with_timeout(coro, timeout: float, name: str):
    try:
        return await asyncio.wait_for(coro, timeout=timeout)
    except asyncio.TimeoutError:
        return []  # graceful degradation
```

### Testes
- 24/24 novos testes passando ‚úÖ
- 81/81 testes totais passando ‚úÖ

---

## 2026-01-28 ‚Äî Feature: Citation Grounding Rigoroso (P1 ‚Äî Zero Hallucination)

### Objetivo
Verifica√ß√£o p√≥s-gera√ß√£o de cita√ß√µes jur√≠dicas na resposta do LLM. Antes de enviar ao usu√°rio, extrai entidades legais do texto e verifica cada uma contra o contexto RAG e o Neo4j.

### Arquitetura
```
ANTES:  LLM gera texto ‚Üí append references ‚Üí enviar (sem verifica√ß√£o)
DEPOIS: LLM gera texto ‚Üí [verify_citations] ‚Üí annotate + fidelity_index ‚Üí enviar
```

### Arquivos Criados
- `apps/api/app/services/ai/citations/grounding.py` ‚Äî Core da verifica√ß√£o:
  - `extract_legal_entities_from_response()` ‚Äî Reutiliza LegalEntityExtractor (regex, <1ms)
  - `verify_against_context()` ‚Äî Verifica entidades contra rag_context
  - `verify_against_neo4j()` ‚Äî Batch Cypher lookup (fail-open)
  - `verify_citations()` ‚Äî Orquestrador async principal
  - `annotate_response_text()` ‚Äî Marca [N√ÉO VERIFICADO] + banner de aviso
  - `GroundingResult`, `CitationVerification`, `VerificationStatus` ‚Äî Dataclasses
- `apps/api/tests/test_citation_grounding.py` ‚Äî 27 testes (7 classes)

### Arquivos Modificados
- `apps/api/app/services/rag/config.py` ‚Äî 4 novos campos:
  - `enable_citation_grounding: bool = True`
  - `citation_grounding_threshold: float = 0.85`
  - `citation_grounding_neo4j: bool = True`
  - `citation_grounding_annotate: bool = True`
- `apps/api/app/services/ai/citations/__init__.py` ‚Äî Exports do grounding
- `apps/api/app/api/endpoints/chats.py` ‚Äî Integra√ß√£o em 2 pontos:
  - Modo multi-modelo (~linha 5209): grounding ap√≥s full_text montado
  - Modo breadth_first (~linha 4170): grounding antes de append_references
  - Metadata persistido com `grounding.to_dict()`

### Scoring
- VERIFIED (contexto + Neo4j) ‚Üí confidence 1.0
- CONTEXT_ONLY ‚Üí confidence 0.9
- NEO4J_ONLY ‚Üí confidence 0.7
- UNVERIFIED ‚Üí confidence 0.0
- `fidelity_index = verified / total` (sem cita√ß√µes = 1.0)

### Performance
Total <20ms (regex <1ms + context check <5ms + Neo4j batch <10ms)

### Testes
- 27 passed, 0 failed
- 91 passed em test_kg_builder.py (regress√£o OK)

### Vari√°veis de Ambiente
| Vari√°vel | Default | Descri√ß√£o |
|---|---|---|
| `CITATION_GROUNDING_ENABLED` | `true` | Feature flag |
| `CITATION_GROUNDING_THRESHOLD` | `0.85` | Fidelity m√≠nimo |
| `CITATION_GROUNDING_NEO4J` | `true` | Verificar Neo4j |
| `CITATION_GROUNDING_ANNOTATE` | `true` | Anotar texto |

---

## 2026-01-28 ‚Äî Feature: Graph-Augmented Retrieval (Neo4j como 3¬™ fonte RRF)

### Objetivo
Mover Neo4j de "decora√ß√£o p√≥s-retrieval" (Stage 9) para **participante ativo do retrieval** (Stage 3c), correndo em paralelo com OpenSearch e Qdrant e contribuindo para o RRF merge.

### Arquitetura
```
ANTES:  Query ‚Üí [OpenSearch ‚à• Qdrant] ‚Üí RRF(2 sinais) ‚Üí Rerank ‚Üí ... ‚Üí Graph Enrich (Stage 9)
DEPOIS: Query ‚Üí [OpenSearch ‚à• Qdrant ‚à• Neo4j] ‚Üí RRF(3 sinais) ‚Üí Rerank ‚Üí ... ‚Üí Graph Enrich (Stage 9)
```

Neo4j usa `LegalEntityExtractor.extract()` (regex, <1ms) para extrair entidades da query, depois `query_chunks_by_entities()` para encontrar chunks via MENTIONS. Habilitado inclusive para citation queries ("Art. 5 CF") onde entity extraction √© especialmente eficaz.

### Arquivos Modificados
- `apps/api/app/services/rag/config.py` ‚Äî 3 novos campos:
  - `enable_graph_retrieval: bool = False` (feature flag, off por padr√£o)
  - `graph_weight: float = 0.3` (peso no RRF, menor que lex/vec)
  - `graph_retrieval_limit: int = 20`
- `apps/api/app/services/rag/pipeline/rag_pipeline.py`:
  - Novos enums: `PipelineStage.GRAPH_SEARCH`, `SearchMode.HYBRID_LEX_VEC_GRAPH`, `SearchMode.HYBRID_LEX_GRAPH`
  - Novo m√©todo `_stage_graph_search()` ‚Äî Stage 3c, fail-open, trace completo
  - `_compute_rrf_score()` ‚Äî novo par√¢metro `graph_rank` (backward-compatible)
  - `_merge_results_rrf()` ‚Äî novo par√¢metro `graph_results` com dedup por chunk_uid
  - `_stage_merge_rrf()` ‚Äî propaga `graph_results` e registra `graph_count` no trace
  - `search()` ‚Äî orquestra√ß√£o paralela de 3 tarefas via `asyncio.gather`, unpack fail-open
- `apps/api/tests/test_kg_builder.py` ‚Äî +19 testes em 5 classes:
  - `TestGraphRetrievalConfig` (2): defaults e env vars
  - `TestRRFGraphRank` (6): graph_rank, backward compat, overlap boost, weight=0
  - `TestMergeResultsRRFGraph` (4): 3 sources merge, empty graph, graph-only chunk, no leaks
  - `TestStageGraphSearch` (4): neo4j=None, no entities, fail-open, normalized chunks
  - `TestPipelineEnums` (3): novos enums existem

### Decis√µes
- **Peso 0.3** (vs 0.5 para lex/vec): graph confirma/boosta, n√£o domina
- **Fail-open em todos os pontos**: Neo4j indispon√≠vel = pipeline continua igual
- **Feature flag off por padr√£o**: rollout gradual via `RAG_ENABLE_GRAPH_RETRIEVAL`
- **Preserva `_enrich_from_neo4j`**: complementar (CRAG retry), n√£o substitutivo
- **Citation queries inclu√≠das**: graph search funciona especialmente bem com "Art. 5 CF"

### Testes
- 91 passed (test_kg_builder.py), 50 passed + 1 skipped (test_neo4j_mvp.py)

### Vari√°veis de Ambiente
| Vari√°vel | Default | Descri√ß√£o |
|---|---|---|
| `RAG_ENABLE_GRAPH_RETRIEVAL` | `false` | Feature flag principal |
| `RAG_GRAPH_WEIGHT` | `0.3` | Peso do graph no RRF |
| `RAG_GRAPH_RETRIEVAL_LIMIT` | `20` | Max chunks do Neo4j |

---

## 2026-01-28 ‚Äî Fix: Separa√ß√£o GraphRAG vs ArgumentRAG (anti-contamina√ß√£o)

### Objetivo
Corrigir 3 problemas de contamina√ß√£o entre o grafo de entidades (GraphRAG) e o grafo argumentativo (ArgumentRAG): separa√ß√£o de queries, detec√ß√£o autom√°tica de intent, e security trimming para Claim/Evidence.

### Problema Identificado
1. **FIND_PATHS misturava graph spaces**: A query Cypher √∫nica traversava TANTO edges de entidades (RELATED_TO, MENTIONS) quanto de argumentos (SUPPORTS, OPPOSES, etc.), permitindo que paths de entidades entrassem em Claim/Evidence sem necessidade
2. **Sem detec√ß√£o autom√°tica de intent**: O sistema usava flag expl√≠cita `argument_graph_enabled` sem analisar a query ‚Äî queries de debate ("argumentos a favor") n√£o ativavam ArgumentRAG automaticamente
3. **Claim/Evidence sem security trimming**: FIND_PATHS verificava escopo de Document para Chunk nodes, mas Claim/Evidence (que t√™m tenant_id/case_id) passavam sem valida√ß√£o

### Arquivos Modificados
- `apps/api/app/services/rag/core/neo4j_mvp.py` ‚Äî **Fix 1 + Fix 3**:
  - `FIND_PATHS` agora √© entity-only (RELATED_TO|MENTIONS|ASSERTS|REFERS_TO apenas, targets: Chunk|Entity)
  - Novo `FIND_PATHS_WITH_ARGUMENTS` inclui todas as edges + targets Claim/Evidence
  - `FIND_PATHS_WITH_ARGUMENTS` tem security trimming para Claim/Evidence: `n.tenant_id = $tenant_id AND ($case_id IS NULL OR n.case_id IS NULL OR n.case_id = $case_id)`
  - `find_paths()` aceita `include_arguments: bool = False` para escolher entre os dois modos
- `apps/api/app/services/rag/pipeline/rag_pipeline.py` ‚Äî **Fix 2**:
  - Nova fun√ß√£o `detect_debate_intent(query)` com regex para cues de debate em portugu√™s (argumentos, tese, contratese, pr√≥s e contras, defesa, contradit√≥rio, fundamenta√ß√£o, impugna√ß√£o, etc.)
  - `_stage_graph_enrich()` auto-habilita `argument_graph_enabled` quando intent √© debate
  - `find_paths()` recebe `include_arguments=argument_graph_enabled` ‚Äî entity-only para queries factuais, argument-aware para queries de debate
- `apps/api/tests/test_kg_builder.py` ‚Äî +29 testes:
  - `TestFindPathsSeparation` (6 testes): entity-only exclui argument edges/targets, argument-aware inclui tudo, m√©todo aceita par√¢metro
  - `TestClaimEvidenceSecurityTrimming` (4 testes): tenant_id, case_id, entity-only sem claim security, chunk security preservado
  - `TestDebateIntentDetection` (19 testes): 9 debate cues (argumentos, tese, contratese, etc.), 5 factual queries (Art. 5¬∫, Lei 8.666, S√∫mula 331, etc.), empty query, phrase matching, pipeline integration
- `apps/api/tests/test_neo4j_mvp.py` ‚Äî Atualizado: testes de FIND_PATHS agora verificam `FIND_PATHS_WITH_ARGUMENTS` para argument relationships

### Testes
- `pytest tests/test_kg_builder.py -v` ‚Äî 72/72 passed
- `pytest tests/test_neo4j_mvp.py tests/test_kg_builder.py -v` ‚Äî 122 passed, 1 skipped

### Decis√µes
- Entity-only como default (n√£o contamina) ‚Äî argument-aware s√≥ quando explicitamente habilitado OU auto-detectado via intent
- Intent detection usa regex simples (zero-cost, determin√≠stico) ‚Äî n√£o precisa de LLM
- Security trimming para Claim/Evidence permite `case_id IS NULL` no node (global claims) quando caller n√£o filtra por case
- `detect_debate_intent()` reconhece 15+ cues de debate em portugu√™s jur√≠dico

---

## 2026-01-28 ‚Äî GraphRAG Phase 3: ArgumentRAG com LLM (Gemini Flash)

### Objetivo
Adicionar extra√ß√£o de argumentos via LLM (Gemini Flash structured output), scoring de evid√™ncias por autoridade de tribunal, e endpoints de visualiza√ß√£o de grafo argumentativo.

### Arquivos Criados
- `apps/api/app/services/rag/core/kg_builder/argument_llm_extractor.py` ‚Äî **ArgumentLLMExtractor**: extra√ß√£o de claims/evidence/actors/issues via Gemini Flash com `response_json_schema`. Schema JSON completo para structured output. M√©todo `extract_and_ingest()` para extra√ß√£o + escrita no Neo4j.
- `apps/api/app/services/rag/core/kg_builder/evidence_scorer.py` ‚Äî **EvidenceScorer**: scoring multi-dimensional por autoridade de tribunal (STF=1.0, STJ=0.95, TRF=0.75, TJ=0.6), tipo de evid√™ncia (jurisprudencia=0.9, legislacao=0.85, pericia=0.8), e stance bonus (pro/contra +0.05).

### Arquivos Modificados
- `apps/api/app/services/rag/core/kg_builder/pipeline.py` ‚Äî `_run_argument_extraction()` agora usa `ArgumentLLMExtractor` com fallback para heur√≠stica (`ArgumentNeo4jService`) se LLM indispon√≠vel
- `apps/api/app/api/endpoints/graph.py` ‚Äî Novos endpoints:
  - `GET /argument-graph/{case_id}` ‚Äî Retorna grafo argumentativo completo (Claims, Evidence, Actors, Issues + edges)
  - `GET /argument-stats` ‚Äî Estat√≠sticas de Claims/Evidence/Actors/Issues por tenant
  - Novos schemas: `ArgumentGraphNode`, `ArgumentGraphEdge`, `ArgumentGraphData`
- `apps/api/tests/test_kg_builder.py` ‚Äî +22 testes Phase 3:
  - `TestEvidenceScorer` (10 testes): scoring STF, doutrina, fato, tribunal_authority, capping
  - `TestArgumentLLMExtractor` (7 testes): schema structure, prompt, empty text, default model
  - `TestPipelineLLMIntegration` (5 testes): pipeline imports, fallback, endpoints

### Testes
- `pytest tests/test_kg_builder.py -v` ‚Äî 43/43 passed
- `pytest tests/test_neo4j_mvp.py tests/test_kg_builder.py -v` ‚Äî 92 passed, 1 skipped

### Decis√µes
- Evidence scoring usa 3 dimens√µes: base (tipo), authority bonus (tribunal * 0.15), stance bonus (0.05)
- LLM extraction usa Gemini Flash com `response_json_schema` para JSON garantido (~$0.01/doc)
- Pipeline faz fallback autom√°tico para heur√≠stica se google-genai n√£o instalado
- Endpoint `/argument-graph/{case_id}` retorna nodes tipados + edges com stance/weight para visualiza√ß√£o

---

## 2026-01-28 ‚Äî GraphRAG Phase 2: KG Builder (neo4j-graphrag-python)

### Objetivo
Adotar `neo4j-graphrag-python` oficial para KG construction, com Components customizados para dom√≠nio jur√≠dico brasileiro: extra√ß√£o regex (LegalRegexExtractor), schema jur√≠dico (legal_schema), entity resolution (LegalFuzzyResolver com rapidfuzz), e pipeline composto.

### Arquivos Criados
- `apps/api/app/services/rag/core/kg_builder/` ‚Äî Novo diret√≥rio com 5 arquivos:
  - `__init__.py` ‚Äî Exports do m√≥dulo
  - `legal_schema.py` ‚Äî Schema jur√≠dico completo: 11 node types (Lei, Artigo, Sumula, Tribunal, Processo, Tema, Claim, Evidence, Actor, Issue, SemanticEntity), 15 relationship types, 23 patterns (triplets v√°lidos)
  - `legal_extractor.py` ‚Äî `LegalRegexExtractor` Component wrapping `LegalEntityExtractor` existente. Converte output regex para format Neo4jGraph (nodes + relationships). Cria MENTIONS e RELATED_TO por co-ocorr√™ncia.
  - `fuzzy_resolver.py` ‚Äî `LegalFuzzyResolver` Component para entity resolution via rapidfuzz. Normaliza√ß√£o espec√≠fica para cita√ß√µes jur√≠dicas brasileiras (Lei n¬∫ 8.666/93 == Lei 8666/1993). Merge via APOC com fallback.
  - `pipeline.py` ‚Äî `run_kg_builder()`: pipeline composto com dois modos:
    - **Simple mode** (default): LegalRegexExtractor + ArgumentNeo4jService + FuzzyResolver
    - **neo4j-graphrag mode** (`KG_BUILDER_USE_GRAPHRAG=true`): SimpleKGPipeline oficial
- `apps/api/tests/test_kg_builder.py` ‚Äî 21 testes (schema, extractor, resolver, pipeline)

### Arquivos Modificados
- `apps/api/requirements.txt` ‚Äî +`neo4j-graphrag>=1.0.0`, +`rapidfuzz>=3.6.0`
- `apps/api/app/api/endpoints/rag.py` ‚Äî Integra√ß√£o fire-and-forget do KG Builder ap√≥s ingest via `KG_BUILDER_ENABLED=true`

### Configura√ß√£o (ENV vars)
- `KG_BUILDER_ENABLED=true`: Ativa KG Builder ap√≥s ingest de documentos
- `KG_BUILDER_USE_LLM=true`: Ativa extra√ß√£o de argumentos via ArgumentNeo4jService
- `KG_BUILDER_USE_GRAPHRAG=true`: Usa SimpleKGPipeline oficial em vez de simple mode
- `KG_BUILDER_RESOLVE_ENTITIES=true` (default): Entity resolution com rapidfuzz

### Testes
- `pytest tests/test_kg_builder.py -v` ‚Äî 21/21 passed
- `pytest tests/test_neo4j_mvp.py tests/test_kg_builder.py -v` ‚Äî 70 passed, 1 skipped

### Decis√µes
- Components t√™m fallback stubs para import sem `neo4j-graphrag` instalado (graceful degradation)
- Entity resolution usa rapidfuzz (C++, Python 3.14 compatible) em vez de spaCy
- Pipeline roda async (fire-and-forget) para n√£o bloquear response do usu√°rio
- Schema seguiu formato oficial neo4j-graphrag: `node_types` com `properties`, `relationship_types`, `patterns`

---

## 2026-01-27 ‚Äî GraphRAG Phase 1: ArgumentRAG Unificado no Neo4j

### Objetivo
Migrar ArgumentRAG (Claims, Evidence, Actors, Issues) do backend legacy NetworkX para Neo4j, com schema unificado, multi-tenant isolation e integra√ß√£o no pipeline RAG via flag `RAG_ARGUMENT_BACKEND`.

### Arquivos Criados
- `apps/api/app/services/rag/core/argument_neo4j.py` ‚Äî **ArgumentNeo4jService** (~900 linhas): Cypher schema (constraints + indexes), MERGE operations para Claims/Evidence/Actor/Issue, `get_debate_context()` para pro/contra, `get_argument_graph()` para visualiza√ß√£o, heur√≠stica de extra√ß√£o de claims, infer√™ncia de stance
- `apps/api/scripts/migrate_arguments_to_neo4j.py` ‚Äî Script de migra√ß√£o NetworkX‚ÜíNeo4j (idempotente, `--dry-run`)

### Arquivos Modificados
- `apps/api/app/services/rag/core/neo4j_mvp.py`:
  - Schema `CREATE_CONSTRAINTS`: +4 constraints (Claim, Evidence, Actor, Issue)
  - Schema `CREATE_INDEXES`: +7 indexes (tenant, case, type)
  - `FIND_PATHS`: expandido com `SUPPORTS|OPPOSES|EVIDENCES|ARGUES|RAISES|CITES|CONTAINS_CLAIM`
  - `FIND_PATHS` target: agora inclui `target:Claim OR target:Evidence`
  - Docstring atualizado com schema completo
- `apps/api/app/services/rag/core/graph_hybrid.py` ‚Äî Labels: `claim‚ÜíClaim`, `evidence‚ÜíEvidence`, `actor‚ÜíActor`, `issue‚ÜíIssue`
- `apps/api/app/services/rag/pipeline/rag_pipeline.py` ‚Äî Stage Graph Enrich:
  - `RAG_ARGUMENT_BACKEND=neo4j` (default): usa `ArgumentNeo4jService.get_debate_context()`
  - `RAG_ARGUMENT_BACKEND=networkx`: usa legacy `ARGUMENT_PACK`
  - `RAG_ARGUMENT_BACKEND=both`: tenta Neo4j primeiro, fallback para legacy
- `apps/api/tests/test_neo4j_mvp.py` ‚Äî +13 testes em `TestPhase1ArgumentRAG`

### Testes
- `pytest tests/test_neo4j_mvp.py -v` ‚Äî 49/49 passed, 1 skipped (Neo4j connection)
- Phase 1 testes cobrem: schema, constraints, indexes, FIND_PATHS, hybrid labels, whitelist, claim extraction, stance inference, debate context, pipeline integration

### Configura√ß√£o
- `RAG_ARGUMENT_BACKEND`: `neo4j` (default) | `networkx` | `both`
- Backward compatible: setar `RAG_ARGUMENT_BACKEND=networkx` para manter comportamento anterior

---

## 2026-01-27 ‚Äî GraphRAG Phase 0: Fix Bugs Criticos

### Objetivo
Corrigir bugs criticos no GraphRAG identificados durante analise comparativa com documentacao oficial Neo4j. Parte do plano de maturacao do GraphRAG (5 phases).

### Bugs Corrigidos
1. **link_entities inexistente** ‚Äî `neo4j_mvp.py:1399` chamava `self.link_entities()` (nao existe), corrigido para `self.link_related_entities()`. Relacoes RELATED_TO nunca eram criadas durante ingest semantico.
2. **Mismatch SEMANTICALLY_RELATED vs RELATED_TO** ‚Äî `semantic_extractor.py` criava relacoes `SEMANTICALLY_RELATED` mas `FIND_PATHS` so percorria `RELATED_TO|MENTIONS`. Paths semanticos nunca eram encontrados. Corrigido para usar `RELATED_TO` com `relation_subtype='semantic'`.
3. **Label SEMANTIC_ENTITY incompativel** ‚Äî Alterado para dual label `:Entity:SemanticEntity` (PascalCase), compativel com `FIND_PATHS` que matcha `:Entity`.
4. **FIND_PATHS incompleto** ‚Äî Expandido para `[:RELATED_TO|MENTIONS|ASSERTS|REFERS_TO*1..N]`, habilitando caminhos via Fact nodes.
5. **Cypher injection** ‚Äî Adicionada whitelist `ALLOWED_RELATIONSHIP_TYPES` em `Neo4jAdapter.add_relationship()` no `graph_factory.py`.
6. **requirements.txt** ‚Äî Adicionado `neo4j>=5.20.0`, comentado `spacy==3.8.2` (incompativel com Python 3.14).

### Arquivos Modificados
- `apps/api/app/services/rag/core/neo4j_mvp.py` ‚Äî Fix link_entities, expandir FIND_PATHS
- `apps/api/app/services/rag/core/semantic_extractor.py` ‚Äî RELATED_TO, dual label Entity:SemanticEntity
- `apps/api/app/services/rag/core/graph_factory.py` ‚Äî Whitelist de relationship types
- `apps/api/app/services/rag/core/graph_hybrid.py` ‚Äî Adicionar SemanticEntity label
- `apps/api/requirements.txt` ‚Äî neo4j, spacy comentado

### Arquivos Criados
- `apps/api/scripts/fix_semantic_relationships.py` ‚Äî Migration script (idempotente) para renomear SEMANTICALLY_RELATED->RELATED_TO e SEMANTIC_ENTITY->SemanticEntity no banco
- `apps/api/tests/test_neo4j_mvp.py` ‚Äî 8 testes novos em TestPhase0BugFixes

### Testes
- `pytest tests/test_neo4j_mvp.py::TestPhase0BugFixes -v` ‚Äî 8/8 passed

### Plano Completo
- Phase 0: Fix bugs criticos (CONCLUIDO)
- Phase 1: Schema unificado ‚Äî ArgumentRAG no Neo4j
- Phase 2: Adotar neo4j-graphrag-python (KG Builder)
- Phase 3: ArgumentRAG com LLM (Gemini Flash)
- Phase 4: Production hardening
- Plano detalhado em: `.claude/plans/cuddly-herding-crystal.md`

### Decisoes Tomadas
- ArgumentRAG e feature core: migrar para Neo4j (Phase 1)
- Adotar neo4j-graphrag-python para KG Builder (sem retrievers)
- Extracao de argumentos via LLM (Gemini Flash) com structured output
- Retrieval nao muda (OpenSearch + Qdrant)
- spaCy inviavel em Python 3.14: usar FuzzyMatchResolver (rapidfuzz)

---

## 2026-01-27 ‚Äî Deep Research Hard Mode (Agentic Multi-Provider)

### Objetivo
Criar modo "Deep Research Hard" com loop agentico Claude orquestrando pesquisa paralela em Gemini, ChatGPT, Perplexity + RAG global/local, gerando estudo profissional com citacoes ABNT.

### Arquivos Criados
- `apps/api/app/services/ai/deep_research_hard_service.py` ‚Äî Servico agentico (1091 linhas, 9 tools, 15 iteracoes max)
- `apps/api/app/services/ai/templates/study_template.py` ‚Äî Prompts para estudo ABNT profissional
- `apps/api/app/services/ai/citations/abnt_classifier.py` ‚Äî Classificador e formatador ABNT (web, juris, legislacao, doutrina, artigo)
- `apps/web/src/components/chat/hard-research-viewer.tsx` ‚Äî Viewer multi-provider + eventos agenticos
- `apps/api/tests/test_deep_research_hard.py` ‚Äî 22 testes
- `apps/api/tests/test_abnt_citations.py` ‚Äî 27 testes

### Arquivos Modificados
- `apps/api/app/schemas/chat.py` ‚Äî Campos `deep_research_mode`, `hard_research_providers`
- `apps/api/app/api/endpoints/chats.py` ‚Äî Branch hard mode no SSE + forward de eventos agenticos
- `apps/api/app/services/ai/citations/base.py` ‚Äî Integracao com abnt_classifier
- `apps/api/app/services/ai/deep_research_service.py` ‚Äî Fix temperature para reasoning models OpenAI (o1/o3/o4)
- `apps/web/src/stores/chat-store.ts` ‚Äî Estado hard mode + SSE handler para 18 event types
- `apps/web/src/components/chat/chat-input.tsx` ‚Äî Toggle Standard/Hard + seletor de fontes (5 providers)
- `apps/web/src/components/chat/chat-interface.tsx` ‚Äî Render condicional HardResearchViewer

### Teste de Integracao Real
- Claude agentico: 15 iteracoes, 19 tool calls, 693 eventos SSE, 59.733 chars de estudo
- Gemini: quota esgotada (429) - ambiente
- OpenAI: conta nao verificada para reasoning - ambiente
- RAG: dependencia faltando no venv - ambiente
- Fix: temperature e effort para modelos reasoning OpenAI

### Decisoes
- Reescreveu de fluxo linear para loop agentico completo (usuario pediu interacao mid-research)
- 9 tools: search_gemini, search_perplexity, search_openai, search_rag_global, search_rag_local, analyze_results, ask_user, generate_study_section, verify_citations
- Tools filtradas pela selecao do usuario na UI (checkboxes)

---

## 2026-01-27 ‚Äî Fechamento de 7 Gaps do PLANO_CLAUDE_AGENT_SDK.md

### Contexto
- An√°lise Codex identificou 7 gaps impedindo plano de estar "cumprido na √≠ntegra"
- Implementa√ß√£o em 6 fases paralelas para fechar todos os gaps

### Gaps Fechados

| # | Gap | Status |
|---|-----|--------|
| 1 | jobs.py ignora OrchestrationRouter | ‚úÖ Branch if/else adicionado |
| 2 | Agent IDs n√£o est√£o no model_registry.py | ‚úÖ 3 entries + helper |
| 3 | workflow.py √© placeholder | ‚úÖ Implementa√ß√£o real com astream() |
| 4 | checkpoint_manager.py e parallel_nodes.py ausentes | ‚úÖ Criados |
| 5 | Componentes frontend n√£o plugados | ‚úÖ Plugados no chat-interface |
| 6 | Endpoints /tool-approval e /restore-checkpoint ausentes | ‚úÖ Adicionados |
| 7 | Nenhum teste unit√°rio | ‚úÖ 5 arquivos criados |

### Arquivos Criados

- `app/services/ai/langgraph/improvements/checkpoint_manager.py` ‚Äî CheckpointManager (create/restore/list/delete)
- `app/services/ai/langgraph/improvements/parallel_nodes.py` ‚Äî run_nodes_parallel, fan_out, fan_in
- `app/services/agent_session_registry.py` ‚Äî Dict global de executors ativos por job_id
- `apps/web/src/components/chat/checkpoint-timeline.tsx` ‚Äî Timeline visual de checkpoints
- `tests/test_orchestration_router.py` ‚Äî 17 testes (routing, execute, context)
- `tests/test_claude_agent_executor.py` ‚Äî 17 testes (init, run, tools, iterations, errors)
- `tests/test_context_manager.py` ‚Äî 29 testes (tokens, window, compact, limits)
- `tests/test_permission_manager.py` ‚Äî 25 testes (policy, overrides, rate limit, audit)
- `tests/test_parallel_executor.py` ‚Äî 28 testes (similarity, merge, execution, timeout, cancel)

### Arquivos Modificados

- `app/services/ai/model_registry.py` ‚Äî 3 agent entries (claude-agent, openai-agent, google-agent) + `is_agent_model()` + `AGENT_MODEL_IDS`
- `app/api/endpoints/jobs.py` ‚Äî `_detect_agent_models()` + branch condicional (agent ‚Üí router, normal ‚Üí LangGraph intacto)
- `app/services/ai/langgraph/workflow.py` ‚Äî Implementa√ß√£o real com astream(), SSEEvents, context compaction, checkpoints
- `app/api/endpoints/chats.py` ‚Äî Endpoints POST `/{chat_id}/tool-approval` e `/{chat_id}/restore-checkpoint`
- `app/services/ai/langgraph/improvements/__init__.py` ‚Äî Exports de CheckpointManager e run_nodes_parallel
- `apps/web/src/components/chat/chat-interface.tsx` ‚Äî ToolApprovalModal, ContextIndicatorCompact, CheckpointTimeline plugados

### Decis√µes T√©cnicas

- **jobs.py**: Branch agent termina com `return`, LangGraph permanece 100% intacto (zero regress√£o)
- **workflow.py**: Lazy import do `legal_workflow_app`, streaming SSE completo (NODE_START, TOKEN, OUTLINE, HIL_REQUIRED, AUDIT_DONE, NODE_COMPLETE, DONE)
- **Endpoints**: Imports lazy dentro das fun√ß√µes para evitar depend√™ncias circulares
- **Frontend**: `ContextIndicatorCompact` substitui indicador b√°sico de token percent

### Verifica√ß√µes
- `python3 -c "import ast; ..."` ‚Äî Syntax OK para todos os arquivos Python
- `tsc --noEmit` ‚Äî Frontend sem erros de tipo
- `eslint` ‚Äî Frontend sem erros de lint

---

## 2026-01-27 ‚Äî MCP Tool Gateway Implementation (Unifica√ß√£o de Tools)

### Contexto
- Implementa√ß√£o de arquitetura de Tool Gateway usando MCP (Model Context Protocol)
- Unifica todas as tools jur√≠dicas em um √∫nico hub consum√≠vel por Claude, OpenAI e Gemini
- Cada provider tem seu adapter: Claude usa MCP nativo, OpenAI via function adapter, Gemini via ADK

### Arquitetura

```
Tool Gateway (MCP Server)
‚îú‚îÄ‚îÄ Tool Registry      ‚Üí Registro unificado de todas as tools
‚îú‚îÄ‚îÄ Policy Engine      ‚Üí allow/ask/deny + rate limit + audit
‚îú‚îÄ‚îÄ MCP Server         ‚Üí JSON-RPC 2.0 sobre HTTP/SSE
‚îî‚îÄ‚îÄ Adapters/
    ‚îú‚îÄ‚îÄ ClaudeMCPAdapter   ‚Üí MCP nativo
    ‚îú‚îÄ‚îÄ OpenAIMCPAdapter   ‚Üí Converte MCP ‚Üí function_calling
    ‚îî‚îÄ‚îÄ GeminiMCPAdapter   ‚Üí Converte MCP ‚Üí FunctionDeclaration + ADK
```

### Arquivos Criados

**app/services/ai/tool_gateway/**
- `__init__.py` ‚Äî Exports do m√≥dulo
- `tool_registry.py` ‚Äî Registro singleton de tools com metadata (policy, category)
- `policy_engine.py` ‚Äî Enforces policies (ALLOW/ASK/DENY), rate limits, audit log
- `mcp_server.py` ‚Äî Servidor MCP JSON-RPC com tools/list e tools/call
- `adapters/__init__.py` ‚Äî Exports dos adapters
- `adapters/base_adapter.py` ‚Äî Interface abstrata
- `adapters/claude_adapter.py` ‚Äî Thin wrapper (Claude √© MCP-native)
- `adapters/openai_adapter.py` ‚Äî Converte MCP ‚Üí OpenAI functions
- `adapters/gemini_adapter.py` ‚Äî Converte MCP ‚Üí Gemini + ADK MCPToolset

### Tools Registradas

| Categoria | Tools | Policy |
|-----------|-------|--------|
| **RAG** | search_rag, search_templates, search_jurisprudencia, search_legislacao | ALLOW |
| **DataJud** | consultar_processo_datajud, buscar_publicacoes_djen | ALLOW |
| **Tribunais** | consultar_processo_pje, consultar_processo_eproc | ALLOW |
| **Document** | read_document, edit_document, create_section | ALLOW/ASK |
| **Sensitive** | protocolar_documento | DENY (requer override) |

### Endpoints FastAPI

```
POST /api/mcp/gateway/rpc          ‚Üí JSON-RPC para tools/list e tools/call
GET  /api/mcp/gateway/sse          ‚Üí SSE para eventos (approval requests)
GET  /api/mcp/gateway/tools        ‚Üí Lista tools com filtro por categoria
POST /api/mcp/gateway/approve/{id} ‚Üí Aprova/rejeita execu√ß√£o pendente
GET  /api/mcp/gateway/audit        ‚Üí Log de auditoria por tenant
```

### Uso nos Executors

```python
# Claude Agent
adapter = ClaudeMCPAdapter(context={"user_id": user_id, "tenant_id": tenant_id})
tools = await adapter.get_tools()
result = await adapter.handle_tool_use(tool_use_block)

# OpenAI Agent
adapter = OpenAIMCPAdapter(context={...})
tools = await adapter.get_tools()  # Formato function calling
results = await adapter.handle_tool_calls(tool_calls)

# Google Agent
adapter = GeminiMCPAdapter(context={...})
genai_tools = adapter.get_genai_tools()  # google.genai.types.Tool
results = await adapter.handle_function_calls(function_calls)
```

### Benef√≠cios
1. **Single Source of Truth**: Uma defini√ß√£o de tool para todos os providers
2. **Policies Centralizadas**: allow/ask/deny aplicadas uniformemente
3. **Audit Trail**: Log de todas as execu√ß√µes por tenant
4. **Rate Limiting**: Controle de uso por tool/tenant
5. **Extensibilidade**: Adicionar nova tool = registrar no registry

---

## 2026-01-27 ‚Äî Integra√ß√£o Tool Gateway nos Executors

### Contexto
- Atualiza√ß√£o dos 3 executores de agentes para usar o Tool Gateway
- Centraliza√ß√£o do carregamento e execu√ß√£o de tools via MCP adapters
- Mant√©m compatibilidade com m√©todos anteriores de carregamento de tools

### Arquivos Modificados

**app/services/ai/claude_agent/executor.py**:
- Import de `ClaudeMCPAdapter` do Tool Gateway
- Novos atributos: `_mcp_adapter`, `_execution_context`
- Novos m√©todos:
  - `_get_context()` ‚Äî Retorna contexto atual para Tool Gateway
  - `_init_mcp_adapter()` ‚Äî Inicializa adapter com contexto
  - `load_tools_from_gateway()` ‚Äî Carrega tools via MCP adapter (recomendado)
  - `execute_tool_via_gateway()` ‚Äî Executa tool_use block via Gateway

**app/services/ai/executors/openai_agent.py**:
- Import de `OpenAIMCPAdapter` do Tool Gateway
- Novos atributos: `_mcp_adapter`, `_execution_context`
- Novos m√©todos:
  - `_get_context()` ‚Äî Retorna contexto atual
  - `_init_mcp_adapter()` ‚Äî Inicializa adapter
  - `load_tools_from_gateway()` ‚Äî Carrega tools no formato OpenAI via Gateway
  - `execute_tool_calls_via_gateway()` ‚Äî Executa tool_calls via Gateway

**app/services/ai/executors/google_agent.py**:
- Import de `GeminiMCPAdapter` do Tool Gateway
- Novos atributos: `_mcp_adapter`, `_execution_context`
- Novos m√©todos:
  - `_get_context()` ‚Äî Retorna contexto atual
  - `_init_mcp_adapter()` ‚Äî Inicializa adapter
  - `load_tools_from_gateway()` ‚Äî Carrega tools no formato Gemini via Gateway
  - `get_genai_tools_from_gateway()` ‚Äî Retorna google.genai.types.Tool via Gateway
  - `execute_function_calls_via_gateway()` ‚Äî Executa function_calls via Gateway

### Padr√£o de Uso

```python
# Claude
executor = ClaudeAgentExecutor(config=config)
await executor.load_tools_from_gateway(context={
    "user_id": user_id,
    "tenant_id": tenant_id,
    "case_id": case_id,
})
# Durante execu√ß√£o, tools s√£o roteadas pelo MCP server automaticamente

# OpenAI
executor = OpenAIAgentExecutor(config=config)
await executor.load_tools_from_gateway(context={...})
# Tool calls podem ser executados via: execute_tool_calls_via_gateway()

# Google
executor = GoogleAgentExecutor(config=config)
await executor.load_tools_from_gateway(context={...})
# ou: executor.get_genai_tools_from_gateway() para uso direto
```

### Decis√µes Tomadas
- Manter compatibilidade: m√©todos antigos (`load_unified_tools`, `register_tool`) continuam funcionando
- Novos m√©todos `*_from_gateway` s√£o recomendados pois passam pelo Tool Gateway com policy enforcement
- Context √© propagado para o MCP server em cada chamada de tool

---

## 2026-01-27 ‚Äî Verifica√ß√£o de Estado vs Arquitetura Recomendada

### Contexto
- Verifica√ß√£o completa do estado atual do Iudex contra arquitetura recomendada
- An√°lise de 5 trilhas: Sources, RAG, Generation, Automation, Governance
- Verifica√ß√£o de templates e MCP tribunais

### Resultados da An√°lise

| Trilha | Status | Detalhes |
|--------|--------|----------|
| **RAG Global + Local** | ‚úÖ 100% | 6 √≠ndices, hybrid search, CRAG gate |
| **DataJud/DJEN** | ‚úÖ 100% | Sync autom√°tico, auto-discovery |
| **Pipeline Gera√ß√£o** | ‚úÖ 100% | 7 fases, 30+ templates, debate multi-agente |
| **Tools/Permiss√µes** | ‚úÖ 100% | 14 tools jur√≠dicas, hierarquia de permiss√µes |
| **Governance** | ‚úÖ 100% | JSONL audit, multi-tenant, billing |

### Templates Jur√≠dicos
- 30+ templates com checklists, vari√°veis, estilos
- Tipos: peti√ß√µes, contratos, recursos, pareceres
- Sistema de vers√µes e customiza√ß√£o por cliente

### Tribunais Service
- **Tipo**: REST API (n√£o MCP protocol)
- **Integrados**: PJe, e-Proc
- **TODO**: e-SAJ

### MCP no Frontend
- `chat-store.ts`: estados `mcpToolCalling`, `mcpUseAllServers`, `mcpServerLabels`
- `chat-input.tsx`: toggle para habilitar MCP + seletor de servidores
- `IUDEX_MCP_SERVERS`: vari√°vel de ambiente para configura√ß√£o

### Pend√™ncias
- [ ] Implementar integra√ß√£o e-SAJ

---

## 2026-01-27 ‚Äî Multi-Provider Agent Executors (OpenAI + Google)

### Contexto
- Continua√ß√£o da sess√£o anterior (ap√≥s compacta√ß√£o)
- Implementa√ß√£o de executores para OpenAI Agents SDK e Google ADK
- Todos os executores compartilham: tools unificadas, permiss√µes, checkpoints, SSE

### Arquivos Criados/Modificados

**executors/base.py** ‚Äî Interface base:
- `AgentProvider` enum (ANTHROPIC, OPENAI, GOOGLE)
- `ExecutorStatus` enum (IDLE, RUNNING, WAITING_APPROVAL, etc.)
- `ExecutorConfig` dataclass (model, max_tokens, permissions, etc.)
- `ExecutorState` dataclass (job_id, tokens, tools, checkpoints)
- `BaseAgentExecutor` ABC (run, resume, register_tool, load_unified_tools)

**executors/openai_agent.py** ‚Äî OpenAI Agents SDK:
- `OpenAIAgentConfig` ‚Äî Config espec√≠fica (model, assistants_api, etc.)
- `OpenAIAgentExecutor` ‚Äî Implementa√ß√£o completa:
  - `run()` ‚Äî Execu√ß√£o com agentic loop
  - `_run_with_chat_completions()` ‚Äî Loop com tool calling
  - `_convert_tool_for_openai()` ‚Äî Converte tools para formato OpenAI
  - Suporte a permiss√µes, checkpoints, streaming SSE

**executors/google_agent.py** ‚Äî Google ADK/Gemini:
- `GoogleAgentConfig` ‚Äî Config espec√≠fica (use_vertex, use_adk)
- `GoogleAgentExecutor` ‚Äî Implementa√ß√£o completa:
  - `_run_with_adk()` ‚Äî Execu√ß√£o via ADK (AdkApp)
  - `_run_agent_loop()` ‚Äî Loop manual para Gemini direto
  - `_create_adk_tools()` ‚Äî Converte tools para formato ADK
  - Suporte a Vertex AI, checkpoints, streaming

**executors/__init__.py** ‚Äî Factory e exports:
- `get_executor_for_provider()` ‚Äî Factory por nome
- `get_available_providers()` ‚Äî Lista providers dispon√≠veis
- Exports de todas as classes e configs

**orchestration/router.py** ‚Äî Atualizado:
- `ExecutorType` enum com OPENAI_AGENT, GOOGLE_AGENT
- `AGENT_MODELS` set com todos agentes
- `AGENT_TO_EXECUTOR` mapping
- `_is_agent_enabled()` helper
- `determine_executor()` atualizado para todos providers
- `execute()` com routing para todos executors
- `_execute_openai_agent()` ‚Äî Execu√ß√£o OpenAI
- `_execute_openai_fallback()` ‚Äî Fallback sem SDK
- `_execute_google_agent()` ‚Äî Execu√ß√£o Google
- `_execute_google_fallback()` ‚Äî Fallback sem ADK

**apps/web/src/config/models.ts** ‚Äî Frontend:
- `AgentId` type expandido: "claude-agent" | "openai-agent" | "google-agent"
- `AGENT_REGISTRY` com configs dos 3 agentes:
  - claude-agent: Claude Agent SDK, tools juridicas
  - openai-agent: OpenAI Agents SDK, checkpoints
  - google-agent: Google ADK, Vertex AI

### Arquitetura Final

```
OrchestrationRouter
‚îú‚îÄ‚îÄ ExecutorType.CLAUDE_AGENT ‚Üí ClaudeAgentExecutor
‚îú‚îÄ‚îÄ ExecutorType.OPENAI_AGENT ‚Üí OpenAIAgentExecutor
‚îú‚îÄ‚îÄ ExecutorType.GOOGLE_AGENT ‚Üí GoogleAgentExecutor
‚îú‚îÄ‚îÄ ExecutorType.PARALLEL ‚Üí ParallelExecutor (agent + debate)
‚îî‚îÄ‚îÄ ExecutorType.LANGGRAPH ‚Üí LangGraph workflow
```

Todos os executores:
- Usam `load_unified_tools()` para carregar as 15 tools
- Compartilham `ToolExecutionContext` (user_id, case_id, etc.)
- Emitem eventos SSE padronizados
- Suportam checkpoints/rewind
- Respeitam hierarquia de permiss√µes

### Vari√°veis de Ambiente
```env
CLAUDE_AGENT_ENABLED=true
OPENAI_AGENT_ENABLED=true
GOOGLE_AGENT_ENABLED=true
PARALLEL_EXECUTION_ENABLED=true
PARALLEL_EXECUTION_TIMEOUT=300
```

### Pr√≥ximos Passos
- [ ] Testar integra√ß√£o completa com todos os providers
- [ ] Rodar Alembic migration para as 3 novas tabelas
- [ ] Verificar lint/type-check no frontend e backend

---

## 2026-01-27 ‚Äî Integra√ß√£o Unificada de Tools (SDK + Legal + MCP)

### Contexto
- Unifica√ß√£o de todas as tools para uso por Claude Agent E LangGraph
- Adapta√ß√£o das tools do Claude SDK para contexto jur√≠dico
- Integra√ß√£o com MCP tools existentes

### Arquivos Criados

**shared/unified_tools.py** (15 tools):
| Tool | Categoria | Risco | Descri√ß√£o |
|------|-----------|-------|-----------|
| `read_document` | document | low | L√™ documentos do caso |
| `write_document` | document | medium | Cria/sobrescreve documentos |
| `edit_document` | document | medium | Edita se√ß√µes espec√≠ficas |
| `find_documents` | search | low | Busca por padr√£o (glob) |
| `search_in_documents` | search | low | Busca texto (grep) |
| `web_search` | search | low | Pesquisa web |
| `web_fetch` | search | low | Busca URL espec√≠fica |
| `delegate_research` | analysis | medium | Subagentes paralelos |
| `search_jurisprudencia` | search | low | Busca tribunais |
| `search_legislacao` | search | low | Busca leis |
| `verify_citation` | citation | low | Verifica cita√ß√µes |
| `search_rag` | search | low | Busca RAG |
| `create_section` | document | medium | Cria se√ß√£o em documento |
| `mcp_tool_search` | system | low | Descobre MCP tools |
| `mcp_tool_call` | system | medium | Executa MCP tool |

**shared/tool_handlers.py**:
- `ToolExecutionContext` ‚Äî Contexto para execu√ß√£o (user_id, case_id, etc.)
- `ToolHandlers` ‚Äî Classe com handlers para cada tool
- `execute_tool()` ‚Äî Fun√ß√£o de conveni√™ncia

**shared/langgraph_integration.py**:
- `LangGraphToolBridge` ‚Äî Bridge entre tools e LangGraph
- `create_tool_node()` ‚Äî Cria node para workflow
- `get_tools_for_langgraph_agent()` ‚Äî Tools + executor para create_react_agent

**shared/startup.py**:
- `init_ai_services()` ‚Äî Inicializa no startup
- `shutdown_ai_services()` ‚Äî Cleanup no shutdown

### Arquivos Modificados
- `shared/__init__.py` ‚Äî Exports de tudo
- `claude_agent/executor.py` ‚Äî M√©todo `load_unified_tools()`
- `main.py` ‚Äî Chamadas de init/shutdown no lifespan

### Uso

**No Claude Agent:**
```python
executor = ClaudeAgentExecutor()
executor.load_unified_tools(context=ToolExecutionContext(user_id="..."))
```

**No LangGraph:**
```python
from app.services.ai.shared import create_tool_node, get_tools_for_langgraph_agent

# Op√ß√£o 1: Node para grafo
tool_node = create_tool_node(context)
builder.add_node("tools", tool_node)

# Op√ß√£o 2: Tools + executor para react agent
tools, executor = get_tools_for_langgraph_agent(context)
agent = create_react_agent(model, tools)
```

### Permiss√µes por Risco
- **LOW** ‚Üí ALLOW (leitura, busca)
- **MEDIUM** ‚Üí ASK (cria√ß√£o, edi√ß√£o)
- **HIGH** ‚Üí DENY (delete, bash)

---

## 2026-01-27 ‚Äî Verifica√ß√£o e Conclus√£o: Claude Agent SDK + LangGraph Improvements

### Contexto
- Verifica√ß√£o final da implementa√ß√£o completa do plano Claude Agent SDK
- Todas as 5 fases foram conclu√≠das com sucesso

### Arquivos Verificados (Backend)

**Estrutura claude_agent/**
- `__init__.py` ‚Äî Exports principais
- `executor.py` (39KB) ‚Äî ClaudeAgentExecutor com run(), resume(), SSE streaming
- `permissions.py` (25KB) ‚Äî PermissionManager com hierarquia session > project > global
- `tools/legal_research.py` (21KB) ‚Äî Tool de pesquisa jur√≠dica
- `tools/document_editor.py` (24KB) ‚Äî Tool de edi√ß√£o de documentos
- `tools/citation_verifier.py` (26KB) ‚Äî Tool de verifica√ß√£o de cita√ß√µes
- `tools/rag_search.py` (21KB) ‚Äî Tool de busca RAG

**Estrutura orchestration/**
- `router.py` (34KB) ‚Äî OrchestrationRouter com determine_executor()
- `parallel_executor.py` (33KB) ‚Äî ParallelExecutor com merge via LLM
- `event_merger.py` (5KB) ‚Äî Merge de eventos SSE

**Estrutura langgraph/**
- `workflow.py` (3.5KB) ‚Äî Workflow base
- `improvements/context_manager.py` (25KB) ‚Äî Compacta√ß√£o com tiktoken
- `subgraphs/parallel_research.py` (28KB) ‚Äî Fan-out/fan-in research

**Estrutura shared/**
- `sse_protocol.py` (11KB) ‚Äî SSEEvent com 24+ tipos de eventos
- `context_protocol.py` (10KB) ‚Äî Protocolo de contexto
- `tool_registry.py` (6KB) ‚Äî Registry de tools

**Models/**
- `tool_permission.py` ‚Äî ToolPermission, PermissionMode, PermissionScope
- `conversation_summary.py` ‚Äî ConversationSummary para compacta√ß√£o
- `checkpoint.py` ‚Äî Checkpoint, SnapshotType para rewind

**Migration/**
- `f6c7d8e9a0b1_add_claude_agent_tables.py` ‚Äî Cria 3 tabelas com √≠ndices

### Arquivos Verificados (Frontend)

- `components/chat/tool-approval-modal.tsx` ‚Äî Modal de aprova√ß√£o Ask/Allow/Deny
- `components/chat/context-indicator.tsx` ‚Äî Indicador visual de contexto
- `components/chat/model-selector.tsx` ‚Äî Se√ß√£o "Agentes" adicionada
- `config/models.ts` ‚Äî AgentConfig, AGENT_REGISTRY com "claude-agent"
- `stores/chat-store.ts` ‚Äî isAgentMode e estados relacionados

### Testes de Import Realizados
```bash
# Todos OK ‚úÖ
from app.models import ToolPermission, ConversationSummary, Checkpoint
from app.services.ai.shared import SSEEvent, SSEEventType
from app.services.ai.claude_agent import ClaudeAgentExecutor, PermissionManager
from app.services.ai.orchestration import OrchestrationRouter, ParallelExecutor
from app.services.ai.langgraph.improvements import ContextManager
from app.services.ai.langgraph.subgraphs import parallel_research_subgraph
```

### Corre√ß√µes Aplicadas
- Adicionado ConversationSummary e Checkpoint ao models/__init__.py

### Status Final
- **FASE 1**: Estrutura e models ‚úÖ
- **FASE 2**: Claude Agent SDK ‚úÖ
- **FASE 3**: LangGraph Improvements ‚úÖ
- **FASE 4**: Orquestra√ß√£o paralela ‚úÖ
- **FASE 5**: Frontend ‚úÖ

### Pr√≥ximos Passos (Opcional)
1. Rodar migration: `alembic upgrade head`
2. Integrar OrchestrationRouter no job_manager.py
3. Criar checkpoint-timeline.tsx (componente visual de timeline)
4. Testes de integra√ß√£o end-to-end

---

## 2026-01-26 ‚Äî FASE 4: Implementa√ß√£o do OrchestrationRouter (Task 4.1)

### Contexto
- Implementa√ß√£o da Fase 4 (Task 4.1) do plano Claude Agent SDK
- Objetivo: implementar o OrchestrationRouter em `apps/api/app/services/ai/orchestration/router.py`

### Arquivos Alterados
- `apps/api/app/services/ai/orchestration/router.py` ‚Äî Implementa√ß√£o completa do OrchestrationRouter
- `apps/api/app/services/ai/orchestration/__init__.py` ‚Äî Atualiza√ß√£o dos exports

### Classes Implementadas

**ExecutorType (Enum):**
- `LANGGRAPH` ‚Äî Workflow LangGraph existente
- `CLAUDE_AGENT` ‚Äî Claude Agent SDK aut√¥nomo
- `PARALLEL` ‚Äî Execu√ß√£o paralela (Agent + valida√ß√£o)

**RoutingDecision (dataclass):**
- `executor_type`, `primary_models`, `secondary_models`, `reason`

**OrchestrationContext (dataclass):**
- Contexto completo para execu√ß√£o de prompts
- Campos: prompt, job_id, user_id, chat_id, case_bundle, rag_context, template_structure, extra_instructions, conversation_history, chat_personality, reasoning_level, temperature, web_search, max_tokens

**OrchestrationRouter (classe principal):**
- Ponto de entrada para execu√ß√£o de prompts
- Drop-in replacement no job_manager

### M√©todos Implementados

| M√©todo | Descri√ß√£o |
|--------|-----------|
| `determine_executor()` | Decide qual executor usar baseado nos modelos e modo |
| `validate_model_selection()` | Valida sele√ß√£o de modelos |
| `execute()` | M√©todo principal - executa prompt e retorna stream SSE |
| `_execute_claude_agent()` | Executa usando Claude Agent SDK |
| `_execute_claude_fallback()` | Fallback quando SDK n√£o dispon√≠vel |
| `_execute_langgraph()` | Executa usando workflow LangGraph existente |
| `_execute_langgraph_fallback()` | Fallback quando LangGraph n√£o dispon√≠vel |
| `_execute_parallel()` | Executa Agent + modelos de valida√ß√£o |
| `_build_legal_system_prompt()` | Constr√≥i system prompt jur√≠dico |
| `_build_full_prompt()` | Constr√≥i prompt completo com contexto |

### Regras de Decis√£o Implementadas
1. Se mode == "minuta" ‚Üí sempre LANGGRAPH
2. Se s√≥ "claude-agent" selecionado ‚Üí CLAUDE_AGENT
3. Se "claude-agent" + outros modelos ‚Üí PARALLEL
4. Se s√≥ modelos normais ‚Üí LANGGRAPH

### Funcionalidades
- Imports din√¢micos para evitar circular imports
- Fallbacks robustos quando componentes n√£o dispon√≠veis
- Singleton via `get_orchestration_router()`
- Configura√ß√£o via vari√°veis de ambiente:
  - `CLAUDE_AGENT_ENABLED` (default: true)
  - `PARALLEL_EXECUTION_ENABLED` (default: true)
  - `PARALLEL_EXECUTION_TIMEOUT` (default: 300s)

### Comandos Executados
- `python3 -m py_compile router.py` ‚Äî OK (sintaxe v√°lida)
- `python3 -m py_compile __init__.py` ‚Äî OK (sintaxe v√°lida)

### Decis√µes Tomadas
- Usar imports din√¢micos para evitar problemas de circular imports
- Implementar fallbacks completos para cada executor
- Manter compatibilidade com job_manager existente via yield de SSEEvent
- Usar OrchestrationContext como abstra√ß√£o unificada de contexto

---

## 2026-01-26 ‚Äî FASE 3: Parallel Research Subgraph (LangGraph)

### Contexto
- Implementa√ß√£o da Fase 3.2 do plano Claude Agent SDK
- Objetivo: criar subgraph de pesquisa paralela para o workflow LangGraph

### Arquivos Criados
- `apps/api/app/services/ai/langgraph/subgraphs/parallel_research.py` ‚Äî Subgraph completo
- `apps/api/app/services/ai/langgraph/subgraphs/__init__.py` ‚Äî Exports do m√≥dulo
- `apps/api/tests/test_parallel_research_subgraph.py` ‚Äî Testes unit√°rios (22 testes)

### Arquivos Modificados
- `apps/api/app/services/ai/langgraph/__init__.py` ‚Äî Adicionados exports do subgraph

### Funcionalidades Implementadas

**ResearchState (TypedDict):**
- Campos de input: query, section_title, thesis, input_text
- Configura√ß√£o: job_id, tenant_id, processo_id, top_k, max_context_chars
- Queries customiz√°veis por fonte
- Resultados intermedi√°rios por fonte
- Output: merged_context, citations_map, sources_used, metrics

**Nodes do Subgraph:**
- `distribute_query` ‚Äî Distribui query principal em queries espec√≠ficas por fonte
- `search_rag_local` ‚Äî Busca em documentos locais (SEI, caso)
- `search_rag_global` ‚Äî Busca em biblioteca global (lei, juris, templates)
- `search_web` ‚Äî Busca web via Perplexity
- `search_jurisprudencia` ‚Äî Busca em base de jurisprud√™ncia
- `parallel_search_node` ‚Äî Executa todas buscas em paralelo via asyncio.gather
- `merge_research_results` ‚Äî Consolida, deduplica, reranqueia e formata contexto

**Fun√ß√µes Helper:**
- `_get_rag_manager()` ‚Äî Obt√©m RAGManager singleton
- `_get_web_search_service()` ‚Äî Obt√©m WebSearchService
- `_get_jurisprudence_service()` ‚Äî Obt√©m JurisprudenceService
- `_hash_content()` ‚Äî Hash MD5 para deduplica√ß√£o
- `_normalize_text()` ‚Äî Normaliza√ß√£o para compara√ß√£o
- `_is_duplicate()` ‚Äî Detec√ß√£o de duplicados
- `_score_result()` ‚Äî Scoring de relev√¢ncia com boosts

**Fun√ß√£o de Conveni√™ncia:**
- `run_parallel_research()` ‚Äî Executa subgraph com par√¢metros simplificados

### Estrutura do Flow
```
distribute ‚Üí parallel_search ‚Üí merge_results ‚Üí END
                  ‚Ü≥ asyncio.gather(rag_local, rag_global, web, juris)
```

### Decis√µes Tomadas
- Fan-out/fan-in via asyncio.gather dentro de um √∫nico node (compatibilidade LangGraph)
- Resultados organizados por source_type no contexto final
- Deduplica√ß√£o por hash MD5 + normaliza√ß√£o de texto
- Reranking por score base + term matches + source boost + recency
- Limite de 5 resultados por tipo de fonte
- Max chars configur√°vel (default: 12000)

### Comandos Executados
- `python3 -c "import ast; ast.parse(...)"` ‚Äî Syntax check OK
- `python3 -m pytest tests/test_parallel_research_subgraph.py` ‚Äî 22 passed

### Verifica√ß√µes
- Syntax: OK
- Imports: OK
- Testes: 22/22 passed

---

## 2026-01-26 ‚Äî FASE 2: Implementa√ß√£o do ClaudeAgentExecutor (Task 2.1)

### Contexto
- Implementa√ß√£o da Fase 2 (Task 2.1) do plano Claude Agent SDK
- Objetivo: criar o executor principal do agente Claude

### Arquivos Criados

**SSE Protocol (shared/sse_protocol.py):**
- `SSEEventType` - Enum com todos os tipos de eventos SSE
- `SSEEvent` - Dataclass para envelope de eventos
- `ToolApprovalMode` - Enum para modos de permiss√£o
- Factory functions para criar eventos espec√≠ficos:
  - `agent_iteration_event`, `tool_call_event`, `tool_result_event`
  - `tool_approval_required_event`, `context_warning_event`
  - `checkpoint_created_event`, `token_event`, `thinking_event`
  - `done_event`, `error_event`

**Claude Agent Executor (claude_agent/executor.py):**
- `AgentConfig` - Configura√ß√£o do executor com:
  - model, max_iterations, max_tokens, temperature
  - context_window, compaction_threshold
  - tool_permissions, enable_thinking, enable_checkpoints
- `AgentState` - Estado runtime do agente com:
  - messages, tokens, tools_called, pending_approvals
  - checkpoints, final_output, error, timestamps
- `AgentStatus` - Enum de status (idle, running, waiting_approval, etc.)
- `ClaudeAgentExecutor` - Classe principal com:
  - `run()` - Loop principal do agente (AsyncGenerator[SSEEvent])
  - `resume()` - Continua ap√≥s aprova√ß√£o de tool
  - `register_tool()` - Registra tools com permiss√µes
  - `cancel()` - Cancela execu√ß√£o
- `create_claude_agent()` - Factory function

### Arquivos Alterados
- `apps/api/app/services/ai/shared/__init__.py` ‚Äî Exports do sse_protocol
- `apps/api/app/services/ai/claude_agent/__init__.py` ‚Äî Adicionados exports do executor

### Funcionalidades Implementadas

**Agent Loop:**
1. Recebe prompt do usu√°rio e contexto
2. Chama Claude com tools habilitados
3. Processa tool_use blocks da resposta
4. Verifica permiss√µes antes de executar (Allow/Deny/Ask)
5. Pausa para aprova√ß√£o quando permission_mode = "ask"
6. Emite eventos SSE para cada a√ß√£o
7. Cria checkpoints autom√°ticos a cada N itera√ß√µes
8. Monitora uso de contexto e emite warnings

**Permission System:**
- ALLOW: executa automaticamente
- DENY: retorna erro sem executar
- ASK: pausa e aguarda resume()

**Event Flow:**
```
AGENT_START ‚Üí [AGENT_ITERATION ‚Üí TOOL_CALL ‚Üí TOOL_RESULT]* ‚Üí DONE
           ‚Ü≥ TOOL_APPROVAL_REQUIRED ‚Üí (pause) ‚Üí resume() ‚Üí ...
```

### Comandos Executados
- `python3 -m py_compile executor.py` ‚Äî OK
- `python3 -m py_compile sse_protocol.py` ‚Äî OK
- `python3 -m py_compile __init__.py` ‚Äî OK (ambos)

### Decis√µes Tomadas
- Uso de AsyncGenerator para streaming de eventos SSE
- Compatibilidade com formato de eventos do JobManager (v1 envelope)
- Separa√ß√£o clara entre config (AgentConfig) e state (AgentState)
- Tool executors s√£o registrados externamente (dependency injection)
- Checkpoints s√£o IDs (persist√™ncia ser√° implementada depois)

### Pr√≥ximos Passos
- [ ] Task 2.2: Criar tools jur√≠dicos (legal_research.py completo)
- [ ] Task 2.4: Adicionar claude-agent no model_registry.py
- [ ] Task 2.5: Integrar com job_manager.py e jobs.py

---

## 2026-01-26 ‚Äî FASE 2: PermissionManager para Claude Agent SDK

### Contexto
- Implementa√ß√£o da Fase 2.3 do plano Claude Agent SDK
- Objetivo: criar sistema de permiss√µes granular para tools do agente

### Arquivos Criados
- `apps/api/app/models/tool_permission.py` ‚Äî Modelo SQLAlchemy para permiss√µes
- `apps/api/app/services/ai/claude_agent/permissions.py` ‚Äî PermissionManager completo

### Arquivos Modificados
- `apps/api/app/models/__init__.py` ‚Äî Adicionado exports do ToolPermission
- `apps/api/app/core/database.py` ‚Äî Adicionado import para auto-create da tabela
- `apps/api/app/services/ai/claude_agent/__init__.py` ‚Äî Exporta classes do permissions

### Funcionalidades Implementadas

**ToolPermission (model SQLAlchemy):**
- `id`, `user_id`, `tool_name` ‚Äî identificacao
- `pattern` ‚Äî padrao glob para matching de input
- `mode` ‚Äî PermissionMode enum (allow/deny/ask)
- `scope` ‚Äî PermissionScope enum (session/project/global)

**PermissionManager (classe principal):**
- `check(tool_name, tool_input)` ‚Üí PermissionCheckResult
- `add_rule(tool_name, mode, scope, pattern)` ‚Üí PermissionRule
- `allow_once()`, `allow_always()`, `deny_always()` ‚Äî shortcuts

**Fun√ß√µes Utilit√°rias:**
- `get_default_permission(tool_name)` ‚Äî retorna default do sistema
- `is_high_risk_tool(tool_name)` ‚Äî detecta tools de alto risco
- `is_read_only_tool(tool_name)` ‚Äî detecta tools apenas leitura

### Decis√µes Tomadas
- Hierarquia de preced√™ncia: session > project > global > system
- Cache de regras com TTL de 60s (configur√°vel)
- Matching de padr√µes glob via fnmatch

### Verifica√ß√µes
- Imports: OK
- Testes de unidade inline: OK

---

## 2026-01-26 ‚Äî FASE 5: Atualiza√ß√£o do model-selector.tsx para incluir se√ß√£o Agentes

### Contexto
- Continua√ß√£o da implementa√ß√£o da Fase 5 do plano Claude Agent SDK
- Objetivo: atualizar o model-selector.tsx para incluir se√ß√£o de Agentes na UI

### Arquivos Alterados
- `apps/web/src/config/models.ts` ‚Äî Adicionada configura√ß√£o de Agentes (AgentConfig, AGENT_REGISTRY)
- `apps/web/src/components/chat/model-selector.tsx` ‚Äî Nova se√ß√£o "Agentes" no dropdown de sele√ß√£o

### Novas Adi√ß√µes em models.ts

**Tipos:**
- `AgentId = "claude-agent"` ‚Äî Tipo union para IDs de agentes
- `AgentConfig` ‚Äî Interface de configura√ß√£o de agentes com campos: id, label, provider, baseModel, isAgent, capabilities, description, icon, tooltip

**Registry:**
- `AGENT_REGISTRY` ‚Äî Registro de agentes dispon√≠veis
- Configura√ß√£o do Claude Agent com capabilities: tools, autonomous, permissions, juridico

**Fun√ß√µes Helper:**
- `getAgentConfig(agentId)` ‚Äî Obt√©m config de um agente pelo ID
- `listAgents()` ‚Äî Lista todos os agentes dispon√≠veis
- `isAgentId(id)` ‚Äî Type guard para verificar se um ID √© de agente

### Altera√ß√µes no model-selector.tsx

**Imports adicionados:**
- `listAgents, AgentId, getAgentConfig, isAgentId` de `@/config/models`
- √çcone `Bot` de `lucide-react`
- Componente `Badge` de `@/components/ui/badge`

**Nova UI:**
- Se√ß√£o "Agentes" separada dos "Modelos" no dropdown
- √çcone Bot com gradiente amber/orange para diferencia√ß√£o visual
- Badge "Agent" em cada item de agente
- Tooltip rico com descri√ß√£o e lista de capabilities do agente
- Atualiza√ß√£o do bot√£o trigger para mostrar corretamente quando um agente est√° selecionado

### Comandos Executados
- `npm run build` ‚Äî OK (compila√ß√£o bem-sucedida)
- `npx eslint` ‚Äî OK (sem erros de lint)

### Decis√µes Tomadas
- Separa√ß√£o visual clara entre Modelos e Agentes usando labels e √≠cones diferentes
- Uso de Badge com cor amber para indicar itens do tipo Agent
- Tooltip detalhado mostrando capabilities do agente para ajudar usu√°rio a entender funcionalidades
- Mantida compatibilidade com sistema existente de toggleModel

---

## 2026-01-26 ‚Äî FASE 5: Atualiza√ß√£o do chat-store.ts para novos eventos SSE

### Contexto
- Implementa√ß√£o da Fase 5 do plano Claude Agent SDK
- Objetivo: atualizar o chat-store.ts para suportar os novos eventos SSE do Claude Agent

### Arquivos Alterados
- `apps/web/src/stores/chat-store.ts` ‚Äî Adicionados novos estados e handlers para Claude Agent SDK

### Novos Estados Adicionados (Interface ChatState)

**Claude Agent SDK State:**
- `isAgentMode: boolean` ‚Äî Indica se est√° em modo agente
- `agentIterationCount: number` ‚Äî Contador de itera√ß√µes do agente
- `contextUsagePercent: number` ‚Äî Porcentagem de uso do contexto
- `lastSummaryId: string | null` ‚Äî ID do √∫ltimo resumo de compacta√ß√£o
- `pendingToolApproval` ‚Äî Dados da tool aguardando aprova√ß√£o
- `toolPermissions: Record<string, 'allow' | 'deny' | 'ask'>` ‚Äî Permiss√µes de tools
- `checkpoints: Array<{id, description, createdAt}>` ‚Äî Lista de checkpoints
- `parallelExecution` ‚Äî Estado de execu√ß√£o paralela de tools
- `lastToolCall` ‚Äî √öltima chamada de tool e seu status

### Novos Handlers de Eventos SSE

| Evento | A√ß√£o |
|--------|------|
| `agent_iteration` | Incrementa contador de itera√ß√µes |
| `tool_call` | Atualiza lastToolCall com status pending |
| `tool_result` | Atualiza lastToolCall com resultado |
| `tool_approval_required` | Configura pendingToolApproval |
| `context_warning` | Atualiza contextUsagePercent |
| `compaction_done` | Atualiza lastSummaryId e contextUsagePercent |
| `checkpoint_created` | Adiciona checkpoint √† lista |
| `parallel_start` | Inicia estado de execu√ß√£o paralela |
| `parallel_progress` | Atualiza progresso da execu√ß√£o paralela |
| `parallel_complete` | Finaliza execu√ß√£o paralela |

### Novas Actions Implementadas

1. **setIsAgentMode(enabled)** ‚Äî Ativa/desativa modo agente
2. **compactConversation()** ‚Äî Solicita compacta√ß√£o da conversa ao backend
3. **approveToolCall(approved, remember?)** ‚Äî Aprova/nega execu√ß√£o de tool
4. **restoreCheckpoint(checkpointId)** ‚Äî Restaura um checkpoint anterior
5. **setToolPermission(tool, permission)** ‚Äî Define permiss√£o para uma tool
6. **clearPendingToolApproval()** ‚Äî Limpa aprova√ß√£o pendente

### Comandos Executados
- `npm run lint --workspace=apps/web` ‚Äî Erros pr√©-existentes (n√£o relacionados)
- `npm run type-check --workspace=apps/web` ‚Äî OK (sem erros)

### Status
- [x] Interface ChatState atualizada com novos tipos
- [x] Valores iniciais adicionados na store
- [x] Handlers de eventos SSE implementados
- [x] Actions implementadas
- [x] Type-check passou

---

## 2026-01-26 ‚Äî FASE 3: ContextManager para LangGraph Improvements

### Contexto
- Implementa√ß√£o da Fase 3 do plano Claude Agent SDK
- Objetivo: criar gerenciador de contexto no estilo Claude Code

### Arquivos Criados
- `apps/api/app/services/ai/langgraph/__init__.py` ‚Äî M√≥dulo principal
- `apps/api/app/services/ai/langgraph/improvements/__init__.py` ‚Äî Subm√≥dulo de melhorias
- `apps/api/app/services/ai/langgraph/improvements/context_manager.py` ‚Äî ContextManager completo
- `apps/api/app/services/ai/langgraph/nodes/__init__.py` ‚Äî Placeholder para nodes

### Funcionalidades Implementadas

**ContextWindow (dataclass):**
- `total_tokens`: Total de tokens no contexto
- `limit`: Limite do modelo
- `threshold`: Threshold de compacta√ß√£o (default 70%)
- `usage_percent`: Porcentagem de uso atual
- `needs_compaction`: Flag calculada automaticamente
- `messages_count` / `tool_results_count`: Contadores

**ContextManager (classe principal):**

1. **count_tokens(messages)** ‚Üí int
   - Usa tiktoken (cl100k_base encoding) se dispon√≠vel
   - Fallback para estimativa ~3.5 chars/token
   - Suporta formato OpenAI e Anthropic (multimodal)

2. **should_compact(messages)** ‚Üí bool
   - Verifica se uso >= threshold (70%)
   - Loga informa√ß√µes quando precisa compactar

3. **compact(messages, preserve_recent, preserve_instructions)** ‚Üí tuple
   - Estrat√©gia em 2 passos:
     - Passo 1: `_clear_old_tool_results()` - limpa tool_results antigos
     - Passo 2: `_summarize_old_messages()` - resume mensagens antigas
   - Retorna (mensagens compactadas, resumo gerado)

4. **_clear_old_tool_results(messages, keep_recent)** ‚Üí List
   - Remove conte√∫do de tool_results antigos
   - Mant√©m identificadores (tool_call_id, tool_use_id)
   - Preserva mensagens recentes intactas

5. **_generate_summary(messages)** ‚Üí str
   - Gera resumo usando Claude Haiku (modelo r√°pido)
   - Preserva: decis√µes, informa√ß√µes cr√≠ticas, contexto necess√°rio
   - Fallback: extra√ß√£o heur√≠stica de pontos principais

6. **estimate_compaction_savings(messages)** ‚Üí Dict
   - Estima economia de tokens antes de compactar
   - √ötil para UI mostrar preview

### Limites por Modelo
```python
MODEL_CONTEXT_LIMITS = {
    "claude-4.5-opus": 200_000,
    "gpt-5.2": 400_000,
    "gemini-2.0-flash": 1_000_000,
    # ... outros modelos
}
```

### Decis√µes Tomadas
- Usar tiktoken para contagem precisa (fallback para estimativa)
- Threshold padr√£o 70% (configur√°vel via env CONTEXT_COMPACTION_THRESHOLD)
- Modelo de resumo: claude-3-haiku-20240307 (r√°pido e barato)
- Singleton via `get_context_manager()` para uso global
- Suporte a inje√ß√£o de cliente Anthropic para testes

### Verifica√ß√µes
- Python syntax: OK (`python3 -m py_compile`)

---

## 2026-01-26 ‚Äî FASE 5: Componente ToolApprovalModal para Claude Agent SDK

### Contexto
- Implementa√ß√£o da Fase 5.2 do plano Claude Agent SDK
- Objetivo: criar modal de aprova√ß√£o de tools do agente

### Arquivos Criados
- `apps/web/src/components/chat/tool-approval-modal.tsx` ‚Äî Modal de aprova√ß√£o de tools

### Funcionalidades Implementadas

**ToolApprovalModal:**
- Exibe nome da tool com label amig√°vel
- Mostra n√≠vel de risco com cores (low/medium/high):
  - Verde: baixo risco (opera√ß√µes de leitura)
  - Amarelo: m√©dio risco (edi√ß√µes)
  - Vermelho: alto risco (bash, file operations)
- Preview do que a tool vai fazer
- Par√¢metros de entrada expand√≠veis/colaps√°veis
- Bot√µes de a√ß√£o:
  - [Aprovar] / [Negar]
  - [Sempre Permitir] / [Sempre Negar]
- Sistema de "lembrar escolha" (session/always)
- Warning especial para tools de alto risco

### Props do Componente
```typescript
interface ToolApprovalModalProps {
  isOpen: boolean;
  onClose: () => void;
  tool: {
    name: string;
    input: Record<string, any>;
    riskLevel: 'low' | 'medium' | 'high';
    description?: string;
  };
  onApprove: (rememberChoice?: 'session' | 'always') => void;
  onDeny: (rememberChoice?: 'session' | 'always') => void;
}
```

### Decis√µes Tomadas
- Seguir padr√£o visual do human-review-modal existente
- Mapeamento de nomes de tools para labels em portugu√™s
- Cores consistentes com sistema de risco do plano
- Preview autom√°tico baseado no tipo de tool
- Op√ß√£o de "lembrar" s√≥ aparece para a√ß√µes de deny ou para approve em high-risk

### Verifica√ß√µes
- ESLint: passou sem erros
- TypeScript: componente sem erros (erro existente no chat-store.ts de outra feature)

---

## 2026-01-26 ‚Äî FASE 5: Componente ContextIndicator para Claude Agent SDK

### Contexto
- Implementa√ß√£o da Fase 5 do plano Claude Agent SDK
- Objetivo: criar componente visual para indicar uso da janela de contexto

### Arquivos Criados
- `apps/web/src/components/chat/context-indicator.tsx` ‚Äî Componente principal

### Funcionalidades Implementadas

**ContextIndicator (vers√£o completa):**
- Barra de progresso com cores din√¢micas:
  - Verde (< 50%): contexto saud√°vel
  - Amarelo (50-70%): uso moderado
  - Vermelho (> 70%): contexto quase cheio
- Tooltip com detalhes (tokens usados / limite)
- Bot√£o "Compactar" aparece quando > 60%
- Loading state durante compacta√ß√£o
- Anima√ß√£o suave na barra (transition-all duration-500)

**ContextIndicatorCompact (vers√£o inline):**
- Badge circular compacto para uso em headers
- Mesmo sistema de cores
- Tooltip com informa√ß√µes detalhadas

### Props do Componente
```typescript
interface ContextIndicatorProps {
  usagePercent: number;
  tokensUsed: number;
  tokenLimit: number;
  onCompact?: () => void;
  isCompacting?: boolean;
}
```

### Decis√µes Tomadas
- Barra de progresso customizada em vez de usar Progress do shadcn (mais controle sobre cores)
- N√∫meros formatados com separador de milhar (pt-BR)
- Bot√£o compactar s√≥ aparece se handler fornecido E uso > 60%
- Vers√£o compacta exportada separadamente para flexibilidade

### Depend√™ncias Utilizadas
- `@/components/ui/button` ‚Äî Bot√£o shadcn
- `@/components/ui/tooltip` ‚Äî Tooltip shadcn
- `lucide-react` ‚Äî √çcones (Loader2, Minimize2)
- `@/lib/utils` ‚Äî Fun√ß√£o cn() para classes condicionais

### Testes Executados
- `npm run lint` ‚Äî Componente sem erros (erros existentes s√£o de outros arquivos)
- `npx tsc --noEmit` ‚Äî Tipos corretos

---

## 2026-01-26 ‚Äî Fix: Diariza√ß√£o pyannote n√£o funcionava (HF_TOKEN timing bug)

### Contexto
- Usu√°rio perguntou se `mlx_vomo.py` captura diferentes professores em uma mesma aula
- Verifica√ß√£o revelou que diariza√ß√£o estava desabilitada por bug de timing

### Problema
- `HF_TOKEN` era lido na linha 195 (n√≠vel de m√≥dulo) antes do `load_dotenv()` ser chamado
- `load_dotenv()` s√≥ era executado na linha 4137, dentro do `__init__` da classe
- Resultado: `HF_TOKEN` sempre era `None`, desabilitando diariza√ß√£o

### Arquivos Alterados
- `mlx_vomo.py` ‚Äî Adicionado `load_dotenv()` no in√≠cio do m√≥dulo (linhas 37-41)

### Comandos Executados
- `pip show pyannote.audio` ‚Äî v4.0.3 instalado ‚úÖ
- `python3 -c "from pyannote.audio import Pipeline..."` ‚Äî Pipeline funciona ‚úÖ
- Teste de carregamento completo ‚Äî Pipeline no device MPS ‚úÖ

### Resultado
- Diariza√ß√£o agora **totalmente funcional**
- Identifica automaticamente diferentes falantes (SPEAKER 1, SPEAKER 2, etc.)
- Tenta mapear speakers para nomes reais de professores via LLM

---

## 2026-01-25 ‚Äî Fase 1: Observabilidade no Pipeline RAG

### Contexto
- Implementa√ß√£o da Fase 1 do roadmap: Observabilidade
- Objetivo: melhorar m√©tricas de tempo por stage e logging estruturado

### Arquivos Alterados

**`apps/api/app/services/rag/pipeline/rag_pipeline.py`**:

1. **M√©todo `to_metrics()` na classe `PipelineTrace`** (linhas 448-507):
   - Novo m√©todo que retorna dict com m√©tricas de lat√™ncia por stage
   - Calcula percentis p50/p95/p99 das lat√™ncias dos stages
   - Inclui: `trace_id`, `total_duration_ms`, `stage_latencies`, `percentiles`, `stage_count`, `error_count`, `stages_with_errors`, `search_mode`, `final_results_count`
   - Nota: percentis s√£o calculados a partir dos stages da trace atual; para p50/p95/p99 acurados entre m√∫ltiplas requisi√ß√µes, agregar `stage_latencies` externamente

2. **Logging estruturado no RRF Merge** (linhas 1706-1717):
   - `logger.error()` agora inclui `extra={}` com: stage, lexical_count, vector_count, error_type, trace_id
   - Adicionado `exc_info=True` para stack trace

3. **Logging estruturado no Visual Search** (linhas 1648-1660):
   - `logger.warning()` agora inclui `extra={}` com: stage, query, tenant_id, error_type, trace_id
   - Adicionado `exc_info=True` para stack trace

4. **Logging estruturado no Pipeline principal** (linhas 3120-3135):
   - `logger.error()` agora inclui `extra={}` com: trace_id, query, indices, collections, stages_completed, stages_failed, error_type, total_duration_ms
   - Permite rastreamento completo do estado do pipeline no momento da falha

### Decis√µes Tomadas
- Percentis calculados inline para evitar depend√™ncia de estat√≠sticas externas
- Logging estruturado usa formato `extra={}` do Python logging (compat√≠vel com formatadores JSON)
- Mantida compatibilidade com c√≥digo existente (sem breaking changes)

### Testes Executados
- `python3 -m py_compile rag_pipeline.py` ‚Äî OK
- Teste manual do m√©todo `to_metrics()` ‚Äî OK
- Verifica√ß√£o de imports e estrutura b√°sica ‚Äî OK

---

## 2026-01-25 ‚Äî Fase 2: Error Handling no Pipeline RAG

### Contexto
- Implementa√ß√£o da Fase 2 do roadmap de otimiza√ß√£o do pipeline RAG
- Objetivo: substituir `except Exception` gen√©ricos por exce√ß√µes espec√≠ficas
- Manter comportamento fail-soft para componentes opcionais
- Propagar erros para componentes obrigat√≥rios quando `fail_open=False`

### Arquivos Criados

**`apps/api/app/services/rag/pipeline/exceptions.py`**:
- Hierarquia completa de exce√ß√µes customizadas
- Classes: `RAGPipelineError` (base), `SearchError`, `LexicalSearchError`, `VectorSearchError`, `EmbeddingError`, `RerankerError`, `CRAGError`, `GraphEnrichError`, `CompressionError`, `ExpansionError`, `QueryExpansionError`, `ComponentInitError`
- Cada exce√ß√£o inclui:
  - `message`: descri√ß√£o do erro
  - `component`: nome do componente que falhou
  - `context`: dict com informa√ß√µes adicionais
  - `recoverable`: indica se o pipeline pode continuar
  - `cause`: exce√ß√£o original encadeada
  - `to_dict()`: serializa√ß√£o para logging/tracing

### Arquivos Alterados

**`apps/api/app/services/rag/pipeline/__init__.py`**:
- Adicionado import e export de todas as exce√ß√µes customizadas

**`apps/api/app/services/rag/pipeline/rag_pipeline.py`**:

1. **Import de exce√ß√µes** (linha ~129): Importadas todas as exce√ß√µes de `exceptions.py`

2. **Query Enhancement** (linha ~1096): `except Exception` agora:
   - Re-raises `QueryExpansionError` se j√° for nossa exce√ß√£o
   - Loga com contexto extra (query, hyde, multiquery)
   - Raises `QueryExpansionError` com causa encadeada quando `fail_open=False`

3. **Lexical Search - per query** (linha ~1332): Logging melhorado com contexto

4. **Lexical Search - stage** (linha ~1355): `except Exception` agora:
   - Re-raises `LexicalSearchError` se j√° for nossa exce√ß√£o
   - Loga com contexto (indices, queries_count)
   - Raises `LexicalSearchError` com causa encadeada

5. **Vector Search - per query** (linha ~1528):
   - Re-raises `EmbeddingError` (indica problemas de modelo)
   - Logging melhorado com contexto

6. **Vector Search - stage** (linha ~1551): `except Exception` agora:
   - Re-raises `VectorSearchError` se j√° for nossa exce√ß√£o
   - Loga com contexto (collections, queries_count)
   - Raises `VectorSearchError` com causa encadeada

7. **CRAG Gate** (linha ~2075): `except Exception` agora:
   - Re-raises `CRAGError` se j√° for nossa exce√ß√£o
   - Loga com contexto (results_count, decision, retry_count)
   - Raises `CRAGError` com causa encadeada

8. **Reranker** (linha ~2158): `except Exception` agora:
   - Re-raises `RerankerError` se j√° for nossa exce√ß√£o
   - Loga com contexto (candidates_count, model)
   - Raises `RerankerError` com causa encadeada

9. **Chunk Expansion** (linha ~2239): `except Exception` agora:
   - Re-raises `ExpansionError` se j√° for nossa exce√ß√£o
   - Loga com contexto (chunks_count, window, max_extra)
   - Raises `ExpansionError` com causa encadeada

10. **Compression** (linha ~2324): `except Exception` agora:
    - Re-raises `CompressionError` se j√° for nossa exce√ß√£o
    - Loga com contexto (results_count, token_budget)
    - Raises `CompressionError` com causa encadeada

11. **Graph Enrich** (linha ~2700): `except Exception` agora:
    - Re-raises `GraphEnrichError` para casos cr√≠ticos
    - Loga com contexto detalhado
    - Mant√©m fail-soft (retorna contexto parcial)

### Decis√µes T√©cnicas
- **Re-raise pattern**: Cada handler verifica se j√° √© nossa exce√ß√£o antes de wrapping
- **Fail-soft preservado**: Componentes opcionais (graph, visual) continuam n√£o propagando
- **Contexto rico**: Cada exce√ß√£o carrega informa√ß√µes √∫teis para debugging
- **Causa encadeada**: Exce√ß√£o original preservada via `cause` parameter
- **Logging estruturado**: Uso de `extra={}` para contexto adicional no logger

### Verifica√ß√µes
- ‚úÖ Sintaxe Python verificada para `exceptions.py`
- ‚úÖ Sintaxe Python verificada para `rag_pipeline.py`
- ‚úÖ Sintaxe Python verificada para `__init__.py`
- ‚úÖ Teste manual de hierarquia de exce√ß√µes funcionando

### Pr√≥ximos Passos (Fase 3+)
- Adicionar m√©tricas de erro por tipo de exce√ß√£o
- Integrar com observabilidade (traces, spans)
- Considerar circuit breaker para falhas recorrentes

---

## 2026-01-25 ‚Äî Fase 4: Async para Chamadas S√≠ncronas no Pipeline RAG

### Contexto
- Implementa√ß√£o da Fase 4 do roadmap de otimiza√ß√£o do pipeline RAG
- Objetivo: envolver chamadas s√≠ncronas que bloqueiam o event loop com `asyncio.to_thread()`
- Opera√ß√µes que demoram >10ms (embedding, reranking, extra√ß√£o de entidades, compress√£o)

### Arquivos Alterados

**`apps/api/app/services/rag/pipeline/rag_pipeline.py`**:

1. **`_stage_vector_search` (linha ~1374)**: `self._embeddings.embed_query(query)` agora usa `asyncio.to_thread`

2. **`_add_graph_chunks_to_results` (linha ~1670)**: `Neo4jEntityExtractor.extract(query)` agora usa `asyncio.to_thread`

3. **`_stage_crag_gate` (linha ~1901)**: Embedding de queries no retry CRAG agora usa `asyncio.to_thread`

4. **`_stage_rerank` (linhas ~2027-2032)**: `self._reranker.rerank()` agora usa `asyncio.to_thread`

5. **`_stage_compress` (linhas ~2158-2162)**: `self._compressor.compress_results()` agora usa `asyncio.to_thread`

6. **`_stage_graph_enrich` (linhas ~2410, 2416)**: `Neo4jEntityExtractor.extract()` para query e resultados agora usa `asyncio.to_thread`

### Decis√µes T√©cnicas
- **asyncio.to_thread**: Escolhido para mover opera√ß√µes CPU-bound ou s√≠ncronas de I/O para threads do pool padr√£o
- **Keyword args**: Para `rerank` e `compress_results`, par√¢metros foram convertidos de keyword para positional pois `to_thread` n√£o suporta kwargs diretamente
- **Import asyncio**: J√° estava presente no arquivo (linha 34)

### Verifica√ß√µes
- ‚úÖ Sintaxe Python verificada
- ‚úÖ 5 testes RAG passando:
  - `test_corrective_flags_do_not_force_legacy`
  - `test_agentic_routing_applies_to_new_pipeline`
  - `test_history_rewrite_applies_to_new_pipeline`
  - `test_dense_research_increases_top_k_in_new_pipeline`
  - `test_new_pipeline_uses_legacy_env_defaults_when_callers_do_not_override`

---

## 2026-01-25 ‚Äî Fase 3: Paraleliza√ß√£o no Pipeline RAG

### Contexto
- Implementa√ß√£o da Fase 3 do roadmap de otimiza√ß√£o do pipeline RAG
- Objetivo: executar busca lexical e vetorial em paralelo usando `asyncio.gather`
- Controle de concorr√™ncia com sem√°foro para limitar opera√ß√µes simult√¢neas

### Arquivos Alterados

**`apps/api/app/services/rag/pipeline/rag_pipeline.py`**:

1. **`__init__` (linha ~637)**: Adicionado `self._search_semaphore = asyncio.Semaphore(5)` para controle de concorr√™ncia

2. **`search()` (linhas ~2701-2758)**: Refatorado Stages 2 e 3 para execu√ß√£o paralela:
   - Queries de cita√ß√£o (`is_citation_query`) continuam executando apenas busca lexical
   - Para queries normais, `_stage_lexical_search` e `_stage_vector_search` agora executam em paralelo via `asyncio.gather`
   - Tratamento de exce√ß√µes com `return_exceptions=True` - se uma busca falhar, a outra continua funcionando
   - Erros s√£o logados e adicionados ao trace, mas n√£o quebram o pipeline
   - Sem√°foro limita a 5 opera√ß√µes de busca concorrentes para evitar sobrecarga

### Decis√µes T√©cnicas
- **Sem√°foro**: Limite de 5 opera√ß√µes foi escolhido como balan√ßo entre performance e uso de recursos
- **Tratamento de erros**: Falha graceful - se lexical falha retorna `[]`, se vector falha retorna `[]`
- **Compatibilidade**: L√≥gica de `skip_vector` e `is_citation_query` preservada

### Verifica√ß√µes
- ‚úÖ Sintaxe Python verificada (`py_compile`)
- ‚úÖ Testes RAG passando (`test_rag_corrective_new_pipeline.py`)

---

## 2026-01-25 ‚Äî Migra√ß√£o para Neo4j Visualization Library (NVL)

### Contexto
- Usu√°rio perguntou qual √© a biblioteca de visualiza√ß√£o mais avan√ßada recomendada pela Neo4j
- Pesquisa identificou NVL como a biblioteca oficial que alimenta Bloom e Neo4j Browser
- Migra√ß√£o completa de react-force-graph-2d para @neo4j-nvl/react

### Pacotes Instalados
```bash
npm install @neo4j-nvl/react @neo4j-nvl/interaction-handlers @neo4j-nvl/base
```

### Arquivos Alterados

**`apps/web/src/app/(dashboard)/graph/page.tsx`**:
- Migra√ß√£o completa para NVL (Neo4j Visualization Library)
- `InteractiveNvlWrapper` como componente principal
- Fun√ß√µes de transforma√ß√£o: `transformToNvlNodes`, `transformToNvlRelationships`
- Handlers atualizados para API NVL:
  - `onNodeClick(node: Node, hitTargets: HitTargets, evt: MouseEvent)`
  - `onHover(element, hitTargets, evt)` com acesso via `hitTargets.nodes[0].data.id`
- Zoom via `nvlRef.current.setZoom()` e `nvlRef.current.fit()`
- Layout force-directed nativo

### Caracter√≠sticas NVL
- **Renderer**: WebGL (fallback canvas)
- **Layout**: Force-directed nativo otimizado
- **Intera√ß√£o**: Clique, hover, drag, zoom, pan
- **Estilos**: Cores por grupo, tamanho por relev√¢ncia, highlight de sele√ß√£o/path

### Tipos Importantes
```typescript
// Node da NVL
interface Node {
  id: string;
  color?: string;
  size?: number;
  caption?: string;
  captionAlign?: 'top' | 'bottom' | 'center';
  selected?: boolean;
  pinned?: boolean;
}

// HitTargetNode (retornado em eventos de hover)
interface HitTargetNode {
  data: Node;           // <- ID est√° aqui: data.id
  targetCoordinates: Point;
  pointerCoordinates: Point;
}
```

### Verifica√ß√µes
- ‚úÖ Type check passou (web app)
- ‚úÖ Lint passou (graph files)

---

## 2026-01-25 ‚Äî Melhorias na P√°gina de Grafo + Autentica√ß√£o

### Contexto
- An√°lise de diferen√ßas entre frontend e backend da p√°gina de grafo
- Implementa√ß√£o de autentica√ß√£o nos endpoints do grafo
- Melhorias de performance e UX com React Query

### Arquivos Alterados

**`apps/api/app/api/endpoints/graph.py`**:
- Adicionada autentica√ß√£o via `get_current_user` em todos os endpoints
- `tenant_id` agora √© extra√≠do automaticamente do usu√°rio logado
- Removido par√¢metro `tenant_id` dos query params (seguran√ßa)

**`apps/web/src/lib/use-graph.ts`** (NOVO):
- React Query hooks para cache das chamadas de API
- `useGraphData`, `useGraphEntity`, `useGraphRemissoes`
- `useSemanticNeighbors` (lazy loading)
- `useGraphPath`, `useGraphStats`
- Prefetch functions para hover preview
- Stale-while-revalidate caching

**`apps/web/src/lib/api-client.ts`**:
- Tipos enriquecidos para `/path` (nodes/edges detalhados)

**`apps/web/src/app/(dashboard)/graph/page.tsx`**:
- Migrado para React Query hooks
- Novo "Modo Caminho" para encontrar path entre 2 n√≥s
- Visualiza√ß√£o enriquecida do caminho com detalhes dos n√≥s
- Tabs para Info/Remiss√µes/Vizinhos Sem√¢nticos
- Lazy loading de vizinhos sem√¢nticos (s√≥ carrega na aba)
- Prefetch on hover para UX mais r√°pida
- Skeletons para loading states

**`apps/web/src/components/ui/skeleton.tsx`** (NOVO):
- Componente shadcn/ui para loading states

### Melhorias Implementadas

1. **Seguran√ßa**: Endpoints agora requerem autentica√ß√£o
2. **Cache**: React Query com stale-while-revalidate (2-5 min)
3. **Visualiza√ß√£o de Path**: Mostra n√≥s intermedi√°rios e chunks
4. **Lazy Loading**: Vizinhos carregam sob demanda
5. **Prefetch**: Dados pr√©-carregados ao passar o mouse

### Testes
- 18 testes passando (test_hybrid_reranker.py)
- Type check OK

---

## 2026-01-25 ‚Äî Reranker H√≠brido: Local + Cohere com Boost Jur√≠dico

### Contexto
- Implementa√ß√£o de reranker h√≠brido para SaaS em produ√ß√£o
- Local cross-encoder para desenvolvimento (gr√°tis)
- Cohere Rerank v3 para produ√ß√£o (escala sem GPU)
- Ambos aplicam boost para termos jur√≠dicos brasileiros

### Arquivos Criados/Alterados

**`apps/api/app/services/rag/core/cohere_reranker.py`** (NOVO):
- `CohereReranker`: integra√ß√£o com Cohere Rerank API
- `CohereRerankerConfig`: configura√ß√£o (modelo, API key, etc)
- Boost jur√≠dico aplicado **p√≥s-Cohere** (Cohere score + legal boost)
- Retry autom√°tico com backoff exponencial

**`apps/api/app/services/rag/core/hybrid_reranker.py`** (NOVO):
- `HybridReranker`: sele√ß√£o autom√°tica entre Local e Cohere
- `RerankerProvider`: enum (auto, local, cohere)
- Auto: dev=local, prod=cohere (se dispon√≠vel)
- Fallback para local se Cohere falhar

**`apps/api/app/services/rag/config.py`**:
- Novas configura√ß√µes:
  - `rerank_provider`: "auto" | "local" | "cohere"
  - `cohere_rerank_model`: "rerank-multilingual-v3.0"
  - `cohere_fallback_to_local`: true
  - `rerank_legal_boost`: 0.1

**`apps/api/app/services/rag/core/reranker.py`**:
- Corrigido padr√£o de Lei (Lei n¬∫ 14.133)

**`apps/api/tests/rag/test_hybrid_reranker.py`** (NOVO):
- 18 testes para providers, config, legal boost

### Configura√ß√£o

```env
# Desenvolvimento (padr√£o)
RERANK_PROVIDER=auto
ENVIRONMENT=development
# Usa cross-encoder local (gr√°tis)

# Produ√ß√£o
RERANK_PROVIDER=auto
ENVIRONMENT=production
COHERE_API_KEY=sua-chave
# Usa Cohere (se API key presente)
```

### Uso

```python
from app.services.rag.core.hybrid_reranker import get_hybrid_reranker

reranker = get_hybrid_reranker()
result = reranker.rerank(query, results)

print(f"Provider: {result.provider_used}")
print(f"Fallback usado: {result.used_fallback}")
```

### Fluxo do Boost Jur√≠dico

```
Query + Docs ‚Üí Cohere Rerank ‚Üí cohere_score
                                    ‚Üì
                           + legal_boost (se match padr√µes)
                                    ‚Üì
                              final_score
```

### Padr√µes Jur√≠dicos Detectados
- `art. 5`, `¬ß 1¬∫`, `inciso I`
- `Lei n¬∫ 14.133`, `Lei 8.666`
- `S√∫mula 331`, `STF`, `STJ`, `TST`
- CNJ: `0000000-00.0000.0.00.0000`
- `C√≥digo Civil`, `habeas corpus`, etc.

### Testes
```
pytest tests/rag/test_hybrid_reranker.py -v
======================= 18 passed =======================
```

---

## 2026-01-25 ‚Äî OCR H√≠brido com Fallback para Cloud

### Contexto
- Implementa√ß√£o de estrat√©gia h√≠brida de OCR para produ√ß√£o
- Tesseract gratuito para volume baixo, cloud OCR para escala
- Suporte a Azure Document Intelligence, Google Vision e Gemini Vision

### Arquivos Criados/Alterados

**`apps/api/app/services/ocr_service.py`** (NOVO):
- `OCRProvider` enum: pdfplumber, tesseract, azure, google, gemini
- `OCRResult` dataclass: resultado com texto, provider, p√°ginas, erro
- `OCRUsageTracker`: rastreia volume di√°rio para decis√£o de fallback
- `HybridOCRService`: servi√ßo principal com estrat√©gia inteligente
  - PDF com texto selecion√°vel ‚Üí pdfplumber (gratuito, r√°pido)
  - Volume baixo ‚Üí Tesseract local
  - Volume alto ou fallback ‚Üí Cloud OCR

**`apps/api/app/core/config.py`**:
- Novas configura√ß√µes de OCR:
  - `OCR_PROVIDER`: provider padr√£o (tesseract)
  - `OCR_CLOUD_THRESHOLD_DAILY`: threshold para cloud (1000 p√°ginas)
  - `AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT/KEY`
  - `GOOGLE_VISION_ENABLED`, `GEMINI_OCR_ENABLED`
  - `GEMINI_OCR_MODEL`: modelo para OCR (gemini-2.0-flash)

**`apps/api/app/services/document_processor.py`**:
- `extract_text_from_image`: usa HybridOCRService com fallback
- `extract_text_from_pdf_with_ocr`: usa HybridOCRService com fallback
- `_extract_text_from_pdf_tesseract`: implementa√ß√£o original preservada

**`apps/api/tests/test_ocr_service.py`** (NOVO):
- 17 testes para OCRProvider, OCRResult, OCRUsageTracker, HybridOCRService
- Testes de isolamento com reset de singleton

### Estrat√©gia de OCR

```
Upload ‚Üí √â PDF com texto? ‚Üí Sim ‚Üí pdfplumber (gr√°tis)
                         ‚Üí N√£o ‚Üí Volume < 1000/dia? ‚Üí Sim ‚Üí Tesseract (gr√°tis)
                                                    ‚Üí N√£o ‚Üí Cloud OCR (Azure/Gemini)
```

### Compara√ß√£o de Custos
| Provider | Custo/1K p√°ginas | Quando usar |
|----------|------------------|-------------|
| pdfplumber | $0 | PDFs com texto selecion√°vel |
| Tesseract | $0 | Volume < 1000 p√°ginas/dia |
| Azure | ~$1.50 | Alta precis√£o, formul√°rios |
| Gemini | ~$0.04/img | Melhor custo-benef√≠cio cloud |

### Testes
```
pytest tests/test_ocr_service.py -v
======================= 17 passed in 0.17s =======================
```

---

## 2026-01-25 ‚Äî Semantic Extractor: Neo4j Vector Index Native

### Contexto
- Refatora√ß√£o do SemanticEntityExtractor para usar √≠ndice vetorial nativo do Neo4j
- Alinhamento com documenta√ß√£o oficial Neo4j 5.x para vector search
- Sistema de fallback robusto quando Neo4j n√£o est√° dispon√≠vel

### Arquivos Alterados

**`apps/api/app/services/rag/core/semantic_extractor.py`:**
- Corrigido `CHECK_VECTOR_INDEX` query (SHOW INDEXES n√£o suporta RETURN)
- Corrigido `_create_vector_index()` para usar DDL com valores hardcoded (par√¢metros n√£o funcionam em DDL)
- Prioridade de index creation: CALL syntax ‚Üí DDL syntax
- Adicionado `LocalEmbeddingsService` (sentence-transformers, sem API key)
- Adicionado `GeminiEmbeddingsService` (fallback quando OpenAI indispon√≠vel)
- Prioridade de embeddings: OpenAI ‚Üí Gemini ‚Üí Local sentence-transformers

### Configura√ß√£o Neo4j Aura
```
NEO4J_URI=neo4j+s://24df7574.databases.neo4j.io
NEO4J_PASSWORD=***
RAG_GRAPH_BACKEND=neo4j
```

### Resultado dos Testes
```
Mode: NEO4J (√≠ndice vetorial nativo)
Entidades encontradas:
- Princ√≠pio da Boa-F√© Objetiva: 0.789
- Boa-F√© Objetiva: 0.779
- Enriquecimento Sem Causa: 0.772
- Prescri√ß√£o: 0.746
```

### Performance
- Neo4j native: ~50ms per query (vector similarity via `db.index.vector.queryNodes`)
- Fallback numpy: ~100ms per query (local cosine similarity)

---

## 2026-01-25 ‚Äî Extra√ß√£o de Remiss√µes entre Dispositivos Legais

### Contexto
- Adicionado extrator de remiss√µes (cross-references) entre dispositivos legais
- Complementa o LegalEntityExtractor existente com detec√ß√£o de rela√ß√µes

### Arquivo Alterado

**`apps/api/app/services/rag/core/neo4j_mvp.py`:**
- Adicionado `REMISSION_PATTERNS` - regex para padr√µes de remiss√£o
- Adicionado `extract_remissions()` - extrai rela√ß√µes entre dispositivos
- Adicionado `extract_with_remissions()` - retorna entidades + remiss√µes

### Tipos de Remiss√µes Detectadas
| Tipo | Padr√£o |
|------|--------|
| `combinado_com` | c/c, em conjunto com |
| `nos_termos_de` | nos termos do, conforme |
| `aplica_se` | aplica-se o |
| `remete_a` | remete ao |
| `por_forca_de` | por for√ßa do |
| `sequencia` | arts. X e Y |

### Uso
```python
from app.services.rag.core.neo4j_mvp import LegalEntityExtractor

result = LegalEntityExtractor.extract_with_remissions(text)
# result['entities'] = dispositivos legais
# result['remissions'] = rela√ß√µes entre dispositivos
```

---

## 2026-01-25 ‚Äî Integra√ß√£o: ColPali no RAG Pipeline + Ingest√£o Visual

### Contexto
- Integra√ß√£o do ColPali Visual Retrieval como stage opcional no RAG Pipeline
- Visual search roda em paralelo com lexical/vector search quando habilitado
- Task Celery para indexa√ß√£o visual ass√≠ncrona de PDFs
- Integra√ß√£o com endpoint de upload de documentos

### Arquivos Alterados

**`apps/api/app/services/rag/pipeline/rag_pipeline.py`:**
- `PipelineStage` enum: Adicionado `VISUAL_SEARCH = "visual_search"`
- `RAGPipeline.__init__`: Adicionado par√¢metro `colpali`
- `_ensure_components`: Inicializa√ß√£o lazy do ColPali quando `COLPALI_ENABLED=true`
- `_stage_visual_search`: Novo m√©todo que executa busca visual via ColPali
- `_merge_visual_results`: Merge de resultados visuais com weight reduzido (0.3)
- `_stage_merge_rrf`: Atualizado para aceitar `visual_results` opcional
- `search` e `search_sync`: Adicionado par√¢metro `visual_search_enabled`

**`apps/api/app/workers/tasks/document_tasks.py`:**
- Nova task `visual_index_task`: Indexa PDF visualmente usando ColPali

**`apps/api/app/workers/tasks/__init__.py`:**
- Export de `visual_index_task`

**`apps/api/app/api/endpoints/documents.py`:**
- Import de `visual_index_task`
- Flag `visual_index` no metadata do upload enfileira indexa√ß√£o visual

### Depend√™ncias Instaladas
```bash
pip install colpali-engine torch pillow pymupdf
```

### Fluxo do Pipeline (Atualizado)
```
Query -> Query Enhancement -> Lexical Search -> Vector Search (condicional)
     -> Visual Search (quando habilitado) -> Merge RRF (inclui visuais)
     -> CRAG Gate -> Rerank -> Expand -> Compress -> Graph Enrich -> Trace
```

### Uso - Busca
```python
# Via par√¢metro (override config)
result = await pipeline.search("tabela de honor√°rios", visual_search_enabled=True)

# Via env var (default)
# COLPALI_ENABLED=true
result = await pipeline.search("gr√°fico de custos")
```

### Uso - Ingest√£o Visual (Upload)
```bash
# Upload com indexa√ß√£o visual
curl -X POST /api/documents/upload \
  -F "file=@documento.pdf" \
  -F 'metadata={"visual_index": true, "tenant_id": "tenant1"}'
```

O documento ser√°:
1. Processado normalmente (extra√ß√£o de texto, OCR se necess√°rio)
2. Enfileirado para indexa√ß√£o visual via task Celery `visual_index`
3. P√°ginas indexadas no Qdrant collection `visual_docs`

### Resultado dos Testes
- ColPali tests: **18 passed**
- Pipeline imports: **OK**
- Syntax check: **OK**
- Task import: **OK**

### Pr√≥ximos Passos
- Criar testes de integra√ß√£o ColPali + Pipeline
- Testar com PDFs reais (tabelas, gr√°ficos, infogr√°ficos)
- Adicionar endpoint dedicado `/api/rag/visual/index` para reindexar documentos existentes

---

## 2026-01-25 ‚Äî Implementa√ß√£o: ColPali Visual Document Retrieval Service

### Contexto
- Implementa√ß√£o do servi√ßo ColPali para retrieval visual de documentos
- PDFs com tabelas, figuras, infogr√°ficos - sem depender de OCR

### Arquivos Criados
- `apps/api/app/services/rag/core/colpali_service.py` ‚Äî Servi√ßo completo:
  - ColPaliConfig com 15+ par√¢metros configur√°veis
  - ColPaliService com lazy loading de modelo
  - Suporte a ColPali, ColQwen2.5, ColSmol
  - Late interaction (MaxSim) para scoring
  - Integra√ß√£o com Qdrant para armazenamento
  - Patch highlights para explainability
- `apps/api/tests/test_colpali_service.py` ‚Äî 18 testes unit√°rios

### Arquivos Alterados
- `apps/api/app/services/rag/core/__init__.py` ‚Äî Exporta√ß√µes adicionadas

### Resultado dos Testes
**18 passed, 0 failed**

### Configura√ß√£o (Environment Variables)
```bash
COLPALI_ENABLED=true
COLPALI_MODEL=vidore/colqwen2.5-v1
COLPALI_DEVICE=auto
COLPALI_BATCH_SIZE=4
COLPALI_QDRANT_COLLECTION=visual_docs
```

### Uso
```python
from app.services.rag.core import get_colpali_service

service = get_colpali_service()
await service.index_pdf("/path/to/doc.pdf", "doc1", "tenant1")
results = await service.search("tabela de custos", "tenant1")
```

### Pr√≥ximos Passos
- Integrar com RAG pipeline (stage adicional)
- Criar endpoint de API para ingest√£o visual
- Testar com PDFs reais

---

## 2026-01-25 ‚Äî Verifica√ß√£o: Retrieval H√≠brido Neo4j (Fase 1 Completa)

### Contexto
- Verifica√ß√£o das altera√ß√µes implementadas seguindo guia de arquitetura h√≠brida
- Valida√ß√£o de consist√™ncia entre neo4j_mvp.py, rag_pipeline.py, graph.py, rag.py

### Resultado: **27 testes passaram, 0 falhas**

### Componentes Verificados

| Arquivo | Status | Detalhes |
|---------|--------|----------|
| `neo4j_mvp.py` | ‚úÖ | FIND_PATHS com path_nodes/edges, security trimming, fulltext/vector indexes |
| `rag_pipeline.py` | ‚úÖ | GraphContext.paths, RAG_LEXICAL_BACKEND, RAG_VECTOR_BACKEND |
| `graph.py` | ‚úÖ | Security em 7+ endpoints (tenant_id, scope, sigilo) |
| `rag.py` | ‚úÖ | RAG_GRAPH_INGEST_ENGINE com mvp/graph_rag/both |

### Fase 1 Implementada
- ‚úÖ Neo4jMVP como camada de grafo (multi-hop 1-2 hops)
- ‚úÖ Paths explic√°veis (path_nodes, path_edges)
- ‚úÖ Security: allowed_scopes, group_ids, case_id, user_id, sigilo
- ‚úÖ Flags: NEO4J_FULLTEXT_ENABLED, NEO4J_VECTOR_INDEX_ENABLED
- ‚úÖ Routing: RAG_LEXICAL_BACKEND, RAG_VECTOR_BACKEND
- ‚úÖ Ingest√£o: RAG_GRAPH_INGEST_ENGINE (mvp/graph_rag/both)

### Pendente (Pr√≥ximos Passos)
- ‚ùå ColPali Service (retrieval visual)
- ‚ùå Neo4j Vector Search wiring
- ‚ùå M√©tricas compara√ß√£o Qdrant vs Neo4j

### Documenta√ß√£o Atualizada
- `docs/PLANO_RETRIEVAL_HIBRIDO.md` ‚Äî Status atualizado

---

## 2026-01-25 ‚Äî Corre√ß√£o: Semantic Extractor alinhado com Neo4j Vector Index

### Contexto
- Usu√°rio questionou se implementa√ß√£o do `semantic_extractor.py` estava alinhada com documenta√ß√£o Neo4j
- Descoberto que a implementa√ß√£o original armazenava embeddings em mem√≥ria Python e fazia similaridade em Python
- Neo4j 5.15+ tem suporte nativo a √≠ndices vetoriais que n√£o estava sendo usado

### Problema Identificado
- `semantic_extractor.py` armazenava seed embeddings em `Dict[str, List[float]]` Python
- C√°lculo de `cosine_similarity()` feito em numpy, n√£o Neo4j
- `graph_neo4j.py` j√° tinha queries para `db.index.vector.queryNodes` n√£o utilizadas

### Arquivos Alterados
- `apps/api/app/services/rag/core/semantic_extractor.py` ‚Äî Refatorado completamente:
  - Seed entities agora armazenados no Neo4j como n√≥s `SEMANTIC_ENTITY`
  - Embeddings armazenados na propriedade `embedding` do n√≥
  - √çndice vetorial criado com `CREATE VECTOR INDEX` (Neo4j 5.x syntax)
  - Busca via `db.index.vector.queryNodes` em vez de numpy
  - Rela√ß√µes `SEMANTICALLY_RELATED` persistidas no grafo

### Decis√µes Tomadas
- Usar label dedicado `SEMANTIC_ENTITY` para seeds sem√¢nticos
- Suportar ambas sintaxes de cria√ß√£o de √≠ndice (5.11+ e 5.15+)
- Dimens√£o 3072 para text-embedding-3-large da OpenAI
- Threshold de similaridade 0.75 para matches sem√¢nticos

### Alinhamento com Neo4j Docs
```cypher
-- Cria√ß√£o de √≠ndice vetorial (Neo4j 5.x)
CREATE VECTOR INDEX semantic_entity_embedding IF NOT EXISTS
FOR (n:SEMANTIC_ENTITY)
ON n.embedding
OPTIONS {indexConfig: {
    `vector.dimensions`: 3072,
    `vector.similarity_function`: 'cosine'
}}

-- Query de similaridade
CALL db.index.vector.queryNodes(
    'semantic_entity_embedding',
    $top_k,
    $embedding
) YIELD node, score
```

### Pr√≥ximos Passos
- Testar cria√ß√£o de √≠ndice em ambiente com Neo4j
- Verificar se SEMANTIC_ENTITY aparece na visualiza√ß√£o do grafo
- Considerar adicionar mais seeds conforme feedback

---

## Template de Entrada

```markdown
## [DATA] ‚Äî Objetivo da Sess√£o

### Contexto
- Motivo/problema que levou √† sess√£o

### Arquivos Alterados
- `caminho/arquivo.ts` ‚Äî descri√ß√£o da mudan√ßa

### Comandos Executados
- `pnpm test` ‚Äî resultado
- `pnpm lint` ‚Äî resultado

### Decis√µes Tomadas
- Por que escolheu X em vez de Y

### Pr√≥ximos Passos
- O que ficou pendente

### Feedback do Usu√°rio
- Coment√°rios/corre√ß√µes recebidas
```

---

## 2026-01-25 ‚Äî Plano de Implementa√ß√£o: Retrieval H√≠brido com Neo4j + ColPali

### Contexto
- Usu√°rio solicitou plano de implementa√ß√£o para arquitetura de retrieval h√≠brida
- Objetivo: manter Qdrant + OpenSearch como candidate generators, adicionar Neo4j como camada de grafo
- Incluir ColPali para retrieval visual de documentos (tabelas, figuras)
- Seguir abordagem em fases para n√£o ficar ref√©m de uma √∫nica tecnologia

### Arquivos Criados
- `docs/PLANO_RETRIEVAL_HIBRIDO.md` ‚Äî Plano completo de implementa√ß√£o com:
  - Arquitetura em 2 fases (MVP + migra√ß√£o gradual)
  - C√≥digo de implementa√ß√£o para 4 novos servi√ßos
  - Configura√ß√£o de environment variables
  - Cronograma e m√©tricas de sucesso

### Pesquisa Realizada
- ColPali: Visual document retrieval usando Vision Language Models
  - Paper: https://arxiv.org/abs/2407.01449
  - Modelos: vidore/colpali, vidore/colqwen2.5-v1, vidore/colsmol
  - Ideal para PDFs com tabelas/figuras sem depender de OCR
- Neo4j Hybrid: Vector Index + Fulltext Index nativos
  - HybridRetriever do neo4j-graphrag-python
  - Vector: HNSW com cosine similarity
  - Fulltext: Lucene com analyzer brasileiro

### Arquitetura Proposta

**Fase 1 (Prioridade - 2-3 semanas):**
- Manter Qdrant + OpenSearch (sem risco)
- Adicionar Neo4j Graph Expansion (1-2 hops)
- Adicionar ColPali para documentos visuais
- Retrieval Router com feature flags

**Fase 2 (Ap√≥s m√©tricas - 2-3 semanas):**
- Neo4j FULLTEXT para UI/lexical
- Neo4j VECTOR INDEX para seeds
- Comparar m√©tricas (lat√™ncia/recall/custo)
- Desligar backends redundantes s√≥ ap√≥s paridade

### Decis√µes Tomadas
- ColQwen2.5 como modelo ColPali default (mais eficiente que original)
- Multi-hop limitado a 2 hops (performance vs completude)
- RRF como m√©todo de fus√£o (j√° usado no pipeline)
- Feature flags para tudo (reversibilidade)

### Pr√≥ximos Passos
1. Implementar `neo4j_graph_expansion.py`
2. Implementar `colpali_service.py`
3. Implementar `retrieval_router.py`
4. Integrar com RAG Pipeline existente
5. Criar endpoints de API
6. Criar componente de visualiza√ß√£o de grafo

### Refer√™ncias
- https://github.com/illuin-tech/colpali
- https://huggingface.co/blog/manu/colpali
- https://neo4j.com/docs/neo4j-graphrag-python/current/
- https://neo4j.com/docs/cypher-manual/current/indexes/semantic-indexes/vector-indexes/

---

## 2026-01-25 ‚Äî Pagina de Visualizacao de Grafo de Conhecimento Juridico

### Contexto
- Usuario solicitou pagina para descobrir relacoes entre dispositivos legais
- Relacoes semanticas (co-ocorrencia, contexto) alem de relacoes explicitas (cita, revoga)
- Checkboxes para filtrar por legislacao, jurisprudencia e doutrina
- Visualizacao interativa do grafo Neo4j

### Arquivos Criados
- `apps/api/app/api/endpoints/graph.py` ‚Äî Endpoints para visualizacao do grafo
  - GET /graph/entities ‚Äî Busca entidades por tipo
  - GET /graph/entity/{id} ‚Äî Detalhes com vizinhos e chunks
  - GET /graph/export ‚Äî Exporta grafo para visualizacao D3/force-graph
  - GET /graph/path ‚Äî Encontra caminhos entre entidades
  - GET /graph/stats ‚Äî Estatisticas do grafo
  - GET /graph/remissoes/{id} ‚Äî Remissoes (referencias cruzadas)
  - GET /graph/semantic-neighbors/{id} ‚Äî Vizinhos semanticos
  - GET /graph/relation-types ‚Äî Tipos de relacoes disponiveis
- `apps/web/src/app/(dashboard)/graph/page.tsx` ‚Äî Pagina de visualizacao do grafo
- `apps/web/src/stores/graph-store.ts` ‚Äî Store Zustand para estado do grafo
- `apps/web/src/types/react-force-graph.d.ts` ‚Äî Tipos TypeScript para react-force-graph

### Arquivos Alterados
- `apps/api/app/api/routes.py` ‚Äî Adicionado router do grafo
- `apps/web/src/lib/api-client.ts` ‚Äî Adicionados metodos para API do grafo

### Dependencias Adicionadas
- `react-force-graph-2d` ‚Äî Visualizacao interativa de grafos

### Funcionalidades
- Visualizacao interativa com zoom, pan e drag
- Filtros por grupo: Legislacao, Jurisprudencia, Doutrina
- Cores por tipo de entidade
- Painel de detalhes ao clicar em no
- Remissoes semanticas (co-ocorrencia em documentos)
- Legenda explicativa
- Estatisticas do grafo

### Tipos de Relacoes Semanticas
- co_occurrence: Entidades mencionadas no mesmo trecho
- related: Conexao semantica inferida pelo contexto
- complementa: Complementa ou detalha outro dispositivo
- interpreta: Oferece interpretacao do dispositivo

### Verificacao
- `npm run type-check` ‚Äî OK
- `npm run lint` ‚Äî Warning menor (useEffect deps)

### Proximos Passos
- Integrar com navegacao do sidebar
- Adicionar busca com autocomplete
- Implementar tooltips nas arestas mostrando tipo de relacao

---

## 2026-01-25 ‚Äî Extens√£o MCP para Tribunais

### Contexto
- Usu√°rio solicitou extens√£o MCP similar ao sei-mcp
- MCP (Model Context Protocol) permite Claude Code interagir com tribunais brasileiros

### Arquivos Criados
**packages/tribunais-mcp/**
- `package.json` ‚Äî Configura√ß√£o do pacote
- `tsconfig.json` ‚Äî Configura√ß√£o TypeScript
- `src/index.ts` ‚Äî Entry point
- `src/server.ts` ‚Äî Servidor MCP
- `src/websocket/server.ts` ‚Äî WebSocket server para comunica√ß√£o com extens√£o Chrome
- `src/tools/all-tools.ts` ‚Äî 35+ ferramentas MCP definidas
- `src/tools/index.ts` ‚Äî Handler de ferramentas
- `src/types/index.ts` ‚Äî Tipos TypeScript
- `src/utils/logger.ts` ‚Äî Logger (usa stderr para n√£o interferir com stdio)

### Ferramentas MCP Implementadas

| Categoria | Ferramentas |
|-----------|-------------|
| Autentica√ß√£o | login, logout, get_session |
| Consulta | buscar_processo, consultar_processo, listar_movimentacoes, listar_documentos, consultar_partes |
| Peticionamento | listar_tipos_peticao, peticionar, iniciar_processo, consultar_protocolo |
| Downloads | download_documento, download_processo, download_certidao |
| Prazos | listar_intimacoes, ciencia_intimacao, listar_prazos |
| Sess√µes | list_sessions, get_session_info, close_session, switch_session |
| Janela | minimize_window, restore_window, focus_window, get_window_state |
| Debug | screenshot, snapshot, navigate, click, type, wait |
| Credenciais | listar_credenciais, testar_credencial |

### Arquivos Alterados
- `apps/tribunais-extension/background.js`:
  - Porta padr√£o alterada para 19998 (MCP)
  - Adicionado campo `serverType` ('mcp' | 'legacy')
  - Handlers MCP: login, logout, screenshot, snapshot, navigate, click, type, wait
  - Handlers de janela: minimize_window, restore_window, focus_window
  - Fun√ß√£o `delegateToContentScript` para comandos delegados

### Arquitetura
```
Claude Code ‚Üî MCP Server (stdio) ‚Üî WebSocket ‚Üî Extens√£o Chrome ‚Üî DOM Tribunal
```

### Uso
```bash
# Iniciar servidor MCP
cd packages/tribunais-mcp
npm run build
node dist/index.js

# Conectar extens√£o Chrome na porta 19998
```

### Vari√°veis de Ambiente
- `TRIBUNAIS_MCP_WS_PORT` ‚Äî Porta WebSocket (default: 19998)
- `TRIBUNAIS_MCP_LOG_LEVEL` ‚Äî N√≠vel de log (debug, info, warn, error)

---

## 2026-01-25 ‚Äî Servico Hibrido de CAPTCHA (2Captcha, Anti-Captcha, CapMonster + HIL)

### Contexto
- Usu√°rio solicitou suporte a CAPTCHAs dif√≠ceis (reCAPTCHA, hCaptcha)
- Escolheu estrat√©gia h√≠brida: servi√ßo primeiro, fallback para resolu√ß√£o manual

### Arquivos Criados
- `apps/tribunais/src/services/captcha-solver.ts` ‚Äî Novo servi√ßo de resolu√ß√£o de CAPTCHA
- `apps/tribunais/tests/captcha-solver.test.ts` ‚Äî Testes unit√°rios (11 testes)
- `apps/tribunais/vitest.config.ts` ‚Äî Configura√ß√£o do Vitest

### Arquivos Alterados
- `apps/tribunais/src/queue/worker.ts` ‚Äî Integrado com CaptchaSolverService, removida fun√ß√£o obsoleta `requestCaptchaSolution`, cleanup de imports
- `apps/tribunais/package.json` ‚Äî Adicionado vitest e scripts de teste

### Funcionalidades do CaptchaSolverService
- **Providers suportados**: 2Captcha, Anti-Captcha, CapMonster, Manual (HIL)
- **Tipos de CAPTCHA**: image, recaptcha_v2, recaptcha_v3, hcaptcha
- **Estrat√©gia h√≠brida**:
  1. Tenta resolver via servi√ßo configurado (API)
  2. Se falhar, fallback para resolu√ß√£o manual (HIL via Redis pub/sub)
- **Configura√ß√£o via env vars**:
  - `CAPTCHA_PROVIDER`: '2captcha' | 'anticaptcha' | 'capmonster' | 'manual'
  - `CAPTCHA_API_KEY`: chave da API do servi√ßo
  - `CAPTCHA_SERVICE_TIMEOUT`: timeout do servi√ßo em ms (default: 120000)
  - `CAPTCHA_FALLBACK_MANUAL`: fallback para HIL se servi√ßo falhar (default: true)

### Testes Implementados
- Configura√ß√£o do solver (valores default, todos os providers)
- Tratamento de erros (API key missing, API failure)
- Fallback para manual (com/sem Redis)
- Tipos de CAPTCHA n√£o suportados

### Decis√µes Tomadas
- Singleton para reutilizar conex√µes Redis
- Polling a cada 5s para 2Captcha/Anti-Captcha, 3s para CapMonster (mais r√°pido)
- Mesmo formato de task do Anti-Captcha para CapMonster (APIs compat√≠veis)
- Callback resolve(null) para cancelamento pelo usu√°rio
- Testes focam em error handling (polling requer mock de timers complexo)

---

## 2026-01-25 ‚Äî UI de CAPTCHA na Extens√£o Chrome e Desktop App

### Contexto
- Implementar interface de usu√°rio para resolver CAPTCHAs na extens√£o Chrome e no app desktop
- Permite que o usu√°rio veja e resolva CAPTCHAs durante opera√ß√µes em tribunais

### Arquivos Alterados

**Extens√£o Chrome:**
- `apps/tribunais-extension/background.js` ‚Äî Adicionado handler `handleRequestCaptchaSolution`, fun√ß√£o `sendCaptchaSolution`, case no switch de comandos, handler de mensagem `captcha_solution`
- `apps/tribunais-extension/popup.html` ‚Äî Adicionados estilos CSS para UI de CAPTCHA (imagem, input, timer, bot√µes), se√ß√£o HTML `captchaPending`
- `apps/tribunais-extension/popup.js` ‚Äî Adicionados elementos DOM, estado `currentCaptcha`/`captchaTimerInterval`, fun√ß√µes `showCaptcha`, `hideCaptcha`, `startCaptchaTimer`, `submitCaptcha`, `cancelCaptcha`, `openTribunalPage`, event listeners

**Desktop App:**
- `apps/tribunais-desktop/src/main/websocket-client.ts` ‚Äî Adicionado case `request_captcha_solution`, m√©todo `sendCaptchaSolution`
- `apps/tribunais-desktop/src/main/index.ts` ‚Äî Import de `shell`, handler `captcha-required`, handlers IPC `solve-captcha` e `open-external`
- `apps/tribunais-desktop/src/preload/index.ts` ‚Äî Adicionados `solveCaptcha`, `openExternal`, canal `captcha-request`
- `apps/tribunais-desktop/src/renderer/index.html` ‚Äî Estilos CSS para CAPTCHA, se√ß√£o HTML `captchaCard`, elementos DOM, fun√ß√µes JavaScript (showCaptcha, hideCaptcha, etc.), event listeners

### Funcionalidades
- Exibe CAPTCHA de imagem com campo de texto
- Timer visual mostrando tempo restante
- Suporte a reCAPTCHA/hCaptcha com bot√£o para abrir p√°gina do tribunal
- Envio de solu√ß√£o ou cancelamento
- Auto-cancel quando expira

### Fluxo de UI
1. Servidor envia `request_captcha_solution` via WebSocket
2. Extension/Desktop armazena dados e mostra notifica√ß√£o
3. UI mostra card de CAPTCHA com imagem e input
4. Usu√°rio digita solu√ß√£o e clica Enviar
5. Solu√ß√£o √© enviada via WebSocket (`captcha_solved`)
6. UI fecha o card

---

## 2026-01-25 ‚Äî Suporte CAPTCHA HIL no Servi√ßo de Tribunais

### Contexto
- Adicionar Human-in-the-Loop para resolu√ß√£o de CAPTCHAs durante opera√ß√µes em tribunais
- CAPTCHAs s√£o comuns em tribunais brasileiros e precisam de interven√ß√£o humana

### Arquivos Alterados
- `apps/tribunais/src/types/index.ts` ‚Äî Adicionados tipos para CAPTCHA: CaptchaType, CaptchaInfo, CaptchaSolution, CaptchaRequiredEvent, CaptchaSolutionResponse
- `apps/tribunais/src/extension/websocket-server.ts` ‚Äî Subscriber para canal `tribunais:captcha_required`, handlers para enviar CAPTCHA ao cliente e receber solu√ß√µes
- `apps/tribunais/src/queue/worker.ts` ‚Äî Subscriber para `tribunais:captcha_solution`, fun√ß√£o `requestCaptchaSolution` com Promise/timeout, `captchaHandler` para integrar com TribunalService
- `apps/tribunais/src/services/tribunal.ts` ‚Äî Interface `ExecuteOperationOptions` com callback `onCaptchaRequired`, integra√ß√£o com config de CAPTCHA do tribunais-playwright

### Fluxo Implementado
1. Worker executa opera√ß√£o no tribunal
2. tribunais-playwright detecta CAPTCHA
3. Callback `onCaptchaRequired` √© chamado
4. Worker publica evento no Redis (`tribunais:captcha_required`)
5. WebSocket server recebe e envia para extens√£o/desktop do usu√°rio
6. Usu√°rio resolve o CAPTCHA
7. Extens√£o/desktop envia solu√ß√£o via WebSocket
8. WebSocket server publica no Redis (`tribunais:captcha_solution`)
9. Worker recebe via subscriber e continua opera√ß√£o

### Decisoes Tomadas
- Timeout de 2 minutos para resolver CAPTCHA
- Se nenhuma extens√£o conectada, publica falha imediatamente
- Cleanup de CAPTCHAs pendentes no graceful shutdown

---

## 2026-01-25 ‚Äî Extensao Chrome para Certificados A3 (tribunais-extension)

### Contexto
- Criar extensao Chrome para automacao de tribunais com certificado digital A3
- Conectar ao servidor Iudex via WebSocket para receber comandos
- Detectar paginas de tribunais e estado de login

### Arquivos Criados
- `apps/tribunais-extension/manifest.json` ‚Äî Manifest V3 com permissoes para dominios de tribunais
- `apps/tribunais-extension/background.js` ‚Äî Service Worker com conexao WebSocket, reconexao automatica, processamento de comandos
- `apps/tribunais-extension/popup.html` ‚Äî Interface do usuario para configuracao e status
- `apps/tribunais-extension/popup.js` ‚Äî Logica do popup (conexao, config, operacoes)
- `apps/tribunais-extension/content.js` ‚Äî Script injetado em paginas de tribunais (deteccao de login, execucao de acoes)
- `apps/tribunais-extension/types.d.ts` ‚Äî Tipos TypeScript para documentacao do protocolo
- `apps/tribunais-extension/README.md` ‚Äî Documentacao da extensao
- `apps/tribunais-extension/icons/` ‚Äî Icones PNG em 16, 32, 48 e 128px

### Funcionalidades Implementadas
- Conexao WebSocket persistente com reconexao automatica
- Autenticacao com userId configurado
- Comandos: authenticate, request_interaction, execute_browser_action, request_signature
- Deteccao de tribunais: TJSP (ESAJ), TRF3 (PJe), PJe generico
- Notificacoes do Chrome para interacao do usuario
- Content script para deteccao de tela de login e certificado

### Decisoes Tomadas
- Manifest V3 para compatibilidade futura
- JavaScript puro (sem build) para simplicidade
- Keepalive com chrome.alarms para manter service worker ativo
- Tipos TypeScript apenas como documentacao (extensao roda JS)

### Proximos Passos
- Testar integracao com servidor WebSocket
- Implementar assinatura digital com certificado A3
- Adicionar mais tribunais na configuracao

---

## 2026-01-25 ‚Äî Integra√ß√£o Backend FastAPI com Servi√ßo de Tribunais

### Contexto
- Criar integra√ß√£o do servi√ßo de tribunais Node.js com o backend FastAPI do Iudex
- Permitir gerenciamento de credenciais, consultas de processos e peticionamento

### Arquivos Criados
- `apps/api/app/schemas/tribunais.py` ‚Äî Schemas Pydantic para request/response (enums, credenciais, opera√ß√µes, processo, webhooks)
- `apps/api/app/services/tribunais_client.py` ‚Äî Cliente HTTP ass√≠ncrono usando httpx para comunica√ß√£o com servi√ßo Node.js
- `apps/api/app/api/endpoints/tribunais.py` ‚Äî Endpoints FastAPI (credenciais, consultas, peticionamento)
- `apps/api/app/api/endpoints/webhooks.py` ‚Äî Handler de webhooks do servi√ßo de tribunais

### Arquivos Alterados
- `apps/api/app/api/routes.py` ‚Äî Adicionados routers de tribunais e webhooks
- `apps/api/app/core/config.py` ‚Äî Adicionadas configura√ß√µes TRIBUNAIS_SERVICE_URL e TRIBUNAIS_WEBHOOK_SECRET

### Endpoints Implementados
- `POST /api/tribunais/credentials/password` ‚Äî Criar credencial com senha
- `POST /api/tribunais/credentials/certificate-a1` ‚Äî Upload de certificado A1
- `POST /api/tribunais/credentials/certificate-a3-cloud` ‚Äî Registrar A3 na nuvem
- `POST /api/tribunais/credentials/certificate-a3-physical` ‚Äî Registrar A3 f√≠sico
- `GET /api/tribunais/credentials/{user_id}` ‚Äî Listar credenciais
- `DELETE /api/tribunais/credentials/{credential_id}` ‚Äî Remover credencial
- `GET /api/tribunais/processo/{credential_id}/{numero}` ‚Äî Consultar processo
- `GET /api/tribunais/processo/{credential_id}/{numero}/documentos` ‚Äî Listar documentos
- `GET /api/tribunais/processo/{credential_id}/{numero}/movimentacoes` ‚Äî Listar movimenta√ß√µes
- `POST /api/tribunais/operations/sync` ‚Äî Opera√ß√£o s√≠ncrona
- `POST /api/tribunais/operations/async` ‚Äî Opera√ß√£o ass√≠ncrona (fila)
- `GET /api/tribunais/operations/{job_id}` ‚Äî Status de opera√ß√£o
- `POST /api/tribunais/peticionar` ‚Äî Protocolar peti√ß√£o
- `POST /api/webhooks/tribunais` ‚Äî Webhook de notifica√ß√µes

### Decis√µes Tomadas
- Usar httpx (async) para comunica√ß√£o com servi√ßo Node.js
- Valida√ß√£o de ownership nas opera√ß√µes (userId deve corresponder ao usu√°rio autenticado)
- Webhooks processados em background para n√£o bloquear resposta
- Schemas com suporte a aliases (camelCase/snake_case) para compatibilidade

### Pr√≥ximos Passos
- Implementar notifica√ß√£o WebSocket ao receber webhooks
- Adicionar testes de integra√ß√£o
- Configurar webhook secret em produ√ß√£o

---

## 2026-01-24 ‚Äî Streaming SSE de √öltima Gera√ß√£o (step.* events)

### Contexto
- Implementar eventos SSE granulares (`step.*`) para criar UI de atividade consistente
- Padronizar todos os provedores (OpenAI, Gemini, Claude, Perplexity, Deep Research)
- Melhorar UX com chips de queries/fontes em tempo real durante streaming

### Arquivos Alterados

#### Backend
- `apps/api/app/services/ai/deep_research_service.py`:
  - Adicionado `_generate_step_id()` helper para IDs √∫nicos
  - Google non-Agent: `step.start`, extra√ß√£o de `grounding_metadata`, `step.done`
  - Google Agent (Interactions API): `step.start`, regex para queries/URLs, `step.done`
  - Perplexity Deep Research: `step.start`, `step.add_source` incremental, `step.done`

- `apps/api/app/services/ai/agent_clients.py`:
  - Adicionado `_extract_grounding_metadata()` helper para Gemini
  - Streaming loop emite `grounding_query` e `grounding_source`
  - Tracking de duplicatas com sets

- `apps/api/app/services/chat_service.py`:
  - Deep Research: propaga eventos `step.*` diretamente ao SSE
  - Gemini Chat: processa `grounding_query` ‚Üí `step.add_query`, `grounding_source` ‚Üí `step.add_source`
  - OpenAI Responses: handlers para `web_search_call.*` e `file_search_call.*`
  - Perplexity Chat: cita√ß√µes incrementais com `step.add_source`

#### Frontend
- `apps/web/src/stores/chat-store.ts`:
  - Handlers para `step.start`, `step.add_query`, `step.add_source`, `step.done`
  - Integra√ß√£o com `upsertActivityStep` existente
  - Acumula√ß√£o de citations no metadata

### Formato dos Eventos SSE
```json
{"type": "step.start", "step_name": "Pesquisando", "step_id": "a1b2c3d4"}
{"type": "step.add_query", "step_id": "a1b2c3d4", "query": "jurisprud√™ncia STF..."}
{"type": "step.add_source", "step_id": "a1b2c3d4", "source": {"title": "STF", "url": "https://..."}}
{"type": "step.done", "step_id": "a1b2c3d4"}
```

### Scores Atualizados
| Provider | Score Anterior | Score Atual |
|----------|----------------|-------------|
| Claude Extended Thinking | 9/10 | 9/10 (j√° excelente) |
| Perplexity Chat | 7/10 | 10/10 |
| Perplexity Deep Research | 7/10 | 10/10 |
| OpenAI Responses API | 7/10 | 10/10 |
| Gemini Chat | 6/10 | 10/10 |
| Gemini Deep Research | 8/10 | 10/10 |

### Decis√µes Tomadas
- Usamos `step_id` √∫nico (uuid[:8]) para permitir m√∫ltiplos steps simult√¢neos
- Grounding metadata extra√≠do tanto de snake_case quanto camelCase (compatibilidade SDK)
- `step.done` emitido mesmo em caso de erro para UI consistente
- Tracking de duplicatas com sets para evitar eventos repetidos

### Pr√≥ximos Passos
- Testar manualmente cada provider
- Verificar que ActivityPanel exibe chips corretamente
- Opcional: adicionar `step.start/done` para Claude thinking (baixa prioridade)

---

## 2026-01-24 ‚Äî Melhorias v2.28 no mlx_vomo.py (Valida√ß√£o e Sanitiza√ß√£o)

### Contexto
- An√°lise de documentos de transcri√ß√£o (`transcricao-1769147720947.docx` e `Bloco 01 - Urban√≠stico_UNIFICADO_FIDELIDADE.md`)
- Identificados problemas de truncamento em tabelas e texto durante chunking
- Headings duplicados (`#### ####`) e separadores inconsistentes

### Arquivos Alterados
- `mlx_vomo.py`:
  - **Novas fun√ß√µes de valida√ß√£o** (linhas 480-850):
    - `corrigir_headings_duplicados()`: Corrige `#### #### T√≠tulo` ‚Üí `#### T√≠tulo`
    - `padronizar_separadores()`: Remove ou padroniza `---`, `***`, `___`
    - `detectar_tabelas_em_par()`: Detecta pares üìã Quadro-s√≠ntese + üéØ Pegadinhas
    - `validar_celulas_tabela()`: Detecta truncamentos conhecidos (ex: "Comcobra", "onto")
    - `chunk_texto_seguro()`: Chunking inteligente que evita cortar tabelas
    - `validar_integridade_pos_merge()`: Valida√ß√£o completa p√≥s-merge
    - `sanitizar_markdown_final()`: Pipeline de sanitiza√ß√£o completo
  - **Melhorias em `_smart_chunk_with_overlap()`**:
    - Overlap 30% maior quando chunk cont√©m tabela
    - Prioriza corte ap√≥s pares de tabelas (üìã + üéØ)
    - Evita cortar no meio de tabelas
  - **Melhorias em `_add_table_to_doc()`**:
    - Novo par√¢metro `table_type` (quadro_sintese, pegadinhas, default)
    - Cores diferenciadas: azul para s√≠ntese, laranja para pegadinhas
    - Zebra striping (linhas alternadas)
    - Largura de colunas otimizada por tipo
  - **Integra√ß√£o em `save_as_word()`**:
    - Chama `sanitizar_markdown_final()` antes de converter
    - Chama `corrigir_tabelas_prematuras()` para reposicionar tabelas no lugar errado
    - Detecta tipo de tabela pelo heading anterior
  - **Nova fun√ß√£o `corrigir_tabelas_prematuras()`**:
    - Detecta quando tabela (üìã ou üéØ) aparece antes do conte√∫do terminar
    - Move automaticamente a tabela para DEPOIS do conte√∫do explicativo
    - Par√¢metros configur√°veis: `min_chars_apos_tabela=100`, `min_linhas_apos=2`
  - **Melhoria no prompt PROMPT_TABLE_APOSTILA**:
    - Adicionada se√ß√£o "ORDEM OBRIGAT√ìRIA: CONTE√öDO PRIMEIRO, TABELA DEPOIS"
    - Exemplos visuais de ERRADO vs CORRETO para guiar o LLM

### Comandos Executados
- `python3 -m py_compile mlx_vomo.py` ‚Äî ‚úÖ Sintaxe OK
- Testes unit√°rios das novas fun√ß√µes ‚Äî ‚úÖ Todos passaram

### Decis√µes Tomadas
- Usar overlap de 30% em vez de 15% para chunks com tabelas (mais seguro)
- Remover separadores horizontais por padr√£o (n√£o agregam valor no DOCX)
- Diferenciar visualmente tabelas de s√≠ntese (azul) e pegadinhas (laranja)
- Valida√ß√£o n√£o-bloqueante (log de warnings, n√£o raise)

### Pr√≥ximos Passos
- Testar com arquivos reais de transcri√ß√£o maiores
- Considerar adicionar √≠ndice remissivo de termos jur√≠dicos
- Avaliar necessidade de exporta√ß√£o PDF simult√¢nea

---

## 2026-01-24 ‚Äî Corre√ß√µes P1/P2 Neo4j Hybrid Mode (An√°lise Paralela)

### Contexto
- An√°lise paralela com 3 agentes identificou 5 issues no Neo4j hybrid mode
- P1 (Cr√≠tico): Falta valida√ß√£o contra colis√£o de labels estruturais (Entity, Document, Chunk)
- P2 (Moderado): Parsing de env vars inconsistente entre `config.py` e `neo4j_mvp.py`

### Arquivos Alterados
- `apps/api/app/services/rag/core/graph_hybrid.py`:
  - Adicionado `FORBIDDEN_LABELS = frozenset({"Entity", "Document", "Chunk", "Relationship"})`
  - `label_for_entity_type()` agora valida contra labels proibidos
  - Docstring expandida explicando as 4 valida√ß√µes aplicadas
- `apps/api/app/services/rag/core/neo4j_mvp.py`:
  - Adicionada fun√ß√£o `_env_bool()` local (consistente com `config.py`)
  - `from_env()` agora usa `_env_bool()` ao inv√©s de parsing inline
  - Defaults agora consistentes: `graph_hybrid_auto_schema=True`, outros `False`
- `apps/api/tests/test_graph_hybrid.py`:
  - Novo teste `test_label_for_entity_type_forbidden_labels()`
  - Valida que nenhum tipo mapeado colide com labels estruturais

### Comandos Executados
- `python tests/test_graph_hybrid.py` ‚Äî 4/4 testes passaram

### Resultados da An√°lise Paralela
1. **Agent 1 (argument_pack)**: Vers√£o produ√ß√£o (`argument_pack.py`) mais completa que patch GPT
2. **Agent 2 (usage patterns)**: 0 m√©todos quebrados no codebase
3. **Agent 3 (Neo4j integration)**: Score 8/10, 5 issues identificados (2 agora corrigidos)

### Corre√ß√µes Adicionais (P3)
- `graph_hybrid.py`: `migrate_hybrid_labels()` agora usa transa√ß√£o expl√≠cita
  - `session.begin_transaction()` para atomicidade
  - Rollback autom√°tico em caso de falha
  - Logging de resultado
- Removido `argument_pack_patched.py` (arquivo legado, vers√£o produ√ß√£o j√° completa)

### Pr√≥ximos Passos
- Testar ingest√£o real para validar Neo4j population

---

## 2026-01-24 ‚Äî Automa√ß√£o GraphRAG (Neo4j) na Ingest√£o + Modo H√≠brido

### Contexto
- Neo4j Aura configurado e conectado com schema correto (:Document, :Chunk, :Entity)
- GraphRAG n√£o estava sendo populado automaticamente durante ingest√£o de documentos
- Usu√°rio solicitou: "quero tudo automatizado"
- Revis√£o da implementa√ß√£o do modo h√≠brido (GPT) identificou whitelist incompleta

### Arquivos Alterados
- `apps/api/app/api/endpoints/rag.py` ‚Äî Adicionado integra√ß√£o autom√°tica com GraphRAG:
  - Import `os` para env vars
  - Helper `_should_ingest_to_graph()` ‚Äî verifica flag expl√≠cito ou `RAG_GRAPH_AUTO_INGEST`
  - Helper `_ingest_document_to_graph()` ‚Äî extrai entidades legais e ingere no Neo4j/NetworkX
  - Modificado `ingest_local()` ‚Äî chama graph ingest ap√≥s RAG ingest
  - Modificado `ingest_global()` ‚Äî chama graph ingest ap√≥s RAG ingest (se n√£o foi duplicado)
- `apps/api/app/services/rag/core/graph_hybrid.py` ‚Äî Expandida whitelist de tipos:
  - Adicionados: jurisprudencia, tese, documento, recurso, acordao, ministro, relator
  - Agora cobre todos os tipos do `EntityType` enum em `graph_rag.py`
- `apps/api/tests/test_graph_hybrid.py` ‚Äî Atualizado testes para novos tipos
- `apps/api/.env` ‚Äî Adicionado:
  - `RAG_GRAPH_AUTO_INGEST=true`
  - `RAG_GRAPH_HYBRID_MODE=true`
  - `RAG_GRAPH_HYBRID_AUTO_SCHEMA=true`

### Decis√µes Tomadas
- **Fail-safe**: Erros de graph ingest n√£o falham a ingest√£o RAG principal
- **Factory pattern**: Usa `get_knowledge_graph()` que seleciona Neo4j ou NetworkX baseado em `RAG_GRAPH_BACKEND`
- **Extra√ß√£o autom√°tica**: Usa `LegalEntityExtractor` para extrair leis, s√∫mulas, jurisprud√™ncia do texto
- **Modo h√≠brido completo**: Labels por tipo (:Entity:Lei, :Entity:Sumula, etc.) para todos os tipos jur√≠dicos
- **Argumentos opcionais**: Flag `extract_arguments` para extrair teses/fundamentos/conclus√µes

### Comandos Executados
- `python -m py_compile app/api/endpoints/rag.py` ‚Äî OK
- Import test ‚Äî OK
- Label test ‚Äî 9/9 testes passaram

### Pr√≥ximos Passos
- Testar ingest√£o real de documento e verificar popula√ß√£o no Neo4j
- Considerar criar endpoint de sincroniza√ß√£o retroativa (documentos j√° ingeridos ‚Üí graph)

---

## 2026-01-24 ‚Äî Commit Consolidado: RAG Quality 9.5/10

### Contexto
- Avaliacao inicial do sistema RAG: 8.5/10
- Implementacao de melhorias para atingir 9.5/10 usando 10 subagentes em paralelo

### Commit
- **Hash**: `ee66fb4`
- **Arquivos**: 42 alterados, 11.371 inser√ß√µes, 116 remo√ß√µes, 19 novos arquivos

### Entreg√°veis por Categoria

**Testes (414 novos):**
- `tests/rag/test_crag_gate.py` ‚Äî 66 testes CRAG gate
- `tests/rag/test_query_expansion.py` ‚Äî 65 testes query expansion
- `tests/rag/test_reranker.py` ‚Äî 53 testes reranker
- `tests/rag/test_qdrant_service.py` ‚Äî 58 testes Qdrant multi-tenant
- `tests/rag/test_opensearch_service.py` ‚Äî 57 testes OpenSearch BM25
- `tests/rag/fixtures.py` ‚Äî Mocks compartilhados com docs jur√≠dicos BR

**Documenta√ß√£o:**
- `docs/rag/ARCHITECTURE.md` ‚Äî Pipeline 10 est√°gios com Mermaid
- `docs/rag/CONFIG.md` ‚Äî 60+ vari√°veis de ambiente documentadas
- `docs/rag/API.md` ‚Äî 5 endpoints com exemplos Python/JS/cURL

**Resili√™ncia:**
- `services/rag/core/resilience.py` ‚Äî CircuitBreaker (CLOSED/OPEN/HALF_OPEN)
- `api/endpoints/health.py` ‚Äî Endpoint `/api/health/rag`

**Evals:**
- `evals/benchmarks/v1.0_legal_domain.jsonl` ‚Äî 87 queries jur√≠dicas
- `services/ai/rag_evaluator.py` ‚Äî M√©tricas legais (citation_coverage, temporal_validity)
- `.github/workflows/rag-eval.yml` ‚Äî CI/CD semanal + PR

**Performance:**
- `services/rag/core/budget_tracker.py` ‚Äî 50k tokens / 5 LLM calls por request
- `services/rag/core/reranker.py` ‚Äî preload() para eliminar cold start
- `services/rag/core/embeddings.py` ‚Äî 31 queries jur√≠dicas comuns pr√©-carregadas

**C√≥digo:**
- `services/rag/utils/env_helpers.py` ‚Äî Consolida√ß√£o de utilit√°rios duplicados
- `services/rag_context.py`, `rag_module.py` ‚Äî Marcados DEPRECATED

### Pr√≥ximos Passos Opcionais
- Configurar secrets GitHub (OPENAI_API_KEY, GOOGLE_API_KEY) para CI/CD
- Rodar `pytest tests/rag/ -v` para verificar todos os 414 testes
- Habilitar preload em staging: `RAG_PRELOAD_RERANKER=true`

---

## 2026-01-24 ‚Äî Budget Cap para RAG Request

### Contexto
- Implementar controle de custos para operacoes HyDE + multi-query no pipeline RAG
- Evitar gastos excessivos com chamadas LLM durante query expansion

### Arquivos Criados
- `apps/api/app/services/rag/core/budget_tracker.py` ‚Äî novo modulo para tracking de orcamento por request

### Arquivos Alterados
- `apps/api/app/services/rag/config.py` ‚Äî adicionadas configuracoes de budget (max_tokens_per_request, max_llm_calls_per_request, warn_at_budget_percent)
- `apps/api/app/services/rag/core/__init__.py` ‚Äî exporta novos componentes do BudgetTracker
- `apps/api/app/services/rag/core/query_expansion.py` ‚Äî integrado BudgetTracker nas funcoes expand_async, generate_hypothetical_document, generate_query_variants, rewrite_query e _call_gemini
- `apps/api/app/services/rag/pipeline/rag_pipeline.py` ‚Äî integrado BudgetTracker no search(), _stage_query_enhancement(), e PipelineTrace

### Comandos Executados
- `python -m py_compile` em todos arquivos alterados ‚Äî OK
- Testes de import e funcionalidade basica ‚Äî OK

### Decisoes Tomadas
- Usar estimativa baseada em caracteres para tokens (evitar dependencias pesadas de tokenizers)
- BudgetTracker como dataclass para facilitar serializacao e uso
- Integrar budget tracking opcional (graceful degradation se modulo nao disponivel)
- Adicionar budget_usage ao PipelineTrace para observabilidade completa

### Funcionalidades Implementadas
1. **BudgetTracker class**: Track tokens e LLM calls por request
2. **Budget config**: max_tokens=50000, max_llm_calls=5, warn_at=80%
3. **Integration points**: query expansion, HyDE, multi-query
4. **Observability**: Usage reports no trace output

### Proximos Passos
- Integrar com embedding tracking no vector search
- Adicionar metricas de budget ao dashboard
- Configurar alertas quando budget excedido

---

## 2026-01-23 ‚Äî Configura√ß√£o do Sistema de Mem√≥ria

### Contexto
- Implementar sistema de mem√≥ria persistente para Claude Code registrar trabalho e melhorar com feedback

### Arquivos Criados
- `CLAUDE.md` ‚Äî mem√≥ria principal do projeto
- `.claude/rules/testing.md` ‚Äî regras de testes
- `.claude/rules/code-style.md` ‚Äî estilo de c√≥digo
- `.claude/rules/security.md` ‚Äî regras de seguran√ßa
- `.claude/rules/api.md` ‚Äî regras da API
- `docs/AI_LOG.md` ‚Äî este arquivo
- `docs/LESSONS_LEARNED.md` ‚Äî li√ß√µes aprendidas

### Comandos Executados
- Nenhum comando de verifica√ß√£o necess√°rio (apenas cria√ß√£o de docs)

### Decis√µes Tomadas
- Estrutura modular com rules separadas por √°rea
- YAML frontmatter em api.md para aplicar s√≥ em apps/api/
- Log e lessons em docs/ para f√°cil acesso

### Pr√≥ximos Passos
- Aplicar estrutura nos demais projetos do Cursor
- Criar script de automa√ß√£o

---

## 2026-01-24 ‚Äî PR2 & PR3: Consolidate Tracing & Unify Pipeline

### Contexto
- Checklist RAG identificou duplica√ß√£o de tracing e m√∫ltiplos pipelines RAG

### PR2: Consolidate Tracing

**Arquivos Alterados:**
- `apps/api/app/services/rag/utils/trace.py` ‚Äî Adicionados 10 novos event types para compatibilidade
  - QUERY_REWRITE, HYDE_GENERATE, GRAPH_EXPAND, ARGUMENT_CONTEXT, CONTEXT_COMPRESS
  - FALLBACK, RAG_ROUTER_DECISION, PROMPT_FINAL, PARENT_CHILD_EXPAND, GENERIC
- `apps/api/app/services/rag/utils/trace.py` ‚Äî Adicionado suporte a conversation_id e message_id
- `apps/api/app/services/rag/utils/trace.py` ‚Äî Adicionada fun√ß√£o trace_event_legacy() para compatibilidade
- `apps/api/app/services/rag_trace.py` ‚Äî Convertido para wrapper que delega ao novo trace.py

**Resultado:**
- C√≥digo legado continua funcionando sem mudan√ßas (rag_trace.py √© wrapper)
- Novo c√≥digo pode usar trace.py diretamente com tipos estruturados
- Um √∫nico sistema de tracing com m√∫ltiplos canais (JSONL, OTel, LangSmith, DB)

### PR3: Unify RAG Pipeline

**Arquivos Criados:**
- `apps/api/app/services/rag/pipeline_adapter.py` ‚Äî Adapter unificado

**Estrat√©gia:**
- Flag `RAG_USE_NEW_PIPELINE` controla qual pipeline usar (default: legacy)
- Quando features espec√≠ficas s√£o necess√°rias (query rewrite com hist√≥rico, adaptive routing, argument graph), usa legacy automaticamente
- Quando poss√≠vel, delega para RAGPipeline novo

**Resultado:**
- API mant√©m compatibilidade total com build_rag_context()
- Novo c√≥digo pode usar build_rag_context_unified() com mesmo interface
- Migra√ß√£o gradual: teste com RAG_USE_NEW_PIPELINE=true quando pronto

### Comandos Executados
- `python -c "from app.services.rag.utils.trace import ..."` ‚Äî OK
- `python -c "from app.services.rag.pipeline_adapter import ..."` ‚Äî OK

### Pr√≥ximos Passos
- Testar com RAG_USE_NEW_PIPELINE=true em ambiente de staging
- Gradualmente migrar callers para usar build_rag_context_unified
- Quando validado, tornar novo pipeline o default

---

## 2026-01-24 ‚Äî Fix TTL Cleanup Field Mismatch (PR1 do checklist RAG)

### Contexto
- Checklist de qualidade RAG identificou que o TTL cleanup n√£o funcionava
- `ttl_cleanup.py` buscava campos inexistentes (`ingested_at`, `created_at`, `timestamp`)
- OpenSearch e Qdrant usam `uploaded_at` como campo de timestamp

### Arquivos Alterados
- `apps/api/app/services/rag/utils/ttl_cleanup.py` ‚Äî Corrigido para usar `uploaded_at`
  - OpenSearch: mudou query de `should` com 3 campos para `must` com `uploaded_at`
  - Qdrant: mudou `timestamp_fields` de 4 campos incorretos para `["uploaded_at"]`
- `apps/api/tests/test_ttl_cleanup.py` ‚Äî Criado novo arquivo com 8 testes unit√°rios

### Comandos Executados
- `python -m py_compile app/services/rag/utils/ttl_cleanup.py` ‚Äî OK
- `pytest tests/test_ttl_cleanup.py -v` ‚Äî 8 passed

### Decis√µes Tomadas
- Usar `must` em vez de `should` no OpenSearch (campo √© obrigat√≥rio, n√£o opcional)
- Teste de c√≥digo-fonte para validar que o campo correto est√° sendo usado (evita mocks complexos)

### Impacto
- **Antes**: TTL cleanup nunca deletava dados (buscava campos que n√£o existiam)
- **Depois**: Dados locais mais antigos que TTL (7 dias) ser√£o corretamente removidos

### Pr√≥ximos Passos (do checklist RAG)
- PR2: Consolidar tracing (`rag_trace.py` ‚Üí `trace.py`)
- PR3: Unificar pipeline (`build_rag_context()` ‚Üí `RAGPipeline`)

---

## 2026-01-24 ‚Äî Simplifica√ß√£o Painel Auditoria + DebateAuditPanel

### Contexto
- Painel de auditoria do Canvas tinha componentes redundantes
- Faltava visibilidade completa dos debates entre agentes no LangGraph

### Arquivos Alterados

**Simplifica√ß√£o do QualityPanel (transcri√ß√£o):**
- `apps/web/src/components/dashboard/quality-panel.tsx`
  - Removidos bot√µes "Validar Fidelidade", "S√≥ Estrutural", "Gerar Sugest√µes (IA)"
  - Mantido apenas "Valida√ß√£o Completa" (HIL Unificado)
  - Removidas fun√ß√µes n√£o utilizadas (handleValidate, handleAnalyzeStructure, handleSemanticSuggestions)
  - Removidos states n√£o utilizados (isValidating, isAnalyzing)

**Ajustes nos pain√©is de Quality Gate e HIL:**
- `apps/web/src/components/dashboard/quality-gate-panel.tsx`
  - Removido defaultValue do accordion (fechado por padr√£o)
  - Adicionado card "Cobertura refs" com percentual
  - Grid agora tem 4 colunas: Compress√£o, Cobertura refs, Refs omitidas, Checks

- `apps/api/app/services/ai/quality_gate.py`
  - Adicionado campo `reference_coverage: float` ao dataclass QualityGateResult
  - Retorna coverage no resultado e no gate_results do n√≥

**Novo componente DebateAuditPanel:**
- `apps/web/src/components/dashboard/debate-audit-panel.tsx` (novo)
  - Mostra drafts completos de cada modelo
  - Exibe diverg√™ncias detalhadas por se√ß√£o
  - Lista issues da cr√≠tica do comit√™
  - Mostra decis√µes do merge (Judge)
  - Exibe risk flags e claims pendentes
  - Accordion com se√ß√µes divergentes abertas por padr√£o

- `apps/web/src/components/dashboard/canvas-container.tsx`
  - Adicionado import e uso do DebateAuditPanel na aba Auditoria

### Comandos Executados
- `npm -w apps/web run type-check` ‚Äî OK
- `python -c "from app.services.ai.quality_gate import ..."` ‚Äî OK

### Decis√µes Tomadas
- HIL Unificado √© o mais completo (diff + corre√ß√£o determin√≠stica + sem√¢ntica)
- PreventiveAuditPanel e QualityPanel removidos do Canvas (espec√≠ficos para transcri√ß√£o)
- DebateAuditPanel permite auditoria completa dos debates multi-agente

### Estrutura Final Aba Auditoria (Canvas)
```
1. Cabe√ßalho Compliance + Risk Badge
2. QualityGatePanel (compress√£o, cobertura, refs omitidas)
3. HilChecklistPanel (10 fatores de risco)
4. Relat√≥rio de Conformidade (Markdown)
5. Tabela de Cita√ß√µes
6. DebateAuditPanel (drafts, diverg√™ncias, cr√≠ticas, merge)
7. HilHistoryPanel (hist√≥rico de intera√ß√µes humanas)
8. AuditIssuesPanel (se houver issues)
```

---

## 2026-01-24 ‚Äî Hist√≥rico de Intera√ß√µes HIL

### Contexto
- Intera√ß√µes HIL (Human-in-the-Loop) n√£o estavam sendo registradas para auditoria
- Faltava hist√≥rico de aprova√ß√µes, edi√ß√µes e instru√ß√µes dadas ao agente

### Arquivos Alterados

**Backend:**
- `apps/api/app/services/ai/langgraph_legal_workflow.py`
  - Adicionado campo `hil_history: List[Dict[str, Any]]` ao DocumentState

- `apps/api/app/api/endpoints/jobs.py`
  - Endpoint `/resume` agora captura conte√∫do original antes de resumir
  - Cria entrada de hist√≥rico com: id, timestamp, checkpoint, user, decis√£o, conte√∫do antes/depois, instru√ß√µes, proposta
  - Inclui `hil_history` no resume_payload para persistir no state
  - Evento `hil_response` agora inclui `hil_entry` completo
  - Evento `done` agora inclui `hil_history`, `processed_sections`, `has_any_divergence`, `divergence_summary`

**Frontend:**
- `apps/web/src/components/dashboard/hil-history-panel.tsx` (novo)
  - Exibe hist√≥rico de todas as intera√ß√µes HIL
  - Cards com: checkpoint, timestamp, usu√°rio, decis√£o
  - Mostra instru√ß√µes dadas ao agente
  - Mostra proposta do usu√°rio (quando rejeita)
  - Diff visual entre conte√∫do original e editado
  - Ordenado por timestamp (mais recente primeiro)

- `apps/web/src/components/dashboard/canvas-container.tsx`
  - Adicionado import e uso do HilHistoryPanel na aba Auditoria

### Estrutura de uma entrada HIL
```json
{
  "id": "uuid",
  "timestamp": "2026-01-24T10:30:00Z",
  "checkpoint": "section",
  "section_title": "Dos Fatos",
  "user_id": "user_123",
  "user_email": "user@example.com",
  "decision": "edited",
  "approved": true,
  "original_content": "...",
  "edited_content": "...",
  "instructions": "...",
  "proposal": "...",
  "iteration": 1
}
```

### Comandos Executados
- `npm -w apps/web run type-check` ‚Äî OK
- `python -m py_compile app/api/endpoints/jobs.py` ‚Äî OK

---

## 2026-01-24 ‚Äî CaseState Enxuto e Audit√°vel

### Contexto
- Codebase precisava de um estado m√≠nimo (CaseState) audit√°vel
- LangGraph DocumentState tinha 90% dos campos necess√°rios mas n√£o era persistido
- Faltavam: tasks[], partes, cnj_number normalizado

### Arquivos Criados
- `apps/api/app/models/workflow_state.py` ‚Äî Persiste DocumentState do LangGraph
  - sources[], citations_map (retrieval)
  - drafts_history, hil_history (vers√µes)
  - routing_decisions, alert_decisions, citation_decisions, audit_decisions, quality_decisions (decisions_log)
  - M√©todo `from_document_state()` para converter do LangGraph

- `apps/api/app/models/case_task.py` ‚Äî Tarefas derivadas com prazos
  - Campos: deadline, priority, status, task_type
  - Sources: manual, djen, workflow, ai_suggested
  - M√©todos: `from_djen_intimation()`, `from_workflow_suggestion()`

- `apps/api/alembic/versions/d3a4f8c9e2b1_add_workflow_state_case_tasks.py` ‚Äî Migra√ß√£o

### Arquivos Alterados
- `apps/api/app/models/case.py`
  - Adicionado `cnj_number` (normalizado no padr√£o CNJ)
  - Adicionado `classe` (classe processual)
  - Adicionado `assunto` (assunto principal)
  - Adicionado `partes` (JSONB com autor, r√©u, terceiros, advogados)
  - M√©todos: `normalize_cnj()`, `add_parte()`, `get_partes_resumo()`

- `apps/api/app/models/__init__.py`
  - Adicionados exports dos novos modelos

- `apps/api/app/api/endpoints/jobs.py`
  - Import de `WorkflowState` e `AsyncSessionLocal`
  - Fun√ß√£o `persist_workflow_state()` para persist√™ncia em background
  - Chamada via `asyncio.create_task()` no evento "done"

### Estrutura Final do CaseState

```
Case (DB)
‚îú‚îÄ‚îÄ cnj_number (normalizado)
‚îú‚îÄ‚îÄ partes (JSONB: autor, r√©u, terceiros)
‚îú‚îÄ‚îÄ classe, assunto, tribunal
‚îî‚îÄ‚îÄ tasks[] ‚Üí CaseTask

WorkflowState (DB) ‚Äî Persistido ap√≥s workflow
‚îú‚îÄ‚îÄ sources[] (documentos recuperados)
‚îú‚îÄ‚îÄ retrieval_queries[]
‚îú‚îÄ‚îÄ citations_map
‚îú‚îÄ‚îÄ drafts_history[]
‚îú‚îÄ‚îÄ hil_history[]
‚îú‚îÄ‚îÄ processed_sections[]
‚îî‚îÄ‚îÄ decisions (routing, alerts, citations, audit, quality)
```

### Comandos Executados
- `python -m py_compile ...` ‚Äî OK para todos os arquivos

### Pr√≥ximos Passos
- ~~Rodar migra√ß√£o: `alembic upgrade head`~~ ‚úÖ
- ~~Criar endpoints REST para consultar WorkflowState e CaseTasks~~ ‚úÖ
- Integrar cria√ß√£o autom√°tica de tasks a partir do DJEN

### Endpoints REST Criados (v5.7)

**WorkflowState:**
- `GET /audit/workflow-states` ‚Äî Lista estados de workflow do usu√°rio
- `GET /audit/workflow-states/{id}` ‚Äî Detalhes completos (auditoria)
- `GET /audit/workflow-states/by-job/{job_id}` ‚Äî Busca por job
- `GET /audit/workflow-states/{id}/sources` ‚Äî Fontes recuperadas
- `GET /audit/workflow-states/{id}/decisions` ‚Äî Decis√µes do workflow
- `GET /audit/workflow-states/{id}/hil-history` ‚Äî Hist√≥rico HIL

**CaseTasks:**
- `GET /audit/tasks` ‚Äî Lista tarefas (filtros: case, status, priority, overdue)
- `GET /audit/tasks/{id}` ‚Äî Detalhes da tarefa
- `POST /audit/tasks` ‚Äî Criar tarefa manual
- `PATCH /audit/tasks/{id}` ‚Äî Atualizar tarefa
- `DELETE /audit/tasks/{id}` ‚Äî Deletar tarefa

**Summary:**
- `GET /audit/summary` ‚Äî Resumo para dashboard

---

## 2026-01-24 ‚Äî Auditoria Detalhada no GeneratorWizard

### Contexto
- A p√°gina de gera√ß√£o de pe√ßas (`/cases/[id]` aba Generation) usava `GeneratorWizard`
- Este componente n√£o tinha os novos pain√©is de auditoria criados para o CanvasContainer
- Usu√°rio pediu para preservar a UI existente e incorporar o painel completo de auditoria

### Arquivos Alterados
- `apps/web/src/components/dashboard/generator-wizard.tsx`
  - Adicionados imports: QualityGatePanel, HilChecklistPanel, DebateAuditPanel, HilHistoryPanel
  - Adicionada se√ß√£o expand√≠vel "Auditoria Detalhada" ap√≥s os pain√©is existentes (JobQualityPanel, etc.)
  - Accordion colaps√°vel com todos os 4 pain√©is de auditoria

### Estrutura Adicionada
```tsx
<Accordion type="single" collapsible>
    <AccordionItem value="audit-details">
        <AccordionTrigger>
            Auditoria Detalhada [Badge: Compliance & HIL]
        </AccordionTrigger>
        <AccordionContent>
            1. QualityGatePanel (compress√£o, cobertura, refs omitidas)
            2. HilChecklistPanel (10 fatores de risco)
            3. DebateAuditPanel (drafts, diverg√™ncias, cr√≠ticas, merge)
            4. HilHistoryPanel (hist√≥rico de intera√ß√µes humanas)
        </AccordionContent>
    </AccordionItem>
</Accordion>
```

### Comandos Executados
- `npm -w apps/web run type-check` ‚Äî OK

### Decis√µes Tomadas
- Se√ß√£o expand√≠vel preserva UI limpa por padr√£o
- Accordion colaps√°vel n√£o atrapalha fluxo de gera√ß√£o
- Mesmos pain√©is do CanvasContainer para consist√™ncia

---

## 2026-01-24 ‚Äî B2 Citer/Verifier Node (Gate Pr√©-Debate)

### Contexto
- An√°lise comparativa entre arquitetura proposta (Times A/B) e fluxo LangGraph atual
- Identificado gap: verifica√ß√£o de rastreabilidade afirma√ß√£o‚Üífonte era parcial (policy [n], retry need_juris)
- Implementado B2 Citer/Verifier como gate obrigat√≥rio entre pesquisa e debate

### Arquivos Criados
- `apps/api/app/services/ai/citer_verifier.py` ‚Äî N√≥ B2 completo com:
  - Extra√ß√£o de afirma√ß√µes jur√≠dicas via LLM
  - Mapeamento para fontes RAG e citations_map
  - Tags [VERIFICAR] em claims sem fonte
  - Decis√£o de force_hil (coverage < 60%) e block_debate (coverage < 30%)

### Arquivos Alterados
- `apps/api/app/services/ai/langgraph_legal_workflow.py`:
  - Adicionado import do citer_verifier_node
  - Adicionados campos ao DocumentState: citer_verifier_result, verified_context, citer_verifier_force_hil, citer_verifier_coverage, citer_verifier_critical_gaps, citer_min_coverage
  - Registrado n√≥ no workflow
  - Alterada edge: fact_check ‚Üí citer_verifier ‚Üí debate (com router condicional)
  - Atualizado docstring do m√≥dulo

### Fluxo Atualizado
```
fact_check ‚Üí citer_verifier ‚Üí [coverage >= 0.3] ‚Üí debate
                            ‚Üí [coverage < 0.3] ‚Üí divergence_hil (skip debate)
```

### Comandos Executados
- `python -m py_compile apps/api/app/services/ai/citer_verifier.py` ‚Äî OK
- `python -c "from app.services.ai.langgraph_legal_workflow import legal_workflow_app"` ‚Äî OK

### Decis√µes Tomadas
- Arquivo separado (citer_verifier.py) para modularidade
- Coverage m√≠nimo padr√£o de 60% (configur√°vel via citer_min_coverage)
- Block debate se coverage < 30% (muito baixo para gerar conte√∫do confi√°vel)
- Router condicional permite skip do debate em casos cr√≠ticos

### Pr√≥ximos Passos
- Testes unit√°rios para citer_verifier_node
- UI para exibir resultado da verifica√ß√£o (coverage, claims verificados/n√£o verificados)
- Considerar Time A (Monitoramento) como pr√≥ximo gap a implementar

---

## 2026-01-24 ‚Äî Documentacao Completa do RAG Pipeline

### Contexto
- Solicitacao de criar pacote de documentacao abrangente para o sistema RAG
- Consolidar informacoes dispersas em codigo e arquivos existentes

### Arquivos Criados
- `docs/rag/ARCHITECTURE.md` ‚Äî Arquitetura do pipeline de 10 estagios
  - Diagrama Mermaid do fluxo completo
  - Descricao detalhada de cada estagio (Query Enhancement, Lexical, Vector, Merge, CRAG, Rerank, Expand, Compress, Graph, Trace)
  - Modelo de seguranca multi-tenant
  - Feature flags e otimizacoes

- `docs/rag/CONFIG.md` ‚Äî Referencia completa de configuracao
  - Todas as 60+ variaveis de ambiente documentadas
  - Agrupadas por categoria (Feature Flags, CRAG, Query Expansion, Reranking, Compression, Storage, Tracing)
  - Valores padrao, ranges validos e exemplos

- `docs/rag/API.md` ‚Äî Documentacao da API REST
  - 5 endpoints: search, ingest/local, ingest/global, delete, stats
  - Request/response schemas com exemplos
  - Codigos de erro e rate limiting
  - Exemplos em Python, JavaScript e cURL

### Arquivos Lidos para Extracao de Informacao
- `apps/api/app/services/rag/config.py` ‚Äî Todas as configuracoes
- `apps/api/app/services/rag/pipeline/rag_pipeline.py` ‚Äî Logica do pipeline
- `apps/api/app/api/endpoints/rag.py` ‚Äî Endpoints da API
- `rag.md` ‚Äî Material de referencia (livro RAG)

### Comandos Executados
- `mkdir -p docs/rag` ‚Äî Criar diretorio

### Decisoes Tomadas
- Documentacao em Portugues (idioma do projeto)
- Mermaid para diagramas (suportado pelo GitHub)
- Organizacao em 3 arquivos separados por publico (arquitetura, ops/config, devs/API)
- Incluir referencias a papers originais (RAG, CRAG, HyDE, RRF)

### Proximos Passos
- Criar testes de validacao da documentacao (links, exemplos)
- Adicionar documentacao de GraphRAG quando Neo4j for expandido
- Criar guia de troubleshooting

---

## 2026-01-24 ‚Äî Consolidacao RAG: Remocao de Shims e Extracao de Utilitarios

### Contexto
- Codigo RAG tinha duplicacao de funcoes utilitarias (env_bool, env_int, env_float)
- Shims `rag_context.py` e `rag_module.py` delegavam para implementacoes reais
- Arquivos importavam dos shims em vez de importar diretamente

### Arquivos Criados
- `apps/api/app/services/rag/utils/env_helpers.py` ‚Äî Funcoes utilitarias extraidas
  - `env_bool()` ‚Äî Parse de boolean de variavel de ambiente
  - `env_int()` ‚Äî Parse de int de variavel de ambiente
  - `env_float()` ‚Äî Parse de float de variavel de ambiente

### Arquivos Alterados

**Fase 1: Atualizacao de imports para usar implementacoes reais:**
- `apps/api/app/api/endpoints/chats.py`
  - `from app.services.rag.pipeline_adapter import build_rag_context_unified as build_rag_context`
- `apps/api/app/services/chat_service.py`
  - `from app.services.rag.pipeline_adapter import build_rag_context_unified as build_rag_context`
- `apps/api/app/services/ai/langgraph_legal_workflow.py`
  - `from app.services.rag_module_old import create_rag_manager, get_scoped_knowledge_graph`
- `apps/api/app/services/document_generator.py`
  - `from app.services.rag_module_old import RAGManager, create_rag_manager`
- `apps/api/app/api/endpoints/admin_rag.py`
  - `from app.services.rag_module_old import create_rag_manager`
- `apps/api/app/api/endpoints/advanced.py`
  - `from app.services.rag_module_old import RAGManager`
- `apps/api/app/services/ai/orchestrator.py`
  - `from app.services.rag_module_old import create_rag_manager`
- `apps/api/app/services/rag/pipeline/rag_pipeline.py`
  - `from app.services.rag_module_old import get_scoped_knowledge_graph`

**Fase 2: Extracao de utilitarios duplicados:**
- `apps/api/app/services/rag_context_legacy.py`
  - Removidas funcoes locais `_env_bool`, `_env_int`, `_env_float`
  - Importa de `app.services.rag.utils.env_helpers`
- `apps/api/app/services/rag/pipeline_adapter.py`
  - Removidas funcoes locais `_env_bool`, `_env_int`, `_env_float`
  - Importa de `app.services.rag.utils.env_helpers`
- `apps/api/app/services/rag/pipeline/rag_pipeline.py`
  - Removidas funcoes locais `_env_bool`, `_env_int`
  - Importa de `app.services.rag.utils.env_helpers`
- `apps/api/app/services/rag/utils/__init__.py`
  - Adicionados exports de `env_bool`, `env_int`, `env_float`

**Atualizacao de documentacao dos shims:**
- `apps/api/app/services/rag_context.py` ‚Äî Marcado como DEPRECATED com imports preferidos
- `apps/api/app/services/rag_module.py` ‚Äî Marcado como DEPRECATED com imports preferidos

### Comandos Executados
- `python -c "from app.services.rag.utils.env_helpers import ..."` ‚Äî OK
- `python -c "from app.services.rag.pipeline_adapter import ..."` ‚Äî OK
- `python -c "from app.services.rag_context import ..."` ‚Äî OK (shim ainda funciona)
- `python -c "from app.services.rag_module import ..."` ‚Äî OK (shim ainda funciona)
- `python -c "import app.api.endpoints.chats; ..."` ‚Äî OK (todos modulos modificados)

### Decisoes Tomadas
- Shims mantidos para compatibilidade (marcados como deprecated)
- Imports diretos usam `rag_module_old` e `rag.pipeline_adapter`
- Funcoes utilitarias centralizadas em `rag/utils/env_helpers.py`
- Alias `_env_bool` mantido nos arquivos para minimizar mudancas internas

### Resultado
- **Antes**: 3 copias de `_env_bool`, `_env_int`, `_env_float`
- **Depois**: 1 implementacao em `env_helpers.py`, importada por 3 arquivos
- Shims continuam funcionando para codigo legado
- Novo codigo deve importar diretamente das implementacoes reais

---

## 2026-01-24 ‚Äî Preload Strategy para Reranker e Embeddings

### Contexto
- Cold start latency no reranker model impactava primeira requisicao RAG
- Necessidade de eliminar latencia inicial carregando modelos no startup

### Arquivos Alterados
- `apps/api/app/services/rag/core/reranker.py`
  - Adicionado metodo `preload()` que carrega modelo e executa warmup inference
  - Adicionado metodo `is_preloaded()` para verificar status
  - Warmup usa query e documento juridico real em portugues

- `apps/api/app/services/rag/core/embeddings.py`
  - Adicionada lista `COMMON_LEGAL_QUERIES` com 31 queries juridicas comuns
  - Adicionada funcao `preload_embeddings_cache()` para pre-carregar embeddings
  - Adicionada funcao `is_embeddings_service_ready()` para verificar status

- `apps/api/app/main.py`
  - Adicionada funcao async `_preload_rag_models()` no lifespan
  - Preload executado em thread pool para nao bloquear event loop
  - Configuravel via `RAG_PRELOAD_RERANKER=true` e `RAG_PRELOAD_EMBEDDINGS=true`

### Variaveis de Ambiente
```bash
# Habilitar preload do reranker (cross-encoder model)
RAG_PRELOAD_RERANKER=true

# Habilitar preload de embeddings de queries juridicas comuns
RAG_PRELOAD_EMBEDDINGS=true
```

### Comandos Executados
- `python -m py_compile app/main.py app/services/rag/core/reranker.py app/services/rag/core/embeddings.py` ‚Äî OK

### Decisoes Tomadas
- Preload via run_in_executor para nao bloquear startup
- Configuracao opt-in via env vars (padrao false)
- Queries de warmup em portugues juridico para otimizar cache hit rate
- Log de tempo de carga para monitoramento

### Impacto
- **Antes**: Primeira query RAG tinha latencia adicional de 2-5s para carregar modelo
- **Depois**: Modelos carregados no startup, primeira query sem cold start

---

## 2026-01-24 ‚Äî CI/CD Integration para RAG Evaluation Automatizada

### Contexto
- Necessidade de automatizar avaliacao de qualidade do sistema RAG
- Workflow CI/CD para validar thresholds de metricas em PRs e pushes
- Execucao semanal completa com metricas LLM

### Arquivos Criados
- `.github/workflows/rag-eval.yml` ‚Äî Workflow principal com:
  - Triggers: push/PR em paths RAG, schedule semanal (Monday 6am UTC), workflow_dispatch manual
  - Job `evaluate`: metricas basicas (context_precision, context_recall)
  - Job `weekly-full-eval`: metricas completas incluindo LLM (faithfulness, answer_relevancy)
  - Thresholds: context_precision >= 0.70, context_recall >= 0.65
  - Comentario automatico em PRs com resultados
  - Upload de artefatos (30 dias para PRs, 90 dias para weekly)

- `evals/benchmarks/v1.0_legal_domain.jsonl` ‚Äî Dataset de benchmark juridico
  - 12 queries cobrindo Lei, Jurisprudencia, Doutrina
  - Topicos: licitacao, sumulas STJ, prisao preventiva, contratos admin, prescricao, dano moral coletivo, habeas corpus, desconsideracao PJ, dolo/culpa, modulacao STF, principios admin, reserva do possivel

- `evals/scripts/run_eval.sh` ‚Äî Script para execucao local
  - Opcoes: --dataset, --top-k, --with-llm, --persist-db, --min-precision, --min-recall
  - Timestamp automatico no output
  - Geracao de report se eval_report.py existir

- `evals/results/.gitkeep` ‚Äî Placeholder para diretorio de resultados

### Arquivos Alterados
- `eval_rag.py` ‚Äî Adicionado alias `--output` para `--out` (compatibilidade CI)
- `.gitignore` ‚Äî Adicionadas regras para ignorar resultados de avaliacao (exceto .gitkeep)

### Arquivos Removidos
- `.github/workflows/rag_eval.yml` ‚Äî Removido (substituido pelo novo rag-eval.yml mais completo)

### Comandos Executados
- `mkdir -p evals/benchmarks evals/scripts evals/results` ‚Äî OK
- `chmod +x evals/scripts/run_eval.sh` ‚Äî OK

### Decisoes Tomadas
- Workflow dispatch manual para flexibilidade em testes
- Schedule semanal com metricas LLM (mais caro, mas completo)
- Thresholds conservadores inicialmente (70%/65%) para permitir baseline
- Comentario em PR usa GitHub Script para melhor formatacao
- Artefatos de weekly com 90 dias para analise de tendencias

### Proximos Passos
- Adicionar mais queries ao benchmark conforme casos de uso reais
- Configurar secrets no GitHub (OPENAI_API_KEY, GOOGLE_API_KEY)
- Ajustar thresholds apos baseline estabelecido
- Integrar com dashboard de observabilidade

---

## 2026-01-24 ‚Äî Legal Domain RAG Evaluation Metrics

### Contexto
- Necessidade de metricas de avaliacao especificas para dominio juridico brasileiro
- Metricas RAGAS padrao nao capturam nuances legais (citacoes, vigencia temporal, jurisdicao)
- Implementacao de avaliador complementar ao RAGAS existente

### Arquivos Criados
- `apps/api/app/services/ai/rag_evaluator.py` ‚Äî Modulo completo com:
  - `LegalEvalResult` dataclass para resultados de avaliacao
  - `extract_legal_claims()` ‚Äî Extrai afirmacoes juridicas do texto
  - `count_cited_claims()` ‚Äî Conta claims com citacoes
  - `evaluate_citation_coverage()` ‚Äî % de claims com fonte atribuida
  - `extract_cited_laws()` ‚Äî Extrai referencias legais (Lei, Decreto, MP, LC, etc.)
  - `is_law_current()` ‚Äî Verifica se lei ainda esta em vigor (database de leis revogadas)
  - `evaluate_temporal_validity()` ‚Äî % de leis citadas ainda vigentes
  - `evaluate_jurisdiction_match()` ‚Äî Verifica se jurisdicao esta correta
  - `extract_legal_entities()` ‚Äî Extrai entidades por tipo (laws, articles, sumulas, decisions)
  - `evaluate_entity_accuracy()` ‚Äî Precision/recall de entidades extraidas
  - `evaluate_legal_answer()` ‚Äî Executa todas as avaliacoes em uma resposta
  - `add_legal_metrics_to_ragas()` ‚Äî Integra metricas legais aos resultados RAGAS
  - `evaluate_legal_batch()` ‚Äî Avalia batch de amostras

### Padroes Regex Implementados
- Leis: Lei, LC, Decreto, Decreto-Lei, MP, Resolucao, IN, Portaria
- Codigos: CF, CPC, CPP, CTN, CDC, CLT, ECA
- Artigos: Art. X, Art. X, caput, Art. X, I, Art. X, ¬ß 1¬∫
- Sumulas: Sumula X TST/STF/STJ, Sumula Vinculante X, OJ X SDI
- Decisoes: RE, REsp, ADI, HC, MS + numeros CNJ

### Database de Leis Revogadas
- Lei 8.666/93 ‚Äî parcialmente revogada (Lei 14.133/2021)
- Lei 10.520/2002 ‚Äî revogada (Lei 14.133/2021)
- MP 927/2020 ‚Äî perdeu eficacia (nao convertida)
- MP 936/2020 ‚Äî convertida (Lei 14.020/2020)
- Decreto-Lei 200/67 ‚Äî parcialmente vigente

### Metricas Implementadas
1. **Citation Coverage** (0-1): % de claims juridicos com citacao
2. **Temporal Validity** (0-1): % de leis citadas em vigor
3. **Jurisdiction Match** (bool): Jurisdicao correta (federal, estadual, municipal, trabalhista)
4. **Entity Precision** (0-1): Entidades corretas / entidades encontradas
5. **Entity Recall** (0-1): Entidades encontradas / entidades esperadas
6. **Legal Score** (0-1): Media ponderada (25% cit + 20% temp + 15% jur + 20% prec + 20% rec)

### Comandos Executados
- `python -m py_compile apps/api/app/services/ai/rag_evaluator.py` ‚Äî OK
- Testes unitarios inline ‚Äî 10/10 passaram

### Integracao com eval_rag.py
- Funcao `add_legal_metrics_to_ragas()` adiciona metricas legais ao payload existente
- Pode ser chamada apos `ragas.evaluate()` para enriquecer resultados
- Adiciona campos `legal_*` ao summary e `legal_metrics` a cada sample

### Proximos Passos
- Integrar chamada ao rag_evaluator no eval_rag.py principal
- Adicionar queries com expected_entities ao benchmark
- Criar dashboard de metricas legais
- Expandir database de leis revogadas

---

## 2026-01-24 ‚Äî Testes Unitarios RAG Pipeline Core

### Contexto
- Componentes core do RAG pipeline (CRAG gate, query expansion, reranker) sem cobertura de testes
- Necessidade de testes que nao dependam de conexoes reais (OpenSearch, Qdrant)
- Uso de mocks para simular comportamentos

### Arquivos Criados

**Estrutura de testes:**
- `apps/api/tests/rag/__init__.py` ‚Äî Pacote de testes RAG
- `apps/api/tests/rag/fixtures.py` ‚Äî Fixtures e mocks compartilhados
  - Mock OpenSearch client responses
  - Mock Qdrant client responses
  - Mock embedding responses
  - Sample legal documents (legislacao, jurisprudencia)
  - Sample queries with expected results
  - Helper functions para assertions

**Testes CRAG Gate (66 testes):**
- `apps/api/tests/rag/test_crag_gate.py`
  - TestCRAGConfig: default values, overrides, from_rag_config
  - TestEvidenceLevel: classification properties, confidence scores
  - TestCRAGEvaluation: serialization, reason property
  - TestCRAGGateClassification: STRONG/MODERATE/LOW/INSUFFICIENT evidence
  - TestCRAGGateDecisions: pass/fail thresholds
  - TestCRAGGateRecommendedActions: strategies por evidence level
  - TestRetryStrategyBuilder: strategies for each evidence level
  - TestCRAGOrchestrator: evaluate, should_retry, get_retry_parameters
  - TestCRAGAuditTrail: create, add_action, finalize, serialization
  - TestCRAGIntegration: search_with_correction, dedupe
  - TestConvenienceFunctions: evaluate_crag_gate, get_retry_strategy
  - TestEdgeCases: single result, negative scores, missing fields

**Testes Query Expansion (65 testes):**
- `apps/api/tests/rag/test_query_expansion.py`
  - TestQueryExpansionConfig: default values, from_rag_config
  - TestTTLCache: get/set, expiration, eviction, stats
  - TestRRFScore: score calculation, rank ordering
  - TestMergeResultsRRF: dedup, fusion boost, top_k
  - TestMergeLexicalVectorRRF: hybrid results, weighted fusion
  - TestLegalAbbreviationExpansion: STF, STJ, CPC, CLT, CF expansion
  - TestQueryExpansionService: cache, heuristic variants
  - TestQueryExpansionServiceWithMockedLLM: HyDE, multi-query, advanced search
  - TestSingletonFactory: get_instance, reset
  - TestEdgeCases: unicode, special characters, LLM failure

**Testes Reranker (53 testes):**
- `apps/api/tests/rag/test_reranker.py`
  - TestRerankerConfig: default values, from_rag_config
  - TestRerankerResult: creation, bool, len, iter
  - TestPortugueseLegalDomainBoost: art, sumula, tribunals, CNJ, lei patterns
  - TestCrossEncoderRerankerCore: empty results, score preservation
  - TestBatchProcessing: multiple queries, top_k
  - TestTextTruncation: short, long, word boundary, empty
  - TestLazyLoading: model not loaded on init, loaded on use
  - TestFallbackBehavior: fallback model, original order
  - TestScoreNormalization: negative scores, min_score filter
  - TestConvenienceFunctions: rerank, rerank_with_metadata
  - TestSingletonPattern: get_instance, reset, cache
  - TestEdgeCases: missing text, empty text, different field names
  - TestLegalDomainIntegration: boost affects ranking

### Comandos Executados
- `pytest tests/rag/test_crag_gate.py -v -o "addopts="` ‚Äî 66 passed
- `pytest tests/rag/test_query_expansion.py -v -o "addopts="` ‚Äî 65 passed
- `pytest tests/rag/test_reranker.py -v -o "addopts="` ‚Äî 53 passed
- `pytest tests/rag/ -v -o "addopts="` ‚Äî 299 passed total

### Decisoes Tomadas
- Fixtures em arquivo separado para reutilizacao
- Mocks de CrossEncoder, OpenSearch, Qdrant para evitar dependencias externas
- Testes de edge cases para robustez
- Documentacao brasileira nos samples (legislacao, jurisprudencia)
- Patterns de domain boost para portugues juridico

### Cobertura de Testes
- **CRAG Gate**: evidence classification, gate decisions, retry strategies, audit trail
- **Query Expansion**: TTL cache, RRF fusion, legal abbreviations, HyDE, multi-query
- **Reranker**: legal domain boost, batch processing, lazy loading, fallback behavior

### Proximos Passos
- Integrar testes ao CI/CD pipeline
- Adicionar testes de integracao com mocks de storage services
- Expandir cobertura para graph enrichment e compression modules

---

## 2026-01-25 ‚Äî Servi√ßo de Automa√ß√£o de Tribunais

### Contexto
- Criar servi√ßo para integrar o Iudex com tribunais brasileiros (PJe, eproc, e-SAJ)
- Suportar consultas e peticionamento
- Suportar 3 m√©todos de autentica√ß√£o: senha, certificado A1, certificado A3

### Arquivos Criados
- `apps/tribunais/package.json` ‚Äî Configura√ß√£o do pacote
- `apps/tribunais/tsconfig.json` ‚Äî Configura√ß√£o TypeScript
- `apps/tribunais/README.md` ‚Äî Documenta√ß√£o completa da API
- `apps/tribunais/src/index.ts` ‚Äî Entry point do servi√ßo
- `apps/tribunais/src/types/index.ts` ‚Äî Tipos (AuthType, OperationType, etc.)
- `apps/tribunais/src/services/crypto.ts` ‚Äî Criptografia AES-256-GCM para credenciais
- `apps/tribunais/src/services/credentials.ts` ‚Äî Gerenciamento de credenciais
- `apps/tribunais/src/services/tribunal.ts` ‚Äî Opera√ß√µes nos tribunais
- `apps/tribunais/src/api/server.ts` ‚Äî Servidor Express
- `apps/tribunais/src/api/routes.ts` ‚Äî Rotas da API REST
- `apps/tribunais/src/queue/worker.ts` ‚Äî Worker BullMQ para opera√ß√µes ass√≠ncronas
- `apps/tribunais/src/extension/websocket-server.ts` ‚Äî WebSocket para extens√µes Chrome
- `apps/tribunais/src/utils/logger.ts` ‚Äî Logger Winston

### Decis√µes Tomadas
- **Express v5**: Usar helper `getParam()` para lidar com params que podem ser array
- **Certificado A1**: Salvar buffer em arquivo tempor√°rio (tribunais-playwright espera path)
- **BullMQ/Redis**: Fila para opera√ß√µes longas e que requerem intera√ß√£o humana
- **WebSocket**: Comunica√ß√£o bidirecional com extens√£o Chrome para certificados A3
- **Mapeamento de tipos**: Converter entre tipos tribunais-playwright ‚Üî Iudex

### Comandos Executados
- `pnpm build` (tribunais-playwright) ‚Äî OK
- `npx tsc --noEmit` (Iudex/apps/tribunais) ‚Äî OK ap√≥s corre√ß√µes

### Arquitetura
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Frontend (Next.js) ‚Üí Backend (FastAPI) ‚Üí Tribunais  ‚îÇ
‚îÇ                                         ‚îÇ           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ API HTTP ‚îÇ  ‚îÇ WebSocket‚îÇ  ‚îÇ Worker (BullMQ)   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ :3100    ‚îÇ  ‚îÇ :3101    ‚îÇ  ‚îÇ (ass√≠ncrono)      ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ               ‚îÇ
    Cert A1/Senha    Cert A3 (extens√£o Chrome)
    (autom√°tico)     (intera√ß√£o humana)
```

### Pr√≥ximos Passos
- Criar extens√£o Chrome para certificados A3
- Integrar com backend FastAPI do Iudex
- Adicionar testes de integra√ß√£o
- Deploy em produ√ß√£o

---

## 2026-01-25 ‚Äî Anexar Documentos a Casos com Integra√ß√£o RAG/Graph

### Contexto
- Usu√°rio solicitou integra√ß√£o completa de documentos com casos
- Documentos anexados devem ser automaticamente indexados no RAG local e no Grafo de Conhecimento
- Respeitar controle de acesso/escopo existente (multi-tenant)

### Arquivos Alterados (Backend)
- `apps/api/app/models/document.py` ‚Äî Adicionados campos:
  - `case_id` ‚Äî FK para casos
  - `rag_ingested`, `rag_ingested_at`, `rag_scope` ‚Äî Tracking de indexa√ß√£o RAG
  - `graph_ingested`, `graph_ingested_at` ‚Äî Tracking de indexa√ß√£o Graph

- `apps/api/app/api/endpoints/cases.py` ‚Äî Novos endpoints:
  - POST `/{case_id}/documents/upload` ‚Äî Upload direto para caso com auto-ingest√£o
  - GET `/{case_id}/documents` ‚Äî Listar documentos do caso
  - POST `/{case_id}/documents/{doc_id}/attach` ‚Äî Anexar documento existente
  - DELETE `/{case_id}/documents/{doc_id}/detach` ‚Äî Desanexar documento

### Arquivos Criados (Backend)
- `apps/api/alembic/versions/e5b6c7d8f9a0_add_document_case_rag_fields.py` ‚Äî Migration Alembic

### Arquivos Alterados (Frontend)
- `apps/web/src/lib/api-client.ts` ‚Äî Novos m√©todos:
  - `getCaseDocuments()` ‚Äî Buscar documentos do caso
  - `uploadDocumentToCase()` ‚Äî Upload direto com FormData
  - `attachDocumentToCase()` ‚Äî Anexar doc existente
  - `detachDocumentFromCase()` ‚Äî Desanexar documento

- `apps/web/src/app/(dashboard)/cases/[id]/page.tsx` ‚Äî Atualizada tab "Arquivos":
  - Lista documentos com status de indexa√ß√£o RAG/Graph
  - Upload via drag-and-drop ou sele√ß√£o de arquivo
  - Indicadores visuais de status (√≠cones verde/amarelo)
  - Bot√£o para desanexar documento do caso
  - Feedback autom√°tico de progresso

### Funcionalidades Implementadas
- **Upload direto para caso**: Arquivo ‚Üí Caso ‚Üí Auto-ingest√£o RAG local + Graph
- **Background tasks**: Processamento ass√≠ncrono de documentos
- **Status tracking**: Campos booleanos + timestamp para cada etapa de ingest√£o
- **UI responsiva**: Drag-and-drop, loading states, status icons
- **Fallback gracioso**: Se novo endpoint falhar, usa busca por tags (legado)

### Fluxo de Ingest√£o
```
Upload ‚Üí Salvar documento ‚Üí Atualizar case_id ‚Üí
  ‚îú‚îÄ‚îÄ Background: Extrair texto (PDF/DOCX/TXT/HTML)
  ‚îú‚îÄ‚îÄ Background: Ingerir RAG local (rag_ingested=true)
  ‚îî‚îÄ‚îÄ Background: Ingerir Graph Neo4j (graph_ingested=true)
```

### Verifica√ß√£o
- `npx tsc --noEmit` ‚Äî OK (sem erros nos arquivos modificados)
- `npm run lint` ‚Äî Erros pr√©-existentes em outros arquivos, n√£o nos modificados

### Pr√≥ximos Passos
- Implementar polling para atualizar status de ingest√£o em tempo real
- Adicionar op√ß√£o para anexar documentos existentes da biblioteca
- Criar visualiza√ß√£o de progresso de ingest√£o

---

## 2026-01-25 ‚Äî Extra√ß√£o Sem√¢ntica de Entidades via Embeddings + RAG

### Contexto
- Grafo Neo4j j√° tinha estrutura para teses e conceitos, mas extra√ß√£o era apenas regex
- Usu√°rio pediu para usar RAG e embeddings (n√£o LLM) para extra√ß√£o sem√¢ntica
- Implementada extra√ß√£o baseada em embedding similarity:
  - Usa EmbeddingsService existente (OpenAI text-embedding-3-large)
  - Conceitos jur√≠dicos pr√©-definidos como "√¢ncoras" (seeds)
  - Similaridade coseno para encontrar conceitos no texto
  - Rela√ß√µes baseadas em proximidade de embedding

### Arquivos Criados/Alterados
- `apps/api/app/services/rag/core/semantic_extractor.py` ‚Äî Extrator baseado em embeddings
  - **33 conceitos seed**: princ√≠pios, institutos, conceitos doutrin√°rios, teses
  - Usa `EmbeddingsService` (text-embedding-3-large, 3072 dims)
  - Similaridade coseno para matching (threshold: 0.75)
  - Rela√ß√µes entre entidades sem√¢nticas e regex (threshold: 0.6)

- `apps/api/app/services/rag/core/neo4j_mvp.py`:
  - Par√¢metro `semantic_extraction: bool` em `ingest_document()`
  - Integra√ß√£o com extrator de embeddings

- `apps/api/app/api/endpoints/graph.py`:
  - `ENTITY_GROUPS` expandido com tipos sem√¢nticos
  - `SEMANTIC_RELATIONS` expandido

### Conceitos Seed (√Çncoras)
| Categoria | Exemplos |
|-----------|----------|
| Princ√≠pios | Legalidade, Contradit√≥rio, Ampla Defesa, Dignidade |
| Institutos | Prescri√ß√£o, Decad√™ncia, Dano Moral, Tutela Antecipada |
| Conceitos | Boa-F√© Objetiva, Abuso de Direito, Venire Contra Factum |
| Teses | Responsabilidade Objetiva do Estado, Teoria da Perda de Uma Chance |

### Fluxo de Extra√ß√£o
```
Documento ‚Üí Chunks ‚Üí Embedding (text-embedding-3-large)
                          ‚îÇ
                          ‚ñº
              Cosine Similarity com Seeds
                          ‚îÇ
                          ‚ñº
              Match (sim >= 0.75) ‚Üí Entidade Sem√¢ntica
                          ‚îÇ
                          ‚ñº
              Similarity com Entidades Regex ‚Üí Rela√ß√µes
```

### Verifica√ß√£o
- `python -c "from app.services.rag.core.semantic_extractor import get_semantic_extractor, LEGAL_CONCEPT_SEEDS; print(len(LEGAL_CONCEPT_SEEDS))"` ‚Äî OK (33 seeds)

---

## 2026-01-26 ‚Äî Melhorias na P√°gina de Grafos: Sele√ß√£o de Materiais e Pesquisa Lexical

### Contexto
- Usu√°rio solicitou funcionalidades t√≠picas de grafos Neo4j na p√°gina `/graph`
- Objetivo: permitir filtrar o grafo por materiais da biblioteca/casos e pesquisa lexical

### Decis√µes de Design
- **Layout**: Painel lateral esquerdo colaps√°vel (confirmado pelo usu√°rio)
- **Pesquisa lexical**: Sistema de tags simples - digitar e pressionar Enter (confirmado pelo usu√°rio)

### Arquivos Criados

**`apps/web/src/components/graph/GraphMaterialSelector.tsx`**:
- Componente de sele√ß√£o de materiais com 3 abas: Documentos, Casos, Biblioteca
- Checkbox para sele√ß√£o m√∫ltipla
- Busca integrada em cada aba
- Exibe badges com itens selecionados
- Toggle para ativar/desativar filtro por materiais

**`apps/web/src/components/graph/GraphLexicalSearch.tsx`**:
- Componente de pesquisa lexical com sistema de tags
- 3 categorias: Termos/Frases, Dispositivos Legais, Autores/Tribunais
- Badges coloridos por categoria (azul, verde, violeta)
- Seletor de modo de correspond√™ncia: "Qualquer (OU)" vs "Todos (E)"
- Bot√£o para limpar todos os filtros

**`apps/web/src/components/graph/index.ts`**:
- Barrel export para os novos componentes

### Arquivos Alterados

**`apps/web/src/stores/graph-store.ts`**:
- Adicionados campos em `GraphFilters`:
  - `selectedDocuments: string[]`
  - `selectedCases: string[]`
  - `filterByMaterials: boolean`
  - `lexicalTerms: string[]`
  - `lexicalAuthors: string[]`
  - `lexicalDevices: string[]`
  - `lexicalMatchMode: 'all' | 'any'`
- Adicionadas 15+ actions para gerenciar os novos filtros
- Atualizado `selectFilteredNodes` para filtrar por termos lexicais no cliente

**`apps/web/src/app/(dashboard)/graph/GraphPageClient.tsx`**:
- Adicionado painel lateral esquerdo colaps√°vel (w-80)
- Abas "Materiais" e "Lexical" com os novos componentes
- Bot√£o de toggle no header para mostrar/ocultar painel de filtros
- Imports de novos √≠cones (PanelLeftClose, PanelLeft, Filter)

**`apps/web/src/components/layout/sidebar-pro.tsx`**:
- Adicionado link para p√°gina de Grafos (`/graph`) no menu lateral
- √çcone: Network

### Estrutura do Painel de Filtros

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ [Materiais] [Lexical]                   ‚îÇ ‚Üê Abas
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                         ‚îÇ
‚îÇ Aba Materiais:                          ‚îÇ
‚îÇ - Toggle "Filtrar por materiais"        ‚îÇ
‚îÇ - Busca                                 ‚îÇ
‚îÇ - [Docs] [Casos] [Biblioteca]           ‚îÇ
‚îÇ - Lista com checkboxes                  ‚îÇ
‚îÇ - Badges selecionados                   ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ Aba Lexical:                            ‚îÇ
‚îÇ - Termos/Frases [tags + input]          ‚îÇ
‚îÇ - Dispositivos Legais [tags + input]    ‚îÇ
‚îÇ - Autores/Tribunais [tags + input]      ‚îÇ
‚îÇ - Modo: [Qualquer OU] [Todos E]         ‚îÇ
‚îÇ - [Limpar filtros]                      ‚îÇ
‚îÇ                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Verifica√ß√£o
- `npx tsc --noEmit` ‚Äî OK (sem erros de tipo)
- Lint: erros pr√©-existentes em outros arquivos (n√£o relacionados √†s mudan√ßas)

---

## 2026-01-26 ‚Äî Integra√ß√£o Lexical Search com Neo4j Fulltext Index

### Contexto
- Usu√°rio solicitou que a busca lexical fosse ancorada no RAG existente
- A implementa√ß√£o original usava `CONTAINS` (ineficiente)
- Tamb√©m solicitou funcionalidade de inserir fatos do RAG local

### Pesquisa Neo4j
Consultada [documenta√ß√£o oficial do Neo4j](https://neo4j.com/docs/cypher-manual/current/indexes/semantic-indexes/full-text-indexes/):
- √çndices fulltext usam Apache Lucene
- Consulta via `db.index.fulltext.queryNodes(indexName, queryString)`
- Suporta operadores Lucene: AND, OR, aspas para match exato
- Retorna `node` e `score` (relev√¢ncia)

### √çndices Fulltext Existentes no Projeto
O projeto j√° tinha √≠ndices fulltext configurados em `neo4j_mvp.py`:
- `rag_entity_fulltext` ‚Üí Entity (name, entity_id, normalized)
- `rag_chunk_fulltext` ‚Üí Chunk (text_preview)
- `rag_doc_fulltext` ‚Üí Document (title)

### Altera√ß√µes no Backend

**`apps/api/app/api/endpoints/graph.py`**:

1. **Endpoint `/graph/lexical-search`** - Reescrito para usar fulltext index:
   ```python
   CALL db.index.fulltext.queryNodes('rag_entity_fulltext', $lucene_query) YIELD node AS e, score
   WHERE e.entity_type IN $types
   ```
   - Constr√≥i query Lucene com AND/OR baseado no match_mode
   - Escapa caracteres especiais do Lucene
   - Retorna `relevance_score` al√©m de `mention_count`
   - Fallback para CONTAINS se √≠ndice fulltext n√£o dispon√≠vel

2. **Endpoint `/graph/add-from-rag`** - J√° existia com implementa√ß√£o correta:
   - Busca chunks de documentos especificados
   - Extrai entidades com `LegalEntityExtractor.extract()`
   - Usa MERGE para entidades (evita duplicatas)
   - Cria relacionamentos MENTIONS

### Integra√ß√£o Frontend (j√° implementada)

**`apps/web/src/lib/api-client.ts`**:
- `graphLexicalSearch()` - chama `/graph/lexical-search`
- `graphAddFromRAG()` - chama `/graph/add-from-rag`

**`apps/web/src/lib/use-graph.ts`**:
- `useLexicalSearch()` - hook com React Query
- `useAddFromRAG()` - mutation hook

**`apps/web/src/components/graph/GraphLexicalSearch.tsx`**:
- Usa `useLexicalSearch` para buscar entidades
- Exibe resultados com score de relev√¢ncia

### Verifica√ß√£o
- `python3 -m py_compile` ‚Äî OK
- `npx tsc --noEmit` ‚Äî OK

### Fluxo Completo

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Frontend: GraphLexicalSearch                                    ‚îÇ
‚îÇ - Usu√°rio digita termos/dispositivos/autores                    ‚îÇ
‚îÇ - useLexicalSearch() faz chamada √† API                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Backend: /graph/lexical-search                                  ‚îÇ
‚îÇ - Constr√≥i Lucene query string (AND/OR)                         ‚îÇ
‚îÇ - CALL db.index.fulltext.queryNodes('rag_entity_fulltext', ...) ‚îÇ
‚îÇ - Retorna entidades rankeadas por score                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Neo4j: rag_entity_fulltext index                                ‚îÇ
‚îÇ - Indexa: Entity.name, Entity.entity_id, Entity.normalized      ‚îÇ
‚îÇ - Apache Lucene engine                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 2026-02-03 ‚Äî Implementacao dos Gaps 7 e 8 do Office Add-in

### Objetivo
Implementar Gap 7 (UI/UX Feedback de Aplicacao) e Gap 8 (Exportacao de Audit Log) para o Word Add-in.

### Arquivos Criados

**Frontend (apps/office-addin)**:
- `src/components/ui/Toast.tsx` ‚Äî Sistema de notificacoes toast com suporte a success/error/warning/info
  - Componente `Toast` com auto-dismiss
  - `ToastContainer` para renderizar multiplos toasts
  - `useToast` hook para gerenciamento local
  - `toast` object global para uso fora de componentes React
  - `useGlobalToast` hook para conectar ao estado global

- `src/components/ui/Spinner.tsx` ‚Äî Componente de loading spinner com tamanhos xs/sm/md/lg

- `src/api/audit-export.ts` ‚Äî Utilitarios de exportacao de relatorios de auditoria
  - `exportAuditReport()` ‚Äî Funcao principal que gera e baixa o relatorio
  - Suporte a formatos: JSON, CSV (com UTF-8 BOM para Excel), PDF (via HTML/print)
  - Inclui resumo com estatisticas e detalhes de cada redline

### Arquivos Modificados

**Frontend**:
- `src/components/playbook/ClauseCard.tsx`:
  - Adicionado estado de loading por acao (apply/comment/highlight/reject)
  - Feedback visual com spinner durante operacoes
  - Mensagem de erro detalhada com botao "Tentar novamente"
  - Callbacks agora retornam Promise para suportar async

- `src/components/playbook/PlaybookPanel.tsx`:
  - Integrado ToastContainer para feedback global
  - Adicionado dropdown de exportacao (JSON/CSV/PDF)
  - Spinners nos botoes de batch actions
  - Toast notifications para sucesso/erro de operacoes

**Backend (apps/api)**:
- `app/schemas/word_addin.py`:
  - Adicionado `AuditReportSummary` ‚Äî Resumo do relatorio
  - Adicionado `AuditReportRedline` ‚Äî Detalhes de cada redline no relatorio
  - Adicionado `AuditReportResponse` ‚Äî Response completo do audit report

- `app/api/endpoints/word_addin.py`:
  - Adicionado import dos novos schemas
  - Novo endpoint `GET /playbook/run/{playbook_run_id}/audit-report`
  - Retorna relatorio completo com estados de redlines (applied/rejected/pending)

### Verificacao
- `python3 -m py_compile` ‚Äî OK para schemas e endpoints
- `npx tsc --noEmit` ‚Äî OK (sem erros de tipo)

### Funcionalidades Implementadas

**Gap 7 ‚Äî UI/UX Feedback**:
- Spinner durante aplicacao de redlines (individual e batch)
- Toast de sucesso/erro apos cada acao
- Mensagem de erro detalhada no card do redline
- Botao "Tentar novamente" em caso de falha
- Feedback visual nos botoes de batch (Apply All, Comentar tudo, etc)

**Gap 8 ‚Äî Exportacao de Audit Log**:
- Dropdown "Exportar" no header da tela de resultados
- Export JSON com estrutura completa do relatorio
- Export CSV com UTF-8 BOM para compatibilidade com Excel
- Export PDF via HTML que abre dialogo de impressao
- Relatorio inclui: resumo, risk score, status de cada redline, timestamps

---

## 2026-02-12 ‚Äî Corre√ß√£o: Aba de Auditoria sem dados em Transcri√ß√£o

### Resumo
Identificada e corrigida falha no frontend da p√°gina de transcri√ß√£o: para jobs do tipo `apostila`, o estado `auditSummary` n√£o era atualizado ao concluir/carregar job, fazendo a aba de auditoria exibir "Auditoria n√£o dispon√≠vel" mesmo com `audit_summary` gerado no backend.

### Arquivos Modificados
- `apps/web/src/app/(dashboard)/transcription/page.tsx`
  - Passa a definir `setAuditSummary(...)` no fluxo `audit_complete` do SSE.
  - Passa a definir `setAuditSummary(...)` na conclus√£o de job (`handleJobCompletion`) para `apostila`.
  - Passa a definir `setAuditSummary(...)` no carregamento de job (`handleLoadJobResult`) para `apostila`.
  - Limpa `auditSummary` ao iniciar/retomar job e ao trocar tipo de transcri√ß√£o, evitando estado residual.

### Verifica√ß√£o
- `npm run -w @iudex/web type-check` sem erros.

---

## 2026-02-12 ‚Äî Robustez de Jobs Paralelos de Transcri√ß√£o (stale watchdog + isolamento + limites)

### Resumo
Implementados ajustes para reduzir jobs presos em paralelo: reconcilia√ß√£o autom√°tica de jobs √≥rf√£os (`running/queued` sem atividade), isolamento de `TranscriptionService` por job ass√≠ncrono e limites configur√°veis de concorr√™ncia para providers cloud.

### Arquivos Modificados
- `apps/api/app/api/endpoints/transcription.py`
  - Adicionado watchdog de stale jobs (`_reconcile_stale_transcription_job`) com thresholds por status via env:
    - `IUDEX_TRANSCRIPTION_STALE_QUEUED_MINUTES` (default 20)
    - `IUDEX_TRANSCRIPTION_STALE_RUNNING_MINUTES` (default 45)
  - Reconcilia√ß√£o aplicada em:
    - `GET /transcription/jobs`
    - `GET /transcription/jobs/{job_id}`
    - `GET /transcription/jobs/{job_id}/stream`
  - Execu√ß√£o local de jobs ass√≠ncronos alterada para inst√¢ncia dedicada de `TranscriptionService` por job (`job_service = TranscriptionService()`), evitando compartilhamento de estado entre jobs paralelos.
  - Normaliza√ß√£o de status cancelado no stream/cancel (`canceled` e `cancelled`).

- `apps/api/app/services/transcription_service.py`
  - Adicionado lock reentrante (`self._vomo_lock`) para proteger muta√ß√µes de `self.vomo` em cen√°rios concorrentes.
  - `_get_vomo(...)` encapsulado no lock para evitar corrida de configura√ß√£o/modelo/provider.

- `apps/api/app/services/transcription_providers.py`
  - Adicionado parser seguro de concorr√™ncia (`_read_max_concurrency`).
  - Novos limites configur√°veis:
    - `ASSEMBLYAI_MAX_CONCURRENCY` (default 2; `0` = sem limite)
    - `ELEVENLABS_MAX_CONCURRENCY` (default 2; `0` = sem limite)
    - `RUNPOD_MAX_CONCURRENCY` segue configur√°vel (default 5).

- `apps/api/app/workers/tasks/document_tasks.py`
  - Tratamento expl√≠cito de retorno `None` do `TranscriptionService` na task Celery, com erro claro para retry/falha terminal.

- `apps/api/tests/test_transcription_queue.py`
  - Testes atualizados para concorr√™ncia cloud configur√°vel (default AssemblyAI=2) e cen√°rio de `ASSEMBLYAI_MAX_CONCURRENCY=0`.

### Verifica√ß√£o
- `python3 -m py_compile` em:
  - `apps/api/app/api/endpoints/transcription.py`
  - `apps/api/app/services/transcription_service.py`
  - `apps/api/app/services/transcription_providers.py`
  - `apps/api/app/workers/tasks/document_tasks.py`
  - `apps/api/tests/test_transcription_queue.py`
- `pytest -q -o addopts='' tests/test_transcription_queue.py` ‚Üí **12 passed**

---

## 2026-02-12 ‚Äî Destrave Operacional de Job de Transcri√ß√£o Preso

### Resumo
Job de transcri√ß√£o identificado como preso em `58%` no stage `transcription`, sem conclus√£o autom√°tica no UI. Realizado destrave operacional no banco de jobs para liberar a fila e evitar bloqueio visual no frontend.

### Contexto
- Job reportado pelo usu√°rio: `ba396bb-6832-4e60-80f3-281da0f17db0`
- Job encontrado no `jobs.db`: `cba396bb-6832-4e60-80f3-281da0f17db0` (prefixo com `c`)
- Estado antes: `running`, `progress=58`, message `"üéôÔ∏è Transcrevendo... (23min)"`

### A√ß√£o Executada
- Atualiza√ß√£o manual em `apps/api/storage/job_manager/jobs.db`:
  - `status='error'`
  - `progress=100`
  - `stage='error'`
  - `message='Job destravado manualmente: transcri√ß√£o ficou presa em 58%.'`
  - `error='Timeout/stall detectado manualmente em 2026-02-12T23:13Z.'`
- Ap√≥s detectar reescrita autom√°tica para `running`, foi realizado rein√≠cio da API local (`uvicorn`) para encerrar task √≥rf√£ em mem√≥ria e reaplicado o status final de erro.

### Verifica√ß√£o
- Consultas sucessivas no `transcription_jobs` confirmaram persist√™ncia em `error` e aus√™ncia de retorno para `running` ap√≥s o destrave.

---

## 2026-02-12 ‚Äî RAW AssemblyAI: Timestamps 60s + Word-Level End-to-End

### Resumo
Corre√ß√£o completa do fluxo RAW para AssemblyAI: timestamps em janela de 60s no modo RAW, preserva√ß√£o de `words`/`segments` no backend e propaga√ß√£o desses campos at√© o frontend (SSE e payload de jobs), permitindo link de √°udio por palavra.

### Arquivos Modificados
- `apps/api/app/services/transcription_service.py`
  - `_get_timestamp_interval_for_mode` agora inclui `RAW` com intervalo de 60s.
  - `process_file` passou a usar estado local (`transcription_words`/`transcription_segments`) no retorno RAW, removendo depend√™ncia de `_aai_apostila_result` para evitar dados stale.
  - `process_file_with_progress` retorna `segments` no RAW e preenche `words/segments` em caminhos AssemblyAI/ElevenLabs/fallbacks.
  - `_transcribe_with_progress_stream` agora retorna tamb√©m `segments` (quando dispon√≠veis).
- `apps/api/app/api/endpoints/transcription.py`
  - Persist√™ncia de `words`/`segments` em jobs (`words.json`/`segments.json`) via `_write_vomo_job_result`.
  - Reidrata√ß√£o desses campos em `_load_job_result_payload`.
  - SSE single e batch (`/vomo/stream` e `/vomo/batch/stream`) agora enviam `words`/`segments` no evento `complete`.
- `apps/web/src/lib/api-client.ts`
  - `transcribeVomoStream` e `transcribeVomoBatchStream` atualizados para aceitar e repassar `words`/`segments` no `onComplete`.

### Decis√µes
- `RAW` foi tratado como modo com timestamps de baixa frequ√™ncia (60s), alinhado ao objetivo de leitura cont√≠nua com pontos de navega√ß√£o.
- Dados word-level foram propagados no contrato de resposta em vez de depender de estado interno da service.
- Em `RAW` com provider cloud (`assemblyai`/`elevenlabs`/`runpod`), o cache textual foi ignorado para evitar retorno sem metadados `words/segments`.

### Verifica√ß√£o
- `python3 -m py_compile apps/api/app/services/transcription_service.py apps/api/app/api/endpoints/transcription.py` sem erros.
- `npm --prefix apps/web run type-check -- --pretty false` sem erros.

---

<!-- Novas entradas acima desta linha -->

## 2026-02-05 ‚Äî Sess√£o 125: Cria√ß√£o do AskModeToggle

### Objetivo
Criar componente de toggle para alternar entre 3 modos de consulta na p√°gina /ask: auto, edit e answer.

### Arquivos Criados
- apps/web/src/components/ask/ask-mode-toggle.tsx ‚Äî Componente principal (2.6KB)
- apps/web/src/components/ask/ask-mode-toggle.example.tsx ‚Äî Exemplo de uso interativo (2.1KB)
- apps/web/src/components/ask/README.md ‚Äî Documenta√ß√£o completa (1.5KB)

### Arquivos Alterados
- apps/web/src/components/ask/index.ts ‚Äî Adicionadas exporta√ß√µes do componente e tipo QueryMode

### Decis√µes T√©cnicas
- **Padr√£o Segmented Control**: Seguiu padr√£o Tabs do shadcn/ui para consist√™ncia
- **√çcones**: Sparkles (Auto), Edit3 (Editar), MessageSquare (Responder) do lucide-react
- **Tooltips**: TooltipProvider com delay 300ms
- **Responsividade**: Labels ocultas < 640px (sm), apenas √≠cones
- **Acessibilidade**: Roles ARIA (tablist/tab), aria-selected, aria-label
- **Estilo**: Aspas simples conforme padr√£o do projeto

### Funcionalidades
- Toggle entre 3 modos: 'auto' | 'edit' | 'answer'
- Tooltips descritivos em portugu√™s
- Interface adaptativa (mobile = √≠cones, desktop = √≠cones + labels)
- Integra√ß√£o com theme system (dark/light mode)

### Verifica√ß√£o
- ‚úÖ ESLint passou sem erros
- ‚úÖ Padr√µes do projeto seguidos
- ‚úÖ Documenta√ß√£o e exemplo criados

---

## 2026-02-07 ‚Äî Fechamento de Gaps do PLANO_AGENT_SDK_INTEGRATION

### Contexto
An√°lise de conformidade do plano identificou 3 gaps pendentes ap√≥s implementa√ß√£o por subagentes. Todos corrigidos nesta sess√£o.

### Arquivos Alterados

**Gap 1 ‚Äî UI Dropdown de Cita√ß√µes (3‚Üí12 estilos)**
- `apps/web/src/components/dashboard/generator-wizard.tsx`
  - Expandido dropdown de 3 op√ß√µes (forense/hibrido/abnt) para 12 estilos
  - Agrupados por regi√£o: BR, Americano, Europeu, Simples (mesmo padr√£o do minuta-settings-drawer.tsx)
  - Adicionados imports de SelectGroup e SelectLabel do shadcn/ui

**Gap 2 ‚Äî Modelos Faltantes no Registry (7 novos)**
- `apps/web/src/config/models.ts`
  - Adicionados ao ModelId type: gpt-5.2-pro, gpt-5.2-codex, gpt-5.1, gpt-5.1-codex, gpt-5.1-codex-mini, gpt-5-nano
  - Adicionadas entradas completas no MODEL_REGISTRY para cada modelo
- `apps/api/app/services/ai/model_registry.py`
  - Espelhados os mesmos 7 modelos no backend com api_model via env var

**Gap 3 ‚Äî Admin Endpoint de Feature Flags**
- `apps/api/app/api/endpoints/admin_flags.py` (NOVO)
  - GET /admin/feature-flags ‚Äî snapshot completo (protegido por require_role("admin"))
  - POST /admin/feature-flags/override ‚Äî set runtime override
  - DELETE /admin/feature-flags/override ‚Äî remove override
  - POST /admin/feature-flags/clear-overrides ‚Äî limpa todos
- `apps/api/app/api/routes.py`
  - Adicionado import e include_router de admin_flags

### Verifica√ß√£o
- `python3 -m py_compile` ‚Äî OK (admin_flags.py, routes.py, model_registry.py)
- `npx tsc --noEmit` ‚Äî OK (sem erros de tipo)

---
