#!/usr/bin/env python3
"""
Script para processar transcri√ß√µes de aulas usando Gemini via OpenRouter
Formata conforme diretrizes espec√≠ficas para concursos de procuradorias
"""

import os
import sys
import time
import re
import requests
from pathlib import Path
from docx import Document
from typing import List, Optional

# Configura√ß√£o
OPENROUTER_API_KEY = "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"
OPENROUTER_BASE_URL = "https://openrouter.ai/api/v1/chat/completions"
MODEL_NAME = "google/gemini-2.0-flash-001"
MAX_OUTPUT_TOKENS = 65_536
MAX_TOKENS_PER_CHUNK = 800_000  # Deixando margem de seguran√ßa
OUTPUT_DIR = Path('/Users/nicholasjacob/Documents/Aplicativos/Iudex/Aulas_PGM_RJ')

PROMPT_FORMATACAO = """Voc√™ √© um especialista em revis√£o de transcri√ß√µes para concursos de procuradorias. Sua tarefa √© revisar a transcri√ß√£o fornecida de uma aula, corrigindo erros de portugu√™s, erros gramaticais e de pontua√ß√£o, melhorando a formata√ß√£o para facilitar a leitura, e mantendo o conte√∫do original. N√£o resuma, n√£o parafraseie e n√£o adicione informa√ß√µes que n√£o estejam na transcri√ß√£o original. Siga estas diretrizes:

- Mantenha o modo em primeira pessoa
- Corrija erros gramaticais, ortogr√°ficos e de pontua√ß√£o, tornando o texto gramaticalmente correto e claro
- Mantenha todo o conte√∫do original, incluindo ideias, exemplos, explica√ß√µes, pausas, hesita√ß√µes e ideias incompletas, fazendo o uso apropriado de aspas, par√™nteses. N√£o resuma, n√£o omita informa√ß√µes nem altere o significado
- Melhore a formata√ß√£o para facilitar a leitura
- Mantenha todo o conte√∫do original, mas corrija erros da linguagem coloquial para torn√°-la mais clara, did√°tica e leg√≠vel
- Ajuste a linguagem coloquial para um portugu√™s padr√£o, mantendo o significado original
- Elimine v√≠cios da oralidade e g√≠rias
- Preserve a sequ√™ncia exata das falas e ideias apresentadas
- Utilize formata√ß√£o e estrutura com par√°grafos bem definidos, facilitando a leitura e compreens√£o, para melhorar a legibilidade, seguindo o fluxo natural do discurso. Evite par√°grafos longos
- Reproduza fielmente as informa√ß√µes, apenas melhorando a clareza e a legibilidade
- Utilize conectivos necess√°rios para tornar o texto mais fluido. Aplique a pontua√ß√£o devida para deixar o texto coeso e coerente
- Corrija v√≠cios de linguagem, como repeti√ß√µes desnecess√°rias, uso excessivo de adv√©rbios, linguagem vaga ou imprecisa, g√≠rias, express√µes redundantes, e outros erros que afetem a clareza e a efic√°cia da comunica√ß√£o, sem alterar o significado do texto
- Identifique e rotule os diferentes falantes, se existentes, organizando suas falas de forma clara
- Divida a aula em t√≥picos e subt√≥picos para melhor organiza√ß√£o e visualiza√ß√£o do conte√∫do
- Enumere os t√≥picos e subt√≥picos, use negrito quando mais apropriado
- Intercale par√°grafos curtos e longos conforme a ideia neles contida, tornando a leitura menos cansativa
- Seja did√°tico sem perder detalhes e conte√∫do
- USE TEXTO CORRIDO NA MEDIDA DO POSS√çVEL
- **Ao final de cada t√≥pico/cap√≠tulo, sintetize/resume o assunto de forma esquematizada, preferencialmente por tabelas

**Ao final de CADA t√≥pico principal, crie uma tabela de s√≠ntese (EXEMPLIFICATIVO, PODENDO SER COMPOSTO POR OUTROS ELEMENTOS NAS COLUNAS):**

| Conceito/Instituto | Defini√ß√£o | Fundamento Legal | Observa√ß√µes |
|-------------------|-----------|-----------------|-------------|
| [Preencher] | [Resumo] | [Art. X, Lei Y] | [Dicas/Exce√ß√µes] |

Por favor, forne√ßa a vers√£o revisada da transcri√ß√£o, seguindo estritamente as diretrizes acima. Lembre-se: o objetivo √© manter o conte√∫do fiel ao original, melhorando apenas a clareza e legibilidade.

<transcri√ß√£o>
{texto}
</transcri√ß√£o>
"""


def extrair_texto_txt(caminho_arquivo: str) -> str:
    """Extrai texto de um arquivo .txt"""
    with open(caminho_arquivo, 'r', encoding='utf-8') as f:
        return f.read()


def extrair_texto_docx(caminho_arquivo: str) -> str:
    """Extrai texto de um arquivo .docx"""
    try:
        doc = Document(caminho_arquivo)
        texto_completo = []
        
        for paragrafo in doc.paragraphs:
            if paragrafo.text.strip():
                texto_completo.append(paragrafo.text)
        
        return '\n\n'.join(texto_completo)
    except Exception as e:
        raise Exception(f"Erro ao ler arquivo DOCX: {e}")


def dividir_texto_em_chunks(texto: str, max_chars: int = 3_200_000) -> List[str]:
    """
    Divide o texto em chunks para n√£o exceder o limite de tokens do modelo.
    Tenta dividir em pontos naturais (par√°grafos).
    Com ~4 chars por token, 800k tokens = ~3.2M chars
    """
    paragrafos = texto.split('\n\n')
    chunks = []
    chunk_atual = []
    tamanho_atual = 0
    
    for paragrafo in paragrafos:
        tamanho_paragrafo = len(paragrafo)
        
        if tamanho_atual + tamanho_paragrafo > max_chars and chunk_atual:
            chunks.append('\n\n'.join(chunk_atual))
            chunk_atual = [paragrafo]
            tamanho_atual = tamanho_paragrafo
        else:
            chunk_atual.append(paragrafo)
            tamanho_atual += tamanho_paragrafo
    
    if chunk_atual:
        chunks.append('\n\n'.join(chunk_atual))
    
    return chunks


def processar_com_openrouter(texto: str, parte_num: int = 1, total_partes: int = 1) -> str:
    """Processa um chunk de texto com Gemini via OpenRouter"""
    
    # Preparar prompt
    if total_partes > 1:
        contexto_adicional = f"\n\n**IMPORTANTE: Esta √© a PARTE {parte_num} de {total_partes} do documento. Mantenha a numera√ß√£o de t√≥picos cont√≠nua e consistente.**\n\n"
    else:
        contexto_adicional = ""
    
    prompt_completo = PROMPT_FORMATACAO.format(texto=texto) + contexto_adicional
    
    print(f"\n{'='*60}")
    print(f"Processando parte {parte_num}/{total_partes}")
    print(f"Tamanho do texto: {len(texto):,} caracteres")
    print(f"{'='*60}\n")
    
    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json",
        "HTTP-Referer": "https://iudex.app",
        "X-Title": "Iudex Transcription Formatter"
    }
    
    payload = {
        "model": MODEL_NAME,
        "messages": [
            {
                "role": "user",
                "content": prompt_completo
            }
        ],
        "temperature": 0.1,
        "max_tokens": MAX_OUTPUT_TOKENS,
        "top_p": 0.95
    }
    
    try:
        response = requests.post(
            OPENROUTER_BASE_URL,
            headers=headers,
            json=payload,
            timeout=600  # 10 minutos de timeout
        )
        response.raise_for_status()
        
        result = response.json()
        return result['choices'][0]['message']['content']
        
    except requests.exceptions.RequestException as e:
        print(f"‚ö†Ô∏è  Erro na requisi√ß√£o: {e}")
        if hasattr(e, 'response') and e.response:
            print(f"   Resposta: {e.response.text}")
        raise


def salvar_resultado(texto: str, nome_arquivo: str) -> Path:
    """Salva o resultado em um arquivo .docx"""
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    doc = Document()
    
    for paragrafo in texto.split('\n'):
        if paragrafo.strip():
            p = doc.add_paragraph(paragrafo)
    
    caminho_saida = OUTPUT_DIR / nome_arquivo
    doc.save(str(caminho_saida))
    
    return caminho_saida


def salvar_resultado_markdown(texto: str, nome_arquivo: str) -> Path:
    """Salva o resultado em um arquivo .md"""
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    caminho_saida = OUTPUT_DIR / nome_arquivo
    with open(caminho_saida, 'w', encoding='utf-8') as f:
        f.write(texto)
    
    return caminho_saida


def main():
    """Fun√ß√£o principal"""
    
    # Caminho do arquivo de entrada
    if len(sys.argv) > 1:
        arquivo_entrada = Path(sys.argv[1])
    else:
        arquivo_entrada = Path('/Users/nicholasjacob/Documents/Aplicativos/Iudex/Aulas_PGM_RJ/Administrativo.txt')
    
    if not arquivo_entrada.exists():
        print(f"‚ùå Arquivo n√£o encontrado: {arquivo_entrada}")
        return
    
    print("üìÑ Extraindo texto do documento...")
    
    if arquivo_entrada.suffix == '.docx':
        texto_original = extrair_texto_docx(str(arquivo_entrada))
    else:
        texto_original = extrair_texto_txt(str(arquivo_entrada))
    
    print(f"‚úÖ Texto extra√≠do: {len(texto_original):,} caracteres")
    print(f"   Estimativa: ~{len(texto_original)//4:,} tokens")
    
    # Dividir em chunks se necess√°rio
    chunks = dividir_texto_em_chunks(texto_original)
    print(f"\nüìä Documento dividido em {len(chunks)} parte(s)")
    
    # Processar cada chunk
    resultados = []
    
    for i, chunk in enumerate(chunks, 1):
        print(f"\nüîÑ Processando parte {i}/{len(chunks)}...")
        
        try:
            resultado = processar_com_openrouter(
                texto=chunk,
                parte_num=i,
                total_partes=len(chunks)
            )
            resultados.append(resultado)
            
            print(f"‚úÖ Parte {i} processada com sucesso")
            
            if i < len(chunks):
                print("‚è≥ Aguardando 2 segundos...")
                time.sleep(2)
                
        except Exception as e:
            print(f"‚ùå Erro ao processar parte {i}: {e}")
            print(f"   Continuando com as partes restantes...")
            continue
    
    # Combinar resultados
    texto_final = '\n\n---\n\n'.join(resultados)
    
    # Salvar resultados
    print("\nüíæ Salvando resultados...")
    
    nome_base = arquivo_entrada.stem
    
    # Salvar em Markdown
    arquivo_md = salvar_resultado_markdown(
        texto_final,
        f'{nome_base}_GEMINI_Formatado.md'
    )
    print(f"‚úÖ Markdown salvo: {arquivo_md}")
    
    # Salvar em DOCX
    try:
        arquivo_docx = salvar_resultado(
            texto_final,
            f'{nome_base}_GEMINI_Formatado.docx'
        )
        print(f"‚úÖ DOCX salvo: {arquivo_docx}")
    except Exception as e:
        print(f"‚ö†Ô∏è  Erro ao salvar DOCX: {e}")
    
    print("\n" + "="*60)
    print("üéâ PROCESSAMENTO CONCLU√çDO!")
    print(f"   Total de partes processadas: {len(resultados)}/{len(chunks)}")
    print(f"   Tamanho final: {len(texto_final):,} caracteres")
    print("="*60)


if __name__ == '__main__':
    main()
