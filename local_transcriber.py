import os
import subprocess
import textwrap
from faster_whisper import WhisperModel
from openai import OpenAI
from tqdm import tqdm
import time

# ================= CONFIGURA√á√ïES =================

INPUT_FOLDER = "Aulas_PGM_RJ"

# Faster-Whisper Local (Otimizado)
WHISPER_MODEL = "medium"  # medium = bom balan√ßo velocidade/qualidade
COMPUTE_TYPE = "int8"     # int8 = muito mais r√°pido
DEVICE = "cpu"            # Mac usa CPU

# OpenAI para formata√ß√£o (mant√©m qualidade premium)
API_KEY = "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"
MODELO_GPT = "gpt-4o"

SYSTEM_PROMPT = """
VOC√ä √â UM REVISOR DE TEXTO JUR√çDICO DE ELITE.
SUA MISS√ÉO: Formatar a transcri√ß√£o bruta abaixo em um texto de estudo (formato apostila).

REGRAS INEGOCI√ÅVEIS:
1. INTEGRIDADE TOTAL: N√£o resuma. N√£o remova explica√ß√µes. Mantenha 100% do conte√∫do t√©cnico.
2. ESTILO: Transforme a fala coloquial em norma culta. Ajuste concord√¢ncias.
3. VISUAL: Use par√°grafos claros. Use **Negrito** para termos jur√≠dicos, leis e princ√≠pios.
4. CITA√á√ïES: Formate refer√™ncias a leis corretamente (Ex: "Art. 5¬∫, inciso LV da CF/88").
5. FLUIDEZ: Remova v√≠cios de linguagem (n√©, tipo, √£hn) que sujem o texto, mas mantenha o racioc√≠nio.

Entrada: Transcri√ß√£o bruta de fala.
Sa√≠da: Texto did√°tico, denso e completo.
"""

# ================= FUN√á√ïES =================

def extract_audio(video_path):
    """Extrai √°udio otimizado para Whisper"""
    audio_path = os.path.splitext(video_path)[0] + ".mp3"
    if os.path.exists(audio_path):
        return audio_path
    
    print(f"‚ö° Extraindo √°udio de {os.path.basename(video_path)}...")
    subprocess.run(
        f'ffmpeg -i "{video_path}" -vn -ac 1 -ar 16000 -b:a 64k "{audio_path}" -y -hide_banner -loglevel error',
        shell=True, check=True
    )
    return audio_path

def transcribe_local_optimized(audio_path):
    """Transcreve localmente com Faster-Whisper + VAD"""
    print(f"üöÄ Transcrevendo com Faster-Whisper LOCAL")
    print(f"   Modelo: {WHISPER_MODEL} | Device: {DEVICE} | Compute: {COMPUTE_TYPE}")
    
    start = time.time()
    
    # Carrega modelo otimizado
    model = WhisperModel(WHISPER_MODEL, device=DEVICE, compute_type=COMPUTE_TYPE)
    
    # Transcreve com VAD (pula sil√™ncios = muito mais r√°pido!)
    segments, info = model.transcribe(
        audio_path,
        beam_size=5,
        language="pt",
        vad_filter=True,  # CRUCIAL: pula sil√™ncios
        vad_parameters=dict(min_silence_duration_ms=500)
    )
    
    print(f"   Idioma: {info.language} (confian√ßa: {info.language_probability:.2f})")
    print(f"   Dura√ß√£o: {info.duration:.1f}s")
    
    # Coleta texto com progresso
    text_segments = []
    with tqdm(total=int(info.duration), unit="s", desc="Transcrevendo") as pbar:
        last_pos = 0
        for segment in segments:
            text_segments.append(segment.text)
            current_pos = int(segment.end)
            pbar.update(current_pos - last_pos)
            last_pos = current_pos
    
    full_text = " ".join(text_segments)
    
    elapsed = (time.time() - start) / 60
    print(f"   ‚úÖ Conclu√≠do em {elapsed:.1f} minutos")
    
    return full_text

def format_with_gpt(full_text, client):
    """Formata usando GPT-4o"""
    print(f"üß† Formatando com {MODELO_GPT}...")
    
    chunks = textwrap.wrap(full_text, 15000, break_long_words=False, replace_whitespace=False)
    print(f"   Dividido em {len(chunks)} partes")
    
    formatted_chunks = []
    for i, chunk in enumerate(tqdm(chunks, desc="Formatando")):
        try:
            response = client.chat.completions.create(
                model=MODELO_GPT,
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": chunk}
                ],
                temperature=0.2
            )
            formatted_chunks.append(response.choices[0].message.content)
        except Exception as e:
            print(f"Erro na parte {i}: {e}")
            formatted_chunks.append(chunk)
    
    return "\n\n".join(formatted_chunks)

def main():
    if not os.path.exists(INPUT_FOLDER):
        print(f"Pasta {INPUT_FOLDER} n√£o encontrada.")
        return
    
    files = sorted([f for f in os.listdir(INPUT_FOLDER) if f.endswith(('.mp4', '.mkv'))])
    client = OpenAI(api_key=API_KEY)
    
    print(f"üî• MODO: Faster-Whisper LOCAL + GPT-4o")
    print(f"   Sem custos de transcri√ß√£o!")
    print(f"   Processamento 100% offline\n")
    
    for filename in files:
        video_path = os.path.join(INPUT_FOLDER, filename)
        base_name = os.path.splitext(filename)[0]
        final_file = os.path.join(INPUT_FOLDER, f"{base_name}_APOSTILA.md")
        
        if os.path.exists(final_file):
            print(f"‚è© Pulando {filename} (j√° processado)")
            continue
        
        print(f"\n{'='*60}")
        print(f"üé¨ {filename}")
        
        start_time = time.time()
        
        # 1. Extra√ß√£o de √°udio
        audio_path = extract_audio(video_path)
        
        # 2. Transcri√ß√£o local (cache check)
        raw_txt = os.path.join(INPUT_FOLDER, f"{base_name}_RAW.txt")
        if os.path.exists(raw_txt):
            print("   üìÇ Usando transcri√ß√£o em cache")
            with open(raw_txt, 'r', encoding='utf-8') as f:
                full_text = f.read()
        else:
            full_text = transcribe_local_optimized(audio_path)
            with open(raw_txt, 'w', encoding='utf-8') as f:
                f.write(full_text)
        
        # 3. Formata√ß√£o GPT
        final_text = format_with_gpt(full_text, client)
        
        # 4. Salvar
        with open(final_file, 'w', encoding='utf-8') as f:
            f.write(f"# {base_name}\n\n{final_text}")
        
        elapsed = (time.time() - start_time) / 60
        print(f"‚ú® CONCLU√çDO em {elapsed:.1f} minutos!")
        print(f"   üìÑ {final_file}")

if __name__ == "__main__":
    main()
