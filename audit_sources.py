#!/usr/bin/env python3
"""
audit_sources.py - Source Attribution Auditor (v1.0)

Detecta problemas de atribui√ß√£o de autoria ANTES da formata√ß√£o final.
Foco em cursos "focados na banca" onde atribui√ß√£o correta √© cr√≠tica.
"""

import os
import re
from google import genai
from google.genai import types

PROMPT_AUDITORIA_FONTES = """
# AUDITORIA DE ATRIBUI√á√ÉO DE FONTES (v1.0)

Voc√™ √© um auditor especializado em **consist√™ncia de fontes acad√™micas**.

## CONTEXTO
Este √© um curso preparat√≥rio focado em "conhecer a banca examinadora".
√â CR√çTICO que as opini√µes, teses e posicionamentos sejam atribu√≠dos aos autores/examinadores CORRETOS.

## SUA TAREFA
Analise o texto formatado comparando com a transcri√ß√£o RAW e identifique:

### 1. üî¥ ERROS DE ATRIBUI√á√ÉO (CR√çTICO)
- Teses atribu√≠das ao autor/examinador errado
- Cita√ß√µes de artigos atribu√≠das √† pessoa incorreta
- Confus√£o entre "o professor disse" vs "o autor X afirma"
- Mistura de opini√µes de diferentes examinadores

**EXEMPLO DE ERRO:**
```
RAW: "O examinador Felipe Silvestre, em seu artigo, defende que..."
FORMATADO: "O procurador Gustavo da Gama defende que..."
‚ùå ERRO: Tese de Felipe atribu√≠da a Gustavo
```

### 2. ‚ö†Ô∏è AMBIGUIDADE DE FONTE
- Uso de "o examinador" quando h√° m√∫ltiplos examinadores
- "O autor" sem especificar qual autor
- Pronomes que geram d√∫vida sobre quem est√° falando

### 3. üìö INCONSIST√äNCIA BIBLIOGR√ÅFICA
- Artigo mencionado no RAW mas autor n√£o citado no formatado
- Nome do examinador mudado (ex: "Felipe" ‚Üí "Gustavo")
- Casos pr√°ticos atribu√≠dos ao examinador errado

## REGRAS DE AN√ÅLISE
‚úÖ N√ÉO marque como erro se:
   - A ordem das informa√ß√µes mudou (mas o autor est√° correto)
   - Houve par√°frase mantendo a autoria correta
   
‚ùå MARQUE como erro se:
   - A autoria foi TROCADA ou OMITIDA
   - Um caso/exemplo foi atribu√≠do ao autor errado
   - H√° confus√£o entre m√∫ltiplos examinadores/autores

## FORMATO DE RESPOSTA (JSON)

Retorne APENAS o JSON (sem markdown):

{{
  "aprovado": true/false,
  "nota_consistencia": 0-10,
  "erros_criticos": [
    {{
      "tipo": "troca_autoria",
      "localizacao": "Se√ß√£o X, par√°grafo Y",
      "trecho_formatado": "Gustavo da Gama defende...",
      "trecho_raw": "Felipe Silvestre defende...",
      "gravidade": "ALTA",
      "correcao_sugerida": "Atribuir corretamente a Felipe Silvestre"
    }}
  ],
  "ambiguidades": [
    {{
      "localizacao": "Se√ß√£o Z",
      "problema": "Uso de 'o examinador' sem especificar qual",
      "sugestao": "Especificar nome completo"
    }}
  ],
  "observacoes": "Coment√°rios gerais sobre consist√™ncia de fontes"
}}

---

<transcricao_raw>
{raw}
</transcricao_raw>

<texto_formatado>
{formatted}
</texto_formatado>
"""


def auditar_atribuicao_fontes(client, raw_text: str, formatted_text: str, doc_name: str, output_path: str = None):
    """
    Audita consist√™ncia de atribui√ß√£o de fontes/autoria.
    
    Args:
        client: Cliente Gemini
        raw_text: Transcri√ß√£o bruta original
        formatted_text: Texto formatado/apostila
        doc_name: Nome do documento (para contexto)
        output_path: Caminho para salvar relat√≥rio (opcional)
    
    Returns:
        dict: Resultado da auditoria com erros encontrados
    """
    print("üîç Auditando atribui√ß√£o de fontes e autoria...")
    
    prompt = PROMPT_AUDITORIA_FONTES.format(raw=raw_text[:100000], formatted=formatted_text[:100000])
    
    try:
        response = client.models.generate_content(
            model='gemini-3-flash-preview',
            contents=prompt,
            config=types.GenerateContentConfig(
                temperature=0.1,  # Baixa para ser preciso
                max_output_tokens=8000,
                response_mime_type="application/json",  # For√ßa JSON
                thinking_config=types.ThinkingConfig(
                    include_thoughts=False,
                    thinking_level="HIGH"  # Auditoria requer racioc√≠nio profundo
                ),
            )
        )
        
        if response.text:
            import json
            resultado = json.loads(response.text)
            
            # Salvar relat√≥rio se path fornecido
            if output_path:
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(resultado, f, ensure_ascii=False, indent=2)
                print(f"‚úÖ Relat√≥rio de atribui√ß√£o salvo: {output_path}")
            
            # Feedback visual
            if resultado.get('aprovado'):
                print(f"‚úÖ Atribui√ß√£o de fontes: APROVADO (Nota: {resultado.get('nota_consistencia')}/10)")
            else:
                erros = len(resultado.get('erros_criticos', []))
                print(f"‚ö†Ô∏è Atribui√ß√£o de fontes: REQUER ATEN√á√ÉO (Nota: {resultado.get('nota_consistencia')}/10)")
                print(f"   üî¥ {erros} erro(s) cr√≠tico(s) de autoria detectado(s)")
            
            return resultado
        
    except Exception as e:
        print(f"‚ùå Erro na auditoria de fontes: {e}")
        return {
            "aprovado": False,
            "nota_consistencia": 0,
            "erros_criticos": [],
            "erro": str(e)
        }


def gerar_relatorio_markdown(resultado: dict, output_md: str):
    """Gera relat√≥rio leg√≠vel em Markdown para revis√£o HIL."""
    
    with open(output_md, 'w', encoding='utf-8') as f:
        f.write("# üìö RELAT√ìRIO DE AUDITORIA DE FONTES\n\n")
        
        status = "‚úÖ APROVADO" if resultado.get('aprovado') else "‚ö†Ô∏è REQUER REVIS√ÉO"
        nota = resultado.get('nota_consistencia', 0)
        
        f.write(f"**Status:** {status}\n")
        f.write(f"**Nota de Consist√™ncia:** {nota}/10\n\n")
        
        erros = resultado.get('erros_criticos', [])
        if erros:
            f.write(f"## üî¥ ERROS CR√çTICOS DE ATRIBUI√á√ÉO ({len(erros)})\n\n")
            for i, erro in enumerate(erros, 1):
                f.write(f"### {i}. {erro.get('tipo', 'Erro de Atribui√ß√£o')}\n\n")
                f.write(f"**Localiza√ß√£o:** {erro.get('localizacao')}\n\n")
                f.write(f"**Gravidade:** {erro.get('gravidade')}\n\n")
                
                if erro.get('trecho_raw'):
                    f.write(f"**RAW (Original):**\n```\n{erro['trecho_raw']}\n```\n\n")
                
                if erro.get('trecho_formatado'):
                    f.write(f"**Formatado (Com Erro):**\n```\n{erro['trecho_formatado']}\n```\n\n")
                
                if erro.get('correcao_sugerida'):
                    f.write(f"**Corre√ß√£o Sugerida:** {erro['correcao_sugerida']}\n\n")
                
                f.write("---\n\n")
        
        ambiguidades = resultado.get('ambiguidades', [])
        if ambiguidades:
            f.write(f"## ‚ö†Ô∏è AMBIGUIDADES ({len(ambiguidades)})\n\n")
            for amb in ambiguidades:
                f.write(f"- **{amb.get('localizacao')}**: {amb.get('problema')}\n")
                f.write(f"  *Sugest√£o:* {amb.get('sugestao')}\n\n")
        
        obs = resultado.get('observacoes')
        if obs:
            f.write(f"## üí¨ Observa√ß√µes Gerais\n\n{obs}\n")
    
    print(f"üìÑ Relat√≥rio markdown salvo: {output_md}")


if __name__ == "__main__":
    import sys
    import logging
    
    logging.basicConfig(level=logging.INFO)
    
    if len(sys.argv) < 3:
        print("Uso: python audit_sources.py <raw.txt> <formatted.md>")
        sys.exit(1)
    
    raw_path = sys.argv[1]
    formatted_path = sys.argv[2]
    
    # Configura√ß√£o b√°sica Gemini
    project_id = os.getenv("GOOGLE_CLOUD_PROJECT", "gen-lang-client-0727883752")
    client = genai.Client(vertexai=True, project=project_id, location="global")
    
    with open(raw_path, 'r', encoding='utf-8') as f:
        raw = f.read()
    
    with open(formatted_path, 'r', encoding='utf-8') as f:
        formatted = f.read()
    
    doc_name = os.path.basename(formatted_path).replace('.md', '')
    json_output = f"{doc_name}_AUDITORIA_FONTES.json"
    md_output = f"{doc_name}_AUDITORIA_FONTES.md"
    
    resultado = auditar_atribuicao_fontes(client, raw, formatted, doc_name, json_output)
    gerar_relatorio_markdown(resultado, md_output)
