"""
Orquestrador de m√∫ltiplos agentes de IA
Sistema que coordena Claude, Gemini e GPT trabalhando juntos
"""

from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from loguru import logger

from app.services.ai.agents import ClaudeAgent, GeminiAgent, GPTAgent
from app.services.ai.base_agent import AgentResponse, AgentReview


@dataclass
class MultiAgentResult:
    """Resultado do processamento multi-agente"""
    final_content: str
    reviews: List[AgentReview]
    consensus: bool
    conflicts: List[str]
    total_tokens: int
    total_cost: float
    processing_time_seconds: float
    metadata: Dict[str, Any]


class MultiAgentOrchestrator:
    """
    Orquestrador que coordena m√∫ltiplos agentes de IA
    
    Fluxo:
    1. Claude gera o documento inicial
    2. Gemini revisa precis√£o jur√≠dica
    3. GPT revisa qualidade textual
    4. Orquestrador consolida feedback
    5. Claude aplica corre√ß√µes (se necess√°rio)
    6. Retorna documento final
    """
    
    def __init__(self):
        logger.info("Inicializando Multi-Agent Orchestrator")
        
        self.claude = ClaudeAgent()
        self.gemini = GeminiAgent()
        self.gpt = GPTAgent()
        
        self.agents = {
            "generator": self.claude,
            "legal_reviewer": self.gemini,
            "text_reviewer": self.gpt
        }
        
        logger.info("‚úÖ Todos os agentes inicializados")
    
    async def generate_document(
        self,
        prompt: str,
        context: Dict[str, Any],
        effort_level: int = 3
    ) -> MultiAgentResult:
        """
        Gera documento com n√≠vel de esfor√ßo vari√°vel
        
        N√≠veis de esfor√ßo:
        1-2: Apenas Claude (r√°pido)
        3: Claude + revis√£o r√°pida
        4-5: Fluxo completo multi-agente com m√∫ltiplas itera√ß√µes
        """
        import time
        start_time = time.time()
        
        logger.info(f"üöÄ Iniciando gera√ß√£o de documento - N√≠vel de esfor√ßo: {effort_level}")
        
        total_tokens = 0
        total_cost = 0.0
        reviews: List[AgentReview] = []
        conflicts: List[str] = []
        
        try:
            # Fase 1: Gera√ß√£o inicial (Claude)
            logger.info("üìù Fase 1: Gera√ß√£o inicial com Claude...")
            initial_response = await self.claude.generate(prompt, context)
            current_content = initial_response.content
            total_tokens += initial_response.tokens_used
            total_cost += initial_response.cost
            
            logger.info(f"‚úÖ Documento inicial gerado ({len(current_content)} caracteres)")
            
            # N√≠vel baixo: retornar direto
            if effort_level <= 2:
                logger.info("‚ö° N√≠vel de esfor√ßo baixo - Retornando documento inicial")
                processing_time = time.time() - start_time
                
                return MultiAgentResult(
                    final_content=current_content,
                    reviews=reviews,
                    consensus=True,
                    conflicts=conflicts,
                    total_tokens=total_tokens,
                    total_cost=total_cost,
                    processing_time_seconds=processing_time,
                    metadata={
                        "effort_level": effort_level,
                        "iterations": 1,
                        "agents_used": ["claude"]
                    }
                )
            
            # Fase 2: Revis√£o jur√≠dica (Gemini)
            logger.info("‚öñÔ∏è Fase 2: Revis√£o jur√≠dica com Gemini...")
            legal_review = await self.gemini.review(
                current_content,
                context,
                criteria=[
                    "Precis√£o de cita√ß√µes legais",
                    "Fundamenta√ß√£o jur√≠dica adequada",
                    "Atualiza√ß√£o da legisla√ß√£o",
                    "Coer√™ncia dos argumentos"
                ]
            )
            reviews.append(legal_review)
            total_tokens += legal_review.metadata.get("tokens_used", 1000)
            total_cost += 0.02  # Custo estimado de revis√£o
            
            logger.info(f"‚úÖ Revis√£o jur√≠dica conclu√≠da - Score: {legal_review.score}/10, Aprovado: {legal_review.approved}")
            
            # Fase 3: Revis√£o textual (GPT)
            logger.info("‚úçÔ∏è Fase 3: Revis√£o textual com GPT...")
            text_review = await self.gpt.review(
                current_content,
                context,
                criteria=[
                    "Gram√°tica e ortografia",
                    "Clareza e objetividade",
                    "Coes√£o textual",
                    "Estilo adequado"
                ]
            )
            reviews.append(text_review)
            total_tokens += text_review.metadata.get("tokens_used", 1000)
            total_cost += 0.03  # Custo estimado de revis√£o
            
            logger.info(f"‚úÖ Revis√£o textual conclu√≠da - Score: {text_review.score}/10, Aprovado: {text_review.approved}")
            
            # Fase 4: Verificar consenso e conflitos
            logger.info("üîç Fase 4: Verificando consenso...")
            consensus = legal_review.approved and text_review.approved
            avg_score = (legal_review.score + text_review.score) / 2
            
            if not consensus:
                conflicts.append(f"Revisores n√£o chegaram a consenso (m√©dia: {avg_score:.1f}/10)")
            
            # Fase 5: Aplicar corre√ß√µes (se esfor√ßo alto e necess√°rio)
            if effort_level >= 4 and (not consensus or avg_score < 8.0):
                logger.info("üîß Fase 5: Aplicando corre√ß√µes com Claude...")
                
                correction_prompt = f"""Com base nas revis√µes abaixo, melhore o documento original:

DOCUMENTO ORIGINAL:
{current_content}

REVIS√ÉO JUR√çDICA (Score: {legal_review.score}/10):
{legal_review.suggested_changes}

REVIS√ÉO TEXTUAL (Score: {text_review.score}/10):
{text_review.suggested_changes}

Aplique as corre√ß√µes sugeridas mantendo a ess√™ncia do documento e gere a vers√£o final aprimorada.
"""
                
                final_response = await self.claude.generate(correction_prompt, context)
                current_content = final_response.content
                total_tokens += final_response.tokens_used
                total_cost += final_response.cost
                
                logger.info("‚úÖ Corre√ß√µes aplicadas - Documento final gerado")
            
            processing_time = time.time() - start_time
            
            logger.info(f"""
üéâ Gera√ß√£o conclu√≠da!
   Tempo: {processing_time:.2f}s
   Tokens: {total_tokens:,}
   Custo: R$ {total_cost:.4f}
   Consenso: {'‚úÖ' if consensus else '‚ùå'}
   Score m√©dio: {avg_score:.1f}/10
""")
            
            return MultiAgentResult(
                final_content=current_content,
                reviews=reviews,
                consensus=consensus,
                conflicts=conflicts,
                total_tokens=total_tokens,
                total_cost=total_cost,
                processing_time_seconds=processing_time,
                metadata={
                    "effort_level": effort_level,
                    "iterations": 2 if effort_level >= 4 else 1,
                    "agents_used": ["claude", "gemini", "gpt"],
                    "average_score": avg_score
                }
            )
            
        except Exception as e:
            logger.error(f"‚ùå Erro no orquestrador multi-agente: {e}")
            raise
    
    async def simple_chat(
        self,
        message: str,
        context: Dict[str, Any],
        conversation_history: Optional[List[Dict]] = None
    ) -> AgentResponse:
        """
        Chat simples usando apenas Claude (mais r√°pido)
        """
        logger.info("üí¨ Modo chat - Usando Claude")
        
        # Adicionar hist√≥rico ao contexto se fornecido
        if conversation_history:
            context["conversation_history"] = conversation_history
        
        return await self.claude.generate(message, context)

