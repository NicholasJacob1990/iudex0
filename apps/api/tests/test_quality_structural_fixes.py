"""
Testes de integra√ß√£o para o fluxo de corre√ß√£o estrutural (HIL).
Valida detec√ß√£o e remo√ß√£o de par√°grafos/se√ß√µes duplicados.
"""

import pytest
import sys
import os
import json

# Adiciona o diret√≥rio raiz do projeto ao path para importar auto_fix_apostilas
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', '..')))


class TestStructuralFixesUnit:
    """Testes unit√°rios para fun√ß√µes de corre√ß√£o estrutural."""

    def test_compute_paragraph_fingerprint_deterministic(self):
        """Fingerprint deve ser determin√≠stico para o mesmo texto."""
        from auto_fix_apostilas import compute_paragraph_fingerprint
        
        text = "Este √© um par√°grafo de teste com mais de cinquenta caracteres para ser considerado."
        
        fp1 = compute_paragraph_fingerprint(text)
        fp2 = compute_paragraph_fingerprint(text)
        
        assert fp1 == fp2
        assert len(fp1) == 12  # MD5 truncado para 12 chars

    def test_compute_paragraph_fingerprint_normalized(self):
        """Fingerprint deve normalizar espa√ßos e case."""
        from auto_fix_apostilas import compute_paragraph_fingerprint
        
        text1 = "Este √© um par√°grafo de teste com mais de cinquenta caracteres para ser considerado."
        text2 = "ESTE   √â   UM   PAR√ÅGRAFO   DE   TESTE   COM   MAIS   DE   CINQUENTA   CARACTERES   PARA   SER   CONSIDERADO."
        
        fp1 = compute_paragraph_fingerprint(text1)
        fp2 = compute_paragraph_fingerprint(text2)
        
        assert fp1 == fp2

    def test_analyze_structural_issues_detects_duplicate_paragraphs(self, tmp_path):
        """Deve detectar par√°grafos duplicados no documento."""
        from auto_fix_apostilas import analyze_structural_issues
        
        # Cria conte√∫do com par√°grafo duplicado
        paragraph = "Este √© um par√°grafo longo o suficiente para ser considerado pelo algoritmo de fingerprinting. Ele precisa ter pelo menos cinquenta caracteres."
        content = f"""# Documento de Teste

{paragraph}

Outro par√°grafo diferente aqui.

{paragraph}

Mais um par√°grafo √∫nico.
"""
        
        test_file = tmp_path / "test_doc.md"
        test_file.write_text(content, encoding="utf-8")
        
        issues = analyze_structural_issues(str(test_file))
        
        assert "duplicate_paragraphs" in issues
        assert len(issues["duplicate_paragraphs"]) >= 1
        assert issues["total_issues"] >= 1

    def test_apply_structural_fixes_removes_duplicate(self, tmp_path):
        """Deve remover par√°grafo duplicado quando aprovado."""
        from auto_fix_apostilas import analyze_structural_issues, apply_structural_fixes_to_file
        
        # Cria conte√∫do com par√°grafo duplicado
        paragraph = "Este √© um par√°grafo longo o suficiente para ser considerado pelo algoritmo de fingerprinting. Ele precisa ter pelo menos cinquenta caracteres."
        content = f"""# Documento de Teste

{paragraph}

Outro par√°grafo diferente aqui.

{paragraph}

Mais um par√°grafo √∫nico.
"""
        
        test_file = tmp_path / "test_doc.md"
        test_file.write_text(content, encoding="utf-8")
        
        # Primeiro analisa
        issues = analyze_structural_issues(str(test_file))
        assert len(issues["duplicate_paragraphs"]) >= 1
        
        # Prepara sugest√µes para aplicar
        suggestions = {
            "duplicate_paragraphs": issues["duplicate_paragraphs"],
            "duplicate_sections": [],
        }
        
        # Aplica corre√ß√µes
        result = apply_structural_fixes_to_file(str(test_file), suggestions)
        
        assert len(result["fixes_applied"]) >= 1
        assert "Removed duplicate paragraph" in result["fixes_applied"][0]
        assert result["new_size"] < result["original_size"]

    def test_apply_structural_fixes_no_false_positives(self, tmp_path):
        """N√£o deve remover par√°grafos √∫nicos."""
        from auto_fix_apostilas import apply_structural_fixes_to_file, compute_paragraph_fingerprint
        
        content = """# Documento de Teste

Este √© o primeiro par√°grafo √∫nico com texto suficiente para ser analisado pelo algoritmo.

Este √© o segundo par√°grafo √∫nico com texto completamente diferente do primeiro par√°grafo.

Este √© o terceiro par√°grafo √∫nico com conte√∫do totalmente distinto dos anteriores.
"""
        
        test_file = tmp_path / "test_doc.md"
        test_file.write_text(content, encoding="utf-8")
        
        # Tenta aplicar com fingerprint que n√£o existe no documento
        suggestions = {
            "duplicate_paragraphs": [{"fingerprint": "inexistente1"}],
            "duplicate_sections": [],
        }
        
        result = apply_structural_fixes_to_file(str(test_file), suggestions)
        
        # Nenhuma corre√ß√£o deve ser aplicada
        assert len(result["fixes_applied"]) == 0
        assert result["new_size"] == result["original_size"]

    def test_analyze_structural_issues_detects_table_misplacement(self, tmp_path):
        """Deve detectar tabela de s√≠ntese posicionada na abertura de H2 com subt√≥picos."""
        from auto_fix_apostilas import analyze_structural_issues

        content = """## 1. Tema Central

Introdu√ß√£o curta da se√ß√£o.

#### üìã Quadro-s√≠ntese ‚Äî Tema Central
| Item | Regra |
| --- | --- |
| A | B |

### 1.1. Primeiro Subt√≥pico

Texto do subt√≥pico.
"""
        test_file = tmp_path / "test_table_misplacement.md"
        test_file.write_text(content, encoding="utf-8")

        issues = analyze_structural_issues(str(test_file))

        assert len(issues.get("table_misplacements", [])) >= 1
        first = issues["table_misplacements"][0]
        assert first["strategy"] == "h2_intro_to_section_end"
        assert "Tema Central" in (first.get("section_title") or "")

    def test_apply_structural_fixes_moves_misplaced_table(self, tmp_path):
        """Deve mover a tabela para o fechamento da se√ß√£o quando aprovada."""
        from auto_fix_apostilas import analyze_structural_issues, apply_structural_fixes_to_file

        content = """## 1. Tema Central

Introdu√ß√£o curta da se√ß√£o.

#### üìã Quadro-s√≠ntese ‚Äî Tema Central
| Item | Regra |
| --- | --- |
| A | B |

### 1.1. Primeiro Subt√≥pico

Texto do subt√≥pico.
"""
        test_file = tmp_path / "test_table_move.md"
        test_file.write_text(content, encoding="utf-8")

        issues = analyze_structural_issues(str(test_file))
        assert issues.get("table_misplacements"), "Esperava detectar tabela fora do lugar"

        suggestions = {
            "duplicate_paragraphs": [],
            "duplicate_sections": [],
            "heading_numbering_issues": [],
            "table_misplacements": issues["table_misplacements"],
        }
        result = apply_structural_fixes_to_file(str(test_file), suggestions)
        assert any("Moved misplaced table" in item for item in result["fixes_applied"])

        fixed = test_file.read_text(encoding="utf-8")
        table_pos = fixed.find("#### üìã Quadro-s√≠ntese ‚Äî Tema Central")
        subtopic_pos = fixed.find("### 1.1. Primeiro Subt√≥pico")
        assert table_pos > subtopic_pos

    def test_analyze_structural_issues_detects_heading_semantic_issue(self, tmp_path):
        """Deve sugerir rename quando t√≠tulo de subt√≥pico n√£o condiz com o conte√∫do."""
        from auto_fix_apostilas import analyze_structural_issues

        content = """## 1. Contexto Inicial

Texto introdut√≥rio da se√ß√£o.

### 1.1. Introdu√ß√£o Geral

A responsabilidade subsidi√°ria da administra√ß√£o p√∫blica na terceiriza√ß√£o exige demonstra√ß√£o concreta de culpa in vigilando, com an√°lise dos deveres de fiscaliza√ß√£o e do √¥nus probat√≥rio no Tema 1118 do STF.
Tamb√©m √© necess√°rio diferenciar inadimplemento trabalhista, encargos previdenci√°rios e medidas preventivas previstas na Lei 14.133, com foco em governan√ßa contratual.
"""
        test_file = tmp_path / "test_heading_semantic.md"
        test_file.write_text(content, encoding="utf-8")

        issues = analyze_structural_issues(str(test_file))
        heading_issues = issues.get("heading_semantic_issues", [])
        assert len(heading_issues) >= 1
        first = heading_issues[0]
        assert first.get("type") in {"heading_semantic_mismatch", "parent_child_topic_drift", "near_duplicate_heading"}
        assert first.get("new_title")

    def test_apply_structural_fixes_renames_heading_title(self, tmp_path):
        """Deve renomear t√≠tulo com fix estrutural determin√≠stico."""
        from auto_fix_apostilas import analyze_structural_issues, apply_structural_fixes_to_file

        content = """## 1. Contexto Inicial

Texto introdut√≥rio da se√ß√£o.

### 1.1. Introdu√ß√£o Geral

A responsabilidade subsidi√°ria da administra√ß√£o p√∫blica na terceiriza√ß√£o exige demonstra√ß√£o concreta de culpa in vigilando, com an√°lise dos deveres de fiscaliza√ß√£o e do √¥nus probat√≥rio no Tema 1118 do STF.
Tamb√©m √© necess√°rio diferenciar inadimplemento trabalhista, encargos previdenci√°rios e medidas preventivas previstas na Lei 14.133, com foco em governan√ßa contratual.
"""
        test_file = tmp_path / "test_heading_rename.md"
        test_file.write_text(content, encoding="utf-8")

        analysis = analyze_structural_issues(str(test_file))
        heading_issues = analysis.get("heading_semantic_issues", [])
        assert heading_issues, "Esperava ao menos um heading sem√¢ntico para renomear"

        suggestions = {
            "duplicate_paragraphs": [],
            "duplicate_sections": [],
            "heading_numbering_issues": [],
            "heading_title_updates": [heading_issues[0]],
            "table_misplacements": [],
        }
        result = apply_structural_fixes_to_file(str(test_file), suggestions)
        assert any("Renamed heading" in item for item in result["fixes_applied"])

        fixed = test_file.read_text(encoding="utf-8")
        new_title = str(heading_issues[0].get("new_title") or "").strip()
        assert new_title
        assert new_title in fixed


class TestQualityServiceIntegration:
    """Testes de integra√ß√£o para o QualityService."""

    @pytest.mark.asyncio
    async def test_analyze_and_apply_flow(self):
        """Testa o fluxo completo: an√°lise ‚Üí aprova√ß√£o ‚Üí aplica√ß√£o."""
        from app.services.quality_service import QualityService
        
        service = QualityService()
        
        # Conte√∫do com par√°grafo duplicado
        paragraph = "Este √© um par√°grafo longo o suficiente para ser considerado pelo algoritmo de fingerprinting. Ele precisa ter pelo menos cinquenta caracteres para o c√°lculo do hash MD5."
        content = f"""# Documento de Teste

{paragraph}

Outro par√°grafo diferente aqui com texto √∫nico.

{paragraph}

Mais um par√°grafo √∫nico no final.
"""
        
        # 1. Analisa
        analysis = await service.analyze_structural_issues(
            content=content,
            document_name="test_doc.md"
        )
        
        assert analysis["total_issues"] >= 1
        assert len(analysis["pending_fixes"]) >= 1
        
        # Encontra o fix de par√°grafo duplicado
        para_fix = next(
            (f for f in analysis["pending_fixes"] if f["type"] == "duplicate_paragraph"),
            None
        )
        assert para_fix is not None
        assert para_fix["fingerprint"] is not None
        
        # 2. Aplica apenas o fix aprovado
        result = await service.apply_approved_fixes(
            content=content,
            approved_fix_ids=[para_fix["id"]],
            approved_fixes=[para_fix]
        )
        
        assert result["success"] is True
        assert len(result["fixes_applied"]) >= 1
        assert "Removed duplicate paragraph" in result["fixes_applied"][0]
        
        # Verifica que o conte√∫do foi reduzido
        assert len(result["fixed_content"]) < len(content)
        
        # Verifica que o par√°grafo duplicado foi removido (aparece s√≥ 1x)
        count = result["fixed_content"].count(paragraph)
        assert count == 1

    @pytest.mark.asyncio
    async def test_apply_with_empty_approved_fixes(self):
        """Deve retornar conte√∫do inalterado quando n√£o h√° fixes aprovados."""
        from app.services.quality_service import QualityService
        
        service = QualityService()
        
        content = "# Documento\n\nConte√∫do simples."
        
        result = await service.apply_approved_fixes(
            content=content,
            approved_fix_ids=[],
            approved_fixes=[]
        )
        
        assert result["success"] is True
        assert result["fixed_content"] == content
        assert len(result["fixes_applied"]) == 0

    @pytest.mark.asyncio
    async def test_apply_with_nonexistent_fingerprint(self):
        """Deve retornar conte√∫do inalterado quando fingerprint n√£o existe."""
        from app.services.quality_service import QualityService
        
        service = QualityService()
        
        content = """# Documento de Teste

Este √© um par√°grafo √∫nico com texto suficiente para ser analisado pelo algoritmo.

Outro par√°grafo tamb√©m √∫nico e diferente do primeiro.
"""
        
        # Tenta aplicar com fingerprint inexistente
        result = await service.apply_approved_fixes(
            content=content,
            approved_fix_ids=["dup_para_inexistente123"],
            approved_fixes=[{
                "id": "dup_para_inexistente123",
                "type": "duplicate_paragraph",
                "fingerprint": "inexistente123",
                "description": "Teste",
                "action": "REMOVE",
                "severity": "low"
            }]
        )
        
        assert result["success"] is True
        # Nenhuma corre√ß√£o aplicada
        assert len(result["fixes_applied"]) == 0

    @pytest.mark.asyncio
    async def test_analyze_structural_issues_ai_refines_heading_gray_zone(self, monkeypatch):
        """Em zona cinza, IA pode refinar o new_title sem quebrar o fluxo estrutural."""
        from app.services.quality_service import QualityService

        service = QualityService()

        class _AutoFixStub:
            @staticmethod
            def analyze_structural_issues(*_args, **_kwargs):
                return {
                    "duplicate_sections": [],
                    "duplicate_paragraphs": [],
                    "heading_numbering_issues": [],
                    "heading_semantic_issues": [
                        {
                            "id": "heading_semantic_12",
                            "type": "heading_semantic_mismatch",
                            "heading_line": 3,
                            "heading_level": 3,
                            "old_title": "Introdu√ß√£o Geral",
                            "new_title": "Introdu√ß√£o e Contexto",
                            "old_raw": "1.1. Introdu√ß√£o Geral",
                            "new_raw": "1.1. Introdu√ß√£o e Contexto",
                            "confidence": 0.83,  # gray zone
                            "reason": "Baixa ader√™ncia entre t√≠tulo e conte√∫do.",
                            "action": "RENAME_RECOMMENDED",
                        }
                    ],
                    "table_misplacements": [],
                    "compression_ratio": None,
                    "compression_warning": None,
                    "missing_laws": [],
                    "missing_sumulas": [],
                    "missing_decretos": [],
                    "missing_julgados": [],
                    "total_content_issues": 0,
                    "total_issues": 1,
                }

        monkeypatch.setattr(service, "_get_auto_fix", lambda: _AutoFixStub())
        monkeypatch.setenv("IUDEX_HEADING_RENAME_AI_ENABLED", "true")
        monkeypatch.setenv("IUDEX_HEADING_RENAME_AI_MODEL", "gemini-2.0-flash")

        async def _fake_gemini(_prompt: str, model: str = "gemini-2.0-flash"):
            assert model.startswith("gemini")
            return json.dumps(
                {
                    "decision": "REWRITE",
                    "new_title": "Responsabilidade na Terceiriza√ß√£o",
                    "confidence": 0.91,
                    "reason": "T√≠tulo proposto cobre melhor o n√∫cleo tem√°tico do bloco.",
                }
            )

        monkeypatch.setattr(service, "_call_gemini", _fake_gemini)

        content = """## 1. Tema Central

### 1.1. Introdu√ß√£o Geral

A responsabilidade subsidi√°ria da administra√ß√£o p√∫blica na terceiriza√ß√£o exige demonstra√ß√£o concreta de culpa e fiscaliza√ß√£o contratual.
"""
        analysis = await service.analyze_structural_issues(
            content=content,
            document_name="test_ai_heading.md",
        )

        heading_fix = next((f for f in analysis.get("pending_fixes", []) if f.get("type") == "heading_semantic_mismatch"), None)
        assert heading_fix is not None
        assert heading_fix.get("new_title") == "Responsabilidade na Terceiriza√ß√£o"
        assert heading_fix.get("action") == "RENAME"
        assert heading_fix.get("rename_source") == "hybrid_ai_rewrite"


class TestIDConsistency:
    """Testes para garantir consist√™ncia de IDs entre an√°lise e aplica√ß√£o."""

    @pytest.mark.asyncio
    async def test_section_ids_are_consistent(self):
        """IDs de se√ß√µes duplicadas devem ser consistentes."""
        from app.services.quality_service import QualityService
        
        service = QualityService()
        
        # Conte√∫do com se√ß√£o duplicada
        content = """# Documento

## 1. Introdu√ß√£o

Texto da introdu√ß√£o.

## 2. Desenvolvimento

Texto do desenvolvimento.

## 3. Introdu√ß√£o

Texto duplicado da introdu√ß√£o.

## 4. Conclus√£o

Texto da conclus√£o.
"""
        
        analysis = await service.analyze_structural_issues(
            content=content,
            document_name="test_sections.md"
        )
        
        # Verifica que os IDs s√£o consistentes (dup_section_0, dup_section_1, etc.)
        section_fixes = [f for f in analysis["pending_fixes"] if f["type"] == "duplicate_section"]
        
        for i, fix in enumerate(section_fixes):
            expected_id = f"dup_section_{i}"
            assert fix["id"] == expected_id, f"ID esperado: {expected_id}, obtido: {fix['id']}"

    @pytest.mark.asyncio
    async def test_paragraph_ids_use_fingerprint(self):
        """IDs de par√°grafos duplicados devem usar fingerprint."""
        from app.services.quality_service import QualityService
        
        service = QualityService()
        
        paragraph = "Este √© um par√°grafo longo o suficiente para ser considerado pelo algoritmo de fingerprinting."
        content = f"""# Documento

{paragraph}

Outro texto.

{paragraph}
"""
        
        analysis = await service.analyze_structural_issues(
            content=content,
            document_name="test_paragraphs.md"
        )
        
        para_fixes = [f for f in analysis["pending_fixes"] if f["type"] == "duplicate_paragraph"]
        
        for fix in para_fixes:
            # ID deve conter o fingerprint
            assert fix["id"].startswith("dup_para_")
            assert fix["fingerprint"] is not None
            assert fix["id"].startswith(f"dup_para_{fix['fingerprint']}")
