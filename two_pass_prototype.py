#!/usr/bin/env python3
"""
Two-Pass Formatting Prototype

Pass 1: Format all content without headers, detect discipline boundaries
Pass 2: Generate complete headers for each discipline based on full content
"""
import os
import sys
import re
from openai import OpenAI
from tqdm import tqdm

# Add current directory to path
sys.path.insert(0, os.getcwd())

def smart_chunk(text, max_size=40000):
    """Divide texto respeitando par√°grafos"""
    if len(text) <= max_size:
        return [text]
    
    paragraphs = text.split('\n\n')
    chunks = []
    current = ""
    
    for para in paragraphs:
        if len(current) + len(para) + 2 <= max_size:
            current += para + "\n\n"
        else:
            if current:
                chunks.append(current.strip())
            
            if len(para) > max_size:
                sentences = para.replace('? ', '?|').replace('! ', '!|').replace('. ', '.|').split('|')
                temp = ""
                for sent in sentences:
                    if len(temp) + len(sent) + 1 <= max_size:
                        temp += sent + " "
                    else:
                        if temp:
                            chunks.append(temp.strip())
                        temp = sent + " "
                current = temp
            else:
                current = para + "\n\n"
    
    if current:
        chunks.append(current.strip())
    
    return chunks

def detect_discipline_transition_via_llm(client, chunk_text):
    """Ask LLM if there is a major discipline change in this chunk"""
    prompt = """Analise o texto abaixo e identifique se h√° uma MUDAN√áA DE PROFESSOR ou APRESENTADOR.

    IMPORTANTE: Retorne TRANSITION apenas se houver men√ß√£o expl√≠cita de um NOVO PROFESSOR assumindo a palavra.
    
    Exemplos que devem retornar TRANSITION:
    - "Agora vamos receber a professora Beatriz"
    - "Professor Bruno vai falar agora"
    - "Passando a palavra para o professor X"
    - Apresenta√ß√£o formal de um novo docente
    
    Exemplos que N√ÉO devem retornar TRANSITION:
    - "Agora vamos falar de Direito Administrativo" (mesmo professor mudando de t√≥pico)
    - "Passando para o pr√≥ximo tema"
    - Mudan√ßas de assunto dentro da mesma fala
    
    Se houver mudan√ßa de PROFESSOR, retorne o nome do professor e sua disciplina:
    [TRANSITION: Prof. [Nome] - [Disciplina]]
    
    Se N√ÉO houver mudan√ßa de professor (apenas mudan√ßa de t√≥pico), retorne:
    NO_TRANSITION
    
    Texto para an√°lise:
    """
    
    # Analyze first 15K and last 5K of chunk to catch transitions anywhere
    if len(chunk_text) > 20000:
        analysis_text = chunk_text[:15000] + "\n\n[...]\n\n" + chunk_text[-5000:]
    else:
        analysis_text = chunk_text
    
    prompt = prompt + analysis_text
    
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "Voc√™ √© um detector de t√≥picos jur√≠dicos."},
            {"role": "user", "content": prompt}
        ],
        temperature=0
    )
    
    content = response.choices[0].message.content.strip()
    if "[TRANSITION:" in content:
        return content.split(":")[1].strip().replace("]", "")
    return None

def format_chunk_content_only(client, chunk, chunk_idx, system_prompt_base):
    """Format chunk content WITHOUT headers"""
    # ... existing logic ...

    user_content = f"""[CHUNK {chunk_idx + 1}]
    
    INSTRU√á√ÉO: Formate o conte√∫do abaixo mantendo 100% das informa√ß√µes.
    - N√ÉO fa√ßa resumos.
    - N√ÉO omita exemplos ou hist√≥rias.
    - N√ÉO gere cabe√ßalhos (Summary/Key Takeaways) - apenas o conte√∫do formatado.
    
    TEXTO:
    {chunk}"""
    
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": system_prompt_base},
            {"role": "user", "content": user_content}
        ],
        timeout=180
    )
    
    return response.choices[0].message.content

def generate_discipline_header(client, discipline_name, full_discipline_content):
    """Generate complete Summary/Key Takeaways/Action Items for entire discipline"""
    # Truncate if too long (keep first 20K + last 10K)
    if len(full_discipline_content) > 30000:
        content_sample = full_discipline_content[:20000] + "\n\n[...]\n\n" + full_discipline_content[-10000:]
    else:
        content_sample = full_discipline_content
    
    header_prompt = f"""Analise TODO o conte√∫do abaixo sobre {discipline_name} e gere APENAS:

## Summary
(Par√°grafo √∫nico de 5-8 linhas resumindo TODA a disciplina, incluindo todos os t√≥picos principais abordados)

## Key Takeaways
(Liste 5-10 pontos-chave extra√≠dos de TODO o conte√∫do da disciplina)

## Action Items
(Liste 5-10 tarefas de estudo baseadas em TODO o conte√∫do da disciplina)

---

CONTE√öDO COMPLETO:
{content_sample}"""
    
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "Voc√™ √© um especialista em criar resumos executivos de material jur√≠dico para concursos."},
            {"role": "user", "content": header_prompt}
        ],
        timeout=180
    )
    
    return response.choices[0].message.content

def two_pass_format():
    """Main two-pass formatting logic"""
    # Load API key
    api_key = os.getenv("CHROMA_OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("API key not found")
    
    client = OpenAI(api_key=api_key)
    
    # Load raw transcription
    raw_file = "/Users/nicholasjacob/Documents/Aplicativos/Iudex/Aulas_PGM_RJ/01_Aula_Inaugural_YouTube_RAW.txt"
    with open(raw_file, 'r', encoding='utf-8') as f:
        transcript_text = f.read()
    
    print(f"üìñ Loaded: {len(transcript_text)} chars")
    
    # Chunk
    chunks = smart_chunk(transcript_text, 40000)
    print(f"üì¶ Chunked into {len(chunks)} parts")
    
    # PASS 1: Format content + detect boundaries
    print("\nüîÑ PASS 1: Formatting content and detecting disciplines...")
    formatted_chunks = []
    discipline_boundaries = []  # [(chunk_idx, discipline_name), ...]
    
    system_prompt = """# PAPEL
Voc√™ √© um especialista em Direito Administrativo e reda√ß√£o jur√≠dica, atuando como revisor s√™nior de material did√°tico para concursos de Procuradoria Municipal/Estadual (PGM/PGE).

# MISS√ÉO
Transformar a transcri√ß√£o bruta de uma videoaula em uma **Apostila de Estudo** clara, did√°tica e fiel ao conte√∫do original, mantendo TODO o conhecimento t√©cnico-jur√≠dico.

# DIRETRIZES DE REVIS√ÉO

## 1. PRESERVA√á√ÉO INTEGRAL DE CONTE√öDO (PRIORIDADE ABSOLUTA)

‚ö†Ô∏è **REGRA DE OURO: Se o professor falou, voc√™ DEVE incluir. NUNCA omita nada.**

### O QUE PRESERVAR (100% do conte√∫do):

‚úÖ **TODO conte√∫do t√©cnico-jur√≠dico:**
- Artigos de lei, s√∫mulas, jurisprud√™ncias (com n√∫meros e anos)
- Autores citados (SEMPRE com nome completo)
- Teorias, correntes doutrin√°rias, diverg√™ncias
- Defini√ß√µes t√©cnicas e conceitos (mesmo que pare√ßam b√°sicos)

‚úÖ **TODOS os exemplos e casos:**
- Exemplos pr√°ticos de aplica√ß√£o
- Casos concretos (reais ou hipot√©ticos)
- Hist√≥rias ilustrativas e anedotas do professor
- Exemplos locais e regionais
- Situa√ß√µes do dia-a-dia mencionadas

‚úÖ **TODO contexto e background:**
- Datas, eventos hist√≥ricos, marcos temporais
- Evolu√ß√£o legislativa (antes/depois de mudan√ßas)
- Conjuntura pol√≠tica e econ√¥mica atual
- Not√≠cias e fatos recentes mencionados

‚úÖ **TODAS as observa√ß√µes do professor:**
- Dicas de prova ("cai muito", "aten√ß√£o", "pegadinha")
- Macetes e mnem√¥nicos
- Analogias e compara√ß√µes did√°ticas
- Cr√≠ticas a leis, pr√°ticas ou institui√ß√µes
- Opini√µes e posicionamentos pessoais
- Especula√ß√µes e "apostas" sobre tend√™ncias futuras
- Sugest√µes de estudo complementar

‚úÖ **TODAS as nuances argumentativas:**
- Estrat√©gias para responder quest√µes
- Argumentos defensivos quando n√£o souber a resposta
- Diferentes formas de abordar o mesmo tema
- Ressalvas e exce√ß√µes √†s regras gerais
- Pontos pol√™micos ou controversos

### ‚ùå NUNCA fa√ßa isso:
- ‚ùå Pensar "isso √© √≥bvio" e omitir
- ‚ùå Pensar "isso √© s√≥ uma hist√≥ria" e cortar
- ‚ùå Pensar "isso √© opini√£o pessoal" e remover
- ‚ùå Pensar "isso √© especula√ß√£o" e ignorar
- ‚ùå Pensar "isso √© exemplo local" e descartar
- ‚ùå Resumir exemplos longos em frases gen√©ricas
- ‚ùå Substituir casos concretos por conceitos abstratos
- ‚ùå Cortar detalhes para "economizar espa√ßo"

## 2. Limpeza de Linguagem (SEM perder conte√∫do)
‚úÖ REMOVA:
- V√≠cios de preenchimento: "n√©", "tipo assim", "sabe"
- Repeti√ß√µes acidentais
- Falsos in√≠cios

‚ùå PRESERVE:
- Repeti√ß√µes intencionais para √™nfase
- Todos os exemplos, casos concretos e analogias

## 3. Estrutura e Formata√ß√£o
- Use hierarquia numerada (## 1., ### 1.1)
- Prefira PROSA CONT√çNUA para explica√ß√µes
- Use BULLETS apenas para listas curtas
- Mantenha a ordem cronol√≥gica da aula
"""
    
    for i, chunk in enumerate(tqdm(chunks, desc="Pass 1")):
        # Detect discipline transition via LLM
        disc = detect_discipline_transition_via_llm(client, chunk)
        if disc:
            discipline_boundaries.append((i, disc))
            print(f"\n   ‚úÖ Detected: {disc} at chunk {i+1}")
        
        # Format content
        formatted = format_chunk_content_only(client, chunk, i, system_prompt)
        formatted_chunks.append(formatted)
    
    # Group by discipline
    print(f"\nüìö Detected {len(discipline_boundaries)} disciplines")
    
    if not discipline_boundaries:
        # No disciplines detected, treat as single discipline
        discipline_boundaries = [(0, "Aula Completa")]
    
    # Add end boundary
    discipline_boundaries.append((len(chunks), "END"))
    
    disciples = []
    for i in range(len(discipline_boundaries) - 1):
        start_idx, disc_name = discipline_boundaries[i]
        end_idx, _ = discipline_boundaries[i + 1]
        
        # Collect all formatted chunks for this discipline
        disc_content = "\n\n".join(formatted_chunks[start_idx:end_idx])
        disciples.append((disc_name, disc_content, start_idx))

    # Merge adjacent same-discipline segments
    merged_disciples = []
    if disciples:
        current_name, current_content, current_start = disciples[0]
        
        for next_name, next_content, next_start in disciples[1:]:
            # Normalize names for comparison (ignore case/accents roughly)
            if next_name.lower().strip() in current_name.lower().strip() or current_name.lower().strip() in next_name.lower().strip():
                # Same discipline, merge content
                current_content += "\n\n" + next_content
            else:
                # Different, push current and start new
                merged_disciples.append((current_name, current_content, current_start))
                current_name, current_content, current_start = next_name, next_content, next_start
        
        merged_disciples.append((current_name, current_content, current_start))
    
    # PASS 2: Generate complete headers
    print("\nüéØ PASS 2: Generating complete discipline headers...")
    final_sections = []
    
    for disc_name, disc_content, start_idx in tqdm(merged_disciples, desc="Pass 2"):
        print(f"\n   üìù Generating header for: {disc_name}")
        header = generate_discipline_header(client, disc_name, disc_content)
        
        final_sections.append(f"# {disc_name}\n\n{header}\n\n---\n\n{disc_content}")
    
    # Combine
    final_output = "\n\n".join(final_sections)
    
    # Save
    output_file = "/Users/nicholasjacob/Documents/Aplicativos/Iudex/Aulas_PGM_RJ/01_Aula_Inaugural_YouTube_APOSTILA_V2.md"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(final_output)
    
    print(f"\n‚úÖ Saved to: {output_file}")
    print(f"üìä Output size: {len(final_output)} chars")
    print(f"üìö Disciplines: {len(disciples)}")

if __name__ == "__main__":
    two_pass_format()
