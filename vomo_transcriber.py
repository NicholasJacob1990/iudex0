import os
import subprocess
import textwrap
from concurrent.futures import ThreadPoolExecutor, as_completed
from openai import OpenAI
from tqdm import tqdm
import time

# ================= CONFIGURA√á√ïES =================

INPUT_FOLDER = "Aulas_PGM_RJ"
API_KEY = "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"
MODELO_GPT = "gpt-4o"

# Configura√ß√£o de chunking paralelo (estilo Vomo AI)
CHUNK_DURATION = 300  # 5 minutos por chunk (tamanho ideal para API)
MAX_WORKERS = 4  # N√∫mero de chunks processados simultaneamente

SYSTEM_PROMPT = """
VOC√ä √â UM REVISOR DE TEXTO JUR√çDICO DE ELITE.
SUA MISS√ÉO: Formatar a transcri√ß√£o bruta abaixo em um texto de estudo (formato apostila).

REGRAS INEGOCI√ÅVEIS:
1. INTEGRIDADE TOTAL: N√£o resuma. N√£o remova explica√ß√µes. Mantenha 100% do conte√∫do t√©cnico.
2. ESTILO: Transforme a fala coloquial em norma culta. Ajuste concord√¢ncias.
3. VISUAL: Use par√°grafos claros. Use **Negrito** para termos jur√≠dicos, leis e princ√≠pios.
4. CITA√á√ïES: Formate refer√™ncias a leis corretamente (Ex: "Art. 5¬∫, inciso LV da CF/88").
5. FLUIDEZ: Remova v√≠cios de linguagem (n√©, tipo, √£hn) que sujem o texto, mas mantenha o racioc√≠nio.

Entrada: Transcri√ß√£o bruta de fala.
Sa√≠da: Texto did√°tico, denso e completo.
"""

# ================= FUN√á√ïES =================

def extract_audio(video_path):
    """Extrai √°udio otimizado para Whisper API"""
    audio_path = os.path.splitext(video_path)[0] + ".mp3"
    if os.path.exists(audio_path):
        return audio_path
    
    print(f"‚ö° Extraindo √°udio de {os.path.basename(video_path)}...")
    subprocess.run(
        f'ffmpeg -i "{video_path}" -vn -ac 1 -ar 16000 -b:a 64k "{audio_path}" -y -hide_banner -loglevel error',
        shell=True, check=True
    )
    return audio_path

def split_audio_chunks(audio_path, chunk_duration=CHUNK_DURATION):
    """Divide o √°udio em chunks para processamento paralelo (estilo Vomo)"""
    base_name = os.path.splitext(audio_path)[0]
    chunk_pattern = f"{base_name}_chunk_%03d.mp3"
    
    # Verifica se j√° foi dividido
    existing_chunks = []
    i = 0
    while os.path.exists(f"{base_name}_chunk_{i:03d}.mp3"):
        existing_chunks.append(f"{base_name}_chunk_{i:03d}.mp3")
        i += 1
    
    if existing_chunks:
        return existing_chunks
    
    print(f"‚úÇÔ∏è Dividindo √°udio em chunks de {chunk_duration}s para processamento paralelo...")
    subprocess.run(
        f'ffmpeg -i "{audio_path}" -f segment -segment_time {chunk_duration} -c copy "{chunk_pattern}" -hide_banner -loglevel error',
        shell=True, check=True
    )
    
    # Lista chunks criados
    chunks = []
    i = 0
    while os.path.exists(f"{base_name}_chunk_{i:03d}.mp3"):
        chunks.append(f"{base_name}_chunk_{i:03d}.mp3")
        i += 1
    
    return chunks

def transcribe_chunk_api(chunk_path, index, client):
    """Transcreve um chunk usando API Whisper"""
    try:
        with open(chunk_path, "rb") as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language="pt"
            )
        return index, transcript.text
    except Exception as e:
        print(f"‚ùå Erro no chunk {index}: {e}")
        return index, ""

def transcribe_parallel(audio_path, client):
    """Transcri√ß√£o paralela estilo Vomo AI"""
    print(f"üöÄ TRANSCRI√á√ÉO PARALELA (estilo Vomo AI)")
    
    # 1. Divide em chunks
    chunks = split_audio_chunks(audio_path)
    print(f"   üì¶ {len(chunks)} chunks criados ({CHUNK_DURATION}s cada)")
    
    # 2. Processa chunks em paralelo
    print(f"   ‚ö° Processando {MAX_WORKERS} chunks simultaneamente...")
    results = [None] * len(chunks)
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {
            executor.submit(transcribe_chunk_api, chunk, i, client): i 
            for i, chunk in enumerate(chunks)
        }
        
        with tqdm(total=len(chunks), desc="Chunks processados") as pbar:
            for future in as_completed(futures):
                index, text = future.result()
                results[index] = text
                pbar.update(1)
    
    # 3. Junta os textos na ordem
    full_text = " ".join(results)
    
    # 4. Limpa chunks tempor√°rios
    for chunk in chunks:
        if os.path.exists(chunk):
            os.remove(chunk)
    
    return full_text

def format_with_gpt(full_text, client):
    """Formata usando GPT-4o"""
    print(f"üß† Formatando com {MODELO_GPT}...")
    
    chunks = textwrap.wrap(full_text, 15000, break_long_words=False, replace_whitespace=False)
    print(f"   Dividido em {len(chunks)} partes")
    
    formatted_chunks = []
    for i, chunk in enumerate(tqdm(chunks, desc="Formatando")):
        try:
            response = client.chat.completions.create(
                model=MODELO_GPT,
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": chunk}
                ],
                temperature=0.2
            )
            formatted_chunks.append(response.choices[0].message.content)
        except Exception as e:
            print(f"Erro na parte {i}: {e}")
            formatted_chunks.append(chunk)
    
    return "\n\n".join(formatted_chunks)

def main():
    if not os.path.exists(INPUT_FOLDER):
        print(f"Pasta {INPUT_FOLDER} n√£o encontrada.")
        return
    
    files = sorted([f for f in os.listdir(INPUT_FOLDER) if f.endswith(('.mp4', '.mkv'))])
    client = OpenAI(api_key=API_KEY)
    
    print(f"üî• MODO VOMO: Transcri√ß√£o Paralela")
    print(f"   Workers: {MAX_WORKERS} simult√¢neos")
    print(f"   Chunk: {CHUNK_DURATION}s por peda√ßo\n")
    
    for filename in files:
        video_path = os.path.join(INPUT_FOLDER, filename)
        base_name = os.path.splitext(filename)[0]
        final_file = os.path.join(INPUT_FOLDER, f"{base_name}_APOSTILA.md")
        
        if os.path.exists(final_file):
            print(f"‚è© Pulando {filename} (j√° processado)")
            continue
        
        print(f"\n{'='*60}")
        print(f"üé¨ {filename}")
        
        start_time = time.time()
        
        # 1. Extra√ß√£o de √°udio
        audio_path = extract_audio(video_path)
        
        # 2. Transcri√ß√£o paralela (cache check)
        raw_txt = os.path.join(INPUT_FOLDER, f"{base_name}_RAW.txt")
        if os.path.exists(raw_txt):
            print("   üìÇ Usando transcri√ß√£o em cache")
            with open(raw_txt, 'r', encoding='utf-8') as f:
                full_text = f.read()
        else:
            full_text = transcribe_parallel(audio_path, client)
            with open(raw_txt, 'w', encoding='utf-8') as f:
                f.write(full_text)
        
        # 3. Formata√ß√£o
        final_text = format_with_gpt(full_text, client)
        
        # 4. Salvar
        with open(final_file, 'w', encoding='utf-8') as f:
            f.write(f"# {base_name}\n\n{final_text}")
        
        elapsed = (time.time() - start_time) / 60
        print(f"‚ú® CONCLU√çDO em {elapsed:.1f} minutos!")
        print(f"   üìÑ {final_file}")

if __name__ == "__main__":
    main()
